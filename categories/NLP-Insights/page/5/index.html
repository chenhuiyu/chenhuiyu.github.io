<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>分类 · NLP Insights</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/28/NLP%20Insights/LONGNET.en/">LONGNET - Scaling Transformers to 1,000,000,000 Tokens</a></h2><time class="has-text-grey" datetime="2023-07-28T06:43:10.000Z">2023-07-28</time><p class="is-flex-grow-2 mt-2">LONGNET：将Transformer扩展到10亿个标记在本篇文章中，我们将详细讨论一个近期发布的先进模型——“LongNet”。该模型由微软亚洲研究院研发，于大约两周前正式公布。LongNet基于Transformer模型构建，其核心理念在于拓展Transformer的应用规模。值得一提的是，研究团队成功地将其扩展至处理10亿个令牌的规模。对于熟悉语言模型的人来说，会明白序列长度对模型性能的影响，因为序列长度决定了在执行注意力机制时，能够关联的令牌数量，从而影响模型可以获取的上下文信息长度。例如，我们希望像GPT这样的模型能拥有更长的上下文，使得模型可以参考更久之前的单词来预测下一个令牌。而LongNet就成功地将这个能力扩展到了10亿个令牌。以下图为例，可以清晰看出，GPT的序列长度仅为512，而Po..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/28/NLP%20Insights/LONGNET.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/28/NLP%20Insights/LONGNET.zh-CN/">LONGNET - Scaling Transformers to 1,000,000,000 Tokens</a></h2><time class="has-text-grey" datetime="2023-07-28T06:43:10.000Z">2023-07-28</time><p class="is-flex-grow-2 mt-2">LONGNET：将Transformer扩展到10亿个标记在本篇文章中，我们将详细讨论一个近期发布的先进模型——“LongNet”。该模型由微软亚洲研究院研发，于大约两周前正式公布。LongNet基于Transformer模型构建，其核心理念在于拓展Transformer的应用规模。值得一提的是，研究团队成功地将其扩展至处理10亿个令牌的规模。对于熟悉语言模型的人来说，会明白序列长度对模型性能的影响，因为序列长度决定了在执行注意力机制时，能够关联的令牌数量，从而影响模型可以获取的上下文信息长度。例如，我们希望像GPT这样的模型能拥有更长的上下文，使得模型可以参考更久之前的单词来预测下一个令牌。而LongNet就成功地将这个能力扩展到了10亿个令牌。以下图为例，可以清晰看出，GPT的序列长度仅为512，而Po..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/28/NLP%20Insights/LONGNET.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/Prompt"><i class="tag post-item-tag">Prompt</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/27/NLP%20Insights/Prompt%20Engineering.en/">Prompt Engineering</a></h2><time class="has-text-grey" datetime="2023-07-27T07:44:10.000Z">2023-07-27</time><p class="is-flex-grow-2 mt-2">Prompt EngineeringPrompt Engineering, 也被称为上下文提示，是指在不更新模型权重的情况下，与LLM（语言模型）进行交互以引导其产生期望输出的方法。它是一门实证科学，提示工程方法的效果在不同模型之间可能会有很大的差异，因此需要进行大量的实验和试探。
本文仅关注自回归语言模型的提示工程，不涉及填空测试、图像生成或多模态模型。在本质上，提示工程的目标是实现模型的对齐和可操控性。您可以查阅我之前关于可控文本生成的帖子。
基本提示方法zero-shot学习和few-shot学习是两种最基本的提示模型方法，这些方法由许多LLM论文首创，并且通常用于评估LLM性能。
zero-shot学习zero-shot学习是将任务文本直接输入模型并要求获得结果。
（所有情感分析示例来自于SST-2..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/27/NLP%20Insights/Prompt%20Engineering.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/Prompt"><i class="tag post-item-tag">Prompt</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/27/NLP%20Insights/Prompt%20Engineering.zh-CN/">Prompt Engineering</a></h2><time class="has-text-grey" datetime="2023-07-27T07:44:10.000Z">2023-07-27</time><p class="is-flex-grow-2 mt-2">Prompt EngineeringPrompt Engineering, 也被称为上下文提示，是指在不更新模型权重的情况下，与LLM（语言模型）进行交互以引导其产生期望输出的方法。它是一门实证科学，提示工程方法的效果在不同模型之间可能会有很大的差异，因此需要进行大量的实验和试探。
本文仅关注自回归语言模型的提示工程，不涉及填空测试、图像生成或多模态模型。在本质上，提示工程的目标是实现模型的对齐和可操控性。您可以查阅我之前关于可控文本生成的帖子。
基本提示方法zero-shot学习和few-shot学习是两种最基本的提示模型方法，这些方法由许多LLM论文首创，并且通常用于评估LLM性能。
zero-shot学习zero-shot学习是将任务文本直接输入模型并要求获得结果。
（所有情感分析示例来自于SST-2..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/27/NLP%20Insights/Prompt%20Engineering.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Deep%20Learning"><i class="tag post-item-tag">Deep Learning</i></a><a href="/tags/Gradient%20Descent"><i class="tag post-item-tag">Gradient Descent</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/09/NLP%20Insights/%E8%AF%A6%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95.zh-CN/">详解梯度下降算法</a></h2><time class="has-text-grey" datetime="2023-07-09T04:59:21.000Z">2023-07-09</time><p class="is-flex-grow-2 mt-2">梯度梯度是一个在微积分中使用的重要概念，它用于衡量函数在给定点上的方向导数沿各个方向最大时的最大值。对于一个标量函数，梯度的方向是函数增长最快的方向，而梯度的反方向则是函数减小最快的方向。
定义对于在点$x \in \mathbb{R}^n$可微的函数$f: \mathbb{R}^n \rightarrow \mathbb{R}$，其梯度被定义为一个向量，其各个分量为函数在该点上的偏导数。对于函数$f(x_1, x_2, …, x_n)$，它的梯度可以表示为：
$$\nabla f(x) = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, …, \frac{\partial f}{\partial x_n} \..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/09/NLP%20Insights/%E8%AF%A6%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Deep%20Learning"><i class="tag post-item-tag">Deep Learning</i></a><a href="/tags/Gradient%20Descent"><i class="tag post-item-tag">Gradient Descent</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/09/NLP%20Insights/%E8%AF%A6%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95.en/">详解梯度下降算法</a></h2><time class="has-text-grey" datetime="2023-07-09T04:59:21.000Z">2023-07-09</time><p class="is-flex-grow-2 mt-2">梯度梯度是一个在微积分中使用的重要概念，它用于衡量函数在给定点上的方向导数沿各个方向最大时的最大值。对于一个标量函数，梯度的方向是函数增长最快的方向，而梯度的反方向则是函数减小最快的方向。
定义对于在点$x \in \mathbb{R}^n$可微的函数$f: \mathbb{R}^n \rightarrow \mathbb{R}$，其梯度被定义为一个向量，其各个分量为函数在该点上的偏导数。对于函数$f(x_1, x_2, …, x_n)$，它的梯度可以表示为：
$$\nabla f(x) = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, …, \frac{\partial f}{\partial x_n} \..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/09/NLP%20Insights/%E8%AF%A6%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/DSSM"><i class="tag post-item-tag">DSSM</i></a><a href="/tags/Recommendation"><i class="tag post-item-tag">Recommendation</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/07/NLP%20Insights/DSSM%20%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.en/">DSSM 模型详解</a></h2><time class="has-text-grey" datetime="2023-07-06T18:14:10.000Z">2023-07-07</time><p class="is-flex-grow-2 mt-2">DSSM (Deep Structured Semantic Models) 模型详解一、模型简介DSSM（Deep Structured Semantic Models）是微软提出的一个深度学习模型，用于学习文本的语义表达。DSSM首次在信息检索领域中被提出，用于处理查询-文档匹配任务，但很快被应用到了各种其他场景，如广告点击率预测，推荐系统等。
二、模型结构DSSM模型主要由三个部分构成：

输入层：在这一层，将输入的文本（查询或者文档）转化为词向量。
深度神经网络：输入层之后是一系列全连接层，它们学习输入的语义表示。
输出层：最后，输出层将深度神经网络的输出转化为概率分布，用于表示查询与文档之间的语义匹配度。

三、在推荐系统中的应用DSSM可应用在推荐系统中，它可以学习用户的行为特征与物品特征的语义..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/07/NLP%20Insights/DSSM%20%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/DSSM"><i class="tag post-item-tag">DSSM</i></a><a href="/tags/Recommendation"><i class="tag post-item-tag">Recommendation</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/07/NLP%20Insights/DSSM%20%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.zh-CN/">DSSM 模型详解</a></h2><time class="has-text-grey" datetime="2023-07-06T18:14:10.000Z">2023-07-07</time><p class="is-flex-grow-2 mt-2">DSSM (Deep Structured Semantic Models) 模型详解一、模型简介DSSM（Deep Structured Semantic Models）是微软提出的一个深度学习模型，用于学习文本的语义表达。DSSM首次在信息检索领域中被提出，用于处理查询-文档匹配任务，但很快被应用到了各种其他场景，如广告点击率预测，推荐系统等。
二、模型结构DSSM模型主要由三个部分构成：

输入层：在这一层，将输入的文本（查询或者文档）转化为词向量。
深度神经网络：输入层之后是一系列全连接层，它们学习输入的语义表示。
输出层：最后，输出层将深度神经网络的输出转化为概率分布，用于表示查询与文档之间的语义匹配度。

三、在推荐系统中的应用DSSM可应用在推荐系统中，它可以学习用户的行为特征与物品特征的语义..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/07/NLP%20Insights/DSSM%20%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Recommendation"><i class="tag post-item-tag">Recommendation</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/07/NLP%20Insights/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3.zh-CN/">推荐系统离线评估指标详解</a></h2><time class="has-text-grey" datetime="2023-07-06T17:20:10.000Z">2023-07-07</time><p class="is-flex-grow-2 mt-2">推荐系统离线评估指标详解本文将详细介绍推荐系统中常用的离线评估指标，包括精确率（Precision）、召回率（Recall）、准确率（Accuracy）、F1-Score、NDCG、命中率（Hit Rate）、AUC、GAUC和对数损失（Log Loss）。这些指标对于评估推荐系统的性能和效果至关重要。这些指标对于评估推荐系统的性能和效果至关重要。
在推荐系统中，精确率衡量了推荐列表中真正符合用户兴趣的物品比例，召回率衡量了所有符合用户兴趣的物品中被成功推荐出的比例。准确率用于衡量模型预测结果与实际结果一致的比例。F1-Score综合考虑了精确率和召回率，对模型进行综合评价。NDCG则用于评价推荐系统排序质量，特别适用于考虑元素相关性排序的推荐系统。
我们将为每个指标提供详细的解释和计算公式，并给出Pyth..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/07/NLP%20Insights/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Recommendation"><i class="tag post-item-tag">Recommendation</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/07/NLP%20Insights/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3.en/">推荐系统离线评估指标详解</a></h2><time class="has-text-grey" datetime="2023-07-06T17:20:10.000Z">2023-07-07</time><p class="is-flex-grow-2 mt-2">推荐系统离线评估指标详解本文将详细介绍推荐系统中常用的离线评估指标，包括精确率（Precision）、召回率（Recall）、准确率（Accuracy）、F1-Score、NDCG、命中率（Hit Rate）、AUC、GAUC和对数损失（Log Loss）。这些指标对于评估推荐系统的性能和效果至关重要。这些指标对于评估推荐系统的性能和效果至关重要。
在推荐系统中，精确率衡量了推荐列表中真正符合用户兴趣的物品比例，召回率衡量了所有符合用户兴趣的物品中被成功推荐出的比例。准确率用于衡量模型预测结果与实际结果一致的比例。F1-Score综合考虑了精确率和召回率，对模型进行综合评价。NDCG则用于评价推荐系统排序质量，特别适用于考虑元素相关性排序的推荐系统。
我们将为每个指标提供详细的解释和计算公式，并给出Pyth..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/07/NLP%20Insights/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3.en/">更多</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><a class="extend prev" rel="prev" href="/categories/NLP-Insights/page/4/"><i class="iconfont icon-prev has-text-grey"></i></a><a class="page-number" href="/categories/NLP-Insights/">1</a><span class="space">&hellip;</span><a class="page-number" href="/categories/NLP-Insights/page/3/">3</a><a class="page-number" href="/categories/NLP-Insights/page/4/">4</a><span class="page-number current">5</span></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container categories-widget category-page"><h3>分类</h3><section><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code-Chronicles/">Code Chronicles</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Debugging-Diaries/">Debugging Diaries</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life-Reflections/">Life Reflections</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-Insights/">NLP Insights</a><span class="category-list-count">50</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tech-Toolbox/">Tech Toolbox</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wanderlust-Adventures/">Wanderlust Adventures</a><span class="category-list-count">2</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>