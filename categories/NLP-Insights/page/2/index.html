<!DOCTYPE html><html class="appearance-auto" lang="[&quot;en&quot;]"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Categories Â· NLP Insights</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2/">ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤åœ¨è¿™é‡Œåˆ†äº«ä¸€ä¸‹æˆ‘è¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itæ¨¡å‹å¹¶ä½¿ç”¨vLLMçš„æ­¥éª¤ï¼Œå¸Œæœ›å¯¹å…¶ä»–äººæœ‰æ‰€å¸®åŠ©ã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»å®‰è£…è¿‡ç¨‹ã€ç¯å¢ƒé…ç½®ä»¥åŠå¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ³•ã€‚
å®‰è£…å’ŒéªŒè¯vLLMé¦–å…ˆï¼Œç¡®ä¿å®‰è£…å¹¶éªŒè¯vLLMçš„ç‰ˆæœ¬æ˜¯0.5.3ã€‚

å®‰è£…vLLMï¼š
1pip install vllm==0.5.3

éªŒè¯å®‰è£…ï¼š
123import vllmprint(vllm.__version__)# è¾“å‡º: 0.5.3

å®‰è£…FlashinferæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®‰è£…Flashinferï¼Œå¹¶ç¡®ä¿æ‚¨çš„torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ã€‚

æ£€æŸ¥torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ï¼š
123import torchprint(torch.__version__)  # åº”è¾“å‡º: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL)/"><img class="post-cover-img js-img-fadeIn" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Language%20Modeling"><i class="tag post-item-tag">Language Modeling</i></a><a href="/tags/Perplexity"><i class="tag post-item-tag">Perplexity</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL)/">å¦‚ä½•å‡†ç¡®è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰</a></h2><time class="has-text-grey" datetime="2024-04-17T04:00:00.000Z">2024-04-17</time><p class="is-flex-grow-2 mt-2">å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰å›°æƒ‘åº¦ï¼ˆPPLï¼‰æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹æœ€å¸¸ç”¨çš„æŒ‡æ ‡ä¹‹ä¸€ã€‚åœ¨æ·±å…¥æ¢è®¨ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥æ³¨æ„è¿™ä¸ªæŒ‡æ ‡ç‰¹åˆ«é€‚ç”¨äºä¼ ç»Ÿè¯­è¨€æ¨¡å‹ï¼ˆæœ‰æ—¶è¢«ç§°ä¸ºè‡ªå›å½’æˆ–å› æœè¯­è¨€æ¨¡å‹ï¼‰ï¼Œè€Œå¯¹äºåƒ BERT è¿™æ ·çš„ masked language models åˆ™æ²¡æœ‰æ˜ç¡®å®šä¹‰ï¼ˆè§æ¨¡å‹æ€»ç»“ï¼‰ã€‚
å›°æƒ‘åº¦è¢«å®šä¹‰ä¸ºåºåˆ—çš„æŒ‡æ•°åŒ–å¹³å‡è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ ‡è®°åŒ–åºåˆ— $X = (x_0, x_1, \dots, x_t)$ï¼Œé‚£ä¹ˆ $X$ çš„å›°æƒ‘åº¦ä¸ºï¼Œ
$$\text{PPL}(X) = \exp \left{ -\frac{1}{t}\sum*{i=1}^t \log p\theta (xi|x*{&amp;lt;i}) \right}$$
å…¶ä¸­ $\log p\theta (x_i|x{&amp;lt;i})$ æ˜¯ç¬¬ i ä¸ªæ ‡è®°çš„å¯¹æ•°ä¼¼..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL)/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://gorilla.cs.berkeley.edu/assets/img/blog_post_8_Leaderboard.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs/"><img class="post-cover-img js-img-fadeIn" src="https://gorilla.cs.berkeley.edu/assets/img/blog_post_8_Leaderboard.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/Agent"><i class="tag post-item-tag">Agent</i></a><a href="/tags/Tool%20Use"><i class="tag post-item-tag">Tool Use</i></a><a href="/tags/Gorilla"><i class="tag post-item-tag">Gorilla</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs/">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹</a></h2><time class="has-text-grey" datetime="2024-02-28T07:19:18.000Z">2024-02-28</time><p class="is-flex-grow-2 mt-2">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹ğŸ¦ Gorilla: Large Language Model Connected with Massive APIsLink: https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html

Berkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œBerkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œ
åœ¨çº¿ä½“éªŒæ¨¡å‹ï¼šGorilla OpenFunctions-v2 ç½‘ç»œæ¼”ç¤º
é¡¹ç›®è¯¦æƒ…ï¼šGitHub
æ¨¡å‹ï¼ˆ7B å‚æ•°ï¼‰åœ¨ HuggingFace ä¸Šçš„é¡µé¢ï¼šgorilla-llm/gorilla-openfunctions-v2

1. ä¼¯å…‹åˆ©å‡½æ•°è°ƒç”¨æ’è¡Œæ¦œè‡ª 2022 å¹´åº•ä»¥æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‡­å€Ÿå…¶æ‰§è¡Œé€šç”¨ä»»åŠ¡çš„å¼ºå¤§èƒ½åŠ›ï¼Œæˆä¸ºä¼—äººå…³æ³¨çš„ç„¦ç‚¹ã€‚..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/FastChat"><i class="tag post-item-tag">FastChat</i></a><a href="/tags/Train"><i class="tag post-item-tag">Train</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91/">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘</a></h2><time class="has-text-grey" datetime="2024-02-26T17:43:18.000Z">2024-02-27</time><p class="is-flex-grow-2 mt-2">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘In this article, we delve into the train.py script of FastChat (https://github.com/lm-sys/FastChat) (https://github.com/lm-sys/FastChat/blob/main/fastchat/train/train.py), a key component for training and optimizing large language models (LLMs). FastChat is an advanced open-source pl..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/FastChat"><i class="tag post-item-tag">FastChat</i></a><a href="/tags/Train"><i class="tag post-item-tag">Train</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/27/NLP%20Insights/FastChat%20%E8%AE%AD%E7%BB%83%E8%84%9A%E6%9C%AC%E4%BB%A3%E7%A0%81%E9%80%90%E8%A1%8C%E8%A7%A3%E6%9E%90-Train.py%20%E3%80%90FastChat%20%E7%B3%BB%E5%88%97%E7%AC%AC%201%20%E7%AF%87%E3%80%91/">FastChat è®­ç»ƒè„šæœ¬ä»£ç é€è¡Œè§£æ-Train.py ã€FastChat ç³»åˆ—ç¬¬ 1 ç¯‡ã€‘</a></h2><time class="has-text-grey" datetime="2024-02-26T17:43:18.000Z">2024-02-27</time><p class="is-flex-grow-2 mt-2">FastChat è®­ç»ƒè„šæœ¬ä»£ç é€è¡Œè§£æ-Train.py ã€FastChat ç³»åˆ—ç¬¬ 1 ç¯‡ã€‘åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ FastChat çš„ train.py è„šæœ¬ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè®­ç»ƒå’Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„å…³é”®ç»„ä»¶ã€‚FastChat æ˜¯ä¸€ä¸ªå…ˆè¿›çš„å¼€æºå¹³å°ï¼Œä¸“æ³¨äºå¼€å‘ã€éƒ¨ç½²å’Œè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èŠå¤©æœºå™¨äººã€‚è¯¥å¹³å°ä¸ä»…æä¾›å¯¹é¡¶å°–æ¨¡å‹å¦‚ Vicuna å’Œ MT-Bench çš„æ”¯æŒï¼Œè¿˜åŒ…æ‹¬ä¸€ä¸ªåˆ†å¸ƒå¼çš„å¤šæ¨¡å‹æœåŠ¡ç³»ç»Ÿï¼Œé…å¤‡äº† Web UI å’Œä¸ OpenAI å…¼å®¹çš„ RESTful APIï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé«˜æ•ˆåœ°è®­ç»ƒå’Œè¯„ä¼°ä»–ä»¬çš„æ¨¡å‹ã€‚
æœ¬æ–‡çš„æ·±å…¥åˆ†æå°†èšç„¦äº train.py è„šæœ¬çš„æºä»£ç ã€‚è¿™ä¸ªè„šæœ¬æ˜¯åŸºäº transformers åº“çš„è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹è®­ç»ƒè„šæœ¬ï¼Œæ¶µç›–äº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œä¿å­˜ç­‰å…³é”®æ­¥éª¤ã€‚æˆ‘ä»¬æ—¨åœ¨æ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/27/NLP%20Insights/FastChat%20%E8%AE%AD%E7%BB%83%E8%84%9A%E6%9C%AC%E4%BB%A3%E7%A0%81%E9%80%90%E8%A1%8C%E8%A7%A3%E6%9E%90-Train.py%20%E3%80%90FastChat%20%E7%B3%BB%E5%88%97%E7%AC%AC%201%20%E7%AF%87%E3%80%91/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/19/NLP%20Insights/%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%ADFine-tuning%E5%92%8CFurther%20Pretraining%E7%9A%84%E5%8C%BA%E5%88%AB/">ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ä¸­Fine-tuningå’ŒFurther Pretrainingçš„åŒºåˆ«</a></h2><time class="has-text-grey" datetime="2024-02-19T07:10:29.000Z">2024-02-19</time><p class="is-flex-grow-2 mt-2">ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ Fine-tuning å’Œ Further Pretraining çš„åŒºåˆ«åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¦‚ GPT å’Œ BERT çš„å‡ºç°ï¼Œå½»åº•æ”¹å˜äº†æˆ‘ä»¬å¤„ç†æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æå’Œé—®ç­”ç­‰ä»»åŠ¡çš„æ–¹å¼ã€‚åœ¨è¿™äº›æ¨¡å‹çš„åº”ç”¨ä¸­ï¼ŒFine-tuningï¼ˆå¾®è°ƒï¼‰å’Œ Further Pretrainingï¼ˆè¿›ä¸€æ­¥é¢„è®­ç»ƒï¼‰æ˜¯ä¸¤ç§å…³é”®æŠ€æœ¯ã€‚è™½ç„¶å®ƒä»¬çœ‹èµ·æ¥ç›¸ä¼¼ï¼Œä½†å®é™…ä¸ŠæœåŠ¡äº NLP æµç¨‹ä¸­çš„ä¸åŒéœ€æ±‚å’Œåœºæ™¯ã€‚
ä»€ä¹ˆæ˜¯ Fine-tuningï¼ŸFine-tuning æ˜¯æŒ‡åœ¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒï¼ˆæˆ–â€œå¾®è°ƒâ€ï¼‰ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ¨¡å‹çš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•åœ¨æ•°æ®é›†ç›¸å¯¹è¾ƒå°ä½†æ ‡æ³¨è‰¯å¥½çš„æƒ…å†µä¸‹ç‰¹åˆ«æœ‰æ•ˆã€‚
ç¤ºä¾‹åœºæ™¯ï¼šæƒ…æ„Ÿåˆ†æå‡è®¾ä½ æœ‰ä¸€ç»„ç”µå½±è¯„è®ºæ•°æ®ï¼Œæ¯æ¡è¯„è®ºéƒ½æ ‡è®°äº†æ­£é¢æˆ–è´Ÿé¢æƒ…æ„Ÿã€‚ä½ æƒ³åˆ›å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹è¯„è®ºçš„æƒ…æ„Ÿã€‚..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/19/NLP%20Insights/%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%ADFine-tuning%E5%92%8CFurther%20Pretraining%E7%9A%84%E5%8C%BA%E5%88%AB/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/19/NLP%20Insights/Understanding%20the%20Differences%20Between%20Fine-tuning%20and%20Further%20Pretraining%20in%20Large%20Language%20Models/">Understanding the Differences Between Fine-tuning and Further Pretraining in Large Language Models</a></h2><time class="has-text-grey" datetime="2024-02-19T07:06:29.000Z">2024-02-19</time><p class="is-flex-grow-2 mt-2">Understanding the Differences Between Fine-tuning and Further Pretraining in Large Language ModelsIn the world of Natural Language Processing (NLP), the advent of large language models like GPT and BERT has revolutionized how we approach tasks such as text classification, sentiment analysis, and question-answering. Two pivotal techniques in leveraging thes..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/19/NLP%20Insights/Understanding%20the%20Differences%20Between%20Fine-tuning%20and%20Further%20Pretraining%20in%20Large%20Language%20Models/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Onnx"><i class="tag post-item-tag">Onnx</i></a><a href="/tags/Deployment"><i class="tag post-item-tag">Deployment</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/08/21/NLP%20Insights/Conver%20Pytorch%20Model%20to%20ONNX%20Format/">Conver Pytorch Model to ONNX Format</a></h2><time class="has-text-grey" datetime="2023-08-21T06:34:18.000Z">2023-08-21</time><p class="is-flex-grow-2 mt-2">ä½¿ç”¨ PyTorch å’Œ ONNX æ£€æŸ¥æ¨¡å‹ä¸€è‡´æ€§åœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„å¼€å‘è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹çš„äº’æ“ä½œæ€§å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚ONNX (Open Neural Network Exchange) æ˜¯ä¸€ç§å¼€æ”¾æ ¼å¼ï¼Œç”¨äºè¡¨ç¤ºæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚å®ƒå…è®¸å¼€å‘è€…åœ¨å„ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ä¹‹é—´è½»æ¾åœ°å…±äº«æ¨¡å‹ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„å¯ç§»æ¤æ€§å’Œäº’æ“ä½œæ€§ã€‚
æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

å°† PyTorch æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼ã€‚
éªŒè¯è½¬æ¢åçš„ ONNX æ¨¡å‹ä¸åŸå§‹ PyTorch æ¨¡å‹çš„è¾“å‡ºæ˜¯å¦ä¸€è‡´ã€‚

1. å¯¼å…¥å¿…è¦çš„åº“é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥ä¸ºæ¨¡å‹è½¬æ¢å’ŒéªŒè¯æ‰€éœ€çš„æ‰€æœ‰åº“ã€‚
123456import osimport sysimport torchimport onnximport onnxruntimeimport numpy as np

..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/08/21/NLP%20Insights/Conver%20Pytorch%20Model%20to%20ONNX%20Format/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/08/02/NLP%20Insights/LLAMA2/">Training Llama 2 Model on Single GPU with int8 Quantization and LoRA</a></h2><time class="has-text-grey" datetime="2023-08-02T07:38:29.000Z">2023-08-02</time><p class="is-flex-grow-2 mt-2">Training Llama 2 Model on Single GPU with int8 Quantization and LoRALlama 2æ¦‚è¿°Llama 2 æ˜¯ä¸€ä¸ªåŒ…å«é¢„è®­ç»ƒå’Œå¾®è°ƒçš„ç”Ÿæˆå¼æ–‡æœ¬æ¨¡å‹çš„é›†åˆï¼Œå…¶è§„æ¨¡ä» 70 äº¿åˆ° 700 äº¿ä¸ªå‚æ•°ä¸ç­‰ã€‚Llama2æ¨¡å‹æ˜¯ç”±Hugo Touvron, Louis Martin, Kevin Stone, Peter Albertç­‰äººåœ¨Llama 2: Open Foundation and Fine-Tuned Chat Modelsä¸­æå‡ºçš„ã€‚
è¯¥è®ºæ–‡çš„æ‘˜è¦å¦‚ä¸‹ï¼š
åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼€å‘å¹¶å‘å¸ƒäº†Llama 2ï¼Œè¿™æ˜¯ä¸€ç»„ä»70äº¿åˆ°700äº¿å‚æ•°çš„é¢„è®­ç»ƒå’Œå¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚æˆ‘ä»¬çš„å¾®è°ƒLLMsï¼Œç§°ä¸ºLlama 2-Chatï¼Œé’ˆå¯¹å¯¹è¯ç”¨ä¾‹è¿›è¡Œäº†ä¼˜åŒ–..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/08/02/NLP%20Insights/LLAMA2/">Read more</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><a class="extend prev" rel="prev" href="/categories/NLP-Insights/"><i class="iconfont icon-prev has-text-grey"></i></a><a class="page-number" href="/categories/NLP-Insights/">1</a><span class="page-number current">2</span><a class="page-number" href="/categories/NLP-Insights/page/3/">3</a><a class="extend next" rel="next" href="/categories/NLP-Insights/page/3/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container categories-widget category-page"><h3>Categories</h3><section><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code-Chronicles/">Code Chronicles</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Debugging-Diaries/">Debugging Diaries</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life-Reflections/">Life Reflections</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-Insights/">NLP Insights</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tech-Toolbox/">Tech Toolbox</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wanderlust-Adventures/">Wanderlust Adventures</a><span class="category-list-count">1</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- çŸ¥ä¹--><!-- é¢†è‹±--><!-- è„¸ä¹¦--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright Â©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>