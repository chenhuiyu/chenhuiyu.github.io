<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Archives · 2024</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/"><img class="post-cover-img js-img-fadeIn" src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/SGLang"><i class="tag post-item-tag">SGLang</i></a><a href="/tags/Structured%20LLM"><i class="tag post-item-tag">Structured LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码</a></h2><time class="has-text-grey" datetime="2024-08-13T08:12:10.000Z">2024-08-13</time><p class="is-flex-grow-2 mt-2">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码作者: Liangsheng Yin, Ying Sheng, Lianmin Zheng日期: 2024 年 2 月 5 日

本文内容基于 LMSYS Org 发布的一篇博客文章，原文链接：LMSYS Org 博客。相关的代码库可以在以下链接找到：SGLang 代码库。
让一个 LLM 始终生成符合特定模式的有效 JSON 或 YAML，对于许多应用来说是一个关键特性。在这篇博客文章中，我们介绍了一种显著加速这种约束解码的优化方法。我们的方法利用了压缩的有限状态机，并且兼容任何正则表达式，因此可以适用于任何 JSON 或 YAML 模式。与现有系统逐步解码一个标记的方式不同，我们的方法分析了正则表达式的有限状态机，压缩了单一的转换路径，并在可能的..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/"><img class="post-cover-img js-img-fadeIn" src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/SGLang"><i class="tag post-item-tag">SGLang</i></a><a href="/tags/Structured%20LLM"><i class="tag post-item-tag">Structured LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码</a></h2><time class="has-text-grey" datetime="2024-08-13T08:12:10.000Z">2024-08-13</time><p class="is-flex-grow-2 mt-2">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码作者: Liangsheng Yin, Ying Sheng, Lianmin Zheng日期: 2024 年 2 月 5 日

本文内容基于 LMSYS Org 发布的一篇博客文章，原文链接：LMSYS Org 博客。相关的代码库可以在以下链接找到：SGLang 代码库。
让一个 LLM 始终生成符合特定模式的有效 JSON 或 YAML，对于许多应用来说是一个关键特性。在这篇博客文章中，我们介绍了一种显著加速这种约束解码的优化方法。我们的方法利用了压缩的有限状态机，并且兼容任何正则表达式，因此可以适用于任何 JSON 或 YAML 模式。与现有系统逐步解码一个标记的方式不同，我们的方法分析了正则表达式的有限状态机，压缩了单一的转换路径，并在可能的..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.en/">使用vLLM运行微调后的Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">使用vLLM运行微调后的Gemma-2-2b-it的详细步骤在这里分享一下我运行微调后的Gemma-2-2b-it模型并使用vLLM的步骤，希望对其他人有所帮助。本文将详细介绍安装过程、环境配置以及常见问题的解决方法。
安装和验证vLLM首先，确保安装并验证vLLM的版本是0.5.3。

安装vLLM：
1pip install vllm==0.5.3

验证安装：
123import vllmprint(vllm.__version__)# 输出: 0.5.3

安装Flashinfer按照以下步骤安装Flashinfer，并确保您的torch版本和CUDA兼容性。

检查torch版本和CUDA兼容性：
123import torchprint(torch.__version__)  # 应输出: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.zh-CN/">使用vLLM运行微调后的Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">使用vLLM运行微调后的Gemma-2-2b-it的详细步骤在这里分享一下我运行微调后的Gemma-2-2b-it模型并使用vLLM的步骤，希望对其他人有所帮助。本文将详细介绍安装过程、环境配置以及常见问题的解决方法。
安装和验证vLLM首先，确保安装并验证vLLM的版本是0.5.3。

安装vLLM：
1pip install vllm==0.5.3

验证安装：
123import vllmprint(vllm.__version__)# 输出: 0.5.3

安装Flashinfer按照以下步骤安装Flashinfer，并确保您的torch版本和CUDA兼容性。

检查torch版本和CUDA兼容性：
123import torchprint(torch.__version__)  # 应输出: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.zh-CN/">Read more</a></section></article></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2026/02/">February 2026</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a><span class="archive-list-count">2</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>