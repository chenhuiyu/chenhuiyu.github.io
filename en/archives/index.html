<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Archives Â· All</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment.zh-CN/">Untitled</a></h2><time class="has-text-grey" datetime="2026-02-20T22:15:00.000Z">2026-02-21</time><p class="is-flex-grow-2 mt-2">Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to JudgmentAbstractEvaluation tasks in artificial intelligence (AI) and natural language processing (NLP) have long been challenging. Traditional evaluation methods, such as those based on matching or embeddings, are limited in assessing complex attrib..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment.en/">Untitled</a></h2><time class="has-text-grey" datetime="2026-02-20T22:15:00.000Z">2026-02-21</time><p class="is-flex-grow-2 mt-2">Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to JudgmentAbstractEvaluation tasks in artificial intelligence (AI) and natural language processing (NLP) have long been challenging. Traditional evaluation methods, such as those based on matching or embeddings, are limited in assessing complex attrib..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Conversational%20AI"><i class="tag post-item-tag">Conversational AI</i></a><a href="/tags/Memory%20Management"><i class="tag post-item-tag">Memory Management</i></a><a href="/tags/SeCom"><i class="tag post-item-tag">SeCom</i></a><a href="/tags/RAG"><i class="tag post-item-tag">RAG</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI.en/">SeCom: Redefining Memory Management in Conversational AI</a></h2><time class="has-text-grey" datetime="2025-06-24T08:00:00.000Z">2025-06-24</time><p class="is-flex-grow-2 mt-2">SeCom: Redefining Memory Management in Conversational AIForewordIâ€™ve recently been diving into memory management for dialog-based AI, especially how to construct and retrieve memories in long-term conversations. During my exploration I came across an eye-opening ICLR 2025 paperâ€”**â€SeCom: On Memory Construction and Retrieval for Personalized Conversational ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Conversational%20AI"><i class="tag post-item-tag">Conversational AI</i></a><a href="/tags/Memory%20Management"><i class="tag post-item-tag">Memory Management</i></a><a href="/tags/SeCom"><i class="tag post-item-tag">SeCom</i></a><a href="/tags/RAG"><i class="tag post-item-tag">RAG</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI.zh-CN/">SeCom: Redefining Memory Management in Conversational AI</a></h2><time class="has-text-grey" datetime="2025-06-24T08:00:00.000Z">2025-06-24</time><p class="is-flex-grow-2 mt-2">SeCom: Redefining Memory Management in Conversational AIForewordIâ€™ve recently been diving into memory management for dialog-based AI, especially how to construct and retrieve memories in long-term conversations. During my exploration I came across an eye-opening ICLR 2025 paperâ€”**â€SeCom: On Memory Construction and Retrieval for Personalized Conversational ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Conversational%20AI"><i class="tag post-item-tag">Conversational AI</i></a><a href="/tags/Memory%20Management"><i class="tag post-item-tag">Memory Management</i></a><a href="/tags/SeCom"><i class="tag post-item-tag">SeCom</i></a><a href="/tags/RAG"><i class="tag post-item-tag">RAG</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/06/24/NLP%20Insights/SeCom:%20%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%AF%9DAI%E7%9A%84%E8%AE%B0%E5%BF%86%E7%AE%A1%E7%90%86.en/">SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†</a></h2><time class="has-text-grey" datetime="2025-06-24T08:00:00.000Z">2025-06-24</time><p class="is-flex-grow-2 mt-2">SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†å†™åœ¨å‰é¢æœ€è¿‘ç¬”è€…ä¸€ç›´åœ¨ç ”ç©¶å¯¹è¯AIä¸­çš„å†…å­˜ç®¡ç†é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é•¿æœŸå¯¹è¯åœºæ™¯ä¸‹çš„è®°å¿†æ„å»ºä¸æ£€ç´¢æŠ€æœ¯ã€‚å‘ç°äº†ä¸€ç¯‡ä»¤äººçœ¼å‰ä¸€äº®çš„ICLR 2025è®ºæ–‡â€”â€”ã€ŠSeCom: On Memory Construction and Retrieval for Personalized Conversational Agentsã€‹ï¼Œç”±Microsoftå’Œæ¸…åå¤§å­¦çš„ç ”ç©¶å›¢é˜Ÿè”åˆå‘è¡¨ã€‚
è¿™ç¯‡è®ºæ–‡æå‡ºçš„SeComæ–¹æ³•å·§å¦™åœ°è§£å†³äº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åœ¨é•¿æœŸå¯¹è¯ä¸­æœ‰æ•ˆç®¡ç†å’Œæ£€ç´¢å†å²ä¿¡æ¯ï¼Ÿä»Šå¤©æƒ³å’Œå¤§å®¶åˆ†äº«ä¸€ä¸‹è¿™ä¸ªæ–¹æ³•çš„æŠ€æœ¯ç»†èŠ‚å’Œåˆ›æ–°ç‚¹ï¼Œå¸Œæœ›èƒ½ä¸ºä»äº‹ç›¸å…³ç ”ç©¶çš„æœ‹å‹ä»¬æä¾›ä¸€äº›å¯å‘ã€‚
1. ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å…³æ³¨å¯¹è¯å†…å­˜ç®¡ç†ï¼Ÿ1.1 é•¿æœŸå¯¹è¯çš„ç°å®æŒ‘æˆ˜åœ¨ä¸LLMsçš„æ—¥å¸¸äº¤äº’ä¸­ï¼Œç›¸ä¿¡å¤§å®¶éƒ½é‡åˆ°è¿‡è¿™æ ·çš„å›°æ‰°ï¼šå½“å¯¹è¯..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/06/24/NLP%20Insights/SeCom:%20%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%AF%9DAI%E7%9A%84%E8%AE%B0%E5%BF%86%E7%AE%A1%E7%90%86.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Conversational%20AI"><i class="tag post-item-tag">Conversational AI</i></a><a href="/tags/Memory%20Management"><i class="tag post-item-tag">Memory Management</i></a><a href="/tags/SeCom"><i class="tag post-item-tag">SeCom</i></a><a href="/tags/RAG"><i class="tag post-item-tag">RAG</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/06/24/NLP%20Insights/SeCom:%20%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%AF%9DAI%E7%9A%84%E8%AE%B0%E5%BF%86%E7%AE%A1%E7%90%86.zh-CN/">SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†</a></h2><time class="has-text-grey" datetime="2025-06-24T08:00:00.000Z">2025-06-24</time><p class="is-flex-grow-2 mt-2">SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†å†™åœ¨å‰é¢æœ€è¿‘ç¬”è€…ä¸€ç›´åœ¨ç ”ç©¶å¯¹è¯AIä¸­çš„å†…å­˜ç®¡ç†é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é•¿æœŸå¯¹è¯åœºæ™¯ä¸‹çš„è®°å¿†æ„å»ºä¸æ£€ç´¢æŠ€æœ¯ã€‚å‘ç°äº†ä¸€ç¯‡ä»¤äººçœ¼å‰ä¸€äº®çš„ICLR 2025è®ºæ–‡â€”â€”ã€ŠSeCom: On Memory Construction and Retrieval for Personalized Conversational Agentsã€‹ï¼Œç”±Microsoftå’Œæ¸…åå¤§å­¦çš„ç ”ç©¶å›¢é˜Ÿè”åˆå‘è¡¨ã€‚
è¿™ç¯‡è®ºæ–‡æå‡ºçš„SeComæ–¹æ³•å·§å¦™åœ°è§£å†³äº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åœ¨é•¿æœŸå¯¹è¯ä¸­æœ‰æ•ˆç®¡ç†å’Œæ£€ç´¢å†å²ä¿¡æ¯ï¼Ÿä»Šå¤©æƒ³å’Œå¤§å®¶åˆ†äº«ä¸€ä¸‹è¿™ä¸ªæ–¹æ³•çš„æŠ€æœ¯ç»†èŠ‚å’Œåˆ›æ–°ç‚¹ï¼Œå¸Œæœ›èƒ½ä¸ºä»äº‹ç›¸å…³ç ”ç©¶çš„æœ‹å‹ä»¬æä¾›ä¸€äº›å¯å‘ã€‚
1. ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å…³æ³¨å¯¹è¯å†…å­˜ç®¡ç†ï¼Ÿ1.1 é•¿æœŸå¯¹è¯çš„ç°å®æŒ‘æˆ˜åœ¨ä¸LLMsçš„æ—¥å¸¸äº¤äº’ä¸­ï¼Œç›¸ä¿¡å¤§å®¶éƒ½é‡åˆ°è¿‡è¿™æ ·çš„å›°æ‰°ï¼šå½“å¯¹è¯..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/06/24/NLP%20Insights/SeCom:%20%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%AF%9DAI%E7%9A%84%E8%AE%B0%E5%BF%86%E7%AE%A1%E7%90%86.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.zh-CN/">Decoder-onlyä¸Encoder-onlyæ¨¡å‹Paddingç­–ç•¥çš„å·®å¼‚</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ Padding çš„å«ä¹‰åœ¨å¤§æ¨¡å‹ (LLM) ä¸­ï¼Œpadding æ˜¯ç”¨äºå°†ä¸åŒé•¿åº¦çš„åºåˆ—è°ƒæ•´ä¸ºåŒä¸€é•¿åº¦çš„æ–¹æ³•ï¼Œä»¥ä¾¿äºæ‰¹é‡ (batch) å¤„ç†ã€‚
ä¾‹å¦‚ï¼š
12å¥å­1: &quot;I love NLP&quot;å¥å­2: &quot;Padding is useful in LLM training&quot;

ä½¿ç”¨ &amp;lt;pad&amp;gt; token è¿›è¡Œå¯¹é½ï¼š
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Padding ä½ç½®çš„é€‰æ‹©ï¼šLeft vs RightPadding æœ‰ä¸¤ç§å¸¸è§æ–¹å¼ï¼š

Right paddingï¼ˆå³å¡«å……ï¼‰ï¼š
1&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.en/">Differences in Padding Strategies Between Decoder-only and Encoder-only Models</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ What is Padding?In Large Language Models (LLMs), padding is a method used to standardize sequence lengths for batch processing.
For example:
12Sentence 1: &quot;I love NLP&quot;Sentence 2: &quot;Padding is useful in LLM training&quot;

Using the &amp;lt;pad&amp;gt; token for alignment:
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Paddi..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.en/">Decoder-onlyä¸Encoder-onlyæ¨¡å‹Paddingç­–ç•¥çš„å·®å¼‚</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ Padding çš„å«ä¹‰åœ¨å¤§æ¨¡å‹ (LLM) ä¸­ï¼Œpadding æ˜¯ç”¨äºå°†ä¸åŒé•¿åº¦çš„åºåˆ—è°ƒæ•´ä¸ºåŒä¸€é•¿åº¦çš„æ–¹æ³•ï¼Œä»¥ä¾¿äºæ‰¹é‡ (batch) å¤„ç†ã€‚
ä¾‹å¦‚ï¼š
12å¥å­1: &quot;I love NLP&quot;å¥å­2: &quot;Padding is useful in LLM training&quot;

ä½¿ç”¨ &amp;lt;pad&amp;gt; token è¿›è¡Œå¯¹é½ï¼š
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Padding ä½ç½®çš„é€‰æ‹©ï¼šLeft vs RightPadding æœ‰ä¸¤ç§å¸¸è§æ–¹å¼ï¼š

Right paddingï¼ˆå³å¡«å……ï¼‰ï¼š
1&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.zh-CN/">Differences in Padding Strategies Between Decoder-only and Encoder-only Models</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ What is Padding?In Large Language Models (LLMs), padding is a method used to standardize sequence lengths for batch processing.
For example:
12Sentence 1: &quot;I love NLP&quot;Sentence 2: &quot;Padding is useful in LLM training&quot;

Using the &amp;lt;pad&amp;gt; token for alignment:
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Paddi..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.zh-CN/">Read more</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><span class="page-number current">1</span><a class="page-number" href="/en/archives/page/2/">2</a><a class="page-number" href="/en/archives/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/en/archives/page/13/">13</a><a class="extend next" rel="next" href="/en/archives/page/2/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2026/02/">February 2026</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a><span class="archive-list-count">2</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- çŸ¥ä¹--><!-- é¢†è‹±--><!-- è„¸ä¹¦--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright Â©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>