<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>DSSM 模型详解</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="DSSM (Deep Structured Semantic Models) 模型详解一、模型简介DSSM（Deep Structured Semantic Models）是微软提出的一个深度学习模型，用于学习文本的语义表达。DSSM首次在信息检索领域中被提出，用于处理查询-文档匹配任务，但很快被应用到了各种其他场景，如广告点击率预测，推荐系统等。
二、模型结构DSSM模型主要由三个部分构成：

输入层：在这一层，将输入的文本（查询或者文档）转化为词向量。
深度神经网络：输入层之后是一系列全连接层，它们学习输入的语义表示。
输出层：最后，输出层将深度神经网络的输出转化为概率分布，用于表示查询与文档之间的语义匹配度。

三、在推荐系统中的应用DSSM可应用在推荐系统中，它可以学习用户的行为特征与物品特征的语义.."><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">DSSM 模型详解</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DSSM-Deep-Structured-Semantic-Models-%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3"><span class="toc-text">DSSM (Deep Structured Semantic Models) 模型详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B"><span class="toc-text">一、模型简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-text">二、模型结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">三、在推荐系统中的应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0"><span class="toc-text">四、模型实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-text">五、训练过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E7%BA%BF%E4%B8%8A%E6%8E%A8%E7%90%86%E6%96%B9%E6%B3%95"><span class="toc-text">六、线上推理方法</span></a></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/DSSM"><i class="tag post-item-tag">DSSM</i></a><a href="/tags/Recommendation"><i class="tag post-item-tag">Recommendation</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">DSSM 模型详解</h1><time class="has-text-grey" datetime="2023-07-06T18:14:10.000Z">2023-07-07</time><article class="mt-2 post-content"><h1 id="DSSM-Deep-Structured-Semantic-Models-模型详解"><a href="#DSSM-Deep-Structured-Semantic-Models-模型详解" class="headerlink" title="DSSM (Deep Structured Semantic Models) 模型详解"></a>DSSM (Deep Structured Semantic Models) 模型详解</h1><h2 id="一、模型简介"><a href="#一、模型简介" class="headerlink" title="一、模型简介"></a>一、模型简介</h2><p>DSSM（Deep Structured Semantic Models）是微软提出的一个深度学习模型，用于学习文本的语义表达。DSSM首次在信息检索领域中被提出，用于处理查询-文档匹配任务，但很快被应用到了各种其他场景，如广告点击率预测，推荐系统等。</p>
<h2 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h2><p>DSSM模型主要由三个部分构成：</p>
<ol>
<li><strong>输入层</strong>：在这一层，将输入的文本（查询或者文档）转化为词向量。</li>
<li><strong>深度神经网络</strong>：输入层之后是一系列全连接层，它们学习输入的语义表示。</li>
<li><strong>输出层</strong>：最后，输出层将深度神经网络的输出转化为概率分布，用于表示查询与文档之间的语义匹配度。</li>
</ol>
<h2 id="三、在推荐系统中的应用"><a href="#三、在推荐系统中的应用" class="headerlink" title="三、在推荐系统中的应用"></a>三、在推荐系统中的应用</h2><p>DSSM可应用在推荐系统中，它可以学习用户的行为特征与物品特征的语义匹配度，用于评估用户对物品的兴趣。在实际应用中，通常将用户行为序列作为查询，将候选物品的特征作为文档，通过DSSM学习用户的实时兴趣，并将兴趣与物品的匹配度用于排序。</p>
<h2 id="四、模型实现"><a href="#四、模型实现" class="headerlink" title="四、模型实现"></a>四、模型实现</h2><p>以下是一个使用PyTorch实现的DSSM模型的示例：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DSSM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(DSSM, self).__init__()</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.linear1 = nn.Linear(vocab_size, hidden_size)</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size, hidden_size)</span><br><span class="line">        self.linear3 = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, query, doc</span>):</span><br><span class="line">        query = self.linear1(query)</span><br><span class="line">        query = torch.relu(query)</span><br><span class="line">        query = self.linear2(query)</span><br><span class="line">        query = torch.relu(query)</span><br><span class="line"></span><br><span class="line">        doc = self.linear1(doc)</span><br><span class="line">        doc = torch.relu(doc)</span><br><span class="line">        doc = self.linear2(doc)</span><br><span class="line">        doc = torch.relu(doc)</span><br><span class="line"></span><br><span class="line">        out = self.linear3(query * doc)</span><br><span class="line">        out = torch.sigmoid(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></tbody></table></figure>
<h2 id="五、训练过程"><a href="#五、训练过程" class="headerlink" title="五、训练过程"></a>五、训练过程</h2><p>在训练DSSM模型时，我们通常会采用pairwise的训练方式，也就是利用正样本（正匹配对）和负样本（负匹配对）进行训练。在信息检索任务中，一个正样本可能是一个查询和一个相关的文档，负样本可能是同一个查询和一个不相关的文档。</p>
<p>对于每个训练样本，都将经过DSSM模型，得到查询和文档的向量表示，然后计算两者的余弦相似度作为预测的匹配分数。接下来，使用一个合适的损失函数，例如交叉熵损失，来优化模型参数。</p>
<p>以下是一个使用PyTorch训练DSSM模型的示例：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = DSSM(vocab_size=<span class="number">10000</span>, hidden_size=<span class="number">128</span>)</span><br><span class="line"><span class="comment"># 使用Adam优化器</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"><span class="comment"># 使用二元交叉熵作为损失函数</span></span><br><span class="line">criterion = torch.nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        query, doc, label = data</span><br><span class="line">        <span class="comment"># 清零梯度</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        output = model(query, doc)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 更新权重</span></span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></tbody></table></figure>
<p>以上代码中，首先初始化了一个DSSM模型，并定义了一个优化器和损失函数。在每个训练步骤中，我们对数据进行前向传播，计算损失，然后进行反向传播和优化。</p>
<p>在训练过程中，可以在验证集上评估模型的效果，并根据需要调整学习率和其他训练参数。训练结束后，通常会在测试集上对模型进行最后的评估，以确保模型能够很好地泛化到未见过的数据。</p>
<p>训练DSSM模型的主要挑战是选择合适的正样本和负样本，以及设置合理的训练参数。在实际应用中，可能需要使用一些策略来平衡正负样本的比例，或者使用更复杂的损失函数来处理不均衡的数据。</p>
<h2 id="六、线上推理方法"><a href="#六、线上推理方法" class="headerlink" title="六、线上推理方法"></a>六、线上推理方法</h2><p>DSSM模型在线上推理主要有以下两个步骤：</p>
<ol>
<li><strong>向量化</strong>：在模型训练完毕后，可以先对所有的物品进行向量化处理，保存为物品的向量表示。当新的用户请求到来时，将用户的行为序列转化为向量表示。</li>
<li><strong>计算相似度</strong>：然后，计算用户向量与各个物品向量的相似度，一般使用余弦相似度作为计算方法。相似度越高，表示用户对物品的兴趣越大。</li>
</ol>
<p>具体实施时，需要注意的是，为了提高在线推理的效率，通常会采用一些近似最近邻搜索的技术（如Faiss等）来快速找到与用户最相似的物品，而不是遍历所有的物品。</p>
<p>总的来说，DSSM是一个非常有效的深度学习模型，用于学习文本或其他类型数据的语义表示，广泛应用于信息检索、推荐系统等多种场景中。</p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2023/07/07/NLP%20Insights/DSSM%20%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.en/" title="DSSM 模型详解"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: DSSM 模型详解</span></a><a class="button is-default" href="/2023/07/07/NLP%20Insights/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3.zh-CN/" title="推荐系统离线评估指标详解"><span class="has-text-weight-semibold">Next: 推荐系统离线评估指标详解</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>