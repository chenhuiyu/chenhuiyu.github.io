<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Categories Â· NLP Insights</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.en/">ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤åœ¨è¿™é‡Œåˆ†äº«ä¸€ä¸‹æˆ‘è¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itæ¨¡å‹å¹¶ä½¿ç”¨vLLMçš„æ­¥éª¤ï¼Œå¸Œæœ›å¯¹å…¶ä»–äººæœ‰æ‰€å¸®åŠ©ã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»å®‰è£…è¿‡ç¨‹ã€ç¯å¢ƒé…ç½®ä»¥åŠå¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ³•ã€‚
å®‰è£…å’ŒéªŒè¯vLLMé¦–å…ˆï¼Œç¡®ä¿å®‰è£…å¹¶éªŒè¯vLLMçš„ç‰ˆæœ¬æ˜¯0.5.3ã€‚

å®‰è£…vLLMï¼š
1pip install vllm==0.5.3

éªŒè¯å®‰è£…ï¼š
123import vllmprint(vllm.__version__)# è¾“å‡º: 0.5.3

å®‰è£…FlashinferæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®‰è£…Flashinferï¼Œå¹¶ç¡®ä¿æ‚¨çš„torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ã€‚

æ£€æŸ¥torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ï¼š
123import torchprint(torch.__version__)  # åº”è¾“å‡º: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.zh-CN/">ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤åœ¨è¿™é‡Œåˆ†äº«ä¸€ä¸‹æˆ‘è¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itæ¨¡å‹å¹¶ä½¿ç”¨vLLMçš„æ­¥éª¤ï¼Œå¸Œæœ›å¯¹å…¶ä»–äººæœ‰æ‰€å¸®åŠ©ã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»å®‰è£…è¿‡ç¨‹ã€ç¯å¢ƒé…ç½®ä»¥åŠå¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ³•ã€‚
å®‰è£…å’ŒéªŒè¯vLLMé¦–å…ˆï¼Œç¡®ä¿å®‰è£…å¹¶éªŒè¯vLLMçš„ç‰ˆæœ¬æ˜¯0.5.3ã€‚

å®‰è£…vLLMï¼š
1pip install vllm==0.5.3

éªŒè¯å®‰è£…ï¼š
123import vllmprint(vllm.__version__)# è¾“å‡º: 0.5.3

å®‰è£…FlashinferæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®‰è£…Flashinferï¼Œå¹¶ç¡®ä¿æ‚¨çš„torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ã€‚

æ£€æŸ¥torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ï¼š
123import torchprint(torch.__version__)  # åº”è¾“å‡º: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.zh-CN/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).zh-CN/"><img class="post-cover-img js-img-fadeIn" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Language%20Modeling"><i class="tag post-item-tag">Language Modeling</i></a><a href="/tags/Perplexity"><i class="tag post-item-tag">Perplexity</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).zh-CN/">å¦‚ä½•å‡†ç¡®è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰</a></h2><time class="has-text-grey" datetime="2024-04-17T04:00:00.000Z">2024-04-17</time><p class="is-flex-grow-2 mt-2">å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰å›°æƒ‘åº¦ï¼ˆPPLï¼‰æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹æœ€å¸¸ç”¨çš„æŒ‡æ ‡ä¹‹ä¸€ã€‚åœ¨æ·±å…¥æ¢è®¨ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥æ³¨æ„è¿™ä¸ªæŒ‡æ ‡ç‰¹åˆ«é€‚ç”¨äºä¼ ç»Ÿè¯­è¨€æ¨¡å‹ï¼ˆæœ‰æ—¶è¢«ç§°ä¸ºè‡ªå›å½’æˆ–å› æœè¯­è¨€æ¨¡å‹ï¼‰ï¼Œè€Œå¯¹äºåƒ BERT è¿™æ ·çš„ masked language models åˆ™æ²¡æœ‰æ˜ç¡®å®šä¹‰ï¼ˆè§æ¨¡å‹æ€»ç»“ï¼‰ã€‚
å›°æƒ‘åº¦è¢«å®šä¹‰ä¸ºåºåˆ—çš„æŒ‡æ•°åŒ–å¹³å‡è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ ‡è®°åŒ–åºåˆ— $X = (x_0, x_1, \dots, x_t)$ï¼Œé‚£ä¹ˆ $X$ çš„å›°æƒ‘åº¦ä¸ºï¼Œ
$$\text{PPL}(X) = \exp \left{ -\frac{1}{t}\sum*{i=1}^t \log p\theta (xi|x*{&amp;lt;i}) \right}$$
å…¶ä¸­ $\log p\theta (x_i|x{&amp;lt;i})$ æ˜¯ç¬¬ i ä¸ªæ ‡è®°çš„å¯¹æ•°ä¼¼..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).zh-CN/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).en/"><img class="post-cover-img js-img-fadeIn" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Language%20Modeling"><i class="tag post-item-tag">Language Modeling</i></a><a href="/tags/Perplexity"><i class="tag post-item-tag">Perplexity</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).en/">å¦‚ä½•å‡†ç¡®è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰</a></h2><time class="has-text-grey" datetime="2024-04-17T04:00:00.000Z">2024-04-17</time><p class="is-flex-grow-2 mt-2">å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰å›°æƒ‘åº¦ï¼ˆPPLï¼‰æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹æœ€å¸¸ç”¨çš„æŒ‡æ ‡ä¹‹ä¸€ã€‚åœ¨æ·±å…¥æ¢è®¨ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥æ³¨æ„è¿™ä¸ªæŒ‡æ ‡ç‰¹åˆ«é€‚ç”¨äºä¼ ç»Ÿè¯­è¨€æ¨¡å‹ï¼ˆæœ‰æ—¶è¢«ç§°ä¸ºè‡ªå›å½’æˆ–å› æœè¯­è¨€æ¨¡å‹ï¼‰ï¼Œè€Œå¯¹äºåƒ BERT è¿™æ ·çš„ masked language models åˆ™æ²¡æœ‰æ˜ç¡®å®šä¹‰ï¼ˆè§æ¨¡å‹æ€»ç»“ï¼‰ã€‚
å›°æƒ‘åº¦è¢«å®šä¹‰ä¸ºåºåˆ—çš„æŒ‡æ•°åŒ–å¹³å‡è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ ‡è®°åŒ–åºåˆ— $X = (x_0, x_1, \dots, x_t)$ï¼Œé‚£ä¹ˆ $X$ çš„å›°æƒ‘åº¦ä¸ºï¼Œ
$$\text{PPL}(X) = \exp \left{ -\frac{1}{t}\sum*{i=1}^t \log p\theta (xi|x*{&amp;lt;i}) \right}$$
å…¶ä¸­ $\log p\theta (x_i|x{&amp;lt;i})$ æ˜¯ç¬¬ i ä¸ªæ ‡è®°çš„å¯¹æ•°ä¼¼..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).en/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://gorilla.cs.berkeley.edu/assets/img/blog_post_8_Leaderboard.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.en/"><img class="post-cover-img js-img-fadeIn" src="https://gorilla.cs.berkeley.edu/assets/img/blog_post_8_Leaderboard.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/Agent"><i class="tag post-item-tag">Agent</i></a><a href="/tags/Tool%20Use"><i class="tag post-item-tag">Tool Use</i></a><a href="/tags/Gorilla"><i class="tag post-item-tag">Gorilla</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.en/">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹</a></h2><time class="has-text-grey" datetime="2024-02-28T07:19:18.000Z">2024-02-28</time><p class="is-flex-grow-2 mt-2">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹ğŸ¦ Gorilla: Large Language Model Connected with Massive APIsLink: https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html

Berkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œBerkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œ
åœ¨çº¿ä½“éªŒæ¨¡å‹ï¼šGorilla OpenFunctions-v2 ç½‘ç»œæ¼”ç¤º
é¡¹ç›®è¯¦æƒ…ï¼šGitHub
æ¨¡å‹ï¼ˆ7B å‚æ•°ï¼‰åœ¨ HuggingFace ä¸Šçš„é¡µé¢ï¼šgorilla-llm/gorilla-openfunctions-v2

1. ä¼¯å…‹åˆ©å‡½æ•°è°ƒç”¨æ’è¡Œæ¦œè‡ª 2022 å¹´åº•ä»¥æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‡­å€Ÿå…¶æ‰§è¡Œé€šç”¨ä»»åŠ¡çš„å¼ºå¤§èƒ½åŠ›ï¼Œæˆä¸ºä¼—äººå…³æ³¨çš„ç„¦ç‚¹ã€‚..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.en/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://gorilla.cs.berkeley.edu/assets/img/blog_post_8_Leaderboard.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.zh-CN/"><img class="post-cover-img js-img-fadeIn" src="https://gorilla.cs.berkeley.edu/assets/img/blog_post_8_Leaderboard.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/Agent"><i class="tag post-item-tag">Agent</i></a><a href="/tags/Tool%20Use"><i class="tag post-item-tag">Tool Use</i></a><a href="/tags/Gorilla"><i class="tag post-item-tag">Gorilla</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.zh-CN/">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹</a></h2><time class="has-text-grey" datetime="2024-02-28T07:19:18.000Z">2024-02-28</time><p class="is-flex-grow-2 mt-2">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹ğŸ¦ Gorilla: Large Language Model Connected with Massive APIsLink: https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html

Berkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œBerkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œ
åœ¨çº¿ä½“éªŒæ¨¡å‹ï¼šGorilla OpenFunctions-v2 ç½‘ç»œæ¼”ç¤º
é¡¹ç›®è¯¦æƒ…ï¼šGitHub
æ¨¡å‹ï¼ˆ7B å‚æ•°ï¼‰åœ¨ HuggingFace ä¸Šçš„é¡µé¢ï¼šgorilla-llm/gorilla-openfunctions-v2

1. ä¼¯å…‹åˆ©å‡½æ•°è°ƒç”¨æ’è¡Œæ¦œè‡ª 2022 å¹´åº•ä»¥æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‡­å€Ÿå…¶æ‰§è¡Œé€šç”¨ä»»åŠ¡çš„å¼ºå¤§èƒ½åŠ›ï¼Œæˆä¸ºä¼—äººå…³æ³¨çš„ç„¦ç‚¹ã€‚..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.zh-CN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/FastChat"><i class="tag post-item-tag">FastChat</i></a><a href="/tags/Train"><i class="tag post-item-tag">Train</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91.en/">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘</a></h2><time class="has-text-grey" datetime="2024-02-26T17:43:18.000Z">2024-02-27</time><p class="is-flex-grow-2 mt-2">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘In this article, we delve into the train.py script of FastChat (https://github.com/lm-sys/FastChat) (https://github.com/lm-sys/FastChat/blob/main/fastchat/train/train.py), a key component for training and optimizing large language models (LLMs). FastChat is an advanced open-source pl..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91.en/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/FastChat"><i class="tag post-item-tag">FastChat</i></a><a href="/tags/Train"><i class="tag post-item-tag">Train</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91.zh-CN/">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘</a></h2><time class="has-text-grey" datetime="2024-02-26T17:43:18.000Z">2024-02-27</time><p class="is-flex-grow-2 mt-2">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘In this article, we delve into the train.py script of FastChat (https://github.com/lm-sys/FastChat) (https://github.com/lm-sys/FastChat/blob/main/fastchat/train/train.py), a key component for training and optimizing large language models (LLMs). FastChat is an advanced open-source pl..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91.zh-CN/">Read more</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><a class="extend prev" rel="prev" href="/en/categories/NLP-Insights/page/2/"><i class="iconfont icon-prev has-text-grey"></i></a><a class="page-number" href="/en/categories/NLP-Insights/">1</a><a class="page-number" href="/en/categories/NLP-Insights/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/en/categories/NLP-Insights/page/4/">4</a><a class="page-number" href="/en/categories/NLP-Insights/page/5/">5</a><a class="extend next" rel="next" href="/en/categories/NLP-Insights/page/4/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container categories-widget category-page"><h3>Categories</h3><section><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code-Chronicles/">Code Chronicles</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Debugging-Diaries/">Debugging Diaries</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life-Reflections/">Life Reflections</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-Insights/">NLP Insights</a><span class="category-list-count">50</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tech-Toolbox/">Tech Toolbox</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wanderlust-Adventures/">Wanderlust Adventures</a><span class="category-list-count">2</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- çŸ¥ä¹--><!-- é¢†è‹±--><!-- è„¸ä¹¦--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright Â©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>