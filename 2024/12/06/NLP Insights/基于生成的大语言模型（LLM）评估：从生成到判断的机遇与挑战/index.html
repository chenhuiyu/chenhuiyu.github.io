<!DOCTYPE html><html lang="[&quot;en&quot;]" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战 | 黑头呆鱼进化之旅</title><meta name="author" content="Huiyu Chen"><meta name="copyright" content="Huiyu Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战摘要人工智能（AI）与自然语言处理（NLP）领域中的评估任务长期面临挑战。传统的评估方法（如基于匹配或嵌入的技术）在判断复杂属性时效果有限。近期大语言模型（LLM）的发展催生了“LLM-as-a-Judge”范式，利用LLM对任务进行评分、排序或选择。本论文对LLM评估方法进行了全面综述，包括其定义、分类框架、评估基准，以及未来的研究方">
<meta property="og:type" content="article">
<meta property="og:title" content="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战">
<meta property="og:url" content="https://chenhuiyu.github.io/2024/12/06/NLP%20Insights/%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E8%AF%84%E4%BC%B0%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%88%90%E5%88%B0%E5%88%A4%E6%96%AD%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E6%8C%91%E6%88%98/index.html">
<meta property="og:site_name" content="黑头呆鱼进化之旅">
<meta property="og:description" content="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战摘要人工智能（AI）与自然语言处理（NLP）领域中的评估任务长期面临挑战。传统的评估方法（如基于匹配或嵌入的技术）在判断复杂属性时效果有限。近期大语言模型（LLM）的发展催生了“LLM-as-a-Judge”范式，利用LLM对任务进行评分、排序或选择。本论文对LLM评估方法进行了全面综述，包括其定义、分类框架、评估基准，以及未来的研究方">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://chenhuiyu.github.io/img/avatar.jpeg">
<meta property="article:published_time" content="2024-12-06T06:34:18.000Z">
<meta property="article:modified_time" content="2024-12-06T08:08:36.085Z">
<meta property="article:author" content="Huiyu Chen">
<meta property="article:tag" content="Onnx">
<meta property="article:tag" content="Deployment">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chenhuiyu.github.io/img/avatar.jpeg"><link rel="shortcut icon" href="/img/favicon.svg"><link rel="canonical" href="https://chenhuiyu.github.io/2024/12/06/NLP%20Insights/%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E8%AF%84%E4%BC%B0%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%88%90%E5%88%B0%E5%88%A4%E6%96%AD%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E6%8C%91%E6%88%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="CySrjlAceN5JQTPeVkDbVQrJgmS-AP_NxBrhTggcHEM"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-E8VVKC5KLZ"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-E8VVKC5KLZ');
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":true,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-12-06 16:08:36'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">42</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/travel/"><i class="fa-fw fas fa-earth"></i><span> Travel</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-heart"></i><span> About</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/sitemap.xml"><i class="fa-fw sitemap fa-sitemap"></i><span> Sitemap</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/background.jpeg')"><nav id="nav"><span id="blog-info"><a href="/" title="黑头呆鱼进化之旅"><span class="site-name">黑头呆鱼进化之旅</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i><span> Books</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/travel/"><i class="fa-fw fas fa-earth"></i><span> Travel</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-heart"></i><span> About</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/sitemap.xml"><i class="fa-fw sitemap fa-sitemap"></i><span> Sitemap</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-12-06T06:34:18.000Z" title="Created 2024-12-06 14:34:18">2024-12-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-12-06T08:08:36.085Z" title="Updated 2024-12-06 16:08:36">2024-12-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NLP-Insights/">NLP Insights</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">8.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>27min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<h1 id="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战"><a href="#基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战" class="headerlink" title="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战"></a>基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>人工智能（AI）与自然语言处理（NLP）领域中的评估任务长期面临挑战。传统的评估方法（如基于匹配或嵌入的技术）在判断复杂属性时效果有限。近期大语言模型（LLM）的发展催生了“LLM-as-a-Judge”范式，利用LLM对任务进行评分、排序或选择。本论文对LLM评估方法进行了全面综述，包括其定义、分类框架、评估基准，以及未来的研究方向。</p>
<hr>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><p>评估是机器学习和NLP的核心问题之一，传统评估方法如BLEU和ROUGE通常基于文本重叠，缺乏对复杂场景的适用性。随着深度学习和LLM的发展（如GPT-4），研究者提出了“LLM-as-a-Judge”模式，以解决传统评估的局限。</p>
<h3 id="1-2-研究问题"><a href="#1-2-研究问题" class="headerlink" title="1.2 研究问题"></a>1.2 研究问题</h3><p>本论文旨在探讨以下问题：</p>
<ul>
<li><strong>评估内容：LLM评估什么？</strong></li>
<li><strong>评估方法：如何进行评估？</strong></li>
<li><strong>应用场景：LLM在哪里评估？</strong></li>
</ul>
<hr>
<h2 id="2-预备知识"><a href="#2-预备知识" class="headerlink" title="2. 预备知识"></a>2. 预备知识</h2><h3 id="2-1-输入格式"><a href="#2-1-输入格式" class="headerlink" title="2.1 输入格式"></a>2.1 输入格式</h3><p>评估输入可分为：</p>
<ul>
<li><strong>点对点（Point-Wise）</strong>：单个样本评估。</li>
<li><strong>对/列表评估（Pair/List-Wise）</strong>：多个样本的比较评估。</li>
</ul>
<h3 id="2-2-输出格式"><a href="#2-2-输出格式" class="headerlink" title="2.2 输出格式"></a>2.2 输出格式</h3><p>评估输出包括：</p>
<ul>
<li><strong>评分（Score）</strong>：对样本进行量化评分。</li>
<li><strong>排序（Ranking）</strong>：根据优劣排序。</li>
<li><strong>选择（Selection）</strong>：从多个候选中选取最佳方案。</li>
</ul>
<hr>
<h2 id="3-评估属性"><a href="#3-评估属性" class="headerlink" title="3. 评估属性"></a>3. 评估属性</h2><h3 id="3-1-有用性（Helpfulness）"><a href="#3-1-有用性（Helpfulness）" class="headerlink" title="3.1 有用性（Helpfulness）"></a>3.1 有用性（Helpfulness）</h3><p>LLM通过指导用户任务和生成反馈，对响应的有用性进行评估。这在AI对齐（Alignment）中尤为重要。</p>
<h3 id="3-2-无害性（Harmlessness）"><a href="#3-2-无害性（Harmlessness）" class="headerlink" title="3.2 无害性（Harmlessness）"></a>3.2 无害性（Harmlessness）</h3><p>评估文本的无害性是生成安全内容的关键。LLM可辅助数据标注或直接评估潜在的有害内容。</p>
<h3 id="3-3-可靠性（Reliability）"><a href="#3-3-可靠性（Reliability）" class="headerlink" title="3.3 可靠性（Reliability）"></a>3.3 可靠性（Reliability）</h3><p>LLM可检测事实性和一致性。例如，通过生成辅助证据或进行对话级别的可靠性评估。</p>
<h3 id="3-4-相关性（Relevance）"><a href="#3-4-相关性（Relevance）" class="headerlink" title="3.4 相关性（Relevance）"></a>3.4 相关性（Relevance）</h3><p>LLM可评估生成或检索内容的相关性，适用于会话、检索增强生成（RAG）等场景。</p>
<h3 id="3-5-可行性（Feasibility）"><a href="#3-5-可行性（Feasibility）" class="headerlink" title="3.5 可行性（Feasibility）"></a>3.5 可行性（Feasibility）</h3><p>在复杂任务中，LLM可对候选步骤或行动进行可行性判断，从而优化决策路径。</p>
<h3 id="3-6-总体质量（Overall-Quality）"><a href="#3-6-总体质量（Overall-Quality）" class="headerlink" title="3.6 总体质量（Overall Quality）"></a>3.6 总体质量（Overall Quality）</h3><p>LLM通过多维度评分生成整体评价，适用于生成任务的综合比较。</p>
<hr>
<h3 id="4-方法论"><a href="#4-方法论" class="headerlink" title="4. 方法论"></a>4. 方法论</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>方法论部分主要探讨如何优化LLM作为评估者（LLM-as-a-Judge）的能力，从调优和提示技术两个方面进行阐述：</p>
<ol>
<li><strong>调优技术</strong>：通过监督微调（SFT）和偏好学习等方法，利用人工标注数据或合成反馈来增强LLM的判断能力。</li>
<li><strong>提示技术</strong>：设计高效的提示策略（如操作交换、规则增强、多代理协作等）以提升LLM在推理和评估过程中的准确性和可靠性。</li>
</ol>
<hr>
<h4 id="4-1-调优技术"><a href="#4-1-调优技术" class="headerlink" title="4.1 调优技术"></a>4.1 调优技术</h4><h5 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h5><h6 id="1-人工标注数据"><a href="#1-人工标注数据" class="headerlink" title="1. 人工标注数据"></a>1. <strong>人工标注数据</strong></h6><p>人工标注数据提供了高质量的训练样本，帮助LLM学习人类偏好。以下是核心研究及其创新点：</p>
<ol>
<li><p><strong>PandaLM</strong>【Wang et al., 2024h】：</p>
<ul>
<li>PandaLM项目收集了多样化的人工标注数据集，涵盖指令生成任务的300,000个样本。</li>
<li>作者通过整合多种数据源（如开放领域问答和对话生成）来增强模型的泛化能力。</li>
<li>该研究的关键创新在于引入了标准化的标注流程，以确保数据质量与一致性。</li>
<li>此外，PandaLM强调多语言支持，通过跨文化的数据标注提高模型的适用性。</li>
<li>最终，PandaLM被证明在多个评估任务上表现优异，其输出与人工评估高度相关。</li>
</ul>
</li>
<li><p><strong>AspectInstruct</strong>【Liu et al., 2024a】：</p>
<ul>
<li>该研究首次提出了一个针对多维度评估的指令调优数据集，涵盖65个任务和27个评估维度。</li>
<li>数据集中包含对话生成、摘要和数据到文本转换等复杂任务的多方面评分。</li>
<li>作者设计了独特的任务分割机制，使模型能够根据上下文理解并优先评估特定维度。</li>
<li>研究的亮点在于数据集的多样性和全面性，为多任务评估提供了新的基准。</li>
<li>最终，该数据集显著提升了LLM在不同评估场景中的多维度理解和评估能力。</li>
</ul>
</li>
</ol>
<h6 id="2-合成数据"><a href="#2-合成数据" class="headerlink" title="2. 合成数据"></a>2. <strong>合成数据</strong></h6><p>合成数据通过LLM生成训练样本，减少了对人工标注的依赖，同时扩展了数据覆盖范围。以下是核心研究及其创新点：</p>
<ol>
<li><p><strong>JudgeLM</strong>【Zhu et al., 2023】：</p>
<ul>
<li>研究者利用GPT-4生成包含任务种子、生成答案及相关评估的高质量数据集。</li>
<li>数据集中包含10万个样本，覆盖了指令生成任务的多种场景。</li>
<li>核心创新点在于引入了生成任务种子的方法，确保生成数据的多样性和针对性。</li>
<li>作者还设计了一种基于偏好学习的优化方法，以提高LLM对细粒度任务的判断能力。</li>
<li>研究表明，经过这种优化后的JudgeLM在多个基准测试中超越了传统方法。</li>
</ul>
</li>
<li><p><strong>Meta-Rewarding</strong>【Wu et al., 2024】：</p>
<ul>
<li>提出了一种新颖的“元奖励”（Meta-Rewarding）方法，通过LLM自我评估生成的判断信号增强训练效果。</li>
<li>该方法要求模型在生成答案后对自己的输出进行评分，从而生成偏好数据。</li>
<li>创新点在于采用策略模型作为评估者，显著提高了数据生成效率和质量。</li>
<li>此外，该研究通过逐步改进的偏好数据训练LLM，提高了其评估任务的鲁棒性。</li>
<li>最终，Meta-Rewarding展示了LLM自我增强能力的潜力，成为偏好学习领域的重要进展。</li>
</ul>
</li>
</ol>
<h5 id="调优方法"><a href="#调优方法" class="headerlink" title="调优方法"></a>调优方法</h5><h6 id="1-监督微调（SFT）"><a href="#1-监督微调（SFT）" class="headerlink" title="1. 监督微调（SFT）"></a>1. <strong>监督微调（SFT）</strong></h6><p>监督微调通过使用人工标注或合成数据，让LLM从示例中学习判断标准。以下是核心研究及其创新点：</p>
<ol>
<li><p><strong>FLAMe</strong>【Vu et al., 2024】：</p>
<ul>
<li>该研究提出了Foundational Large Autorater Models (FLAMe)，利用超过500万个样本进行大规模多任务监督微调。</li>
<li>FLAMe在多任务数据中引入了统一的评价标准，提高了模型在多样化任务中的评估能力。</li>
<li>创新点在于采用多任务学习框架，将多个评估维度集成到一个模型中。</li>
<li>作者还设计了任务分层训练策略，使模型能够逐步掌握复杂的评估任务。</li>
<li>实验结果表明，FLAMe在多个生成任务上的表现优于传统评估指标。</li>
</ul>
</li>
<li><p><strong>JSFT</strong>【Lee et al., 2024】：</p>
<ul>
<li>提出了Judge-augmented Supervised Fine-Tuning（JSFT）方法，通过扩展偏好学习数据增强微调效果。</li>
<li>数据集中包含点对点和对比评估任务，以全面覆盖多种评估场景。</li>
<li>创新点在于引入了多阶段训练策略，结合监督学习和偏好学习优化模型性能。</li>
<li>此外，研究者设计了简化提示机制，显著提高了模型处理复杂输入的能力。</li>
<li>JSFT的实验结果显示，其生成的评估结果在多个基准上超过了现有方法。</li>
</ul>
</li>
</ol>
<h6 id="2-偏好学习"><a href="#2-偏好学习" class="headerlink" title="2. 偏好学习"></a>2. <strong>偏好学习</strong></h6><p>偏好学习通过优化LLM的比较和排序能力，适用于复杂评估任务。以下是核心研究及其创新点：</p>
<ol>
<li><p><strong>HALU-J</strong>【Wang et al., 2024a】：</p>
<ul>
<li>提出了一种基于批评的偏好学习方法，专注于选择相关证据并生成详细批评。</li>
<li>创新点在于设计了多证据选择机制，提高了LLM的可靠性评估能力。</li>
<li>该方法通过Directed Preference Optimization（DPO）进行优化，使模型能够更准确地判断任务间的优劣。</li>
<li>HALU-J还结合了上下文推理，扩展了偏好学习的应用场景。</li>
<li>实验表明，HALU-J显著提升了复杂任务的评估准确性，尤其是在事实性和逻辑性判断上。</li>
</ul>
</li>
<li><p><strong>Self-Taught Evaluators</strong>【Wang et al., 2024f】：</p>
<ul>
<li>该研究提出了一种自学习的评估者方法，利用被扰乱的指令生成低质量数据作为偏好学习的负样本。</li>
<li>自学习方法通过自动生成的次优响应，提供了丰富的训练数据。</li>
<li>创新点在于通过动态调整偏好信号，提升了模型的适应性和通用性。</li>
<li>作者还设计了基于多轮交互的学习策略，使模型能够在动态环境中自我优化。</li>
<li>实验结果显示，Self-Taught Evaluators在多个开放式生成任务中表现优异。</li>
</ul>
</li>
</ol>
<h3 id="4-2-提示技术"><a href="#4-2-提示技术" class="headerlink" title="4.2 提示技术"></a>4.2 提示技术</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>提示技术（Prompting）通过设计高效的提示策略和推理流程优化LLM的评估能力。这部分探讨如何在推理阶段利用提示技术提升判断精度，减少偏差，并增强模型的评估鲁棒性。主要方法包括操作交换、规则增强、多代理协作、演示、多轮交互以及比较加速。</p>
<hr>
<h4 id="4-2-1-操作交换（Swapping-Operation）"><a href="#4-2-1-操作交换（Swapping-Operation）" class="headerlink" title="4.2.1 操作交换（Swapping Operation）"></a>4.2.1 操作交换（Swapping Operation）</h4><h5 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h5><p>操作交换技术通过更改候选项顺序减少评估的偏置性，确保LLM对输入顺序不敏感，从而提高评估的公平性和可靠性。</p>
<h6 id="1-MT-Bench【Zheng-et-al-2023】："><a href="#1-MT-Bench【Zheng-et-al-2023】：" class="headerlink" title="1. MT-Bench【Zheng et al., 2023】："></a>1. <strong>MT-Bench</strong>【Zheng et al., 2023】：</h6><ul>
<li>本研究首次系统性地提出操作交换技术，通过多轮评估减少LLM的顺序敏感性。</li>
<li>创新点在于引入“对称性检查”机制：将候选项顺序互换，若评分结果一致，则标记为稳定，否则标记为不稳定。</li>
<li>作者发现操作交换能够有效减少由于位置偏差导致的错误判断。</li>
<li>该技术应用于多任务评估中，尤其是在复杂生成任务的排序中表现突出。</li>
<li>MT-Bench为后续的LLM评估技术提供了一个重要的公平性基准。</li>
</ul>
<h6 id="2-Starling【Zhu-et-al-2024a】："><a href="#2-Starling【Zhu-et-al-2024a】：" class="headerlink" title="2. Starling【Zhu et al., 2024a】："></a>2. <strong>Starling</strong>【Zhu et al., 2024a】：</h6><ul>
<li>提出一种类似链式推理（Chain-of-Thought, CoT）的提示技术，通过全面评估所有候选项的两两关系，再总结为最终排序。</li>
<li>创新点在于强制模型生成所有可能的对比结果，确保评估全面且无偏。</li>
<li>作者还设计了一种交叉验证机制，进一步提高评估稳定性。</li>
<li>实验显示，这种方法显著减少了位置偏差带来的误差，特别是在排序任务中表现优异。</li>
<li>Starling验证了链式思维结合操作交换技术的潜力，尤其在复杂对比任务中的效果显著。</li>
</ul>
<hr>
<h4 id="4-2-2-规则增强（Rule-Augmentation）"><a href="#4-2-2-规则增强（Rule-Augmentation）" class="headerlink" title="4.2.2 规则增强（Rule Augmentation）"></a>4.2.2 规则增强（Rule Augmentation）</h4><h5 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h5><p>规则增强技术通过在提示中嵌入明确的原则、标准或参考内容，使模型能够更加系统地评估任务，从而提升评估的准确性和一致性。</p>
<h6 id="1-Constitutional-AI【Bai-et-al-2022】："><a href="#1-Constitutional-AI【Bai-et-al-2022】：" class="headerlink" title="1. Constitutional AI【Bai et al., 2022】："></a>1. <strong>Constitutional AI</strong>【Bai et al., 2022】：</h6><ul>
<li>本研究引入了“原则驱动”的规则增强方法，利用帮助性、无害性和诚实性等标准指导模型评估。</li>
<li>创新点在于为每个评估维度定义详细的评分标准，并通过原则约束生成内容。</li>
<li>作者采用多层提示设计，使LLM能够逐步推理并给出最终评估。</li>
<li>实验表明，这种方法显著提升了模型在复杂场景中的判断一致性。</li>
<li>Constitutional AI成为后续研究的重要基石，为基于规则的评估技术奠定了基础。</li>
</ul>
<h6 id="2-OAIF【Guo-et-al-2024】："><a href="#2-OAIF【Guo-et-al-2024】：" class="headerlink" title="2. OAIF【Guo et al., 2024】："></a>2. <strong>OAIF</strong>【Guo et al., 2024】：</h6><ul>
<li>提出了在线AI反馈（Online AI Feedback, OAIF）框架，通过实时原则指导提升模型评估的灵活性。</li>
<li>核心创新点在于动态调整评估规则，使模型能够适应多变的任务需求。</li>
<li>OAIF引入了细粒度的多维评分策略，为每个候选项生成独立的评估报告。</li>
<li>作者验证了这种方法在实时决策中的潜力，尤其在对话和生成任务中表现突出。</li>
<li>OAIF展现了规则增强的实时适应能力，为实时评估任务提供了新方向。</li>
</ul>
<hr>
<h4 id="4-2-3-多代理协作（Multi-agent-Collaboration）"><a href="#4-2-3-多代理协作（Multi-agent-Collaboration）" class="headerlink" title="4.2.3 多代理协作（Multi-agent Collaboration）"></a>4.2.3 多代理协作（Multi-agent Collaboration）</h4><h5 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h5><p>多代理协作通过组合多个LLM的评估结果，减少单一模型的偏差，提高评估的准确性和鲁棒性。这种方法强调模型之间的角色分工和合作。</p>
<h6 id="1-Peer-Rank-PR-【Li-et-al-2023】："><a href="#1-Peer-Rank-PR-【Li-et-al-2023】：" class="headerlink" title="1. **Peer Rank (PR)**【Li et al., 2023】："></a>1. **Peer Rank (PR)**【Li et al., 2023】：</h6><ul>
<li>提出了同行排名算法，整合多个LLM的对比偏好生成最终排序。</li>
<li>创新点在于设计了“加权投票”机制，根据模型之间的评分一致性调整权重。</li>
<li>该研究还探讨了代理间的协作效率和鲁棒性，提出了优化协作路径的方法。</li>
<li>PR的实验结果显示，其生成的评估结果在排序准确性上优于传统单模型方法。</li>
<li>该研究为多模型协作技术奠定了理论基础，是后续研究的重要参考。</li>
</ul>
<h6 id="2-Cascaded-Selective-Evaluation【Jung-et-al-2024】："><a href="#2-Cascaded-Selective-Evaluation【Jung-et-al-2024】：" class="headerlink" title="2. Cascaded Selective Evaluation【Jung et al., 2024】："></a>2. <strong>Cascaded Selective Evaluation</strong>【Jung et al., 2024】：</h6><ul>
<li>设计了级联选择评估框架，首先由较弱的模型进行初步评估，仅在需要时调用更强大的模型。</li>
<li>创新点在于通过分级策略优化计算成本，同时确保评估结果的高质量。</li>
<li>作者提出了一种交叉验证机制，结合多个代理的结果生成最终判断。</li>
<li>研究表明，这种级联策略在复杂任务中表现出显著的资源效率提升。</li>
<li>Cascaded Selective Evaluation展示了多代理协作在资源有限情况下的潜力。</li>
</ul>
<hr>
<h4 id="4-2-4-演示（Demonstration）"><a href="#4-2-4-演示（Demonstration）" class="headerlink" title="4.2.4 演示（Demonstration）"></a>4.2.4 演示（Demonstration）</h4><h5 id="概述-5"><a href="#概述-5" class="headerlink" title="概述"></a>概述</h5><p>演示技术利用具体的示例作为提示，帮助LLM学习评估标准。这种方法通过少量高质量样例显著提高模型的评估能力。</p>
<h6 id="1-ALLURE【Hasanbeig-et-al-2023】："><a href="#1-ALLURE【Hasanbeig-et-al-2023】：" class="headerlink" title="1. ALLURE【Hasanbeig et al., 2023】："></a>1. <strong>ALLURE</strong>【Hasanbeig et al., 2023】：</h6><ul>
<li>提出了迭代演示技术，通过在提示中加入显著偏差的示例提高模型的鲁棒性。</li>
<li>创新点在于采用动态演示方法，逐步更新提示以适应不同的评估任务。</li>
<li>研究表明，这种方法在低资源场景中表现出色，尤其是在新任务的适应性上有显著提升。</li>
<li>作者还探讨了如何选择代表性样例以最大化演示效果。</li>
<li>ALLURE验证了高质量演示样例在提升评估能力方面的重要性。</li>
</ul>
<h6 id="2-ICE【Jain-et-al-2023b】："><a href="#2-ICE【Jain-et-al-2023b】：" class="headerlink" title="2. ICE【Jain et al., 2023b】："></a>2. <strong>ICE</strong>【Jain et al., 2023b】：</h6><ul>
<li>提出了交互式多维评估框架，通过少量上下文示例指导LLM评估。</li>
<li>创新点在于将评估任务分解为多个独立维度，每个维度都有针对性的示例支持。</li>
<li>研究表明，ICE框架显著减少了模型在多维任务中的评估偏差。</li>
<li>实验结果显示，其生成的评估结果在与人工评价的一致性上达到高水平。</li>
<li>ICE为多维度评估任务的提示设计提供了新思路。</li>
</ul>
<hr>
<h4 id="4-2-5-多轮交互（Multi-turn-Interaction）"><a href="#4-2-5-多轮交互（Multi-turn-Interaction）" class="headerlink" title="4.2.5 多轮交互（Multi-turn Interaction）"></a>4.2.5 多轮交互（Multi-turn Interaction）</h4><h5 id="概述-6"><a href="#概述-6" class="headerlink" title="概述"></a>概述</h5><p>多轮交互通过动态调整提示和上下文信息，为LLM提供更全面的评估依据，适用于需要多步推理的复杂任务。</p>
<h6 id="1-KIEval【Yu-et-al-2024】："><a href="#1-KIEval【Yu-et-al-2024】：" class="headerlink" title="1. KIEval【Yu et al., 2024】："></a>1. <strong>KIEval</strong>【Yu et al., 2024】：</h6><ul>
<li>提出了知识交互式评估框架，通过动态问答生成丰富的上下文信息。</li>
<li>创新点在于引入了“交互者”角色，模拟用户和模型之间的动态交互。</li>
<li>作者设计了一种鲁棒性检测机制，避免因上下文污染导致的错误评估。</li>
<li>研究表明，KIEval在复杂任务中的表现优于传统静态评估方法。</li>
<li>此框架适用于多维度评估，特别是在需要动态调整上下文的场景中。</li>
</ul>
<h6 id="2-Auto-Arena【Zhao-et-al-2024c】："><a href="#2-Auto-Arena【Zhao-et-al-2024c】：" class="headerlink" title="2. Auto-Arena【Zhao et al., 2024c】："></a>2. <strong>Auto-Arena</strong>【Zhao et al., 2024c】：</h6><ul>
<li>设计了一种多轮辩论框架，允许多个模型围绕特定任务进行交互讨论。</li>
<li>创新点在于结合多轮问答和动态评分机制，从不同角度对候选答案进行评估。</li>
<li>研究表明，这种方法能够揭示候选答案间的深层次差异。</li>
<li>作者还探讨了如何通过动态调整辩论内容提高评估效率。</li>
<li>Auto-Arena展示了多轮交互在复杂评估任务中的潜力。</li>
</ul>
<hr>
<h4 id="4-2-6-比较加速（Comparison-Acceleration）"><a href="#4-2-6-比较加速（Comparison-Acceleration）" class="headerlink" title="4.2.6 比较加速（Comparison Acceleration）"></a>4.2.6 比较加速（Comparison Acceleration）</h4><h5 id="概述-7"><a href="#概述-7" class="headerlink" title="概述"></a>概述</h5><p>比较加速技术通过优化比较流程，减少多候选排序任务的计算成本，提高评估效率。</p>
<h6 id="1-Ranked-Pairing【Zhai-et-al-2024】："><a href="#1-Ranked-Pairing【Zhai-et-al-2024】：" class="headerlink" title="1. Ranked Pairing【Zhai et al., 2024】："></a>1. <strong>Ranked Pairing</strong>【Zhai et al., 2024】：</h6><ul>
<li>提出了一种基于基线比较的排序方法，通过对所有候选项与基线进行比较确定优劣。</li>
<li>创新点在于避免传统两两比较的高计算开销，显著提高了评估效率。</li>
<li>作者还设计了一种自适应比较策略，进一步优化排序性能。</li>
<li>研究表明，Ranked Pairing在大规模排序任务中表现出极高的效率。</li>
<li>此方法特别适用于需要快速生成排序结果的场景。</li>
</ul>
<h6 id="2-Tournament-based-Comparison【Lee-et-al-2024】："><a href="#2-Tournament-based-Comparison【Lee-et-al-2024】：" class="headerlink" title="2. Tournament-based Comparison【Lee et al., 2024】："></a>2. <strong>Tournament-based Comparison</strong>【Lee et al., 2024】：</h6><ul>
<li>采用锦标赛式的比较方法，构建树状结构逐层筛选最佳</li>
</ul>
<p>候选。</p>
<ul>
<li>创新点在于结合拒绝采样和多轮比较，减少了低质量候选的影响。</li>
<li>作者探讨了不同树结构设计对评估效率和准确性的影响。</li>
<li>实验结果显示，该方法在多候选任务中显著提高了计算效率。</li>
<li>Tournament-based Comparison展示了基于结构化比较的潜在优势。</li>
</ul>
<hr>
<h3 id="5-应用场景"><a href="#5-应用场景" class="headerlink" title="5. 应用场景"></a>5. 应用场景</h3><h4 id="概述-8"><a href="#概述-8" class="headerlink" title="概述"></a>概述</h4><p>LLM-as-a-Judge的应用场景已从最初的生成任务评估扩展到多个领域，包括评估、对齐（Alignment）、检索和推理（Reasoning）。这一部分系统性地介绍这些应用场景，讨论每种应用的具体任务和代表性研究。</p>
<hr>
<h4 id="5-1-评估"><a href="#5-1-评估" class="headerlink" title="5.1 评估"></a>5.1 评估</h4><h5 id="概述-9"><a href="#概述-9" class="headerlink" title="概述"></a>概述</h5><p>LLM-as-a-Judge最初的核心应用是评估任务，包括开放式生成任务（如对话生成、摘要生成）、推理任务，以及其他新兴任务。通过LLM评估，能够更精准地捕捉复杂生成任务中的质量、相关性及逻辑性等维度。</p>
<h6 id="1-MD-Judge【Li-et-al-2024f】："><a href="#1-MD-Judge【Li-et-al-2024f】：" class="headerlink" title="1. MD-Judge【Li et al., 2024f】："></a>1. <strong>MD-Judge</strong>【Li et al., 2024f】：</h6><ul>
<li>提出了专门针对安全性相关问答的评估框架，用于检测LLM在生成敏感内容时的可靠性。</li>
<li>创新点在于设计了多维度的安全性评估标准，包括潜在伤害性、道德风险以及语言误导性。</li>
<li>作者通过对比多个LLM的评估能力，验证了MD-Judge框架的鲁棒性。</li>
<li>此框架在评估复杂场景（如恶意问题）的生成效果方面表现突出。</li>
<li>MD-Judge为生成模型的安全性评估提供了一个新的基准。</li>
</ul>
<h6 id="2-Chan框架【Chan-et-al-2023】："><a href="#2-Chan框架【Chan-et-al-2023】：" class="headerlink" title="2. Chan框架【Chan et al., 2023】："></a>2. <strong>Chan框架</strong>【Chan et al., 2023】：</h6><ul>
<li>提出了一个多代理辩论框架，通过让多个LLM角色分别生成答案并彼此评估，提升生成任务的评估质量。</li>
<li>创新点在于设计了角色分工机制，不同模型在辩论中扮演不同的立场，从多角度评估候选答案。</li>
<li>研究表明，该框架能够显著提升评估结果的细粒度和多样性。</li>
<li>作者还探讨了模型间的交互如何影响评估的一致性和公平性。</li>
<li>Chan框架在开放式文本生成任务中的应用表明，模型之间的协作能够显著改进评估质量。</li>
</ul>
<h6 id="3-ICE【Jain-et-al-2023b】："><a href="#3-ICE【Jain-et-al-2023b】：" class="headerlink" title="3. ICE【Jain et al., 2023b】："></a>3. <strong>ICE</strong>【Jain et al., 2023b】：</h6><ul>
<li>提出了交互式多维评估框架，通过少量上下文示例指导LLM评估。</li>
<li>创新点在于将评估任务分解为多个独立维度，每个维度都有针对性的示例支持。</li>
<li>研究表明，ICE框架显著减少了模型在多维任务中的评估偏差。</li>
<li>实验结果显示，其生成的评估结果在与人工评价的一致性上达到高水平。</li>
<li>ICE为多维度评估任务的提示设计提供了新思路。</li>
</ul>
<hr>
<h4 id="5-2-对齐（Alignment）"><a href="#5-2-对齐（Alignment）" class="headerlink" title="5.2 对齐（Alignment）"></a>5.2 对齐（Alignment）</h4><h5 id="概述-10"><a href="#概述-10" class="headerlink" title="概述"></a>概述</h5><p>对齐任务的目标是通过训练或微调使LLM的生成内容更符合人类的价值观和偏好。LLM-as-a-Judge被广泛用于生成对齐数据和评估对齐效果。</p>
<h6 id="1-Constitutional-AI【Bai-et-al-2022】：-1"><a href="#1-Constitutional-AI【Bai-et-al-2022】：-1" class="headerlink" title="1. Constitutional AI【Bai et al., 2022】："></a>1. <strong>Constitutional AI</strong>【Bai et al., 2022】：</h6><ul>
<li>提出了基于原则对齐的框架，通过定义帮助性、无害性和诚实性等原则，优化生成模型的输出。</li>
<li>创新点在于将原则融入奖励建模过程，利用LLM生成的偏好信号构建对齐数据集。</li>
<li>作者通过多轮实验验证了这种基于规则的对齐方法对生成质量的显著提升。</li>
<li>此框架适用于各种生成任务，尤其在减少有害输出方面效果显著。</li>
<li>Constitutional AI的成功展示了基于规则的对齐方法的潜力。</li>
</ul>
<h6 id="2-DIRECT-RLAIF【Lee-et-al-2023】："><a href="#2-DIRECT-RLAIF【Lee-et-al-2023】：" class="headerlink" title="2. DIRECT-RLAIF【Lee et al., 2023】："></a>2. <strong>DIRECT-RLAIF</strong>【Lee et al., 2023】：</h6><ul>
<li>提出了一种直接强化学习对齐反馈（DIRECT-RLAIF）方法，通过较大的LLM生成偏好信号指导较小模型。</li>
<li>核心创新点在于利用较强的LLM模型作为动态评估者，避免传统奖励模型中存在的“奖励陈旧性”问题。</li>
<li>作者验证了这种方法在对齐生成任务中的有效性，特别是在开放式对话中的显著改进。</li>
<li>DIRECT-RLAIF为更高效的对齐方法提供了理论基础。</li>
<li>研究结果表明，这种方法可以在较少人工干预的情况下生成符合人类偏好的内容。</li>
</ul>
<h6 id="3-OAIF【Guo-et-al-2024】："><a href="#3-OAIF【Guo-et-al-2024】：" class="headerlink" title="3. OAIF【Guo et al., 2024】："></a>3. <strong>OAIF</strong>【Guo et al., 2024】：</h6><ul>
<li>提出了在线AI反馈（Online AI Feedback, OAIF）框架，通过实时原则指导提升模型评估的灵活性。</li>
<li>核心创新点在于动态调整评估规则，使模型能够适应多变的任务需求。</li>
<li>OAIF引入了细粒度的多维评分策略，为每个候选项生成独立的评估报告。</li>
<li>作者验证了这种方法在实时决策中的潜力，尤其在对话和生成任务中表现突出。</li>
<li>OAIF展现了规则增强的实时适应能力，为实时评估任务提供了新方向。</li>
</ul>
<hr>
<h4 id="5-3-检索（Retrieval）"><a href="#5-3-检索（Retrieval）" class="headerlink" title="5.3 检索（Retrieval）"></a>5.3 检索（Retrieval）</h4><h5 id="概述-11"><a href="#概述-11" class="headerlink" title="概述"></a>概述</h5><p>在检索场景中，LLM-as-a-Judge主要用于提升文档排序的精度和检索增强生成（RAG）的效果。通过更高效的排序算法，LLM能够在传统检索和复杂生成任务中提供更高质量的相关性评估。</p>
<h6 id="1-Ranked-Pairing【Zhai-et-al-2024】：-1"><a href="#1-Ranked-Pairing【Zhai-et-al-2024】：-1" class="headerlink" title="1. Ranked Pairing【Zhai et al., 2024】："></a>1. <strong>Ranked Pairing</strong>【Zhai et al., 2024】：</h6><ul>
<li>提出了一种基于基线比较的排序方法，通过对所有候选项与基线进行比较确定优劣。</li>
<li>创新点在于避免传统两两比较的高计算开销，显著提高了评估效率。</li>
<li>作者还设计了一种自适应比较策略，进一步优化排序性能。</li>
<li>研究表明，Ranked Pairing在大规模排序任务中表现出极高的效率。</li>
<li>此方法特别适用于需要快速生成排序结果的场景。</li>
</ul>
<h6 id="2-LLM-Eval【Lin-and-Chen-2023a】："><a href="#2-LLM-Eval【Lin-and-Chen-2023a】：" class="headerlink" title="2. LLM-Eval【Lin and Chen, 2023a】："></a>2. <strong>LLM-Eval</strong>【Lin and Chen, 2023a】：</h6><ul>
<li>提出了在对话生成中的相关性评估框架，利用LLM替代人工标注。</li>
<li>创新点在于设计了结合上下文和生成内容的提示技术，确保评估更加精确。</li>
<li>作者通过对比实验验证了LLM在会话相关性评估中的潜力，结果与人工标注高度一致。</li>
<li>此框架显著减少了评估成本，同时提升了效率。</li>
<li>LLM-Eval在对话生成任务中的应用表明，模型在生成评估中的角色日益重要。</li>
</ul>
<h6 id="3-ToT-Tree-of-Thought-【Yao-et-al-2023a】："><a href="#3-ToT-Tree-of-Thought-【Yao-et-al-2023a】：" class="headerlink" title="3. **ToT (Tree of Thought)**【Yao et al., 2023a】："></a>3. **ToT (Tree of Thought)**【Yao et al., 2023a】：</h6><ul>
<li>提出了通过树状结构增强推理能力的方法，并结合LLM进行评估。</li>
<li>创新点在于引入了状态评估模块，通过逐步筛选最优推理路径提升检索和生成任务的精度。</li>
<li>研究表明，ToT框架显著提升了复杂任务的解决能力，尤其在多步推理和决策中表现优异。</li>
<li>作者还提出了评估路径的动态调整机制，使LLM能够更灵活地应对多样化任务。</li>
<li>ToT验证了结构化评估框架在复杂任务中的有效性。</li>
</ul>
<hr>
<h4 id="5-4-推理（Reasoning）"><a href="#5-4-推理（Reasoning）" class="headerlink" title="5.4 推理（Reasoning）"></a>5.4 推理（Reasoning）</h4><h5 id="概述-12"><a href="#概述-12" class="headerlink" title="概述"></a>概述</h5><p>推理任务的核心是评估LLM的中间推理过程和最终答案的正确性。LLM-as-a-Judge在数学推理、时间推理和复杂逻辑推理任务中展示了显著的评估能力。</p>
<h6 id="1-HALU-J【Wang-et-al-2024a】："><a href="#1-HALU-J【Wang-et-al-2024a】：" class="headerlink" title="1. HALU-J【Wang et al., 2024a】："></a>1. <strong>HALU-J</strong>【Wang et al., 2024a】：</h6><ul>
<li>提出了一种基于批评的偏好学习方法，专注于选择相关证据并生成详细批评。</li>
<li>创新点在于设计了多证据选择机制，提高了LLM的可靠性评估能力。</li>
<li>该方法通过Directed Preference Optimization（DPO）进行优化，使模型能够更准确地判断任务间的优劣。</li>
<li>HALU-J还结合了上下文推理，扩展了偏好学习的应用场景。</li>
<li>实验表明，HALU-J显著提升了复杂任务的评估准确性，尤其是在事实性和逻辑性判断上。</li>
</ul>
<h6 id="2-KIEval【Yu-et-al-2024】："><a href="#2-KIEval【Yu-et-al-2024】：" class="headerlink" title="2. KIEval【Yu et al., 2024】："></a>2. <strong>KIEval</strong>【Yu et al., 2024】：</h6><ul>
<li>提出了知识交互式评估框架，通过动态问答生成丰富的上下文信息。</li>
<li>创新点在于引入了“交互者”角色，模拟用户和模型之间的动态交互。</li>
<li>作者设计了一种鲁棒性检测机制，避免因上下文污染导致的错误评估。</li>
<li>研究表明，KIEval在复杂任务中的表现优于传统静态评估方法。</li>
<li>此框架适用于多维度评估，特别是在需要动态调整上下文的场景中。</li>
</ul>
<hr>
<h3 id="6-评估基准"><a href="#6-评估基准" class="headerlink" title="6. 评估基准"></a>6. 评估基准</h3><h4 id="概述-13"><a href="#概述-13" class="headerlink" title="概述"></a>概述</h4><p>评估基准是验证LLM-as-a-Judge能力的重要工具。本节整理并介绍当前用于不同评估维度的基准，包括有用性、无害性、可靠性等方面的具体框架和其核心思想。这些基准覆盖了从对话生成到复杂任务推理的广泛应用场景，为后续研究提供了关键数据支持。</p>
<hr>
<h5 id="6-1-综合评估基准"><a href="#6-1-综合评估基准" class="headerlink" title="6.1 综合评估基准"></a>6.1 综合评估基准</h5><h6 id="1-SORRY-Bench【Xie-et-al-2024a】："><a href="#1-SORRY-Bench【Xie-et-al-2024a】：" class="headerlink" title="1. SORRY-Bench【Xie et al., 2024a】："></a>1. <strong>SORRY-Bench</strong>【Xie et al., 2024a】：</h6><ul>
<li>设计了一个专注于安全性和无害性评估的综合基准，重点测试LLM对潜在有害内容的拒绝能力。</li>
<li>创新点在于提供了一个多模型对比框架，包括开源和专有LLM的表现分析。</li>
<li>基准数据集涵盖多种潜在危险场景，如政治敏感内容和虚假信息生成。</li>
<li>作者还引入了动态拒绝率作为衡量指标，展示了不同模型在拒绝任务中的细粒度表现。</li>
<li>实验表明，小型LLM经过微调后可以在安全性评估中达到与大型模型相当的水平。</li>
</ul>
<h6 id="2-HalluJudge【Luo-et-al-2024】："><a href="#2-HalluJudge【Luo-et-al-2024】：" class="headerlink" title="2. HalluJudge【Luo et al., 2024】："></a>2. <strong>HalluJudge</strong>【Luo et al., 2024】：</h6><ul>
<li>提出了一个专门用于对话级事实性评估的基准，涵盖大规模对话数据集。</li>
<li>核心创新在于设计了一种细粒度的事实性评分机制，通过引入上下文验证生成内容的准确性。</li>
<li>数据集中包括多种类型的事实性错误，如数据遗漏、模糊表述和直接虚假信息。</li>
<li>HalluJudge还整合了自动化和人工评估方法，提高了基准的覆盖面和可靠性。</li>
<li>实验结果表明，HalluJudge能够显著提高LLM在对话场景中的事实性检测能力。</li>
</ul>
<hr>
<h5 id="6-2-专用领域评估基准"><a href="#6-2-专用领域评估基准" class="headerlink" title="6.2 专用领域评估基准"></a>6.2 专用领域评估基准</h5><h6 id="1-FaithScore【Jing-et-al-2024】："><a href="#1-FaithScore【Jing-et-al-2024】：" class="headerlink" title="1. FaithScore【Jing et al., 2024】："></a>1. <strong>FaithScore</strong>【Jing et al., 2024】：</h6><ul>
<li>FaithScore是第一个跨模态的可靠性评估框架，适用于文本和图像生成任务。</li>
<li>创新点在于设计了多模态评估方法，结合语言和视觉信号来验证生成内容的真实性。</li>
<li>数据集覆盖了从事实描述到跨模态推理的多个任务，测试了模型的全局一致性和细节准确性。</li>
<li>FaithScore还引入了多阶段评分机制，逐步分解任务以提高评估的精细化程度。</li>
<li>实验显示，FaithScore在多模态生成任务中的评估结果与人工评分高度一致。</li>
</ul>
<h6 id="2-GEMBA【Kocmi-and-Federmann-2023】："><a href="#2-GEMBA【Kocmi-and-Federmann-2023】：" class="headerlink" title="2. GEMBA【Kocmi and Federmann, 2023】："></a>2. <strong>GEMBA</strong>【Kocmi and Federmann, 2023】：</h6><ul>
<li>GEMBA基准专注于机器翻译和文本摘要任务的整体质量评估。</li>
<li>核心创新点在于结合BLEU等传统指标和LLM生成的综合评分，提供更全面的评估结果。</li>
<li>数据集中包含多种语言和领域的真实文本，覆盖多样化的任务需求。</li>
<li>作者设计了一种动态反馈机制，允许LLM在评估过程中进行自适应调整。</li>
<li>GEMBA基准的引入显著推动了机器翻译和摘要任务中LLM-as-a-Judge的应用。</li>
</ul>
<h6 id="3-Just-Eval【Lin-et-al-2023】："><a href="#3-Just-Eval【Lin-et-al-2023】：" class="headerlink" title="3. Just-Eval【Lin et al., 2023】："></a>3. <strong>Just-Eval</strong>【Lin et al., 2023】：</h6><ul>
<li>提出了一个基于生成内容有用性和无害性的综合基准，适用于广泛的开放式任务。</li>
<li>创新点在于为不同任务设计了定制化的评估标准，并结合多维评分系统生成最终评价。</li>
<li>数据集中涵盖了对话、问答和复杂推理等任务，验证了基准的通用性。</li>
<li>作者还分析了模型在不同任务和领域上的表现，提供了详细的对比结果。</li>
<li>Just-Eval的应用表明，评估框架需要结合任务特点进行优化，才能最大化评估的准确性。</li>
</ul>
<hr>
<h4 id="6-3-动态评估基准"><a href="#6-3-动态评估基准" class="headerlink" title="6.3 动态评估基准"></a>6.3 动态评估基准</h4><h6 id="1-RevisEval【Zhang-et-al-2024e】："><a href="#1-RevisEval【Zhang-et-al-2024e】：" class="headerlink" title="1. RevisEval【Zhang et al., 2024e】："></a>1. <strong>RevisEval</strong>【Zhang et al., 2024e】：</h6><ul>
<li>RevisEval通过引入动态自我修正机制，让LLM在生成评估之前对输出进行多次调整。</li>
<li>核心创新在于结合LLM的自我纠错能力，将最终输出用于多维度评估。</li>
<li>数据集中覆盖了对话生成、摘要和复杂推理任务，验证了基准的动态适应能力。</li>
<li>RevisEval引入了多轮反馈机制，允许模型在评估过程中迭代改进。</li>
<li>实验结果表明，动态评估能够显著提升复杂任务中评估的精确性和稳定性。</li>
</ul>
<h6 id="2-Meta-ranking【Liu-et-al-2024c】："><a href="#2-Meta-ranking【Liu-et-al-2024c】：" class="headerlink" title="2. Meta-ranking【Liu et al., 2024c】："></a>2. <strong>Meta-ranking</strong>【Liu et al., 2024c】：</h6><ul>
<li>Meta-ranking框架通过弱模型生成初步排序，再由强模型进行最终评估。</li>
<li>创新点在于使用多阶段的排名方法，提高评估效率并降低计算开销。</li>
<li>数据集中包含了多种任务类型，并通过实验验证了Meta-ranking的通用性。</li>
<li>该框架特别适用于大规模排序任务，显著减少了评估时间。</li>
<li>Meta-ranking展示了弱模型和强模型协作评估的潜力，是多模型评估的新方向。</li>
</ul>
<hr>
<h3 id="7-挑战与未来方向"><a href="#7-挑战与未来方向" class="headerlink" title="7. 挑战与未来方向"></a>7. 挑战与未来方向</h3><h4 id="概述-14"><a href="#概述-14" class="headerlink" title="概述"></a>概述</h4><p>尽管LLM-as-a-Judge在评估任务中展现了强大能力，但依然面临着多方面的挑战。主要问题包括评估偏差与脆弱性、动态与复杂任务中的适应性，以及人机协同评估的潜力。本节探讨这些挑战并提出未来的研究方向。</p>
<hr>
<h5 id="7-1-偏差与脆弱性"><a href="#7-1-偏差与脆弱性" class="headerlink" title="7.1 偏差与脆弱性"></a>7.1 偏差与脆弱性</h5><h6 id="1-OffsetBias【Park-et-al-2024】："><a href="#1-OffsetBias【Park-et-al-2024】：" class="headerlink" title="1. OffsetBias【Park et al., 2024】："></a>1. <strong>OffsetBias</strong>【Park et al., 2024】：</h6><ul>
<li>OffsetBias通过设计一个去偏优化框架，减少LLM在评估任务中的位置偏差和内容偏见。</li>
<li>创新点在于使用合成数据生成“坏”样本，通过训练模型识别并修正偏差。</li>
<li>作者提出了一种多维度的去偏学习机制，确保评估在不同场景下的一致性。</li>
<li>研究表明，OffsetBias能够显著降低模型在生成任务中的不公平表现。</li>
<li>此方法为减少LLM评估中的偏差问题提供了重要方向。</li>
</ul>
<h6 id="2-SORRY-Bench【Xie-et-al-2024a】："><a href="#2-SORRY-Bench【Xie-et-al-2024a】：" class="headerlink" title="2. SORRY-Bench【Xie et al., 2024a】："></a>2. <strong>SORRY-Bench</strong>【Xie et al., 2024a】：</h6><ul>
<li>进一步研究了模型在拒绝有害内容时可能出现的误拒绝问题。</li>
<li>创新点在于结合动态评分机制和拒绝数据集，分析模型在多种任务中的拒绝倾向。</li>
<li>作者指出，小型模型在特定场景中可能比大型模型更高效。</li>
<li>实验结果表明，SORRY-Bench能够帮助识别并减轻评估偏差。</li>
<li>此基准成为探讨评估脆弱性的一个重要工具。</li>
</ul>
<hr>
<h5 id="7-2-动态与复杂评估"><a href="#7-2-动态与复杂评估" class="headerlink" title="7.2 动态与复杂评估"></a>7.2 动态与复杂评估</h5><h6 id="1-Tree-of-Thought-ToT-【Yao-et-al-2023a】："><a href="#1-Tree-of-Thought-ToT-【Yao-et-al-2023a】：" class="headerlink" title="1. **Tree of Thought (ToT)**【Yao et al., 2023a】："></a>1. **Tree of Thought (ToT)**【Yao et al., 2023a】：</h6><ul>
<li>ToT通过树状结构优化复杂任务的多步推理和评估。</li>
<li>创新点在于结合动态状态评估机制，使评估更加适应复杂多变的任务需求。</li>
<li>数据集中覆盖了需要多步推理的复杂任务，如问答和决策优化。</li>
<li>实验表明，ToT框架显著提升了复杂任务的解决能力和评估准确性。</li>
<li>该研究为动态评估提供了新的理论和实践支持。</li>
</ul>
<h6 id="2-RAIN【Li-et-al-2024】："><a href="#2-RAIN【Li-et-al-2024】：" class="headerlink" title="2. RAIN【Li et al., 2024】："></a>2. <strong>RAIN</strong>【Li et al., 2024】：</h6><ul>
<li>RAIN提出了可回溯的自回归推理机制，让LLM能够在评估过程中动态修正错误。</li>
<li>创新点在于结合自我评估和多轮推理机制，确保最终输出的高质量。</li>
<li>作者还设计了一种动态调整机制，使模型能够适应不同任务的变化。</li>
<li>实验显示，RAIN在复杂任务中的评估能力优于传统静态方法。</li>
<li>此框架展示了动态评估在复杂场景中的潜力。</li>
</ul>
<hr>
<h5 id="7-3-自我评估与人机协同"><a href="#7-3-自我评估与人机协同" class="headerlink" title="7.3 自我评估与人机协同"></a>7.3 自我评估与人机协同</h5><h6 id="1-Self-Taught-Evaluators【Wang-et-al-2024f】："><a href="#1-Self-Taught-Evaluators【Wang-et-al-2024f】：" class="headerlink" title="1. Self-Taught Evaluators【Wang et al., 2024f】："></a>1. <strong>Self-Taught Evaluators</strong>【Wang et al., 2024f】：</h6><ul>
<li>提出了一种自我学习框架，模型通过生成低质量数据对自身进行动态优化。</li>
<li>创新点在于引入了一种动态评估机制，让模型能够逐步提升自身评估能力。</li>
<li>数据集中包括了多种类型的任务，为自我评估提供了广泛支持。</li>
<li>Self-Taught Evaluators展示了模型在无需人工干预情况下的自我提升能力。</li>
<li>此框架为自动化评估任务提供了新思路。</li>
</ul>
<h6 id="2-Meta-Rewarding【Wu-et-al-2024】："><a href="#2-Meta-Rewarding【Wu-et-al-2024】：" class="headerlink" title="2. Meta-Rewarding【Wu et al., 2024】："></a>2. <strong>Meta-Rewarding</strong>【Wu et al., 2024】：</h6><ul>
<li>Meta-Rewarding通过将LLM的自评估信号作为偏好数据，用于进一步优化模型。</li>
<li>创新点在于结合策略模型自我反馈，增强模型的自适应能力。</li>
<li>作者还探讨了如何动态调整评估策略以提高鲁棒性。</li>
<li>实验表明，Meta-Rewarding能够显著提升复杂任务中的评估效果。</li>
<li>该研究展示了人机协同评估的潜在优势。</li>
</ul>
<hr>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Onnx/">Onnx</a><a class="post-meta__tags" href="/tags/Deployment/">Deployment</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/12/06/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment/" title=""><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info"></div></div></a></div><div class="next-post pull-right"><a href="/2024/12/03/Life%20Reflections/Reflections%20on%20Identity%20and%20Subjectivity/" title="Reflections on Identity and Subjectivity"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Reflections on Identity and Subjectivity</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/08/21/NLP%20Insights/Conver%20Pytorch%20Model%20to%20ONNX%20Format/" title="Conver Pytorch Model to ONNX Format"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-21</div><div class="title">Conver Pytorch Model to ONNX Format</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Huiyu Chen</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">42</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chenhuiyu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/chenhuiyu" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:chenhuiyu1997@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Welcome to my blog! I'm Huiyu, a data scientist in Singapore, passionate about NLP and AI. Here, I share insights on tech and sprinkle in some travel stories from my adventures.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E8%AF%84%E4%BC%B0%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%88%90%E5%88%B0%E5%88%A4%E6%96%AD%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">1.</span> <span class="toc-text">基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%BC%95%E8%A8%80"><span class="toc-number">1.2.</span> <span class="toc-text">1. 引言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E8%83%8C%E6%99%AF"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.1 背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E7%A0%94%E7%A9%B6%E9%97%AE%E9%A2%98"><span class="toc-number">1.2.2.</span> <span class="toc-text">1.2 研究问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86"><span class="toc-number">1.3.</span> <span class="toc-text">2. 预备知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E8%BE%93%E5%85%A5%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.3.1.</span> <span class="toc-text">2.1 输入格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.2 输出格式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%AF%84%E4%BC%B0%E5%B1%9E%E6%80%A7"><span class="toc-number">1.4.</span> <span class="toc-text">3. 评估属性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%9C%89%E7%94%A8%E6%80%A7%EF%BC%88Helpfulness%EF%BC%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.1 有用性（Helpfulness）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%97%A0%E5%AE%B3%E6%80%A7%EF%BC%88Harmlessness%EF%BC%89"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.2 无害性（Harmlessness）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%8F%AF%E9%9D%A0%E6%80%A7%EF%BC%88Reliability%EF%BC%89"><span class="toc-number">1.4.3.</span> <span class="toc-text">3.3 可靠性（Reliability）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E7%9B%B8%E5%85%B3%E6%80%A7%EF%BC%88Relevance%EF%BC%89"><span class="toc-number">1.4.4.</span> <span class="toc-text">3.4 相关性（Relevance）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E5%8F%AF%E8%A1%8C%E6%80%A7%EF%BC%88Feasibility%EF%BC%89"><span class="toc-number">1.4.5.</span> <span class="toc-text">3.5 可行性（Feasibility）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-%E6%80%BB%E4%BD%93%E8%B4%A8%E9%87%8F%EF%BC%88Overall-Quality%EF%BC%89"><span class="toc-number">1.4.6.</span> <span class="toc-text">3.6 总体质量（Overall Quality）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%96%B9%E6%B3%95%E8%AE%BA"><span class="toc-number">1.4.7.</span> <span class="toc-text">4. 方法论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">1.4.7.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E8%B0%83%E4%BC%98%E6%8A%80%E6%9C%AF"><span class="toc-number">1.4.7.2.</span> <span class="toc-text">4.1 调优技术</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90"><span class="toc-number">1.4.7.2.1.</span> <span class="toc-text">数据来源</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-%E4%BA%BA%E5%B7%A5%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE"><span class="toc-number">1.4.7.2.1.1.</span> <span class="toc-text">1. 人工标注数据</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE"><span class="toc-number">1.4.7.2.1.2.</span> <span class="toc-text">2. 合成数据</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B0%83%E4%BC%98%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.7.2.2.</span> <span class="toc-text">调优方法</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%EF%BC%88SFT%EF%BC%89"><span class="toc-number">1.4.7.2.2.1.</span> <span class="toc-text">1. 监督微调（SFT）</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-%E5%81%8F%E5%A5%BD%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.4.7.2.2.2.</span> <span class="toc-text">2. 偏好学习</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF"><span class="toc-number">1.4.8.</span> <span class="toc-text">4.2 提示技术</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-1"><span class="toc-number">1.4.8.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-%E6%93%8D%E4%BD%9C%E4%BA%A4%E6%8D%A2%EF%BC%88Swapping-Operation%EF%BC%89"><span class="toc-number">1.4.8.2.</span> <span class="toc-text">4.2.1 操作交换（Swapping Operation）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-2"><span class="toc-number">1.4.8.2.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-MT-Bench%E3%80%90Zheng-et-al-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.2.1.1.</span> <span class="toc-text">1. MT-Bench【Zheng et al., 2023】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Starling%E3%80%90Zhu-et-al-2024a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.2.1.2.</span> <span class="toc-text">2. Starling【Zhu et al., 2024a】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E8%A7%84%E5%88%99%E5%A2%9E%E5%BC%BA%EF%BC%88Rule-Augmentation%EF%BC%89"><span class="toc-number">1.4.8.3.</span> <span class="toc-text">4.2.2 规则增强（Rule Augmentation）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-3"><span class="toc-number">1.4.8.3.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Constitutional-AI%E3%80%90Bai-et-al-2022%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.3.1.1.</span> <span class="toc-text">1. Constitutional AI【Bai et al., 2022】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-OAIF%E3%80%90Guo-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.3.1.2.</span> <span class="toc-text">2. OAIF【Guo et al., 2024】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-%E5%A4%9A%E4%BB%A3%E7%90%86%E5%8D%8F%E4%BD%9C%EF%BC%88Multi-agent-Collaboration%EF%BC%89"><span class="toc-number">1.4.8.4.</span> <span class="toc-text">4.2.3 多代理协作（Multi-agent Collaboration）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-4"><span class="toc-number">1.4.8.4.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Peer-Rank-PR-%E3%80%90Li-et-al-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.4.1.1.</span> <span class="toc-text">1. **Peer Rank (PR)**【Li et al., 2023】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Cascaded-Selective-Evaluation%E3%80%90Jung-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.4.1.2.</span> <span class="toc-text">2. Cascaded Selective Evaluation【Jung et al., 2024】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-4-%E6%BC%94%E7%A4%BA%EF%BC%88Demonstration%EF%BC%89"><span class="toc-number">1.4.8.5.</span> <span class="toc-text">4.2.4 演示（Demonstration）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-5"><span class="toc-number">1.4.8.5.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-ALLURE%E3%80%90Hasanbeig-et-al-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.5.1.1.</span> <span class="toc-text">1. ALLURE【Hasanbeig et al., 2023】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-ICE%E3%80%90Jain-et-al-2023b%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.5.1.2.</span> <span class="toc-text">2. ICE【Jain et al., 2023b】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-5-%E5%A4%9A%E8%BD%AE%E4%BA%A4%E4%BA%92%EF%BC%88Multi-turn-Interaction%EF%BC%89"><span class="toc-number">1.4.8.6.</span> <span class="toc-text">4.2.5 多轮交互（Multi-turn Interaction）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-6"><span class="toc-number">1.4.8.6.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-KIEval%E3%80%90Yu-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.6.1.1.</span> <span class="toc-text">1. KIEval【Yu et al., 2024】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Auto-Arena%E3%80%90Zhao-et-al-2024c%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.6.1.2.</span> <span class="toc-text">2. Auto-Arena【Zhao et al., 2024c】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-6-%E6%AF%94%E8%BE%83%E5%8A%A0%E9%80%9F%EF%BC%88Comparison-Acceleration%EF%BC%89"><span class="toc-number">1.4.8.7.</span> <span class="toc-text">4.2.6 比较加速（Comparison Acceleration）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-7"><span class="toc-number">1.4.8.7.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Ranked-Pairing%E3%80%90Zhai-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.7.1.1.</span> <span class="toc-text">1. Ranked Pairing【Zhai et al., 2024】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Tournament-based-Comparison%E3%80%90Lee-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.8.7.1.2.</span> <span class="toc-text">2. Tournament-based Comparison【Lee et al., 2024】：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.4.9.</span> <span class="toc-text">5. 应用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-8"><span class="toc-number">1.4.9.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.9.2.</span> <span class="toc-text">5.1 评估</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-9"><span class="toc-number">1.4.9.2.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-MD-Judge%E3%80%90Li-et-al-2024f%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.2.1.1.</span> <span class="toc-text">1. MD-Judge【Li et al., 2024f】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Chan%E6%A1%86%E6%9E%B6%E3%80%90Chan-et-al-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.2.1.2.</span> <span class="toc-text">2. Chan框架【Chan et al., 2023】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-ICE%E3%80%90Jain-et-al-2023b%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.2.1.3.</span> <span class="toc-text">3. ICE【Jain et al., 2023b】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-%E5%AF%B9%E9%BD%90%EF%BC%88Alignment%EF%BC%89"><span class="toc-number">1.4.9.3.</span> <span class="toc-text">5.2 对齐（Alignment）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-10"><span class="toc-number">1.4.9.3.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Constitutional-AI%E3%80%90Bai-et-al-2022%E3%80%91%EF%BC%9A-1"><span class="toc-number">1.4.9.3.1.1.</span> <span class="toc-text">1. Constitutional AI【Bai et al., 2022】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-DIRECT-RLAIF%E3%80%90Lee-et-al-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.3.1.2.</span> <span class="toc-text">2. DIRECT-RLAIF【Lee et al., 2023】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-OAIF%E3%80%90Guo-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.3.1.3.</span> <span class="toc-text">3. OAIF【Guo et al., 2024】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-%E6%A3%80%E7%B4%A2%EF%BC%88Retrieval%EF%BC%89"><span class="toc-number">1.4.9.4.</span> <span class="toc-text">5.3 检索（Retrieval）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-11"><span class="toc-number">1.4.9.4.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Ranked-Pairing%E3%80%90Zhai-et-al-2024%E3%80%91%EF%BC%9A-1"><span class="toc-number">1.4.9.4.1.1.</span> <span class="toc-text">1. Ranked Pairing【Zhai et al., 2024】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-LLM-Eval%E3%80%90Lin-and-Chen-2023a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.4.1.2.</span> <span class="toc-text">2. LLM-Eval【Lin and Chen, 2023a】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-ToT-Tree-of-Thought-%E3%80%90Yao-et-al-2023a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.4.1.3.</span> <span class="toc-text">3. **ToT (Tree of Thought)**【Yao et al., 2023a】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-%E6%8E%A8%E7%90%86%EF%BC%88Reasoning%EF%BC%89"><span class="toc-number">1.4.9.5.</span> <span class="toc-text">5.4 推理（Reasoning）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-12"><span class="toc-number">1.4.9.5.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-HALU-J%E3%80%90Wang-et-al-2024a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.5.1.1.</span> <span class="toc-text">1. HALU-J【Wang et al., 2024a】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-KIEval%E3%80%90Yu-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.9.5.1.2.</span> <span class="toc-text">2. KIEval【Yu et al., 2024】：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E8%AF%84%E4%BC%B0%E5%9F%BA%E5%87%86"><span class="toc-number">1.4.10.</span> <span class="toc-text">6. 评估基准</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-13"><span class="toc-number">1.4.10.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#6-1-%E7%BB%BC%E5%90%88%E8%AF%84%E4%BC%B0%E5%9F%BA%E5%87%86"><span class="toc-number">1.4.10.1.1.</span> <span class="toc-text">6.1 综合评估基准</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-SORRY-Bench%E3%80%90Xie-et-al-2024a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.1.1.1.</span> <span class="toc-text">1. SORRY-Bench【Xie et al., 2024a】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-HalluJudge%E3%80%90Luo-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.1.1.2.</span> <span class="toc-text">2. HalluJudge【Luo et al., 2024】：</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-2-%E4%B8%93%E7%94%A8%E9%A2%86%E5%9F%9F%E8%AF%84%E4%BC%B0%E5%9F%BA%E5%87%86"><span class="toc-number">1.4.10.1.2.</span> <span class="toc-text">6.2 专用领域评估基准</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-FaithScore%E3%80%90Jing-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.1.2.1.</span> <span class="toc-text">1. FaithScore【Jing et al., 2024】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-GEMBA%E3%80%90Kocmi-and-Federmann-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.1.2.2.</span> <span class="toc-text">2. GEMBA【Kocmi and Federmann, 2023】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-Just-Eval%E3%80%90Lin-et-al-2023%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.1.2.3.</span> <span class="toc-text">3. Just-Eval【Lin et al., 2023】：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-%E5%8A%A8%E6%80%81%E8%AF%84%E4%BC%B0%E5%9F%BA%E5%87%86"><span class="toc-number">1.4.10.2.</span> <span class="toc-text">6.3 动态评估基准</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-RevisEval%E3%80%90Zhang-et-al-2024e%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.2.0.1.</span> <span class="toc-text">1. RevisEval【Zhang et al., 2024e】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Meta-ranking%E3%80%90Liu-et-al-2024c%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.10.2.0.2.</span> <span class="toc-text">2. Meta-ranking【Liu et al., 2024c】：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">1.4.11.</span> <span class="toc-text">7. 挑战与未来方向</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-14"><span class="toc-number">1.4.11.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#7-1-%E5%81%8F%E5%B7%AE%E4%B8%8E%E8%84%86%E5%BC%B1%E6%80%A7"><span class="toc-number">1.4.11.1.1.</span> <span class="toc-text">7.1 偏差与脆弱性</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-OffsetBias%E3%80%90Park-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.11.1.1.1.</span> <span class="toc-text">1. OffsetBias【Park et al., 2024】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-SORRY-Bench%E3%80%90Xie-et-al-2024a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.11.1.1.2.</span> <span class="toc-text">2. SORRY-Bench【Xie et al., 2024a】：</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-2-%E5%8A%A8%E6%80%81%E4%B8%8E%E5%A4%8D%E6%9D%82%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.11.1.2.</span> <span class="toc-text">7.2 动态与复杂评估</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Tree-of-Thought-ToT-%E3%80%90Yao-et-al-2023a%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.11.1.2.1.</span> <span class="toc-text">1. **Tree of Thought (ToT)**【Yao et al., 2023a】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-RAIN%E3%80%90Li-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.11.1.2.2.</span> <span class="toc-text">2. RAIN【Li et al., 2024】：</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-3-%E8%87%AA%E6%88%91%E8%AF%84%E4%BC%B0%E4%B8%8E%E4%BA%BA%E6%9C%BA%E5%8D%8F%E5%90%8C"><span class="toc-number">1.4.11.1.3.</span> <span class="toc-text">7.3 自我评估与人机协同</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Self-Taught-Evaluators%E3%80%90Wang-et-al-2024f%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.11.1.3.1.</span> <span class="toc-text">1. Self-Taught Evaluators【Wang et al., 2024f】：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Meta-Rewarding%E3%80%90Wu-et-al-2024%E3%80%91%EF%BC%9A"><span class="toc-number">1.4.11.1.3.2.</span> <span class="toc-text">2. Meta-Rewarding【Wu et al., 2024】：</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/" title="推理 LLM 的可视化指南：探索推理时计算技术与 DeepSeek-R1">推理 LLM 的可视化指南：探索推理时计算技术与 DeepSeek-R1</a><time datetime="2025-02-11T03:50:29.000Z" title="Created 2025-02-11 11:50:29">2025-02-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/11/Life%20Reflections/%E8%BF%BD%E9%80%90%E4%B8%8E%E5%80%92%E5%BD%B1/" title="追逐与倒影">追逐与倒影</a><time datetime="2024-12-10T18:29:06.000Z" title="Created 2024-12-11 02:29:06">2024-12-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/06/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment/" title="No title">No title</a><time datetime="2024-12-06T07:50:03.238Z" title="Created 2024-12-06 15:50:03">2024-12-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/06/NLP%20Insights/%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E8%AF%84%E4%BC%B0%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%88%90%E5%88%B0%E5%88%A4%E6%96%AD%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E6%8C%91%E6%88%98/" title="基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战">基于生成的大语言模型（LLM）评估：从生成到判断的机遇与挑战</a><time datetime="2024-12-06T06:34:18.000Z" title="Created 2024-12-06 14:34:18">2024-12-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/03/Life%20Reflections/Reflections%20on%20Identity%20and%20Subjectivity/" title="Reflections on Identity and Subjectivity">Reflections on Identity and Subjectivity</a><time datetime="2024-12-03T06:11:06.000Z" title="Created 2024-12-03 14:11:06">2024-12-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Huiyu Chen</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>