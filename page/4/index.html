<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO.en/">LoRA, DPO, KTO 与 SFT 技术详解</a></h2><time class="has-text-grey" datetime="2024-10-23T08:26:29.000Z">2024-10-23</time><p class="is-flex-grow-2 mt-2">LoRA, DPO, KTO 与 SFT 技术详解本篇文档将详细介绍几种在大型语言模型（如 LLAMA3）微调和优化中的重要技术，包括 SFT（Supervised Fine-Tuning）、LoRA（Low-Rank Adaptation）、Alignment 技术、KTO（Kahneman-Tversky Optimization） 和 DPO（Direct Preference Optimization）。文中还将详细阐述每种技术的原理、具体实现方法以及相应的损失函数与优化器选择。

1. SFT（Supervised Fine-Tuning）1.1 原理SFT 是一种传统的微调方法，通过监督学习对预训练模型进行微调，调整模型的参数使其在特定任务上表现更好。SFT 通常用于针对特定的标注数据进行模型微..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO.zh-CN/">LoRA, DPO, KTO 与 SFT 技术详解</a></h2><time class="has-text-grey" datetime="2024-10-23T08:26:29.000Z">2024-10-23</time><p class="is-flex-grow-2 mt-2">LoRA, DPO, KTO 与 SFT 技术详解本篇文档将详细介绍几种在大型语言模型（如 LLAMA3）微调和优化中的重要技术，包括 SFT（Supervised Fine-Tuning）、LoRA（Low-Rank Adaptation）、Alignment 技术、KTO（Kahneman-Tversky Optimization） 和 DPO（Direct Preference Optimization）。文中还将详细阐述每种技术的原理、具体实现方法以及相应的损失函数与优化器选择。

1. SFT（Supervised Fine-Tuning）1.1 原理SFT 是一种传统的微调方法，通过监督学习对预训练模型进行微调，调整模型的参数使其在特定任务上表现更好。SFT 通常用于针对特定的标注数据进行模型微..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO.zh-CN/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/"><img class="post-cover-img js-img-fadeIn" src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/SGLang"><i class="tag post-item-tag">SGLang</i></a><a href="/tags/Structured%20LLM"><i class="tag post-item-tag">Structured LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码</a></h2><time class="has-text-grey" datetime="2024-08-13T08:12:10.000Z">2024-08-13</time><p class="is-flex-grow-2 mt-2">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码作者: Liangsheng Yin, Ying Sheng, Lianmin Zheng日期: 2024 年 2 月 5 日

本文内容基于 LMSYS Org 发布的一篇博客文章，原文链接：LMSYS Org 博客。相关的代码库可以在以下链接找到：SGLang 代码库。
让一个 LLM 始终生成符合特定模式的有效 JSON 或 YAML，对于许多应用来说是一个关键特性。在这篇博客文章中，我们介绍了一种显著加速这种约束解码的优化方法。我们的方法利用了压缩的有限状态机，并且兼容任何正则表达式，因此可以适用于任何 JSON 或 YAML 模式。与现有系统逐步解码一个标记的方式不同，我们的方法分析了正则表达式的有限状态机，压缩了单一的转换路径，并在可能的..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/"><img class="post-cover-img js-img-fadeIn" src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/SGLang"><i class="tag post-item-tag">SGLang</i></a><a href="/tags/Structured%20LLM"><i class="tag post-item-tag">Structured LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码</a></h2><time class="has-text-grey" datetime="2024-08-13T08:12:10.000Z">2024-08-13</time><p class="is-flex-grow-2 mt-2">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码作者: Liangsheng Yin, Ying Sheng, Lianmin Zheng日期: 2024 年 2 月 5 日

本文内容基于 LMSYS Org 发布的一篇博客文章，原文链接：LMSYS Org 博客。相关的代码库可以在以下链接找到：SGLang 代码库。
让一个 LLM 始终生成符合特定模式的有效 JSON 或 YAML，对于许多应用来说是一个关键特性。在这篇博客文章中，我们介绍了一种显著加速这种约束解码的优化方法。我们的方法利用了压缩的有限状态机，并且兼容任何正则表达式，因此可以适用于任何 JSON 或 YAML 模式。与现有系统逐步解码一个标记的方式不同，我们的方法分析了正则表达式的有限状态机，压缩了单一的转换路径，并在可能的..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2-2b-it"><i class="tag post-item-tag">Gemma-2-2b-it</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.
Installation and Verification of vLLMFirst, ensure that you have installed and verified vLLM version 0.5.3.

Install vLLM:
1!pip install vllm==0.5.3

Verify th..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.en/">使用vLLM运行微调后的Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">使用vLLM运行微调后的Gemma-2-2b-it的详细步骤在这里分享一下我运行微调后的Gemma-2-2b-it模型并使用vLLM的步骤，希望对其他人有所帮助。本文将详细介绍安装过程、环境配置以及常见问题的解决方法。
安装和验证vLLM首先，确保安装并验证vLLM的版本是0.5.3。

安装vLLM：
1pip install vllm==0.5.3

验证安装：
123import vllmprint(vllm.__version__)# 输出: 0.5.3

安装Flashinfer按照以下步骤安装Flashinfer，并确保您的torch版本和CUDA兼容性。

检查torch版本和CUDA兼容性：
123import torchprint(torch.__version__)  # 应输出: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.en/">更多</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/vLLM"><i class="tag post-item-tag">vLLM</i></a><a href="/tags/Gemma-2"><i class="tag post-item-tag">Gemma-2</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.zh-CN/">使用vLLM运行微调后的Gemma-2</a></h2><time class="has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time><p class="is-flex-grow-2 mt-2">使用vLLM运行微调后的Gemma-2-2b-it的详细步骤在这里分享一下我运行微调后的Gemma-2-2b-it模型并使用vLLM的步骤，希望对其他人有所帮助。本文将详细介绍安装过程、环境配置以及常见问题的解决方法。
安装和验证vLLM首先，确保安装并验证vLLM的版本是0.5.3。

安装vLLM：
1pip install vllm==0.5.3

验证安装：
123import vllmprint(vllm.__version__)# 输出: 0.5.3

安装Flashinfer按照以下步骤安装Flashinfer，并确保您的torch版本和CUDA兼容性。

检查torch版本和CUDA兼容性：
123import torchprint(torch.__version__)  # 应输出: 2...</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2.zh-CN/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).zh-CN/"><img class="post-cover-img js-img-fadeIn" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Language%20Modeling"><i class="tag post-item-tag">Language Modeling</i></a><a href="/tags/Perplexity"><i class="tag post-item-tag">Perplexity</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).zh-CN/">如何准确计算固定长度模型的困惑度（PPL）</a></h2><time class="has-text-grey" datetime="2024-04-17T04:00:00.000Z">2024-04-17</time><p class="is-flex-grow-2 mt-2">如何计算固定长度模型的困惑度（PPL）困惑度（PPL）是评估语言模型最常用的指标之一。在深入探讨之前，我们应该注意这个指标特别适用于传统语言模型（有时被称为自回归或因果语言模型），而对于像 BERT 这样的 masked language models 则没有明确定义（见模型总结）。
困惑度被定义为序列的指数化平均负对数似然。如果我们有一个标记化序列 $X = (x_0, x_1, \dots, x_t)$，那么 $X$ 的困惑度为，
$$\text{PPL}(X) = \exp \left{ -\frac{1}{t}\sum*{i=1}^t \log p\theta (xi|x*{&amp;lt;i}) \right}$$
其中 $\log p\theta (x_i|x{&amp;lt;i})$ 是第 i 个标记的对数似..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).zh-CN/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).en/"><img class="post-cover-img js-img-fadeIn" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Language%20Modeling"><i class="tag post-item-tag">Language Modeling</i></a><a href="/tags/Perplexity"><i class="tag post-item-tag">Perplexity</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).en/">如何准确计算固定长度模型的困惑度（PPL）</a></h2><time class="has-text-grey" datetime="2024-04-17T04:00:00.000Z">2024-04-17</time><p class="is-flex-grow-2 mt-2">如何计算固定长度模型的困惑度（PPL）困惑度（PPL）是评估语言模型最常用的指标之一。在深入探讨之前，我们应该注意这个指标特别适用于传统语言模型（有时被称为自回归或因果语言模型），而对于像 BERT 这样的 masked language models 则没有明确定义（见模型总结）。
困惑度被定义为序列的指数化平均负对数似然。如果我们有一个标记化序列 $X = (x_0, x_1, \dots, x_t)$，那么 $X$ 的困惑度为，
$$\text{PPL}(X) = \exp \left{ -\frac{1}{t}\sum*{i=1}^t \log p\theta (xi|x*{&amp;lt;i}) \right}$$
其中 $\log p\theta (x_i|x{&amp;lt;i})$ 是第 i 个标记的对数似..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL).en/">更多</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><a class="extend prev" rel="prev" href="/page/3/"><i class="iconfont icon-prev has-text-grey"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/5/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><style>.search-widget .search-input {
    border: none;
    outline: none;
    background: transparent;
    color: var(--second-text-color);
}
.search-widget .search-content {
    position: absolute;
    left: 0;
    top: calc(100% - 3px);
    z-index: 2;

    width: 100%;
    height: 0;
    max-height: 550px;

    overflow: auto;
    box-sizing: border-box;

    background: var(--top-bar-bg-color);
    backdrop-filter: blur(var(--backdropFilter));
    -webkit-backdrop-filter: blur(var(--backdropFilter));

    border-bottom-left-radius: var(--borderRadius);
    border-bottom-right-radius: var(--borderRadius);
    box-shadow: 0 12px 15px rgba(0, 0, 0, 0.08);
}

.search-widget .search-content a:hover h5 {
    color: #3273dc!important;
}
</style><main class="aside-card-container search-widget is-relative"><label for="searchInput"><div class="is-flex px-4" id="searchButton"><i class="iconfont icon--search1 mr-1"></i><input class="search-input is-flex-grow-1" id="searchInput" placeholder="搜索内容.."></div></label><section class="search-content content" id="searchContent"></section></main><script>var searchDatabase = []
var searchInputEl = document.getElementById('searchInput')
var searchButtonEl = document.getElementById('searchButton')
var searchResultEl = document.getElementById('searchContent')

searchInputEl.oninput = function (evt) {
    var searchValue = evt.srcElement.value
    var haveSearchValue = Boolean(searchValue.trim())
    if (!haveSearchValue) {
        searchResultEl.style.height = 0
        searchResultEl.innerHTML = null
        return
    }

    var searchResults = searching(searchValue)

    if (searchResults.length > 0) {
        renderSearchResults(searchResults)
    }
}

function renderSearchResults(results) {
    searchResultEl.innerHTML = null
    var fragment = document.createDocumentFragment()

    results.forEach(function (item) {
        var link = document.createElement('a')
        var title = document.createElement('h5')
        var content = document.createElement('p')

        title.className = 'mb-1'
        title.innerText = item.title
        content.innerText = item.content

        link.href = item.link
        link.appendChild(title)
        link.appendChild(content)
        link.className = 'p-4 is-block'

        fragment.appendChild(link)
    })

    searchResultEl.appendChild(fragment)
    searchResultEl.style.height = 'auto'
}

function searching(inputText) {
    var inputTexts = inputText.split(' ')
    var searchResults = []
    inputTexts.forEach(function (searchKey) {
        var haveSearchValue = Boolean(searchKey.trim())
        if (!haveSearchValue) return

        var key = searchKey.toLowerCase()

        for (var entry of searchDatabase) {
            var title = entry.getElementsByTagName('title')[0].textContent
            var link = entry.getElementsByTagName('link')[0].getAttribute('href')
            var contentWithTags = entry.getElementsByTagName('content')[0].textContent
            var rawContent = contentWithTags.trim().replace(/<[^>]+>/g, '').toLowerCase()

            var LENGTH = 80
            var finalContent = ''
            var contentLength = rawContent.length
            var searchResultIdx = rawContent.indexOf(key)

            var startIdx = searchResultIdx - 20,
                endIdx = startIdx + LENGTH

            if (startIdx < 0) {
                startIdx = 0
                endIdx = 100
            }

            endIdx > contentLength && (endIdx = contentLength)

            finalContent = rawContent.substring(startIdx, endIdx)

            if (title.indexOf(key) > -1 || searchResultIdx > -1) {
                searchResults.push({
                    link: link,
                    title: title,
                    content: finalContent
                })
            }
        }
    })
    return searchResults
}

searchButtonEl.onclick = function () {
    if (searchDatabase.length > 0) return;

    fetch(window.location.href + '/search.xml').then(res => res.text()).then(res => {
        var domparser = new DOMParser
        var doc = domparser.parseFromString(res, 'application/xml')
        searchDatabase = doc.getElementsByTagName('search')[0].children
    })
}</script><main class="aside-card-container profile-widget"><!-- todo: 使用取色工具动态阴影--><section class="is-flex is-flex-direction-column is-justify-content-center is-align-items-center"><section class="is-flex is-justify-content-center avatar is-clipped"><div class="avatar-placeholder"></div></section><h3 class="user-name">user</h3><blockquote class="has-text-centered is-relative"><span style="margin-bottom: 5px;">May the Force be with you</span></blockquote><address class="has-text-centered has-text-grey"><i class="iconfont icon-location" style="margin-right: 5px;"></i><span class="has-text-grey">In the dust</span></address></section><section class="sns-container is-flex is-justify-content-center is-align-items-center"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section></main><main class="aside-card-container recent-widget"><h3>最近</h3><ul><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="https://ui-avatars.com/api/?background=f5f5f5&amp;name=Lo" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO.en/">LoRA, DPO, KTO 与 SFT 技术详解</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2024-10-23T08:26:29.000Z">2024-10-23</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="https://ui-avatars.com/api/?background=f5f5f5&amp;name=Lo" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO.zh-CN/">LoRA, DPO, KTO 与 SFT 技术详解</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2024-10-23T08:26:29.000Z">2024-10-23</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.en/">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2024-08-13T08:12:10.000Z">2024-08-13</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81.zh-CN/">使用压缩有限状态机进行本地 LLM 的快速 JSON 解码</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2024-08-13T08:12:10.000Z">2024-08-13</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="https://ui-avatars.com/api/?background=f5f5f5&amp;name=De" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.en/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="https://ui-avatars.com/api/?background=f5f5f5&amp;name=De" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM.zh-CN/">Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2024-08-07T02:30:00.000Z">2024-08-07</time></section></li></ul></main><main class="aside-card-container categories-widget category-page"><h3>分类</h3><section><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code-Chronicles/">Code Chronicles</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Debugging-Diaries/">Debugging Diaries</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life-Reflections/">Life Reflections</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-Insights/">NLP Insights</a><span class="category-list-count">50</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tech-Toolbox/">Tech Toolbox</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wanderlust-Adventures/">Wanderlust Adventures</a><span class="category-list-count">2</span></li></ul></section></main><main class="aside-card-container archives-widget"><h3>归档</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2026/02/">二月 2026</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">六月 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">三月 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">二月 2025</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">十二月 2024</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">十月 2024</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">八月 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">四月 2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">三月 2024</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">一月 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a><span class="archive-list-count">2</span></li></ul></section></main><main class="aside-card-container tag-widget"><h3>标签</h3><section><a href="/tags/IssueFix"><span class="tag post-item-tag" style="margin-bottom: 5px;">IssueFix</span></a><a href="/tags/Blog"><span class="tag post-item-tag" style="margin-bottom: 5px;">Blog</span></a><a href="/tags/Git"><span class="tag post-item-tag" style="margin-bottom: 5px;">Git</span></a><a href="/tags/K8s"><span class="tag post-item-tag" style="margin-bottom: 5px;">K8s</span></a><a href="/tags/Language%20Modeling"><span class="tag post-item-tag" style="margin-bottom: 5px;">Language Modeling</span></a><a href="/tags/Perplexity"><span class="tag post-item-tag" style="margin-bottom: 5px;">Perplexity</span></a><a href="/tags/Onnx"><span class="tag post-item-tag" style="margin-bottom: 5px;">Onnx</span></a><a href="/tags/Deployment"><span class="tag post-item-tag" style="margin-bottom: 5px;">Deployment</span></a><a href="/tags/Chatbot"><span class="tag post-item-tag" style="margin-bottom: 5px;">Chatbot</span></a><a href="/tags/DSSM"><span class="tag post-item-tag" style="margin-bottom: 5px;">DSSM</span></a><a href="/tags/Recommendation"><span class="tag post-item-tag" style="margin-bottom: 5px;">Recommendation</span></a><a href="/tags/LLM"><span class="tag post-item-tag" style="margin-bottom: 5px;">LLM</span></a><a href="/tags/FastChat"><span class="tag post-item-tag" style="margin-bottom: 5px;">FastChat</span></a><a href="/tags/Train"><span class="tag post-item-tag" style="margin-bottom: 5px;">Train</span></a><a href="/tags/Agent"><span class="tag post-item-tag" style="margin-bottom: 5px;">Agent</span></a><a href="/tags/Tool%20Use"><span class="tag post-item-tag" style="margin-bottom: 5px;">Tool Use</span></a><a href="/tags/Gorilla"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gorilla</span></a><a href="/tags/Prompt"><span class="tag post-item-tag" style="margin-bottom: 5px;">Prompt</span></a><a href="/tags/vLLM"><span class="tag post-item-tag" style="margin-bottom: 5px;">vLLM</span></a><a href="/tags/Gemma-2-2b-it"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gemma-2-2b-it</span></a><a href="/tags/Conversational%20AI"><span class="tag post-item-tag" style="margin-bottom: 5px;">Conversational AI</span></a><a href="/tags/Memory%20Management"><span class="tag post-item-tag" style="margin-bottom: 5px;">Memory Management</span></a><a href="/tags/SeCom"><span class="tag post-item-tag" style="margin-bottom: 5px;">SeCom</span></a><a href="/tags/RAG"><span class="tag post-item-tag" style="margin-bottom: 5px;">RAG</span></a><a href="/tags/Gemma-2"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gemma-2</span></a><a href="/tags/SGLang"><span class="tag post-item-tag" style="margin-bottom: 5px;">SGLang</span></a><a href="/tags/Structured%20LLM"><span class="tag post-item-tag" style="margin-bottom: 5px;">Structured LLM</span></a><a href="/tags/Language%20Learning"><span class="tag post-item-tag" style="margin-bottom: 5px;">Language Learning</span></a><a href="/tags/English%20Vocabulary"><span class="tag post-item-tag" style="margin-bottom: 5px;">English Vocabulary</span></a><a href="/tags/Deep%20Learning"><span class="tag post-item-tag" style="margin-bottom: 5px;">Deep Learning</span></a><a href="/tags/Gradient%20Descent"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gradient Descent</span></a><a href="/tags/Living%20in%20Singapore"><span class="tag post-item-tag" style="margin-bottom: 5px;">Living in Singapore</span></a><a href="/tags/Guide%20to%20Living%20on%20Singapore%20Island"><span class="tag post-item-tag" style="margin-bottom: 5px;">Guide to Living on Singapore Island</span></a><a href="/tags/Sports"><span class="tag post-item-tag" style="margin-bottom: 5px;">Sports</span></a><a href="/tags/%E5%9D%A1%E5%B2%9B%E7%94%9F%E6%B4%BB%E6%8C%87%E5%8C%97"><span class="tag post-item-tag" style="margin-bottom: 5px;">坡岛生活指北</span></a><a href="/tags/Small%20Talk"><span class="tag post-item-tag" style="margin-bottom: 5px;">Small Talk</span></a><a href="/tags/%E6%9D%82%E8%B0%88"><span class="tag post-item-tag" style="margin-bottom: 5px;">杂谈</span></a><a href="/tags/Python"><span class="tag post-item-tag" style="margin-bottom: 5px;">Python</span></a><a href="/tags/Leetcode"><span class="tag post-item-tag" style="margin-bottom: 5px;">Leetcode</span></a><a href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98"><span class="tag post-item-tag" style="margin-bottom: 5px;">每日一题</span></a><a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92"><span class="tag post-item-tag" style="margin-bottom: 5px;">动态规划</span></a><a href="/tags/FAISS"><span class="tag post-item-tag" style="margin-bottom: 5px;">FAISS</span></a><a href="/tags/Embedding"><span class="tag post-item-tag" style="margin-bottom: 5px;">Embedding</span></a><a href="/tags/Python%20Basic"><span class="tag post-item-tag" style="margin-bottom: 5px;">Python Basic</span></a><a href="/tags/Daily%20Challenge"><span class="tag post-item-tag" style="margin-bottom: 5px;">Daily Challenge</span></a><a href="/tags/%E5%8F%8C%E5%91%A8%E8%B5%9B"><span class="tag post-item-tag" style="margin-bottom: 5px;">双周赛</span></a></section></main><main class="aside-card-container friend-widget"><h3>友链</h3><section><a target="_blank" rel="noopener" href="https://www.google.com/"><span class="tag post-item-tag" style="margin-bottom: 5px;">Google</span></a><a target="_blank" rel="noopener" href="https://www.github.com/"><span class="tag post-item-tag" style="margin-bottom: 5px;">Github</span></a><a target="_blank" rel="noopener" href="https://v2ex.com/"><span class="tag post-item-tag" style="margin-bottom: 5px;">V2EX</span></a><a target="_blank" rel="noopener" href="https://twitter.com/"><span class="tag post-item-tag" style="margin-bottom: 5px;">Twitter</span></a></section></main></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>