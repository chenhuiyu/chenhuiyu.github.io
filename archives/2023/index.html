<!DOCTYPE html><html class="appearance-auto" lang="[&quot;en&quot;]"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Archives · 2023</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2023/09/24/NLP%20Insights/Create%20a%20Telegram%20Bot%20with%20Python%20and%20OpenAI%20in%2010%20Minutes/step1.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/09/24/NLP%20Insights/Create%20a%20Telegram%20Bot%20with%20Python%20and%20OpenAI%20in%2010%20Minutes/"><img class="post-cover-img js-img-fadeIn" src="/2023/09/24/NLP%20Insights/Create%20a%20Telegram%20Bot%20with%20Python%20and%20OpenAI%20in%2010%20Minutes/step1.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Chatbot"><i class="tag post-item-tag">Chatbot</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/09/24/NLP%20Insights/Create%20a%20Telegram%20Bot%20with%20Python%20and%20OpenAI%20in%2010%20Minutes/">🤖 Create a Telegram Bot with Python and OpenAI in 10 Minutes! 🚀</a></h2><time class="has-text-grey" datetime="2023-09-23T19:13:03.000Z">2023-09-24</time><p class="is-flex-grow-2 mt-2">🤖 Create a Telegram Bot with Python and OpenAI in 10 Minutes! 🚀In this fun tutorial, we’ll show you how to create a Telegram bot that can chat with users and generate witty responses. We’ll explain each step in detail, making it easy for you to get started!
Step 1: Create a Telegram Bot 🤖First, let’s create your very own Telegram bot. Here’s how:

Open ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/09/24/NLP%20Insights/Create%20a%20Telegram%20Bot%20with%20Python%20and%20OpenAI%20in%2010%20Minutes/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2023/09/24/NLP%20Insights/%E5%8D%81%E5%88%86%E9%92%9F%E7%94%A8%20Python%20%E5%92%8C%20OpenAI%20%E5%88%9B%E5%BB%BA%20Telegram%20%E6%9C%BA%E5%99%A8%E4%BA%BA/step1.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/09/24/NLP%20Insights/%E5%8D%81%E5%88%86%E9%92%9F%E7%94%A8%20Python%20%E5%92%8C%20OpenAI%20%E5%88%9B%E5%BB%BA%20Telegram%20%E6%9C%BA%E5%99%A8%E4%BA%BA/"><img class="post-cover-img js-img-fadeIn" src="/2023/09/24/NLP%20Insights/%E5%8D%81%E5%88%86%E9%92%9F%E7%94%A8%20Python%20%E5%92%8C%20OpenAI%20%E5%88%9B%E5%BB%BA%20Telegram%20%E6%9C%BA%E5%99%A8%E4%BA%BA/step1.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Chatbot"><i class="tag post-item-tag">Chatbot</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/09/24/NLP%20Insights/%E5%8D%81%E5%88%86%E9%92%9F%E7%94%A8%20Python%20%E5%92%8C%20OpenAI%20%E5%88%9B%E5%BB%BA%20Telegram%20%E6%9C%BA%E5%99%A8%E4%BA%BA/">🤖 十分钟用 Python 和 OpenAI 创建 Telegram 机器人！ 🚀</a></h2><time class="has-text-grey" datetime="2023-09-23T19:12:03.000Z">2023-09-24</time><p class="is-flex-grow-2 mt-2">🤖 十分钟用 Python 和 OpenAI 创建 Telegram 机器人！ 🚀在这个有趣的教程中，我们将向您展示如何创建一个具有的 Telegram 机器人，该机器人能够与用户聊天并生成幽默回复。我们将详细解释每一步，让您轻松入门！
步骤 1：创建 Telegram 机器人 🤖首先，让我们来创建您自己的 Telegram 机器人。这是如何做的：

打开 Telegram 应用并搜索 “BotFather”。
在 BotFather 聊天中，使用 /newbot 命令创建一个新机器人。您需要为机器人取个名字，比如 “PunshineBot”。
BotFather 会为您生成一个独一无二的 API 令牌（Token）。一定要妥善保存这个令牌，稍后我们会在代码中用到它。



步骤 2：导入必要的库 �..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/09/24/NLP%20Insights/%E5%8D%81%E5%88%86%E9%92%9F%E7%94%A8%20Python%20%E5%92%8C%20OpenAI%20%E5%88%9B%E5%BB%BA%20Telegram%20%E6%9C%BA%E5%99%A8%E4%BA%BA/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/IssueFix"><i class="tag post-item-tag">IssueFix</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/09/13/Debugging%20Diaries/Resolving%20Port%20Conflicts:%20Identifying%20and%20Terminating%20Processes/">Resolving Port Conflicts: Identifying and Terminating Processes</a></h2><time class="has-text-grey" datetime="2023-09-13T04:10:55.000Z">2023-09-13</time><p class="is-flex-grow-2 mt-2">Resolving Port Conflicts: Identifying and Terminating ProcessesTable of Contents
Introduction 📝
Finding Processes on Windows 🕵️‍♂️
Finding Processes on Linux/macOS 🐧
Viewing Process Details 📊
Terminating Processes ⛔️

Introduction 📝Sometimes, when you try to start an application or service, you may encounter an “Address already in use” error. This mea..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/09/13/Debugging%20Diaries/Resolving%20Port%20Conflicts:%20Identifying%20and%20Terminating%20Processes/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/IssueFix"><i class="tag post-item-tag">IssueFix</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/09/13/Debugging%20Diaries/%E8%A7%A3%E5%86%B3%E7%AB%AF%E5%8F%A3%E5%86%B2%E7%AA%81%EF%BC%9A%E6%9F%A5%E6%89%BE%E5%B9%B6%E7%BB%88%E6%AD%A2%E8%BF%9B%E7%A8%8B/">解决端口冲突：查找并终止进程</a></h2><time class="has-text-grey" datetime="2023-09-13T04:10:55.000Z">2023-09-13</time><p class="is-flex-grow-2 mt-2">解决端口冲突：查找并终止进程目录
简介
在Windows上查找进程 🕵️‍♂️
在Linux/macOS上查找进程 🐧
查看进程详细信息 📊
终止进程 ⛔️

简介有时候，当你尝试启动一个应用程序或服务时，可能会遇到”Address already in use”（地址已经在使用）的错误，这意味着指定的端口已经被另一个进程占用。为了解决这个问题，你需要确定哪个进程正在使用该端口，并可以选择终止该进程或更改应用程序的端口配置。
在Windows上查找进程 🕵️‍♂️在Windows上，你可以使用命令提示符来查找正在使用特定端口的进程。打开命令提示符，并执行以下命令：
1netstat -ano | findstr :8080

这个命令会列出所有正在使用端口8080的进程，并显示它们的进程ID（PID..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/09/13/Debugging%20Diaries/%E8%A7%A3%E5%86%B3%E7%AB%AF%E5%8F%A3%E5%86%B2%E7%AA%81%EF%BC%9A%E6%9F%A5%E6%89%BE%E5%B9%B6%E7%BB%88%E6%AD%A2%E8%BF%9B%E7%A8%8B/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Python%20Basic"><i class="tag post-item-tag">Python Basic</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/08/23/Code%20Chronicles/Python-Uninterrupted%20Remote%20Program%20Execution:%203%20Methods/">无断开烦恼！远程服务器后台运行程序的3种方法：`nohup`、`tmux`和`screen`</a></h2><time class="has-text-grey" datetime="2023-08-23T06:46:03.000Z">2023-08-23</time><p class="is-flex-grow-2 mt-2">无断开烦恼！远程服务器后台运行程序的3种方法：nohup、tmux和screenUninterrupted Remote Program Execution: 3 Methods在数据分析或机器学习项目中，经常需要在远程服务器上运行耗时长、计算密集型的任务。通过SSH连接到远程服务器是常见的操作方式。但是，如何确保在断开SSH连接之后，远程服务器上的程序能够继续运行呢？本文详细介绍了三种方法：nohup、tmux和screen。
使用nohup命令开始
连接到远程机器：在本地终端中执行以下命令。
 1ssh username@remote-server-address

启动后台程序：在远程机器上执行。
 1nohup your-command-to-run-the-program &amp;amp;

例如：
1..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/08/23/Code%20Chronicles/Python-Uninterrupted%20Remote%20Program%20Execution:%203%20Methods/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Python%20Basic"><i class="tag post-item-tag">Python Basic</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/08/22/Code%20Chronicles/Python-subprocess/">超越Python的边界：`subprocess` 助你一键执行外部命令</a></h2><time class="has-text-grey" datetime="2023-08-22T11:06:03.000Z">2023-08-22</time><p class="is-flex-grow-2 mt-2">超越Python的边界：subprocess 助你一键执行外部命令在日常开发中，有时候我们希望能够从 Python 脚本中执行系统命令或者其他程序。Python 提供了 subprocess 模块，使得这一操作变得既简单又安全。
介绍subprocess 模块是 Python 标准库的一部分，它提供了一种简单统一的方法来执行外部命令，与进程交互，读取它的输出，并获取它的返回码。无论你是在自动化某个系统任务，还是简单地想要从另一个程序中获取数据，subprocess 都能助你一臂之力。
功能与用途
执行外部命令：你可以轻易地从 Python 脚本中运行任何外部命令，就像在命令行中输入命令一样。这种能力使得你能够在你的 Python 程序中调用并集成其他命令行工具，扩展你的应用的功能。

捕获命令的输出：如果你..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/08/22/Code%20Chronicles/Python-subprocess/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Onnx"><i class="tag post-item-tag">Onnx</i></a><a href="/tags/Deployment"><i class="tag post-item-tag">Deployment</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/08/21/NLP%20Insights/Conver%20Pytorch%20Model%20to%20ONNX%20Format/">Conver Pytorch Model to ONNX Format</a></h2><time class="has-text-grey" datetime="2023-08-21T06:34:18.000Z">2023-08-21</time><p class="is-flex-grow-2 mt-2">使用 PyTorch 和 ONNX 检查模型一致性在机器学习和深度学习的开发过程中，模型的互操作性变得越来越重要。ONNX (Open Neural Network Exchange) 是一种开放格式，用于表示机器学习和深度学习模型。它允许开发者在各种深度学习框架之间轻松地共享模型，从而提高了模型的可移植性和互操作性。
本教程将指导您完成以下步骤：

将 PyTorch 模型转换为 ONNX 格式。
验证转换后的 ONNX 模型与原始 PyTorch 模型的输出是否一致。

1. 导入必要的库首先，我们导入为模型转换和验证所需的所有库。
123456import osimport sysimport torchimport onnximport onnxruntimeimport numpy as np

..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/08/21/NLP%20Insights/Conver%20Pytorch%20Model%20to%20ONNX%20Format/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/08/02/NLP%20Insights/LLAMA2/">Training Llama 2 Model on Single GPU with int8 Quantization and LoRA</a></h2><time class="has-text-grey" datetime="2023-08-02T07:38:29.000Z">2023-08-02</time><p class="is-flex-grow-2 mt-2">Training Llama 2 Model on Single GPU with int8 Quantization and LoRALlama 2概述Llama 2 是一个包含预训练和微调的生成式文本模型的集合，其规模从 70 亿到 700 亿个参数不等。Llama2模型是由Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert等人在Llama 2: Open Foundation and Fine-Tuned Chat Models中提出的。
该论文的摘要如下：
在这项工作中，我们开发并发布了Llama 2，这是一组从70亿到700亿参数的预训练和微调的大型语言模型（LLMs）。我们的微调LLMs，称为Llama 2-Chat，针对对话用例进行了优化..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/08/02/NLP%20Insights/LLAMA2/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2023/07/28/NLP%20Insights/LONGNET/Figure_1.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/07/28/NLP%20Insights/LONGNET/"><img class="post-cover-img js-img-fadeIn" src="/2023/07/28/NLP%20Insights/LONGNET/Figure_1.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/28/NLP%20Insights/LONGNET/">LONGNET - Scaling Transformers to 1,000,000,000 Tokens</a></h2><time class="has-text-grey" datetime="2023-07-28T06:43:10.000Z">2023-07-28</time><p class="is-flex-grow-2 mt-2">LONGNET：将Transformer扩展到10亿个标记在本篇文章中，我们将详细讨论一个近期发布的先进模型——“LongNet”。该模型由微软亚洲研究院研发，于大约两周前正式公布。LongNet基于Transformer模型构建，其核心理念在于拓展Transformer的应用规模。值得一提的是，研究团队成功地将其扩展至处理10亿个令牌的规模。对于熟悉语言模型的人来说，会明白序列长度对模型性能的影响，因为序列长度决定了在执行注意力机制时，能够关联的令牌数量，从而影响模型可以获取的上下文信息长度。例如，我们希望像GPT这样的模型能拥有更长的上下文，使得模型可以参考更久之前的单词来预测下一个令牌。而LongNet就成功地将这个能力扩展到了10亿个令牌。以下图为例，可以清晰看出，GPT的序列长度仅为512，而Po..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/28/NLP%20Insights/LONGNET/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a><a href="/tags/Prompt"><i class="tag post-item-tag">Prompt</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/07/27/NLP%20Insights/Prompt%20Engineering/">Prompt Engineering</a></h2><time class="has-text-grey" datetime="2023-07-27T07:44:10.000Z">2023-07-27</time><p class="is-flex-grow-2 mt-2">Prompt EngineeringPrompt Engineering, 也被称为上下文提示，是指在不更新模型权重的情况下，与LLM（语言模型）进行交互以引导其产生期望输出的方法。它是一门实证科学，提示工程方法的效果在不同模型之间可能会有很大的差异，因此需要进行大量的实验和试探。
本文仅关注自回归语言模型的提示工程，不涉及填空测试、图像生成或多模态模型。在本质上，提示工程的目标是实现模型的对齐和可操控性。您可以查阅我之前关于可控文本生成的帖子。
基本提示方法zero-shot学习和few-shot学习是两种最基本的提示模型方法，这些方法由许多LLM论文首创，并且通常用于评估LLM性能。
zero-shot学习zero-shot学习是将任务文本直接输入模型并要求获得结果。
（所有情感分析示例来自于SST-2..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/07/27/NLP%20Insights/Prompt%20Engineering/">Read more</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><span class="page-number current">1</span><a class="page-number" href="/archives/2023/page/2/">2</a><a class="page-number" href="/archives/2023/page/3/">3</a><a class="extend next" rel="next" href="/archives/2023/page/2/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2026/02/">February 2026</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a><span class="archive-list-count">1</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>