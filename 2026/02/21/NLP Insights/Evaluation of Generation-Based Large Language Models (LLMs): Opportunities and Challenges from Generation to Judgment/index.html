<!DOCTYPE html><html class="appearance-auto" lang="[&quot;en&quot;]"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to JudgmentAbstractEvaluation tasks in artificial intelligence (AI) and natural language processing (NLP) have long been challenging. Traditional evaluation methods, such as those based on matching or embeddings, are limited in assessing complex attrib.."><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="黑头呆鱼进化之旅" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center"></p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Evaluation-of-Generation-Based-Large-Language-Models-LLMs-Opportunities-and-Challenges-from-Generation-to-Judgment"><span class="toc-text">Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to Judgment</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1. Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Background"><span class="toc-text">1.1 Background</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Research-Questions"><span class="toc-text">1.2 Research Questions</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Preliminary-Knowledge"><span class="toc-text">2. Preliminary Knowledge</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Input-Formats"><span class="toc-text">2.1 Input Formats</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Output-Formats"><span class="toc-text">2.2 Output Formats</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Evaluation-Attributes"><span class="toc-text">3. Evaluation Attributes</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Helpfulness"><span class="toc-text">3.1 Helpfulness</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Harmlessness"><span class="toc-text">3.2 Harmlessness</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-Reliability"><span class="toc-text">3.3 Reliability</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Relevance"><span class="toc-text">3.4 Relevance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-Feasibility"><span class="toc-text">3.5 Feasibility</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-Overall-Quality"><span class="toc-text">3.6 Overall Quality</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Methodology"><span class="toc-text">4. Methodology</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Overview"><span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-Fine-Tuning-Techniques"><span class="toc-text">4.1 Fine-Tuning Techniques</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Data-Sources"><span class="toc-text">Data Sources</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Human-Labeled-Data"><span class="toc-text">1. Human-Labeled Data</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Synthetic-Data"><span class="toc-text">2. Synthetic Data</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Fine-Tuning-Methods"><span class="toc-text">Fine-Tuning Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-Supervised-Fine-Tuning-SFT"><span class="toc-text">1. Supervised Fine-Tuning (SFT)</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-Preference-Learning"><span class="toc-text">2. Preference Learning</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Applications"><span class="toc-text">5. Applications</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Overview-1"><span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-Evaluation"><span class="toc-text">5.1 Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Overview-2"><span class="toc-text">Overview</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-Challenges-and-Future-Directions"><span class="toc-text">7. Challenges and Future Directions</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Overview-3"><span class="toc-text">Overview</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#7-1-Bias-and-Vulnerabilities"><span class="toc-text">7.1 Bias and Vulnerabilities</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-2-Dynamic-and-Complex-Evaluations"><span class="toc-text">7.2 Dynamic and Complex Evaluations</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-3-Self-Evaluation-and-Human-AI-Collaboration"><span class="toc-text">7.3 Self-Evaluation and Human-AI Collaboration</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div><div class="column is-9"><header class="my-4"></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle"></h1><time class="has-text-grey" datetime="2026-02-20T21:56:22.871Z">2026-02-21</time><article class="mt-2 post-content"><h1 id="Evaluation-of-Generation-Based-Large-Language-Models-LLMs-Opportunities-and-Challenges-from-Generation-to-Judgment"><a href="#Evaluation-of-Generation-Based-Large-Language-Models-LLMs-Opportunities-and-Challenges-from-Generation-to-Judgment" class="headerlink" title="Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to Judgment"></a>Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to Judgment</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Evaluation tasks in artificial intelligence (AI) and natural language processing (NLP) have long been challenging. Traditional evaluation methods, such as those based on matching or embeddings, are limited in assessing complex attributes. The recent development of large language models (LLMs) has given rise to the “LLM-as-a-Judge” paradigm, which utilizes LLMs for scoring, ranking, or selection tasks. This paper provides a comprehensive review of LLM evaluation methodologies, including their definitions, classification frameworks, benchmarks, and future research directions.</p>
<hr>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><h3 id="1-1-Background"><a href="#1-1-Background" class="headerlink" title="1.1 Background"></a>1.1 Background</h3><p>Evaluation is one of the core issues in machine learning and NLP. Traditional evaluation methods such as BLEU and ROUGE often rely on text overlap and lack applicability in complex scenarios. With the development of deep learning and LLMs (e.g., GPT-4), researchers have proposed the “LLM-as-a-Judge” paradigm to address the limitations of traditional evaluation methods.</p>
<h3 id="1-2-Research-Questions"><a href="#1-2-Research-Questions" class="headerlink" title="1.2 Research Questions"></a>1.2 Research Questions</h3><p>This paper aims to explore the following questions:</p>
<ul>
<li><strong>What do LLMs evaluate?</strong></li>
<li><strong>How is evaluation conducted?</strong></li>
<li><strong>Where are LLMs applied for evaluation?</strong></li>
</ul>
<hr>
<h2 id="2-Preliminary-Knowledge"><a href="#2-Preliminary-Knowledge" class="headerlink" title="2. Preliminary Knowledge"></a>2. Preliminary Knowledge</h2><h3 id="2-1-Input-Formats"><a href="#2-1-Input-Formats" class="headerlink" title="2.1 Input Formats"></a>2.1 Input Formats</h3><p>Evaluation inputs can be categorized as follows:</p>
<ul>
<li><strong>Point-Wise</strong>: Evaluation of a single sample.</li>
<li><strong>Pair/List-Wise</strong>: Comparative evaluation of multiple samples.</li>
</ul>
<h3 id="2-2-Output-Formats"><a href="#2-2-Output-Formats" class="headerlink" title="2.2 Output Formats"></a>2.2 Output Formats</h3><p>Evaluation outputs include:</p>
<ul>
<li><strong>Scores</strong>: Quantitative scoring of samples.</li>
<li><strong>Ranking</strong>: Ordering based on merit.</li>
<li><strong>Selection</strong>: Choosing the best option among candidates.</li>
</ul>
<hr>
<h2 id="3-Evaluation-Attributes"><a href="#3-Evaluation-Attributes" class="headerlink" title="3. Evaluation Attributes"></a>3. Evaluation Attributes</h2><h3 id="3-1-Helpfulness"><a href="#3-1-Helpfulness" class="headerlink" title="3.1 Helpfulness"></a>3.1 Helpfulness</h3><p>LLMs evaluate the helpfulness of responses by guiding user tasks and generating feedback, which is crucial in AI alignment.</p>
<h3 id="3-2-Harmlessness"><a href="#3-2-Harmlessness" class="headerlink" title="3.2 Harmlessness"></a>3.2 Harmlessness</h3><p>Evaluating the harmlessness of text is key to generating safe content. LLMs assist in data labeling or directly assess potential harmful content.</p>
<h3 id="3-3-Reliability"><a href="#3-3-Reliability" class="headerlink" title="3.3 Reliability"></a>3.3 Reliability</h3><p>LLMs detect factual accuracy and consistency, e.g., generating supporting evidence or conducting conversation-level reliability evaluations.</p>
<h3 id="3-4-Relevance"><a href="#3-4-Relevance" class="headerlink" title="3.4 Relevance"></a>3.4 Relevance</h3><p>LLMs assess the relevance of generated or retrieved content, applicable in scenarios like conversations and retrieval-augmented generation (RAG).</p>
<h3 id="3-5-Feasibility"><a href="#3-5-Feasibility" class="headerlink" title="3.5 Feasibility"></a>3.5 Feasibility</h3><p>In complex tasks, LLMs judge the feasibility of candidate steps or actions to optimize decision paths.</p>
<h3 id="3-6-Overall-Quality"><a href="#3-6-Overall-Quality" class="headerlink" title="3.6 Overall Quality"></a>3.6 Overall Quality</h3><p>By scoring across multiple dimensions, LLMs provide an overall evaluation, suitable for comprehensive comparisons in generation tasks.</p>
<hr>
<h3 id="4-Methodology"><a href="#4-Methodology" class="headerlink" title="4. Methodology"></a>4. Methodology</h3><h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h4><p>The methodology section focuses on optimizing the capabilities of LLMs as evaluators (LLM-as-a-Judge) through two approaches: fine-tuning and prompt engineering.</p>
<ol>
<li><strong>Fine-Tuning Techniques</strong>: Enhancing LLM judgment capabilities using supervised fine-tuning (SFT) and preference learning with labeled or synthetic feedback.</li>
<li><strong>Prompt Engineering</strong>: Designing effective prompt strategies, such as operation swapping, rule enhancement, and multi-agent collaboration, to improve inference and evaluation accuracy and reliability.</li>
</ol>
<hr>
<h4 id="4-1-Fine-Tuning-Techniques"><a href="#4-1-Fine-Tuning-Techniques" class="headerlink" title="4.1 Fine-Tuning Techniques"></a>4.1 Fine-Tuning Techniques</h4><h5 id="Data-Sources"><a href="#Data-Sources" class="headerlink" title="Data Sources"></a>Data Sources</h5><h6 id="1-Human-Labeled-Data"><a href="#1-Human-Labeled-Data" class="headerlink" title="1. Human-Labeled Data"></a>1. <strong>Human-Labeled Data</strong></h6><p>Human-labeled data provides high-quality training samples that help LLMs learn human preferences. Key studies and innovations include:</p>
<ol>
<li><p><strong>PandaLM</strong> [Wang et al., 2024h]:</p>
<ul>
<li>Collected a diverse dataset with 300,000 samples for instruction-generation tasks.</li>
<li>Enhanced generalization by integrating data sources like open-domain QA and dialogue generation.</li>
<li>Introduced standardized annotation workflows for consistency and emphasized multilingual support.</li>
</ul>
</li>
<li><p><strong>AspectInstruct</strong> [Liu et al., 2024a]:</p>
<ul>
<li>Introduced a dataset tailored for multi-dimensional evaluation, covering 65 tasks and 27 evaluation dimensions.</li>
<li>Designed a unique task segmentation mechanism for contextual understanding and dimension prioritization.</li>
</ul>
</li>
</ol>
<h6 id="2-Synthetic-Data"><a href="#2-Synthetic-Data" class="headerlink" title="2. Synthetic Data"></a>2. <strong>Synthetic Data</strong></h6><p>Synthetic data generated by LLMs reduces dependency on human labeling and expands data coverage. Key studies and innovations include:</p>
<ol>
<li><p><strong>JudgeLM</strong> [Zhu et al., 2023]:</p>
<ul>
<li>Generated a dataset with 100,000 samples, covering various instruction-generation scenarios.</li>
<li>Introduced task-seeding methods to ensure diversity and specificity.</li>
</ul>
</li>
<li><p><strong>Meta-Rewarding</strong> [Wu et al., 2024]:</p>
<ul>
<li>Proposed “meta-rewarding,” using LLM self-evaluation signals to enhance training effectiveness.</li>
</ul>
</li>
</ol>
<h5 id="Fine-Tuning-Methods"><a href="#Fine-Tuning-Methods" class="headerlink" title="Fine-Tuning Methods"></a>Fine-Tuning Methods</h5><h6 id="1-Supervised-Fine-Tuning-SFT"><a href="#1-Supervised-Fine-Tuning-SFT" class="headerlink" title="1. Supervised Fine-Tuning (SFT)"></a>1. <strong>Supervised Fine-Tuning (SFT)</strong></h6><p>SFT trains LLMs using human-labeled or synthetic data to learn evaluation criteria. Key studies include:</p>
<ol>
<li><p><strong>FLAMe</strong> [Vu et al., 2024]:</p>
<ul>
<li>Leveraged a multi-task learning framework with 5 million samples for multi-task SFT.</li>
<li>Unified evaluation standards across diverse tasks.</li>
</ul>
</li>
<li><p><strong>JSFT</strong> [Lee et al., 2024]:</p>
<ul>
<li>Combined SFT with preference learning to optimize performance on diverse evaluation tasks.</li>
</ul>
</li>
</ol>
<h6 id="2-Preference-Learning"><a href="#2-Preference-Learning" class="headerlink" title="2. Preference Learning"></a>2. <strong>Preference Learning</strong></h6><p>Preference learning optimizes LLM comparison and ranking capabilities for complex evaluations. Key studies include:</p>
<ol>
<li><p><strong>HALU-J</strong> [Wang et al., 2024a]:</p>
<ul>
<li>Employed directed preference optimization (DPO) with multi-evidence selection mechanisms.</li>
</ul>
</li>
<li><p><strong>Self-Taught Evaluators</strong> [Wang et al., 2024f]:</p>
<ul>
<li>Used self-generated suboptimal responses as negative samples for dynamic improvement.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-Applications"><a href="#5-Applications" class="headerlink" title="5. Applications"></a>5. Applications</h3><h4 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h4><p>The applications of LLM-as-a-Judge have expanded from generation evaluation to alignment, retrieval, and reasoning. This section systematically introduces these applications, their specific tasks, and representative studies.</p>
<hr>
<h4 id="5-1-Evaluation"><a href="#5-1-Evaluation" class="headerlink" title="5.1 Evaluation"></a>5.1 Evaluation</h4><h5 id="Overview-2"><a href="#Overview-2" class="headerlink" title="Overview"></a>Overview</h5><p>LLM-as-a-Judge was initially applied to evaluation tasks like dialogue generation and summarization. Key studies include:</p>
<ol>
<li><p><strong>MD-Judge</strong> [Li et al., 2024f]:</p>
<ul>
<li>Evaluated safety-related Q&amp;A frameworks, focusing on harmfulness and ethical risks.</li>
</ul>
</li>
<li><p><strong>Chan Framework</strong> [Chan et al., 2023]:</p>
<ul>
<li>Introduced a multi-agent debate framework for improved evaluation quality.</li>
</ul>
</li>
<li><p><strong>ICE</strong> [Jain et al., 2023b]:</p>
<ul>
<li>Used few-shot examples for interactive multi-dimensional evaluation.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="7-Challenges-and-Future-Directions"><a href="#7-Challenges-and-Future-Directions" class="headerlink" title="7. Challenges and Future Directions"></a>7. Challenges and Future Directions</h3><h4 id="Overview-3"><a href="#Overview-3" class="headerlink" title="Overview"></a>Overview</h4><p>Despite its powerful capabilities, LLM-as-a-Judge faces challenges such as evaluation bias, adaptability to dynamic tasks, and the potential of human-AI collaborative evaluation. This section explores these challenges and outlines future research directions.</p>
<h5 id="7-1-Bias-and-Vulnerabilities"><a href="#7-1-Bias-and-Vulnerabilities" class="headerlink" title="7.1 Bias and Vulnerabilities"></a>7.1 Bias and Vulnerabilities</h5><ol>
<li><strong>OffsetBias</strong> [Park et al., 2024]:<ul>
<li>Proposed a de-biasing framework to mitigate positional and content biases.</li>
</ul>
</li>
</ol>
<h5 id="7-2-Dynamic-and-Complex-Evaluations"><a href="#7-2-Dynamic-and-Complex-Evaluations" class="headerlink" title="7.2 Dynamic and Complex Evaluations"></a>7.2 Dynamic and Complex Evaluations</h5><ol>
<li><strong>Tree of Thought (ToT)</strong> [Yao et al., 2023a]:<ul>
<li>Enhanced multi-step reasoning with dynamic state evaluation mechanisms.</li>
</ul>
</li>
</ol>
<h5 id="7-3-Self-Evaluation-and-Human-AI-Collaboration"><a href="#7-3-Self-Evaluation-and-Human-AI-Collaboration" class="headerlink" title="7.3 Self-Evaluation and Human-AI Collaboration"></a>7.3 Self-Evaluation and Human-AI Collaboration</h5><ol>
<li><p><strong>Self-Taught Evaluators</strong> [Wang et al., 2024f]:</p>
<ul>
<li>Highlighted the potential for models to improve through self-learning mechanisms.</li>
</ul>
</li>
<li><p><strong>Meta-Rewarding</strong> [Wu et al., 2024]:</p>
<ul>
<li>Demonstrated the advantages of integrating self-evaluation signals into optimization.</li>
</ul>
</li>
</ol>
<hr>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI/" title="SeCom: Redefining Memory Management in Conversational AI"><span class="has-text-weight-semibold">Next: SeCom: Redefining Memory Management in Conversational AI</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>