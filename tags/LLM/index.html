<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>user's blog</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">user's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>æ ‡ç­¾ Â· LLM</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">é¦–é¡µ</a></h3><h3 class="is-inline-block"><a href="/about">å…³äº</a></h3><h3 class="is-inline-block"><a href="/archives">å½’æ¡£</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">é¦–é¡µ</a></h3><h3 class="is-inline-block"><a href="/about">å…³äº</a></h3><h3 class="is-inline-block"><a href="/archives">å½’æ¡£</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.zh-CN/">Decoder-onlyä¸Encoder-onlyæ¨¡å‹Paddingç­–ç•¥çš„å·®å¼‚</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ Padding çš„å«ä¹‰åœ¨å¤§æ¨¡å‹ (LLM) ä¸­ï¼Œpadding æ˜¯ç”¨äºå°†ä¸åŒé•¿åº¦çš„åºåˆ—è°ƒæ•´ä¸ºåŒä¸€é•¿åº¦çš„æ–¹æ³•ï¼Œä»¥ä¾¿äºæ‰¹é‡ (batch) å¤„ç†ã€‚
ä¾‹å¦‚ï¼š
12å¥å­1: &quot;I love NLP&quot;å¥å­2: &quot;Padding is useful in LLM training&quot;

ä½¿ç”¨ &amp;lt;pad&amp;gt; token è¿›è¡Œå¯¹é½ï¼š
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Padding ä½ç½®çš„é€‰æ‹©ï¼šLeft vs RightPadding æœ‰ä¸¤ç§å¸¸è§æ–¹å¼ï¼š

Right paddingï¼ˆå³å¡«å……ï¼‰ï¼š
1&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.zh-CN/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.en/">Differences in Padding Strategies Between Decoder-only and Encoder-only Models</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ What is Padding?In Large Language Models (LLMs), padding is a method used to standardize sequence lengths for batch processing.
For example:
12Sentence 1: &quot;I love NLP&quot;Sentence 2: &quot;Padding is useful in LLM training&quot;

Using the &amp;lt;pad&amp;gt; token for alignment:
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Paddi..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.en/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.en/">Decoder-onlyä¸Encoder-onlyæ¨¡å‹Paddingç­–ç•¥çš„å·®å¼‚</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ Padding çš„å«ä¹‰åœ¨å¤§æ¨¡å‹ (LLM) ä¸­ï¼Œpadding æ˜¯ç”¨äºå°†ä¸åŒé•¿åº¦çš„åºåˆ—è°ƒæ•´ä¸ºåŒä¸€é•¿åº¦çš„æ–¹æ³•ï¼Œä»¥ä¾¿äºæ‰¹é‡ (batch) å¤„ç†ã€‚
ä¾‹å¦‚ï¼š
12å¥å­1: &quot;I love NLP&quot;å¥å­2: &quot;Padding is useful in LLM training&quot;

ä½¿ç”¨ &amp;lt;pad&amp;gt; token è¿›è¡Œå¯¹é½ï¼š
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Padding ä½ç½®çš„é€‰æ‹©ï¼šLeft vs RightPadding æœ‰ä¸¤ç§å¸¸è§æ–¹å¼ï¼š

Right paddingï¼ˆå³å¡«å……ï¼‰ï¼š
1&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C.en/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.zh-CN/">Differences in Padding Strategies Between Decoder-only and Encoder-only Models</a></h2><time class="has-text-grey" datetime="2025-03-06T09:43:10.000Z">2025-03-06</time><p class="is-flex-grow-2 mt-2">ğŸ“Œ What is Padding?In Large Language Models (LLMs), padding is a method used to standardize sequence lengths for batch processing.
For example:
12Sentence 1: &quot;I love NLP&quot;Sentence 2: &quot;Padding is useful in LLM training&quot;

Using the &amp;lt;pad&amp;gt; token for alignment:
12&quot;I love NLP &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt; &amp;lt;pad&amp;gt;&quot;&quot;Padding is useful in LLM training&quot;


ğŸ“Œ Paddi..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models.zh-CN/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2.en/">MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</a></h2><time class="has-text-grey" datetime="2025-02-11T03:50:29.000Z">2025-02-11</time><p class="is-flex-grow-2 mt-2">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²åŸæ–‡åœ°å€ï¼šA Visual Guide to Mixture of Experts (MoE)
ğŸ“… ä½œè€…ï¼šMaarten Grootendorst
ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥

æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—ç›®å½•
MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²
æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—
ç›®å½•
ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ
Experts
Dense Layers
Sparse Layers
What does an Expert Learn?
ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰





å½“æˆ‘ä»¬æŸ¥çœ‹æœ€æ–°å‘å¸ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼ŒLarge ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2.en/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2.zh-CN/">MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</a></h2><time class="has-text-grey" datetime="2025-02-11T03:50:29.000Z">2025-02-11</time><p class="is-flex-grow-2 mt-2">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²åŸæ–‡åœ°å€ï¼šA Visual Guide to Mixture of Experts (MoE)
ğŸ“… ä½œè€…ï¼šMaarten Grootendorst
ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥

æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—ç›®å½•
MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²
æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—
ç›®å½•
ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ
Experts
Dense Layers
Sparse Layers
What does an Expert Learn?
ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰





å½“æˆ‘ä»¬æŸ¥çœ‹æœ€æ–°å‘å¸ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼ŒLarge ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2.zh-CN/">æ›´å¤š</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://user-images.githubusercontent.com/your-image-url.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1.zh-CN/"><img class="post-cover-img js-img-fadeIn" src="https://user-images.githubusercontent.com/your-image-url.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1.zh-CN/">æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1</a></h2><time class="has-text-grey" datetime="2025-02-11T03:50:29.000Z">2025-02-11</time><p class="is-flex-grow-2 mt-2">æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1åŸæ–‡åœ°å€ï¼šA Visual Guide to Reasoning LLMs
ğŸ“… ä½œè€…ï¼šMaarten Grootendorst
ğŸ“† æ—¥æœŸï¼š2025 å¹´ 2 æœˆ 3 æ—¥

ğŸ“Œ å¼•è¨€DeepSeek-R1ã€OpenAI o3-mini å’Œ Google Gemini 2.0 Flash Thinking æ˜¯å¦‚ä½•é€šè¿‡â€œæ¨ç†â€æ¡†æ¶å°† LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹, Large Language Modelsï¼‰ æ‰©å±•åˆ°æ–°é«˜åº¦çš„å…¸å‹ç¤ºä¾‹ã€‚
å®ƒä»¬æ ‡å¿—ç€ä» æ‰©å±•è®­ç»ƒæ—¶è®¡ç®—ï¼ˆtrain-time computeï¼‰ åˆ° æ‰©å±•æ¨ç†æ—¶è®¡ç®—ï¼ˆtest-time computeï¼‰ çš„èŒƒå¼è½¬å˜ã€‚
åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æä¾›äº† è¶…è¿‡ 40 å¼ å®šåˆ¶å¯è§†åŒ–å›¾è¡¨ï¼Œå¸¦ä½ æ·±å…¥æ¢ç´¢ï¼š
..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1.zh-CN/">æ›´å¤š</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="https://user-images.githubusercontent.com/your-image-url.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1.en/"><img class="post-cover-img js-img-fadeIn" src="https://user-images.githubusercontent.com/your-image-url.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1.en/">æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1</a></h2><time class="has-text-grey" datetime="2025-02-11T03:50:29.000Z">2025-02-11</time><p class="is-flex-grow-2 mt-2">æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1åŸæ–‡åœ°å€ï¼šA Visual Guide to Reasoning LLMs
ğŸ“… ä½œè€…ï¼šMaarten Grootendorst
ğŸ“† æ—¥æœŸï¼š2025 å¹´ 2 æœˆ 3 æ—¥

ğŸ“Œ å¼•è¨€DeepSeek-R1ã€OpenAI o3-mini å’Œ Google Gemini 2.0 Flash Thinking æ˜¯å¦‚ä½•é€šè¿‡â€œæ¨ç†â€æ¡†æ¶å°† LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹, Large Language Modelsï¼‰ æ‰©å±•åˆ°æ–°é«˜åº¦çš„å…¸å‹ç¤ºä¾‹ã€‚
å®ƒä»¬æ ‡å¿—ç€ä» æ‰©å±•è®­ç»ƒæ—¶è®¡ç®—ï¼ˆtrain-time computeï¼‰ åˆ° æ‰©å±•æ¨ç†æ—¶è®¡ç®—ï¼ˆtest-time computeï¼‰ çš„èŒƒå¼è½¬å˜ã€‚
åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æä¾›äº† è¶…è¿‡ 40 å¼ å®šåˆ¶å¯è§†åŒ–å›¾è¡¨ï¼Œå¸¦ä½ æ·±å…¥æ¢ç´¢ï¼š
..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1.en/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies.en/">Detailed Explanation of LoRA, DPO, KTO, and SFT Technologies</a></h2><time class="has-text-grey" datetime="2024-10-23T08:26:29.000Z">2024-10-23</time><p class="is-flex-grow-2 mt-2">Introduction to LLM Training Terminology:LoRA, DPO, KTO, and SFT TechnologiesThis document provides a detailed introduction to several important techniques used in fine-tuning and optimizing large language models (such as LLAMA3), including SFT (Supervised Fine-Tuning), LoRA (Low-Rank Adaptation), Alignment technologies, KTO (Kahneman-Tversky Optimization)..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies.en/">æ›´å¤š</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LLM"><i class="tag post-item-tag">LLM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies.zh-CN/">Detailed Explanation of LoRA, DPO, KTO, and SFT Technologies</a></h2><time class="has-text-grey" datetime="2024-10-23T08:26:29.000Z">2024-10-23</time><p class="is-flex-grow-2 mt-2">Introduction to LLM Training Terminology:LoRA, DPO, KTO, and SFT TechnologiesThis document provides a detailed introduction to several important techniques used in fine-tuning and optimizing large language models (such as LLAMA3), including SFT (Supervised Fine-Tuning), LoRA (Low-Rank Adaptation), Alignment technologies, KTO (Kahneman-Tversky Optimization)..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies.zh-CN/">æ›´å¤š</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><span class="page-number current">1</span><a class="page-number" href="/tags/LLM/page/2/">2</a><a class="page-number" href="/tags/LLM/page/3/">3</a><a class="extend next" rel="next" href="/tags/LLM/page/2/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container tag-widget is-in-tag-page"><h3>æ ‡ç­¾</h3><section><a href="/tags/IssueFix"><span class="tag post-item-tag" style="margin-bottom: 5px;">IssueFix</span></a><a href="/tags/Blog"><span class="tag post-item-tag" style="margin-bottom: 5px;">Blog</span></a><a href="/tags/Git"><span class="tag post-item-tag" style="margin-bottom: 5px;">Git</span></a><a href="/tags/K8s"><span class="tag post-item-tag" style="margin-bottom: 5px;">K8s</span></a><a href="/tags/Language%20Modeling"><span class="tag post-item-tag" style="margin-bottom: 5px;">Language Modeling</span></a><a href="/tags/Perplexity"><span class="tag post-item-tag" style="margin-bottom: 5px;">Perplexity</span></a><a href="/tags/Onnx"><span class="tag post-item-tag" style="margin-bottom: 5px;">Onnx</span></a><a href="/tags/Deployment"><span class="tag post-item-tag" style="margin-bottom: 5px;">Deployment</span></a><a href="/tags/Chatbot"><span class="tag post-item-tag" style="margin-bottom: 5px;">Chatbot</span></a><a href="/tags/DSSM"><span class="tag post-item-tag" style="margin-bottom: 5px;">DSSM</span></a><a href="/tags/Recommendation"><span class="tag post-item-tag" style="margin-bottom: 5px;">Recommendation</span></a><a href="/tags/LLM"><span class="tag post-item-tag" style="margin-bottom: 5px;">LLM</span></a><a href="/tags/FastChat"><span class="tag post-item-tag" style="margin-bottom: 5px;">FastChat</span></a><a href="/tags/Train"><span class="tag post-item-tag" style="margin-bottom: 5px;">Train</span></a><a href="/tags/Agent"><span class="tag post-item-tag" style="margin-bottom: 5px;">Agent</span></a><a href="/tags/Tool%20Use"><span class="tag post-item-tag" style="margin-bottom: 5px;">Tool Use</span></a><a href="/tags/Gorilla"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gorilla</span></a><a href="/tags/Prompt"><span class="tag post-item-tag" style="margin-bottom: 5px;">Prompt</span></a><a href="/tags/vLLM"><span class="tag post-item-tag" style="margin-bottom: 5px;">vLLM</span></a><a href="/tags/Gemma-2-2b-it"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gemma-2-2b-it</span></a><a href="/tags/Conversational%20AI"><span class="tag post-item-tag" style="margin-bottom: 5px;">Conversational AI</span></a><a href="/tags/Memory%20Management"><span class="tag post-item-tag" style="margin-bottom: 5px;">Memory Management</span></a><a href="/tags/SeCom"><span class="tag post-item-tag" style="margin-bottom: 5px;">SeCom</span></a><a href="/tags/RAG"><span class="tag post-item-tag" style="margin-bottom: 5px;">RAG</span></a><a href="/tags/Gemma-2"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gemma-2</span></a><a href="/tags/SGLang"><span class="tag post-item-tag" style="margin-bottom: 5px;">SGLang</span></a><a href="/tags/Structured%20LLM"><span class="tag post-item-tag" style="margin-bottom: 5px;">Structured LLM</span></a><a href="/tags/Language%20Learning"><span class="tag post-item-tag" style="margin-bottom: 5px;">Language Learning</span></a><a href="/tags/English%20Vocabulary"><span class="tag post-item-tag" style="margin-bottom: 5px;">English Vocabulary</span></a><a href="/tags/Deep%20Learning"><span class="tag post-item-tag" style="margin-bottom: 5px;">Deep Learning</span></a><a href="/tags/Gradient%20Descent"><span class="tag post-item-tag" style="margin-bottom: 5px;">Gradient Descent</span></a><a href="/tags/Living%20in%20Singapore"><span class="tag post-item-tag" style="margin-bottom: 5px;">Living in Singapore</span></a><a href="/tags/Guide%20to%20Living%20on%20Singapore%20Island"><span class="tag post-item-tag" style="margin-bottom: 5px;">Guide to Living on Singapore Island</span></a><a href="/tags/Sports"><span class="tag post-item-tag" style="margin-bottom: 5px;">Sports</span></a><a href="/tags/%E5%9D%A1%E5%B2%9B%E7%94%9F%E6%B4%BB%E6%8C%87%E5%8C%97"><span class="tag post-item-tag" style="margin-bottom: 5px;">å¡å²›ç”Ÿæ´»æŒ‡åŒ—</span></a><a href="/tags/Small%20Talk"><span class="tag post-item-tag" style="margin-bottom: 5px;">Small Talk</span></a><a href="/tags/%E6%9D%82%E8%B0%88"><span class="tag post-item-tag" style="margin-bottom: 5px;">æ‚è°ˆ</span></a><a href="/tags/Python"><span class="tag post-item-tag" style="margin-bottom: 5px;">Python</span></a><a href="/tags/Leetcode"><span class="tag post-item-tag" style="margin-bottom: 5px;">Leetcode</span></a><a href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98"><span class="tag post-item-tag" style="margin-bottom: 5px;">æ¯æ—¥ä¸€é¢˜</span></a><a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92"><span class="tag post-item-tag" style="margin-bottom: 5px;">åŠ¨æ€è§„åˆ’</span></a><a href="/tags/FAISS"><span class="tag post-item-tag" style="margin-bottom: 5px;">FAISS</span></a><a href="/tags/Embedding"><span class="tag post-item-tag" style="margin-bottom: 5px;">Embedding</span></a><a href="/tags/Python%20Basic"><span class="tag post-item-tag" style="margin-bottom: 5px;">Python Basic</span></a><a href="/tags/Daily%20Challenge"><span class="tag post-item-tag" style="margin-bottom: 5px;">Daily Challenge</span></a><a href="/tags/%E5%8F%8C%E5%91%A8%E8%B5%9B"><span class="tag post-item-tag" style="margin-bottom: 5px;">åŒå‘¨èµ›</span></a></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- çŸ¥ä¹--><!-- é¢†è‹±--><!-- è„¸ä¹¦--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright Â©</span><span> user 2026</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script src="/js/lang-switch.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>