<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…</title>
  
  <subtitle>åªèº«æ‰“ç è¿‡è‰åŸ</subtitle>
  <link href="https://chenhuiyu.github.io/atom.xml" rel="self"/>
  
  <link href="https://chenhuiyu.github.io/"/>
  <updated>2026-02-20T21:56:22.871Z</updated>
  <id>https://chenhuiyu.github.io/</id>
  
  <author>
    <name>Huiyu Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="https://chenhuiyu.github.io/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment/"/>
    <id>https://chenhuiyu.github.io/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment/</id>
    <published>2026-02-20T21:56:22.871Z</published>
    <updated>2026-02-20T21:56:22.871Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Evaluation-of-Generation-Based-Large-Language-Models-LLMs-Opportunities-and-Challenges-from-Generation-to-Judgment"><a href="#Evaluation-of-Generation-Based-Large-Language-Models-LLMs-Opportunities-and-Challenges-from-Generation-to-Judgment" class="headerlink" title="Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to Judgment"></a>Evaluation of Generation-Based Large Language Models (LLMs): Opportunities and Challenges from Generation to Judgment</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Evaluation tasks in artificial intelligence (AI) and natural language processing (NLP) have long been challenging. Traditional evaluation methods, such as those based on matching or embeddings, are limited in assessing complex attributes. The recent development of large language models (LLMs) has given rise to the â€œLLM-as-a-Judgeâ€ paradigm, which utilizes LLMs for scoring, ranking, or selection tasks. This paper provides a comprehensive review of LLM evaluation methodologies, including their definitions, classification frameworks, benchmarks, and future research directions.</p><hr><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><h3 id="1-1-Background"><a href="#1-1-Background" class="headerlink" title="1.1 Background"></a>1.1 Background</h3><p>Evaluation is one of the core issues in machine learning and NLP. Traditional evaluation methods such as BLEU and ROUGE often rely on text overlap and lack applicability in complex scenarios. With the development of deep learning and LLMs (e.g., GPT-4), researchers have proposed the â€œLLM-as-a-Judgeâ€ paradigm to address the limitations of traditional evaluation methods.</p><h3 id="1-2-Research-Questions"><a href="#1-2-Research-Questions" class="headerlink" title="1.2 Research Questions"></a>1.2 Research Questions</h3><p>This paper aims to explore the following questions:</p><ul><li><strong>What do LLMs evaluate?</strong></li><li><strong>How is evaluation conducted?</strong></li><li><strong>Where are LLMs applied for evaluation?</strong></li></ul><hr><h2 id="2-Preliminary-Knowledge"><a href="#2-Preliminary-Knowledge" class="headerlink" title="2. Preliminary Knowledge"></a>2. Preliminary Knowledge</h2><h3 id="2-1-Input-Formats"><a href="#2-1-Input-Formats" class="headerlink" title="2.1 Input Formats"></a>2.1 Input Formats</h3><p>Evaluation inputs can be categorized as follows:</p><ul><li><strong>Point-Wise</strong>: Evaluation of a single sample.</li><li><strong>Pair/List-Wise</strong>: Comparative evaluation of multiple samples.</li></ul><h3 id="2-2-Output-Formats"><a href="#2-2-Output-Formats" class="headerlink" title="2.2 Output Formats"></a>2.2 Output Formats</h3><p>Evaluation outputs include:</p><ul><li><strong>Scores</strong>: Quantitative scoring of samples.</li><li><strong>Ranking</strong>: Ordering based on merit.</li><li><strong>Selection</strong>: Choosing the best option among candidates.</li></ul><hr><h2 id="3-Evaluation-Attributes"><a href="#3-Evaluation-Attributes" class="headerlink" title="3. Evaluation Attributes"></a>3. Evaluation Attributes</h2><h3 id="3-1-Helpfulness"><a href="#3-1-Helpfulness" class="headerlink" title="3.1 Helpfulness"></a>3.1 Helpfulness</h3><p>LLMs evaluate the helpfulness of responses by guiding user tasks and generating feedback, which is crucial in AI alignment.</p><h3 id="3-2-Harmlessness"><a href="#3-2-Harmlessness" class="headerlink" title="3.2 Harmlessness"></a>3.2 Harmlessness</h3><p>Evaluating the harmlessness of text is key to generating safe content. LLMs assist in data labeling or directly assess potential harmful content.</p><h3 id="3-3-Reliability"><a href="#3-3-Reliability" class="headerlink" title="3.3 Reliability"></a>3.3 Reliability</h3><p>LLMs detect factual accuracy and consistency, e.g., generating supporting evidence or conducting conversation-level reliability evaluations.</p><h3 id="3-4-Relevance"><a href="#3-4-Relevance" class="headerlink" title="3.4 Relevance"></a>3.4 Relevance</h3><p>LLMs assess the relevance of generated or retrieved content, applicable in scenarios like conversations and retrieval-augmented generation (RAG).</p><h3 id="3-5-Feasibility"><a href="#3-5-Feasibility" class="headerlink" title="3.5 Feasibility"></a>3.5 Feasibility</h3><p>In complex tasks, LLMs judge the feasibility of candidate steps or actions to optimize decision paths.</p><h3 id="3-6-Overall-Quality"><a href="#3-6-Overall-Quality" class="headerlink" title="3.6 Overall Quality"></a>3.6 Overall Quality</h3><p>By scoring across multiple dimensions, LLMs provide an overall evaluation, suitable for comprehensive comparisons in generation tasks.</p><hr><h3 id="4-Methodology"><a href="#4-Methodology" class="headerlink" title="4. Methodology"></a>4. Methodology</h3><h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h4><p>The methodology section focuses on optimizing the capabilities of LLMs as evaluators (LLM-as-a-Judge) through two approaches: fine-tuning and prompt engineering.</p><ol><li><strong>Fine-Tuning Techniques</strong>: Enhancing LLM judgment capabilities using supervised fine-tuning (SFT) and preference learning with labeled or synthetic feedback.</li><li><strong>Prompt Engineering</strong>: Designing effective prompt strategies, such as operation swapping, rule enhancement, and multi-agent collaboration, to improve inference and evaluation accuracy and reliability.</li></ol><hr><h4 id="4-1-Fine-Tuning-Techniques"><a href="#4-1-Fine-Tuning-Techniques" class="headerlink" title="4.1 Fine-Tuning Techniques"></a>4.1 Fine-Tuning Techniques</h4><h5 id="Data-Sources"><a href="#Data-Sources" class="headerlink" title="Data Sources"></a>Data Sources</h5><h6 id="1-Human-Labeled-Data"><a href="#1-Human-Labeled-Data" class="headerlink" title="1. Human-Labeled Data"></a>1. <strong>Human-Labeled Data</strong></h6><p>Human-labeled data provides high-quality training samples that help LLMs learn human preferences. Key studies and innovations include:</p><ol><li><p><strong>PandaLM</strong> [Wang et al., 2024h]:</p><ul><li>Collected a diverse dataset with 300,000 samples for instruction-generation tasks.</li><li>Enhanced generalization by integrating data sources like open-domain QA and dialogue generation.</li><li>Introduced standardized annotation workflows for consistency and emphasized multilingual support.</li></ul></li><li><p><strong>AspectInstruct</strong> [Liu et al., 2024a]:</p><ul><li>Introduced a dataset tailored for multi-dimensional evaluation, covering 65 tasks and 27 evaluation dimensions.</li><li>Designed a unique task segmentation mechanism for contextual understanding and dimension prioritization.</li></ul></li></ol><h6 id="2-Synthetic-Data"><a href="#2-Synthetic-Data" class="headerlink" title="2. Synthetic Data"></a>2. <strong>Synthetic Data</strong></h6><p>Synthetic data generated by LLMs reduces dependency on human labeling and expands data coverage. Key studies and innovations include:</p><ol><li><p><strong>JudgeLM</strong> [Zhu et al., 2023]:</p><ul><li>Generated a dataset with 100,000 samples, covering various instruction-generation scenarios.</li><li>Introduced task-seeding methods to ensure diversity and specificity.</li></ul></li><li><p><strong>Meta-Rewarding</strong> [Wu et al., 2024]:</p><ul><li>Proposed â€œmeta-rewarding,â€ using LLM self-evaluation signals to enhance training effectiveness.</li></ul></li></ol><h5 id="Fine-Tuning-Methods"><a href="#Fine-Tuning-Methods" class="headerlink" title="Fine-Tuning Methods"></a>Fine-Tuning Methods</h5><h6 id="1-Supervised-Fine-Tuning-SFT"><a href="#1-Supervised-Fine-Tuning-SFT" class="headerlink" title="1. Supervised Fine-Tuning (SFT)"></a>1. <strong>Supervised Fine-Tuning (SFT)</strong></h6><p>SFT trains LLMs using human-labeled or synthetic data to learn evaluation criteria. Key studies include:</p><ol><li><p><strong>FLAMe</strong> [Vu et al., 2024]:</p><ul><li>Leveraged a multi-task learning framework with 5 million samples for multi-task SFT.</li><li>Unified evaluation standards across diverse tasks.</li></ul></li><li><p><strong>JSFT</strong> [Lee et al., 2024]:</p><ul><li>Combined SFT with preference learning to optimize performance on diverse evaluation tasks.</li></ul></li></ol><h6 id="2-Preference-Learning"><a href="#2-Preference-Learning" class="headerlink" title="2. Preference Learning"></a>2. <strong>Preference Learning</strong></h6><p>Preference learning optimizes LLM comparison and ranking capabilities for complex evaluations. Key studies include:</p><ol><li><p><strong>HALU-J</strong> [Wang et al., 2024a]:</p><ul><li>Employed directed preference optimization (DPO) with multi-evidence selection mechanisms.</li></ul></li><li><p><strong>Self-Taught Evaluators</strong> [Wang et al., 2024f]:</p><ul><li>Used self-generated suboptimal responses as negative samples for dynamic improvement.</li></ul></li></ol><hr><h3 id="5-Applications"><a href="#5-Applications" class="headerlink" title="5. Applications"></a>5. Applications</h3><h4 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h4><p>The applications of LLM-as-a-Judge have expanded from generation evaluation to alignment, retrieval, and reasoning. This section systematically introduces these applications, their specific tasks, and representative studies.</p><hr><h4 id="5-1-Evaluation"><a href="#5-1-Evaluation" class="headerlink" title="5.1 Evaluation"></a>5.1 Evaluation</h4><h5 id="Overview-2"><a href="#Overview-2" class="headerlink" title="Overview"></a>Overview</h5><p>LLM-as-a-Judge was initially applied to evaluation tasks like dialogue generation and summarization. Key studies include:</p><ol><li><p><strong>MD-Judge</strong> [Li et al., 2024f]:</p><ul><li>Evaluated safety-related Q&amp;A frameworks, focusing on harmfulness and ethical risks.</li></ul></li><li><p><strong>Chan Framework</strong> [Chan et al., 2023]:</p><ul><li>Introduced a multi-agent debate framework for improved evaluation quality.</li></ul></li><li><p><strong>ICE</strong> [Jain et al., 2023b]:</p><ul><li>Used few-shot examples for interactive multi-dimensional evaluation.</li></ul></li></ol><hr><h3 id="7-Challenges-and-Future-Directions"><a href="#7-Challenges-and-Future-Directions" class="headerlink" title="7. Challenges and Future Directions"></a>7. Challenges and Future Directions</h3><h4 id="Overview-3"><a href="#Overview-3" class="headerlink" title="Overview"></a>Overview</h4><p>Despite its powerful capabilities, LLM-as-a-Judge faces challenges such as evaluation bias, adaptability to dynamic tasks, and the potential of human-AI collaborative evaluation. This section explores these challenges and outlines future research directions.</p><h5 id="7-1-Bias-and-Vulnerabilities"><a href="#7-1-Bias-and-Vulnerabilities" class="headerlink" title="7.1 Bias and Vulnerabilities"></a>7.1 Bias and Vulnerabilities</h5><ol><li><strong>OffsetBias</strong> [Park et al., 2024]:<ul><li>Proposed a de-biasing framework to mitigate positional and content biases.</li></ul></li></ol><h5 id="7-2-Dynamic-and-Complex-Evaluations"><a href="#7-2-Dynamic-and-Complex-Evaluations" class="headerlink" title="7.2 Dynamic and Complex Evaluations"></a>7.2 Dynamic and Complex Evaluations</h5><ol><li><strong>Tree of Thought (ToT)</strong> [Yao et al., 2023a]:<ul><li>Enhanced multi-step reasoning with dynamic state evaluation mechanisms.</li></ul></li></ol><h5 id="7-3-Self-Evaluation-and-Human-AI-Collaboration"><a href="#7-3-Self-Evaluation-and-Human-AI-Collaboration" class="headerlink" title="7.3 Self-Evaluation and Human-AI Collaboration"></a>7.3 Self-Evaluation and Human-AI Collaboration</h5><ol><li><p><strong>Self-Taught Evaluators</strong> [Wang et al., 2024f]:</p><ul><li>Highlighted the potential for models to improve through self-learning mechanisms.</li></ul></li><li><p><strong>Meta-Rewarding</strong> [Wu et al., 2024]:</p><ul><li>Demonstrated the advantages of integrating self-evaluation signals into optimization.</li></ul></li></ol><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Evaluation-of-Generation-Based-Large-Language-Models-LLMs-Opportunities-and-Challenges-from-Generation-to-Judgment&quot;&gt;&lt;a href=&quot;#Evalua</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>SeCom: Redefining Memory Management in Conversational AI</title>
    <link href="https://chenhuiyu.github.io/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI/"/>
    <id>https://chenhuiyu.github.io/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI/</id>
    <published>2025-06-24T08:00:00.000Z</published>
    <updated>2026-02-20T21:56:22.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SeCom-Redefining-Memory-Management-in-Conversational-AI"><a href="#SeCom-Redefining-Memory-Management-in-Conversational-AI" class="headerlink" title="SeCom: Redefining Memory Management in Conversational AI"></a>SeCom: Redefining Memory Management in Conversational AI</h1><h2 id="Foreword"><a href="#Foreword" class="headerlink" title="Foreword"></a>Foreword</h2><p>Iâ€™ve recently been diving into memory management for dialog-based AI, especially how to construct and retrieve memories in long-term conversations. During my exploration I came across an eye-opening ICLR 2025 paperâ€”**â€SeCom: On Memory Construction and Retrieval for Personalized Conversational Agentsâ€**â€”a collaboration between Microsoft and Tsinghua University.</p><p>SeCom solves a core problem: <strong>How can an agent effectively manage and retrieve historical information in prolonged conversations?</strong> In this post Iâ€™ll unpack the methodâ€™s key ideas and technical innovations, hoping to spark inspiration for researchers working in this arena.</p><h2 id="1-Why-Should-We-Care-About-Dialog-Memory-Management"><a href="#1-Why-Should-We-Care-About-Dialog-Memory-Management" class="headerlink" title="1. Why Should We Care About Dialog Memory Management?"></a>1. Why Should We Care About Dialog Memory Management?</h2><h3 id="1-1-Real-World-Challenges-in-Long-Conversations"><a href="#1-1-Real-World-Challenges-in-Long-Conversations" class="headerlink" title="1.1 Real-World Challenges in Long Conversations"></a>1.1 Real-World Challenges in Long Conversations</h3><p>Anyone who chats with LLMs regularly has probably experienced this: once a conversation grows long, the agent seems to â€œforgetâ€ earlier context or respond incoherently. Thatâ€™s the memory problem in action.</p><p>Even with long-context models, super-long dialogs increase compute cost and often degrade quality. Key challenges include:</p><ul><li><strong>Context length limits</strong>: Token budgets remain finite.</li><li><strong>Information relevance</strong>: History contains plenty of facts irrelevant to the current query.</li><li><strong>Semantic coherence</strong>: Related information may be scattered across non-contiguous turns.</li><li><strong>Personalization</strong>: The agent must remember user preferences and interaction patterns.</li></ul><h3 id="1-2-A-Quick-Landscape-of-Existing-Approaches"><a href="#1-2-A-Quick-Landscape-of-Existing-Approaches" class="headerlink" title="1.2 A Quick Landscape of Existing Approaches"></a>1.2 A Quick Landscape of Existing Approaches</h3><p>The communityâ€™s strategies roughly split into three camps:</p><ol><li><strong>â€œGive Me Everythingâ€ (full history)</strong><ul><li>Complete information, zero recall loss.</li><li>But like moving an entire library just to find one bookâ€”computational overkill.</li></ul></li><li><strong>â€œBullet-Point Digestâ€ (summaries)</strong><ul><li>Compact and efficient.</li><li>Risk of omitting crucial details during abstraction.</li></ul></li><li><strong>â€œPrecision Strikeâ€ (retrieval-based)</strong><ul><li>Fetch only what you need, exactly when you need it.</li><li>Success hinges on choosing the right retrieval granularityâ€”precisely the issue SeCom addresses.</li></ul></li></ol><h4 id="1-2-3-Retrieval-Augmented-Generation-RAG-in-Dialog"><a href="#1-2-3-Retrieval-Augmented-Generation-RAG-in-Dialog" class="headerlink" title="1.2.3 Retrieval-Augmented Generation (RAG) in Dialog"></a>1.2.3 Retrieval-Augmented Generation (RAG) in Dialog</h4><p>RAG faces dialog-specific hurdles:</p><ul><li><strong>Chunking strategy</strong>: How to segment a dialog into retrievable units.</li><li><strong>Relevance estimation</strong>: Harder than in static docs due to dialog dynamics.</li><li><strong>Temporal dependency</strong>: Order matters; turns refer to earlier context.</li></ul><h3 id="1-3-The-Granularity-Dilemma"><a href="#1-3-The-Granularity-Dilemma" class="headerlink" title="1.3 The Granularity Dilemma"></a>1.3 The Granularity Dilemma</h3><p>We often index memories at the turn-level or at the whole-conversation level. Both extremes break down:</p><ul><li><strong>Turn-level</strong> â†’ fragments context, loses dependencies, retrieval recall suffers.</li><li><strong>Conversation-level</strong> â†’ topic mixture, lots of noise, retrieval becomes coarse.</li><li><strong>Summaries</strong> â†’ irreversible information loss.</li></ul><p>SeComâ€™s insight: dialog naturally contains <strong>paragraph-level thematic boundaries</strong>. Segmenting at this â€œjust-rightâ€ granularity preserves coherence without exploding memory size.</p><h2 id="2-Inside-SeCom"><a href="#2-Inside-SeCom" class="headerlink" title="2. Inside SeCom"></a>2. Inside SeCom</h2><h3 id="2-1-Two-Key-Insights"><a href="#2-1-Two-Key-Insights" class="headerlink" title="2.1 Two Key Insights"></a>2.1 Two Key Insights</h3><ol><li><strong>Paragraph-like Topic Shifts</strong> exist in dialog just as in essays.</li><li><strong>Natural Language Is Redundant</strong>â€”filler words, confirmations, small talk, etc. Removing them boosts retrieval precision.</li></ol><p>Hence <strong>SeCom = Segmentation + Compression</strong>.</p><h3 id="2-2-System-Pipeline"><a href="#2-2-System-Pipeline" class="headerlink" title="2.2 System Pipeline"></a>2.2 System Pipeline</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">History â†’ [Segmenter] â†’ Paragraph-level units â†’ [Compressor] â†’ Denoised memories â†’ [Retriever] â†’ Relevant context â†’ [Generator] â†’ Final reply</span><br></pre></td></tr></tbody></table></figure><p>Technically:</p><ol><li>Segmenter $f_{\mathcal I}$ splits the dialog.</li><li>Compressor $f_{comp}$ denoises each segment.</li><li>Retriever $f_R$ ranks memories for the current user utterance $u^*$.</li><li>LLM $f_{LLM}$ produces the answer based on top-N memories.</li></ol><h3 id="2-3-How-to-Segment-Without-Labels"><a href="#2-3-How-to-Segment-Without-Labels" class="headerlink" title="2.3 How to Segment Without Labels"></a>2.3 How to Segment Without Labels</h3><p>SeCom leverages GPT-4 in a <strong>zero-shot</strong> fashion: craft a prompt asking the model to mark topic boundaries and output span indices. No training data required.</p><p>When limited gold data are available, a <strong>reflection-based</strong> loop iteratively refines the guidelines using WindowDiff scores and GPT-4 reasoning.</p><p>An <strong>incremental segmenter</strong> decides on-the-fly whether a new turn merges into the previous segment or starts a fresh one.</p><h3 id="2-4-Denoising-via-LLMLingua-2"><a href="#2-4-Denoising-via-LLMLingua-2" class="headerlink" title="2.4 Denoising via LLMLingua-2"></a>2.4 Denoising via LLMLingua-2</h3><p>LLMLingua-2 scores token importance and keeps the top $(1-r)$ fraction (e.g., 25 %) accordingly. Empirically, retaining just 25 % tokens preserves <strong>&gt;95 %</strong> key information, lifts retrieval GPT4Score by <strong>+9.46</strong>, and yields 4 Ã— speed-up.</p><h3 id="2-5-Hybrid-Retrieval"><a href="#2-5-Hybrid-Retrieval" class="headerlink" title="2.5 Hybrid Retrieval"></a>2.5 Hybrid Retrieval</h3><p>BM25 (sparse) and MPNet (dense) scores are linearly combined:</p><p>$$\text{score}_{hybrid}=\alpha,\text{BM25}+(1-\alpha),\text{MPNet}, \quad \alpha=0.6$$</p><h2 id="3-Final-Thoughts"><a href="#3-Final-Thoughts" class="headerlink" title="3. Final Thoughts"></a>3. Final Thoughts</h2><h3 id="3-1-What-SeCom-Teaches-Us"><a href="#3-1-What-SeCom-Teaches-Us" class="headerlink" title="3.1 What SeCom Teaches Us"></a>3.1 What SeCom Teaches Us</h3><ul><li><strong>Simplicity Wins</strong>: Segment + Compress, nothing fancy, yet highly effective.</li><li><strong>Understand the Problem First</strong>: The authors nailed the granularity pain-point before designing a solution.</li></ul><p>Future directions:</p><ul><li><strong>Personalized segmentation</strong> tuned to each userâ€™s dialog style.</li><li><strong>Real-time adaptation</strong> of compression and segmentation based on quality metrics.</li></ul><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><strong>Paper</strong>: <a href="https://www.arxiv.org/abs/2502.05589">SeCom: On Memory Construction and Retrieval for Personalized Conversational Agents (ICLR 2025)</a></li><li><strong>Project Page</strong>: <a href="https://llmlingua.com/secom.html">https://llmlingua.com/secom.html</a></li><li><strong>Code</strong>: SeCom-main</li><li><strong>Datasets</strong>: LOCOMO, Long-MT-Bench+, DialSeg711, TIAGE, SuperDialSeg</li></ul><p><em>This post is based on Microsoft &amp; Tsinghua Universityâ€™s ICLR 2025 paper. Please refer to the original publication and open-source repo for implementation details.</em> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SeCom-Redefining-Memory-Management-in-Conversational-AI&quot;&gt;&lt;a href=&quot;#SeCom-Redefining-Memory-Management-in-Conversational-AI&quot; class=&quot;h</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="Conversational AI" scheme="https://chenhuiyu.github.io/tags/Conversational-AI/"/>
    
    <category term="Memory Management" scheme="https://chenhuiyu.github.io/tags/Memory-Management/"/>
    
    <category term="SeCom" scheme="https://chenhuiyu.github.io/tags/SeCom/"/>
    
    <category term="RAG" scheme="https://chenhuiyu.github.io/tags/RAG/"/>
    
  </entry>
  
  <entry>
    <title>SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†</title>
    <link href="https://chenhuiyu.github.io/2025/06/24/NLP%20Insights/SeCom:%20%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%AF%9DAI%E7%9A%84%E8%AE%B0%E5%BF%86%E7%AE%A1%E7%90%86/"/>
    <id>https://chenhuiyu.github.io/2025/06/24/NLP%20Insights/SeCom:%20%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%AF%9DAI%E7%9A%84%E8%AE%B0%E5%BF%86%E7%AE%A1%E7%90%86/</id>
    <published>2025-06-24T08:00:00.000Z</published>
    <updated>2026-02-20T21:56:22.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SeCom-é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†"><a href="#SeCom-é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†" class="headerlink" title="SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†"></a>SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†</h1><h2 id="å†™åœ¨å‰é¢"><a href="#å†™åœ¨å‰é¢" class="headerlink" title="å†™åœ¨å‰é¢"></a>å†™åœ¨å‰é¢</h2><p>æœ€è¿‘ç¬”è€…ä¸€ç›´åœ¨ç ”ç©¶å¯¹è¯AIä¸­çš„å†…å­˜ç®¡ç†é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é•¿æœŸå¯¹è¯åœºæ™¯ä¸‹çš„è®°å¿†æ„å»ºä¸æ£€ç´¢æŠ€æœ¯ã€‚å‘ç°äº†ä¸€ç¯‡ä»¤äººçœ¼å‰ä¸€äº®çš„ICLR 2025è®ºæ–‡â€”â€”<strong>ã€ŠSeCom: On Memory Construction and Retrieval for Personalized Conversational Agentsã€‹</strong>ï¼Œç”±Microsoftå’Œæ¸…åå¤§å­¦çš„ç ”ç©¶å›¢é˜Ÿè”åˆå‘è¡¨ã€‚</p><p>è¿™ç¯‡è®ºæ–‡æå‡ºçš„SeComæ–¹æ³•å·§å¦™åœ°è§£å†³äº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š<strong>å¦‚ä½•åœ¨é•¿æœŸå¯¹è¯ä¸­æœ‰æ•ˆç®¡ç†å’Œæ£€ç´¢å†å²ä¿¡æ¯</strong>ï¼Ÿä»Šå¤©æƒ³å’Œå¤§å®¶åˆ†äº«ä¸€ä¸‹è¿™ä¸ªæ–¹æ³•çš„æŠ€æœ¯ç»†èŠ‚å’Œåˆ›æ–°ç‚¹ï¼Œå¸Œæœ›èƒ½ä¸ºä»äº‹ç›¸å…³ç ”ç©¶çš„æœ‹å‹ä»¬æä¾›ä¸€äº›å¯å‘ã€‚</p><h2 id="1-ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å…³æ³¨å¯¹è¯å†…å­˜ç®¡ç†ï¼Ÿ"><a href="#1-ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å…³æ³¨å¯¹è¯å†…å­˜ç®¡ç†ï¼Ÿ" class="headerlink" title="1. ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å…³æ³¨å¯¹è¯å†…å­˜ç®¡ç†ï¼Ÿ"></a>1. ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å…³æ³¨å¯¹è¯å†…å­˜ç®¡ç†ï¼Ÿ</h2><h3 id="1-1-é•¿æœŸå¯¹è¯çš„ç°å®æŒ‘æˆ˜"><a href="#1-1-é•¿æœŸå¯¹è¯çš„ç°å®æŒ‘æˆ˜" class="headerlink" title="1.1 é•¿æœŸå¯¹è¯çš„ç°å®æŒ‘æˆ˜"></a>1.1 é•¿æœŸå¯¹è¯çš„ç°å®æŒ‘æˆ˜</h3><p>åœ¨ä¸LLMsçš„æ—¥å¸¸äº¤äº’ä¸­ï¼Œç›¸ä¿¡å¤§å®¶éƒ½é‡åˆ°è¿‡è¿™æ ·çš„å›°æ‰°ï¼šå½“å¯¹è¯å˜å¾—å¾ˆé•¿æ—¶ï¼ŒAIä¼¼ä¹â€å¿˜è®°â€äº†ä¹‹å‰è®¨è®ºçš„å†…å®¹ï¼Œæˆ–è€…ç»™å‡ºçš„å›ç­”ä¸å‰é¢çš„ä¸Šä¸‹æ–‡ä¸å¤Ÿè¿è´¯ã€‚è¿™èƒŒååæ˜ çš„æ­£æ˜¯é•¿æœŸå¯¹è¯ä¸­çš„å†…å­˜ç®¡ç†æŒ‘æˆ˜ã€‚</p><p>éšç€å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯çš„æˆç†Ÿï¼ŒåŸºäºLLMçš„å¯¹è¯ä»£ç†å·²ç»æ·±å…¥åˆ°æˆ‘ä»¬ç”Ÿæ´»çš„æ–¹æ–¹é¢é¢ã€‚ä½†æ˜¯ï¼Œå½“æˆ‘ä»¬å¸Œæœ›ä¸AIè¿›è¡ŒçœŸæ­£çš„é•¿æœŸã€ä¸ªæ€§åŒ–äº¤äº’æ—¶â€”â€”æ¯”å¦‚è·¨è¶Šæ•°å¤©ã€æ•°å‘¨çš„é¡¹ç›®è®¨è®ºï¼Œç°æœ‰çš„æŠ€æœ¯å°±æ˜¾å¾—åŠ›ä¸ä»å¿ƒäº†ã€‚</p><p>é•¿æœŸå¯¹è¯é¢ä¸´çš„ä¸»è¦æŠ€æœ¯æŒ‘æˆ˜åŒ…æ‹¬ï¼š</p><ul><li><strong>ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶</strong>ï¼šå³ä½¿æ˜¯æ”¯æŒé•¿ä¸Šä¸‹æ–‡çš„æ¨¡å‹ï¼Œåœ¨å¤„ç†è¶…é•¿å¯¹è¯æ—¶ä¹Ÿé¢ä¸´è®¡ç®—æˆæœ¬å’Œæ€§èƒ½ä¸‹é™çš„é—®é¢˜</li><li><strong>ä¿¡æ¯ç›¸å…³æ€§</strong>ï¼šå†å²å¯¹è¯ä¸­å¯èƒ½åŒ…å«å¤§é‡ä¸å½“å‰æŸ¥è¯¢æ— å…³çš„ä¿¡æ¯</li><li><strong>è¯­ä¹‰è¿è´¯æ€§</strong>ï¼šç›¸å…³ä¿¡æ¯å¯èƒ½åˆ†æ•£åœ¨å¤šä¸ªä¸è¿ç»­çš„å¯¹è¯è½®æ¬¡ä¸­</li><li><strong>ä¸ªæ€§åŒ–è®°å¿†</strong>ï¼šéœ€è¦è®°ä½ç”¨æˆ·çš„åå¥½ã€ä¹ æƒ¯å’Œå†å²äº¤äº’æ¨¡å¼</li></ul><h3 id="1-2-ç¬”è€…å¯¹Memoryç®¡ç†é¢†åŸŸçš„è§‚å¯Ÿ"><a href="#1-2-ç¬”è€…å¯¹Memoryç®¡ç†é¢†åŸŸçš„è§‚å¯Ÿ" class="headerlink" title="1.2 ç¬”è€…å¯¹Memoryç®¡ç†é¢†åŸŸçš„è§‚å¯Ÿ"></a>1.2 ç¬”è€…å¯¹Memoryç®¡ç†é¢†åŸŸçš„è§‚å¯Ÿ</h3><p>åœ¨æ·±å…¥ç ”ç©¶è¿™ä¸ªé¢†åŸŸçš„è¿‡ç¨‹ä¸­ï¼Œç¬”è€…å‘ç°å¯¹è¯å†…å­˜ç®¡ç†å…¶å®æ˜¯ä¸€ä¸ªç›¸å½“å¤æ‚çš„ç³»ç»Ÿå·¥ç¨‹ã€‚å®ƒçš„æ ¸å¿ƒç›®æ ‡å¬èµ·æ¥å¾ˆç®€å•ï¼šä»å†å²å¯¹è¯ä¸­æå–ã€å­˜å‚¨å’Œæ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œä»¥æ”¯æŒå½“å‰å¯¹è¯çš„ç”Ÿæˆã€‚ä½†å®é™…å®ç°èµ·æ¥ï¼Œéœ€è¦è§£å†³ä¸‰ä¸ªå…³é”®é—®é¢˜ï¼š</p><ol><li><strong>å†…å­˜æ„å»ºï¼ˆMemory Constructionï¼‰</strong>ï¼šå¦‚ä½•å°†è‡ªç„¶è¯­è¨€å¯¹è¯è½¬æ¢ä¸ºç»“æ„åŒ–çš„å†…å­˜å•å…ƒï¼Ÿ</li><li><strong>å†…å­˜æ£€ç´¢ï¼ˆMemory Retrievalï¼‰</strong>ï¼šé¢å¯¹æµ·é‡å†å²ä¿¡æ¯ï¼Œå¦‚ä½•å¿«é€Ÿå‡†ç¡®åœ°æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Ÿ</li><li><strong>å“åº”ç”Ÿæˆï¼ˆResponse Generationï¼‰</strong>ï¼šå¦‚ä½•åŸºäºæ£€ç´¢åˆ°çš„è®°å¿†ç”Ÿæˆè¿è´¯ã€ä¸ªæ€§åŒ–çš„å›å¤ï¼Ÿ</li></ol><p>å¬èµ·æ¥æ˜¯ä¸æ˜¯å¾ˆåƒäººç±»çš„è®°å¿†æœºåˆ¶ï¼Ÿç¡®å®å¦‚æ­¤ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆè¿™ä¸ªé—®é¢˜å¦‚æ­¤æœ‰è¶£å’Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</p><h4 id="1-2-2-ç°æœ‰æ–¹æ³•çš„â€ä¸‰å›½æ¼”ä¹‰â€"><a href="#1-2-2-ç°æœ‰æ–¹æ³•çš„â€ä¸‰å›½æ¼”ä¹‰â€" class="headerlink" title="1.2.2 ç°æœ‰æ–¹æ³•çš„â€ä¸‰å›½æ¼”ä¹‰â€"></a>1.2.2 ç°æœ‰æ–¹æ³•çš„â€ä¸‰å›½æ¼”ä¹‰â€</h4><p>åœ¨ç ”ç©¶è¿‡ç¨‹ä¸­ï¼Œç¬”è€…å‘ç°ç°æœ‰çš„æ–¹æ³•å¤§è‡´å¯ä»¥åˆ†ä¸ºä¸‰å¤§æµæ´¾ï¼Œæ¯ä¸ªéƒ½æœ‰è‡ªå·±çš„â€å“²å­¦â€ï¼š</p><p><strong>â€œå…¨ç›˜æ‰˜å‡ºâ€æ´¾ï¼ˆåŸºäºå®Œæ•´å†å²ï¼‰</strong>ï¼š</p><ul><li><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šæ—¢ç„¶ä¸çŸ¥é“ä»€ä¹ˆé‡è¦ï¼Œé‚£å°±å…¨éƒ¨ç»™ä½ ï¼</li><li><strong>ä¼˜åŠ¿</strong>ï¼šä¿¡æ¯å®Œæ•´ï¼Œç»ä¸é—æ¼</li><li><strong>é—®é¢˜</strong>ï¼šå°±åƒæŠŠæ•´ä¸ªå›¾ä¹¦é¦†æ¬ç»™ä½ æ‰¾ä¸€æœ¬ä¹¦ï¼Œæ•ˆç‡å¯æƒ³è€ŒçŸ¥</li></ul><p><strong>â€œæçº²æŒˆé¢†â€æ´¾ï¼ˆåŸºäºæ‘˜è¦ï¼‰</strong>ï¼š</p><ul><li><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šé‡è¦çš„ä¿¡æ¯æµ“ç¼©æˆæ‘˜è¦å°±å¤Ÿäº†</li><li><strong>ä¼˜åŠ¿</strong>ï¼šä¿¡æ¯å‹ç¼©ï¼Œè®¡ç®—é«˜æ•ˆ</li><li><strong>é—®é¢˜</strong>ï¼šæ‘˜è¦è¿‡ç¨‹ä¸­é‡è¦ç»†èŠ‚å¯èƒ½â€æ„å¤–å¤±è¸ªâ€</li></ul><p><strong>â€œç²¾å‡†æ‰“å‡»â€æ´¾ï¼ˆåŸºäºæ£€ç´¢ï¼‰</strong>ï¼š</p><ul><li><strong>ä»£è¡¨æ–¹æ³•</strong>ï¼šè½®æ¬¡çº§æ£€ç´¢ã€ä¼šè¯çº§æ£€ç´¢</li><li><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šéœ€è¦ä»€ä¹ˆå°±æ£€ç´¢ä»€ä¹ˆï¼ŒæŒ‰éœ€å–ç”¨</li><li><strong>ä¼˜åŠ¿</strong>ï¼šè®¡ç®—æ•ˆç‡é«˜ï¼Œå®šä½ç²¾ç¡®</li><li><strong>é—®é¢˜</strong>ï¼šå…³é”®åœ¨äºå¦‚ä½•ç¡®å®šæ£€ç´¢çš„â€ç²’åº¦â€â€”â€”è¿™æ­£æ˜¯SeComè¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼</li></ul><h4 id="1-2-3-æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨å¯¹è¯ä¸­çš„åº”ç”¨"><a href="#1-2-3-æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨å¯¹è¯ä¸­çš„åº”ç”¨" class="headerlink" title="1.2.3 æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨å¯¹è¯ä¸­çš„åº”ç”¨"></a>1.2.3 æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨å¯¹è¯ä¸­çš„åº”ç”¨</h4><p>æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯åœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä¸»è¦åŒ…æ‹¬ï¼š</p><ul><li>**Dense Passage Retrieval (DPR)**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„å¯†é›†æ£€ç´¢æ¨¡å‹</li><li><strong>BM25</strong>ï¼šåŸºäºè¯é¢‘ç»Ÿè®¡çš„ç¨€ç–æ£€ç´¢æ–¹æ³•</li><li><strong>Hybrid Retrieval</strong>ï¼šç»“åˆå¯†é›†æ£€ç´¢å’Œç¨€ç–æ£€ç´¢çš„ä¼˜åŠ¿</li></ul><p>ç„¶è€Œï¼Œç°æœ‰RAGæ–¹æ³•åœ¨å¯¹è¯åœºæ™¯ä¸­é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ï¼š</p><ul><li><strong>åˆ†å—ç­–ç•¥ï¼ˆChunking Strategyï¼‰</strong>ï¼šå¦‚ä½•å°†å¯¹è¯åˆ†å‰²ä¸ºæ£€ç´¢å•å…ƒ</li><li><strong>ç›¸å…³æ€§åˆ¤æ–­</strong>ï¼šå¯¹è¯çš„ç›¸å…³æ€§åˆ¤æ–­æ¯”æ–‡æ¡£æ£€ç´¢æ›´å¤æ‚</li><li><strong>æ—¶åºä¾èµ–</strong>ï¼šå¯¹è¯å…·æœ‰å¼ºæ—¶åºæ€§ï¼Œå‰åæ–‡å…³ç³»é‡è¦</li></ul><h3 id="1-3-å†…å­˜ç²’åº¦é—®é¢˜çš„æ·±å±‚åˆ†æ"><a href="#1-3-å†…å­˜ç²’åº¦é—®é¢˜çš„æ·±å±‚åˆ†æ" class="headerlink" title="1.3 å†…å­˜ç²’åº¦é—®é¢˜çš„æ·±å±‚åˆ†æ"></a>1.3 å†…å­˜ç²’åº¦é—®é¢˜çš„æ·±å±‚åˆ†æ</h3><h4 id="1-3-1-è½®æ¬¡çº§å†…å­˜çš„å±€é™æ€§"><a href="#1-3-1-è½®æ¬¡çº§å†…å­˜çš„å±€é™æ€§" class="headerlink" title="1.3.1 è½®æ¬¡çº§å†…å­˜çš„å±€é™æ€§"></a>1.3.1 è½®æ¬¡çº§å†…å­˜çš„å±€é™æ€§</h4><p>è½®æ¬¡çº§å†…å­˜å°†æ¯ä¸ªç”¨æˆ·-ä»£ç†äº¤äº’ï¼ˆturnï¼‰ä½œä¸ºç‹¬ç«‹çš„å†…å­˜å•å…ƒï¼š</p><p><strong>æ•°å­¦è¡¨ç¤º</strong>ï¼š<br>è®¾å¯¹è¯å†å² $\mathcal{H} = {\mathbf{c}<em>i}</em>{i=1}^C$ï¼Œå…¶ä¸­æ¯ä¸ªä¼šè¯ $\mathbf{c}<em>i = {\mathbf{t}<em>j}</em>{j=1}^{T_i}$<br>è½®æ¬¡çº§å†…å­˜ï¼š$|\mathcal{M}| = \sum</em>{i=1}^C T_i$ï¼Œæ¯ä¸ª $\mathbf{m} \in \mathcal{M}$ å¯¹åº”ä¸€ä¸ªè½®æ¬¡ $\mathbf{t}$</p><p><strong>ä¸»è¦é—®é¢˜</strong>ï¼š</p><ul><li><strong>ä¿¡æ¯ç¢ç‰‡åŒ–</strong>ï¼šç›¸å…³ä¿¡æ¯åˆ†æ•£åœ¨å¤šä¸ªè½®æ¬¡ä¸­ï¼Œå•ä¸ªè½®æ¬¡å¯èƒ½ç¼ºä¹å®Œæ•´è¯­ä¹‰</li><li><strong>ä¸Šä¸‹æ–‡ç¼ºå¤±</strong>ï¼šè½®æ¬¡é—´çš„ä¾èµ–å…³ç³»ä¸¢å¤±</li><li><strong>æ£€ç´¢ç²¾åº¦ä½</strong>ï¼šæŸ¥è¯¢è¯æ±‡å¯èƒ½ä¸ç›´æ¥å‡ºç°åœ¨ç›¸å…³è½®æ¬¡ä¸­</li></ul><p><strong>å…·ä½“ç¤ºä¾‹</strong>ï¼š<br>ç”¨æˆ·åœ¨ç¬¬3è½®è¯¢é—®â€ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ â€ï¼Œç¬¬5è½®è¯¢é—®â€ç›‘ç£å­¦ä¹ çš„ä¾‹å­â€ï¼Œç¬¬8è½®è¯¢é—®â€å¦‚ä½•é€‰æ‹©ç®—æ³•â€ã€‚å½“ç”¨æˆ·åœ¨ç¬¬10è½®è¯¢é—®â€ä¹‹å‰æåˆ°çš„åˆ†ç±»ç®—æ³•æ€§èƒ½å¦‚ä½•è¯„ä¼°â€æ—¶ï¼Œè½®æ¬¡çº§æ£€ç´¢å¯èƒ½æ— æ³•æ‰¾åˆ°å®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚</p><h4 id="1-3-2-ä¼šè¯çº§å†…å­˜çš„å±€é™æ€§"><a href="#1-3-2-ä¼šè¯çº§å†…å­˜çš„å±€é™æ€§" class="headerlink" title="1.3.2 ä¼šè¯çº§å†…å­˜çš„å±€é™æ€§"></a>1.3.2 ä¼šè¯çº§å†…å­˜çš„å±€é™æ€§</h4><p>ä¼šè¯çº§å†…å­˜å°†æ•´ä¸ªå¯¹è¯ä¼šè¯ä½œä¸ºå†…å­˜å•å…ƒï¼š</p><p><strong>æ•°å­¦è¡¨ç¤º</strong>ï¼š<br>ä¼šè¯çº§å†…å­˜ï¼š$|\mathcal{M}| = C$ï¼Œæ¯ä¸ª $\mathbf{m} \in \mathcal{M}$ å¯¹åº”ä¸€ä¸ªä¼šè¯ $\mathbf{c}$</p><p><strong>ä¸»è¦é—®é¢˜</strong>ï¼š</p><ul><li><strong>ä¸»é¢˜æ··æ‚</strong>ï¼šå•ä¸ªä¼šè¯å¯èƒ½åŒ…å«å¤šä¸ªä¸ç›¸å…³ä¸»é¢˜</li><li><strong>å™ªå£°å¹²æ‰°</strong>ï¼šå¤§é‡æ— å…³ä¿¡æ¯å½±å“æ£€ç´¢å’Œç”Ÿæˆè´¨é‡</li><li><strong>æ£€ç´¢ç²—ç³™</strong>ï¼šæ— æ³•ç²¾ç¡®å®šä½åˆ°å…·ä½“ç›¸å…³å†…å®¹</li></ul><p><strong>å…·ä½“ç¤ºä¾‹</strong>ï¼š<br>ä¸€ä¸ªä¼šè¯ä¸­ç”¨æˆ·è®¨è®ºäº†æœºå™¨å­¦ä¹ ã€çƒ¹é¥ªé£Ÿè°±ã€æ—…è¡Œè®¡åˆ’å’Œç”µå½±æ¨èã€‚å½“æŸ¥è¯¢æœºå™¨å­¦ä¹ ç›¸å…³é—®é¢˜æ—¶ï¼Œæ£€ç´¢åˆ°çš„ä¼šè¯åŒ…å«å¤§é‡æ— å…³çš„çƒ¹é¥ªå’Œæ—…è¡Œä¿¡æ¯ã€‚</p><h4 id="1-3-3-æ‘˜è¦åŒ–æ–¹æ³•çš„ä¿¡æ¯æŸå¤±"><a href="#1-3-3-æ‘˜è¦åŒ–æ–¹æ³•çš„ä¿¡æ¯æŸå¤±" class="headerlink" title="1.3.3 æ‘˜è¦åŒ–æ–¹æ³•çš„ä¿¡æ¯æŸå¤±"></a>1.3.3 æ‘˜è¦åŒ–æ–¹æ³•çš„ä¿¡æ¯æŸå¤±</h4><p>æ‘˜è¦åŒ–æ–¹æ³•é€šè¿‡å‹ç¼©å¯¹è¯å†…å®¹æ¥å‡å°‘ä¿¡æ¯é‡ï¼š</p><p><strong>ä¸»è¦é—®é¢˜</strong>ï¼š</p><ul><li><strong>ç»†èŠ‚ä¸¢å¤±</strong>ï¼šæ‘˜è¦è¿‡ç¨‹ä¸­é‡è¦ç»†èŠ‚å¯èƒ½è¢«çœç•¥</li><li><strong>ä¸»è§‚æ€§</strong>ï¼šæ‘˜è¦è´¨é‡ä¾èµ–äºæ¨¡å‹çš„ç†è§£èƒ½åŠ›</li><li><strong>ä¸å¯é€†æ€§</strong>ï¼šä¸€æ—¦ä¿¡æ¯è¢«æ‘˜è¦ï¼ŒåŸå§‹ç»†èŠ‚æ— æ³•æ¢å¤</li></ul><h2 id="2-SeComçš„è®¾è®¡"><a href="#2-SeComçš„è®¾è®¡" class="headerlink" title="2. SeComçš„è®¾è®¡"></a>2. SeComçš„è®¾è®¡</h2><h3 id="2-1-æ ¸å¿ƒå‘ç°"><a href="#2-1-æ ¸å¿ƒå‘ç°" class="headerlink" title="2.1 æ ¸å¿ƒå‘ç°"></a>2.1 æ ¸å¿ƒå‘ç°</h3><p>SeComï¼ˆ<strong>Se</strong>gmentation + <strong>Com</strong>pressionï¼‰çš„ä¸¤ä¸ªæ ¸å¿ƒå‘ç°ï¼š</p><p><strong>æ´å¯Ÿä¸€ï¼šå¯¹è¯å¤©ç„¶å…·æœ‰â€æ®µè½â€ç»“æ„</strong><br>å°±åƒæˆ‘ä»¬å†™æ–‡ç« ä¼šåˆ†æ®µä¸€æ ·ï¼Œäººç±»çš„å¯¹è¯å…¶å®ä¹Ÿæœ‰å¤©ç„¶çš„ä¸»é¢˜è¾¹ç•Œã€‚æ¯”å¦‚åœ¨ä¸€æ¬¡é•¿å¯¹è¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½å…ˆè®¨è®ºå·¥ä½œé¡¹ç›®ï¼Œç„¶åè½¬åˆ°å‘¨æœ«è®¡åˆ’ï¼Œå†èŠåˆ°æœ€è¿‘çœ‹çš„ç”µå½±ã€‚æ¯ä¸ªä¸»é¢˜å°±æ˜¯ä¸€ä¸ªå¤©ç„¶çš„â€æ®µè½â€ã€‚</p><p>ä¼ ç»Ÿæ–¹æ³•è¦ä¹ˆæŠŠæ¯å¥è¯å½“ä½œç‹¬ç«‹å•å…ƒï¼ˆå¤ªç¢ç‰‡åŒ–ï¼‰ï¼Œè¦ä¹ˆæŠŠæ•´ä¸ªå¯¹è¯å½“ä½œä¸€ä¸ªæ•´ä½“ï¼ˆå¤ªç²—ç³™ï¼‰ï¼Œè€ŒSeComæ‰¾åˆ°äº†ä¸­é—´çš„æœ€ä½³å¹³è¡¡ç‚¹â€”â€”<strong>æ®µè½çº§çš„è¯­ä¹‰å•å…ƒ</strong>ã€‚</p><p><strong>æ´å¯ŸäºŒï¼šè‡ªç„¶è¯­è¨€å……æ»¡â€åºŸè¯â€</strong><br>è¿™å¬èµ·æ¥æœ‰ç‚¹åˆ»è–„ï¼Œä½†ç¡®å®å¦‚æ­¤ã€‚æˆ‘ä»¬æ—¥å¸¸å¯¹è¯ä¸­å……æ»¡äº†â€å—¯â€ã€â€é‚£ä¸ªâ€ã€â€ä½ çŸ¥é“çš„â€è¿™æ ·çš„å†—ä½™è¡¨è¾¾ï¼Œè¿˜æœ‰å¤§é‡çš„é‡å¤ã€ç¡®è®¤ã€å®¢å¥—è¯ã€‚è¿™äº›åœ¨äººé™…äº¤æµä¸­å¾ˆé‡è¦ï¼Œä½†å¯¹æœºå™¨æ£€ç´¢æ¥è¯´å°±æ˜¯å™ªå£°ã€‚</p><p>SeComé€šè¿‡æ™ºèƒ½å‹ç¼©ï¼Œä¿ç•™å…³é”®ä¿¡æ¯çš„åŒæ—¶å»é™¤è¿™äº›â€å™ªå£°â€ï¼Œè®©æ£€ç´¢æ›´åŠ ç²¾å‡†ã€‚</p><h3 id="2-2-ç³»ç»Ÿè®¾è®¡"><a href="#2-2-ç³»ç»Ÿè®¾è®¡" class="headerlink" title="2.2 ç³»ç»Ÿè®¾è®¡"></a>2.2 ç³»ç»Ÿè®¾è®¡</h3><p>SeComçš„æ•´ä½“æ¶æ„è®¾è®¡éå¸¸ä¼˜é›…ï¼Œå°±åƒä¸€æ¡é«˜æ•ˆçš„æµæ°´çº¿ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">å†å²å¯¹è¯ â†’ [åˆ†æ®µå™¨] â†’ æ®µè½çº§å†…å­˜å•å…ƒ â†’ [å‹ç¼©å™¨] â†’ å»å™ªå†…å­˜å•å…ƒ â†’ [æ£€ç´¢å™¨] â†’ ç›¸å…³ä¸Šä¸‹æ–‡ â†’ [ç”Ÿæˆå™¨] â†’ æœ€ç»ˆå›å¤</span><br></pre></td></tr></tbody></table></figure><p>ç”¨æ›´ç›´è§‚çš„è¯æ¥è§£é‡Šè¿™ä¸ªæµç¨‹ï¼š</p><ol><li><strong>åˆ†æ®µå™¨</strong>ï¼šå°†æ‚ä¹±çš„å¯¹è¯å†å²æŒ‰ä¸»é¢˜â€åˆ‡å—â€</li><li><strong>å‹ç¼©å™¨</strong>ï¼šå°†æ¯ä¸ªâ€å—â€ä¸­çš„åºŸè¯å»æ‰ï¼Œä¿ç•™ç²¾å</li><li><strong>æ£€ç´¢å™¨</strong>ï¼šæ ¹æ®å½“å‰é—®é¢˜æ‰¾åˆ°æœ€ç›¸å…³çš„â€å—â€</li><li><strong>ç”Ÿæˆå™¨</strong>ï¼šåŸºäºç›¸å…³ä¿¡æ¯ç”Ÿæˆå›ç­”</li></ol><p><strong>æŠ€æœ¯è¡¨ç¤º</strong>ï¼ˆæ²¡ä»€ä¹ˆç”¨ï¼Œå†™ç»™å–œæ¬¢æ•°å­¦çš„æœ‹å‹ï¼‰ï¼š<br>è®¾ $f_{\mathcal{I}}$ ä¸ºåˆ†æ®µå™¨ï¼Œ$f_{Comp}$ ä¸ºå‹ç¼©å™¨ï¼Œ$f_R$ ä¸ºæ£€ç´¢å™¨ï¼Œ$f_{LLM}$ ä¸ºç”Ÿæˆå™¨</p><p>å®Œæ•´æµç¨‹ï¼š</p><ol><li>${\mathbf{s}<em>k}</em>{k=1}^K \leftarrow f_{\mathcal{I}}(\mathcal{H})$ ï¼ˆå¯¹è¯åˆ†æ®µï¼‰</li><li>${\mathbf{m}<em>k}</em>{k=1}^K \leftarrow f_{Comp}({\mathbf{s}<em>k}</em>{k=1}^K)$ ï¼ˆå‹ç¼©å»å™ªï¼‰</li><li>${\mathbf{m}<em>n}</em>{n=1}^N \leftarrow f_R(u^*, {\mathbf{m}<em>k}</em>{k=1}^K, N)$ ï¼ˆå†…å­˜æ£€ç´¢ï¼‰</li><li>$r^* = f_{LLM}(u^*, {\mathbf{m}<em>n}</em>{n=1}^N)$ ï¼ˆå“åº”ç”Ÿæˆï¼‰</li></ol><h3 id="2-3-åˆ†æ®µç®—æ³•ï¼šæ•™AIå­¦ä¼šâ€æ–­å¥â€"><a href="#2-3-åˆ†æ®µç®—æ³•ï¼šæ•™AIå­¦ä¼šâ€æ–­å¥â€" class="headerlink" title="2.3 åˆ†æ®µç®—æ³•ï¼šæ•™AIå­¦ä¼šâ€æ–­å¥â€"></a>2.3 åˆ†æ®µç®—æ³•ï¼šæ•™AIå­¦ä¼šâ€æ–­å¥â€</h3><h4 id="2-3-1-é›¶æ ·æœ¬åˆ†æ®µ"><a href="#2-3-1-é›¶æ ·æœ¬åˆ†æ®µ" class="headerlink" title="2.3.1 é›¶æ ·æœ¬åˆ†æ®µ"></a>2.3.1 é›¶æ ·æœ¬åˆ†æ®µ</h4><p>å¦‚ä½•è®©AIè‡ªåŠ¨è¯†åˆ«å¯¹è¯ä¸­çš„ä¸»é¢˜è¾¹ç•Œï¼Ÿä¼ ç»Ÿæ–¹æ³•éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è®­ç»ƒä¸“é—¨çš„åˆ†æ®µæ¨¡å‹ï¼Œè€ŒSeComé‡‡ç”¨äº†ä¸€ä¸ªéå¸¸èªæ˜çš„â€é›¶æ ·æœ¬â€æ–¹æ³•ã€‚</p><p><strong>æ ¸å¿ƒæ€è·¯</strong>ï¼š<br>æ—¢ç„¶GPT-4è¿™æ ·çš„å¤§æ¨¡å‹å·²ç»å…·å¤‡äº†å¼ºå¤§çš„æ–‡æœ¬ç†è§£èƒ½åŠ›ï¼Œä¸ºä»€ä¹ˆä¸ç›´æ¥è®©å®ƒæ¥åˆ¤æ–­å¯¹è¯çš„ä¸»é¢˜è¾¹ç•Œå‘¢ï¼Ÿå°±åƒè®©ä¸€ä¸ªæ–‡å­¦è€å¸ˆæ¥ç»™æ–‡ç« åˆ†æ®µä¸€æ ·ã€‚</p><p><strong>è¾“å…¥é¢„å¤„ç†</strong>ï¼š<br>å°†å¯¹è¯ä¼šè¯å¢å¼ºä¸ºç»“æ„åŒ–æ ¼å¼ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Turn j: </span><br><span class="line">[user]: u_j</span><br><span class="line">[agent]: r_j</span><br></pre></td></tr></tbody></table></figure><p><strong>åˆ†æ®µæç¤ºè®¾è®¡</strong>ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œè¯†åˆ«ä¸»é¢˜è¾¹ç•Œï¼Œå°†å¯¹è¯åˆ†å‰²ä¸ºè¯­ä¹‰è¿è´¯çš„æ®µè½ã€‚</span><br><span class="line">æ¯ä¸ªæ®µè½åº”è¯¥ï¼š</span><br><span class="line">1. å›´ç»•å•ä¸€ä¸»é¢˜æˆ–ç›¸å…³ä¸»é¢˜</span><br><span class="line">2. åŒ…å«å®Œæ•´çš„äº¤äº’åºåˆ—</span><br><span class="line">3. å…·æœ‰æ˜ç¡®çš„å¼€å§‹å’Œç»“æŸè¾¹ç•Œ</span><br><span class="line"></span><br><span class="line">å¯¹è¯å†…å®¹ï¼š</span><br><span class="line">[å¯¹è¯å†…å®¹]</span><br><span class="line"></span><br><span class="line">è¯·è¾“å‡ºæ¯ä¸ªæ®µè½çš„èµ·å§‹å’Œç»“æŸè½®æ¬¡ç¼–å·ã€‚</span><br></pre></td></tr></tbody></table></figure><p><strong>ä¼˜åŠ¿</strong>ï¼š</p><ul><li>æ— éœ€è®­ç»ƒæ•°æ®ï¼Œé€‚ç”¨äºå¼€æ”¾åŸŸå¯¹è¯</li><li>åˆ©ç”¨LLMçš„å¼ºå¤§ç†è§£èƒ½åŠ›</li><li>å¯å¤„ç†å¤æ‚çš„ä¸»é¢˜è½¬æ¢æ¨¡å¼</li></ul><h4 id="2-3-2-åŸºäºåæ€çš„åˆ†æ®µä¼˜åŒ–"><a href="#2-3-2-åŸºäºåæ€çš„åˆ†æ®µä¼˜åŒ–" class="headerlink" title="2.3.2 åŸºäºåæ€çš„åˆ†æ®µä¼˜åŒ–"></a>2.3.2 åŸºäºåæ€çš„åˆ†æ®µä¼˜åŒ–</h4><p>å½“æœ‰å°‘é‡æ ‡æ³¨æ•°æ®æ—¶ï¼Œé‡‡ç”¨åæ€æœºåˆ¶ä¼˜åŒ–åˆ†æ®µæ•ˆæœï¼š</p><p><strong>ç®—æ³•æ­¥éª¤</strong>ï¼š</p><ol><li><strong>åˆå§‹åˆ†æ®µ</strong>ï¼šä½¿ç”¨é›¶æ ·æœ¬æ–¹æ³•å¯¹æ‰¹é‡æ•°æ®è¿›è¡Œåˆ†æ®µ</li><li><strong>é”™è¯¯è¯†åˆ«</strong>ï¼šåŸºäºWindowDiffæŒ‡æ ‡é€‰æ‹©top-Kä¸ªåˆ†æ®µé”™è¯¯æœ€å¤§çš„æ ·æœ¬</li><li><strong>åæ€å­¦ä¹ </strong>ï¼šè®©LLMåˆ†æåˆ†æ®µé”™è¯¯ï¼Œæ›´æ–°åˆ†æ®µæŒ‡å¯¼åŸåˆ™</li><li><strong>è¿­ä»£ä¼˜åŒ–</strong>ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹ç›´åˆ°æ”¶æ•›</li></ol><p><strong>åæ€æç¤ºè®¾è®¡</strong>ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">åˆ†æä»¥ä¸‹åˆ†æ®µé”™è¯¯ï¼Œå¹¶æ›´æ–°åˆ†æ®µæŒ‡å¯¼åŸåˆ™ï¼š</span><br><span class="line"></span><br><span class="line">é”™è¯¯æ¡ˆä¾‹ï¼š</span><br><span class="line">[åˆ†æ®µç»“æœ] vs [æ ‡å‡†ç­”æ¡ˆ]</span><br><span class="line"></span><br><span class="line">è¯·åˆ†æé”™è¯¯åŸå› å¹¶æä¾›æ”¹è¿›çš„åˆ†æ®µæŒ‡å¯¼åŸåˆ™ã€‚</span><br></pre></td></tr></tbody></table></figure><p><strong>æ•°å­¦è¡¨ç¤º</strong>ï¼š<br>è®¾ $\boldsymbol{G}<em>m$ ä¸ºç¬¬mè½®çš„åˆ†æ®µæŒ‡å¯¼åŸåˆ™ï¼Œæ›´æ–°å…¬å¼ä¸ºï¼š<br>$$\boldsymbol{G}</em>{m+1} = \boldsymbol{G}_m - \eta \nabla \mathcal{L}(\boldsymbol{G}_m)$$</p><p>å…¶ä¸­ $\nabla \mathcal{L}(\boldsymbol{G}_m)$ ä¸ºLLMéšå¼ä¼°è®¡çš„åˆ†æ®µæŸå¤±æ¢¯åº¦ã€‚</p><h4 id="2-3-3-å¢é‡åˆ†æ®µç®—æ³•"><a href="#2-3-3-å¢é‡åˆ†æ®µç®—æ³•" class="headerlink" title="2.3.3 å¢é‡åˆ†æ®µç®—æ³•"></a>2.3.3 å¢é‡åˆ†æ®µç®—æ³•</h4><p>å¯¹äºæ–°å¢çš„å¯¹è¯è½®æ¬¡ï¼Œè®¾è®¡å¢é‡åˆ†æ®µç®—æ³•ï¼š</p><p><strong>ç®—æ³•æµç¨‹</strong>ï¼š</p><ol><li>è¾“å…¥æ–°è½®æ¬¡ $\mathbf{t}<em>{new}$ å’Œå‰ä¸€æ®µè½ $\mathbf{s}</em>{prev}$</li><li>åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶ï¼š$binary = f_{judge}(\mathbf{t}<em>{new}, \mathbf{s}</em>{prev})$</li><li>å¦‚æœåˆå¹¶ï¼š$\mathbf{s}<em>{prev} \leftarrow \mathbf{s}</em>{prev} \cup {\mathbf{t}_{new}}$</li><li>å¦åˆ™ï¼šåˆ›å»ºæ–°æ®µè½ $\mathbf{s}<em>{new} = {\mathbf{t}</em>{new}}$</li></ol><p><strong>åˆ¤æ–­æç¤º</strong>ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">åˆ¤æ–­æ–°çš„ç”¨æˆ·-æœºå™¨äººè½®æ¬¡æ˜¯å¦åº”è¯¥ä¸å‰ä¸€æ®µè½åˆå¹¶ï¼š</span><br><span class="line"></span><br><span class="line">æ–°è½®æ¬¡ï¼š[æ–°è½®æ¬¡å†…å®¹]</span><br><span class="line">å‰ä¸€æ®µè½ï¼š[å‰ä¸€æ®µè½å†…å®¹]</span><br><span class="line"></span><br><span class="line">å¦‚æœå±äºåŒä¸€ä¸»é¢˜ï¼Œå›ç­”"Yes"ï¼Œå¦åˆ™å›ç­”"No"ã€‚</span><br></pre></td></tr></tbody></table></figure><h3 id="2-4-å‹ç¼©å¼å†…å­˜å»å™ª"><a href="#2-4-å‹ç¼©å¼å†…å­˜å»å™ª" class="headerlink" title="2.4 å‹ç¼©å¼å†…å­˜å»å™ª"></a>2.4 å‹ç¼©å¼å†…å­˜å»å™ª</h3><h4 id="2-4-1-è‡ªç„¶è¯­è¨€å†—ä½™æ€§åˆ†æ"><a href="#2-4-1-è‡ªç„¶è¯­è¨€å†—ä½™æ€§åˆ†æ" class="headerlink" title="2.4.1 è‡ªç„¶è¯­è¨€å†—ä½™æ€§åˆ†æ"></a>2.4.1 è‡ªç„¶è¯­è¨€å†—ä½™æ€§åˆ†æ</h4><p><strong>ç†è®ºåŸºç¡€</strong>ï¼š<br>æ ¹æ®Shannonä¿¡æ¯è®ºï¼Œè‡ªç„¶è¯­è¨€å…·æœ‰é«˜åº¦å†—ä½™æ€§ï¼Œå†—ä½™ç‡çº¦ä¸º50-75%ã€‚è¿™ç§å†—ä½™åœ¨äººç±»äº¤æµä¸­æœ‰åŠ©äºé”™è¯¯çº æ­£å’Œç†è§£ï¼Œä½†åœ¨æœºå™¨æ£€ç´¢ä¸­æ„æˆå™ªå£°ã€‚</p><p><strong>å†—ä½™ç±»å‹</strong>ï¼š</p><ol><li><strong>è¯æ±‡å†—ä½™</strong>ï¼šåŒä¹‰è¯ã€é‡å¤è¡¨è¾¾</li><li><strong>è¯­æ³•å†—ä½™</strong>ï¼šå†—ä½™çš„è¯­æ³•ç»“æ„</li><li><strong>è¯­ä¹‰å†—ä½™</strong>ï¼šé‡å¤çš„è¯­ä¹‰ä¿¡æ¯</li><li><strong>å¯¹è¯å†—ä½™</strong>ï¼šå®¢å¥—è¯ã€ç¡®è®¤æ€§å›å¤</li></ol><h4 id="2-4-2-LLMLingua-2å‹ç¼©åŸç†"><a href="#2-4-2-LLMLingua-2å‹ç¼©åŸç†" class="headerlink" title="2.4.2 LLMLingua-2å‹ç¼©åŸç†"></a>2.4.2 LLMLingua-2å‹ç¼©åŸç†</h4><p><strong>ç®—æ³•æ ¸å¿ƒ</strong>ï¼š<br>LLMLingua-2åŸºäºtokené‡è¦æ€§è¯„åˆ†è¿›è¡Œå‹ç¼©ï¼š</p><ol><li><p><strong>é‡è¦æ€§è¯„åˆ†</strong>ï¼š<br>$$s_i = f_{score}(x_i | x_{&lt;i}, x_{&gt;i})$$<br>å…¶ä¸­ $x_i$ ä¸ºç¬¬iä¸ªtokenï¼Œ$x_{&lt;i}$ å’Œ $x_{&gt;i}$ ä¸ºä¸Šä¸‹æ–‡</p></li><li><p><strong>åŠ¨æ€å‹ç¼©</strong>ï¼š<br>æ ¹æ®ç›®æ ‡å‹ç¼©ç‡ $r$ï¼Œä¿ç•™top $(1-r) \times N$ ä¸ªé‡è¦token</p></li><li><p><strong>è¯­ä¹‰ä¿æŒ</strong>ï¼š<br>é€šè¿‡åŒå‘ä¸Šä¸‹æ–‡å»ºæ¨¡ç¡®ä¿å…³é”®è¯­ä¹‰ä¿¡æ¯ä¸ä¸¢å¤±</p></li></ol><p><strong>å‹ç¼©æ•ˆæœåˆ†æ</strong>ï¼š<br>å®éªŒè¡¨æ˜ï¼Œ75%å‹ç¼©ç‡ä¸‹ï¼š</p><ul><li>å…³é”®ä¿¡æ¯ä¿ç•™ç‡ &gt; 95%</li><li>æ£€ç´¢ç›¸å…³æ€§æå‡ 9.46åˆ†ï¼ˆGPT4Scoreï¼‰</li><li>è®¡ç®—æ•ˆç‡æå‡ 4å€</li></ul><h4 id="2-4-3-å‹ç¼©å¯¹æ£€ç´¢æ€§èƒ½çš„å½±å“"><a href="#2-4-3-å‹ç¼©å¯¹æ£€ç´¢æ€§èƒ½çš„å½±å“" class="headerlink" title="2.4.3 å‹ç¼©å¯¹æ£€ç´¢æ€§èƒ½çš„å½±å“"></a>2.4.3 å‹ç¼©å¯¹æ£€ç´¢æ€§èƒ½çš„å½±å“</h4><p><strong>ç›¸ä¼¼æ€§å˜åŒ–åˆ†æ</strong>ï¼š<br>è®¾ $sim(q, s)$ ä¸ºæŸ¥è¯¢qä¸æ®µè½sçš„ç›¸ä¼¼æ€§</p><p>å‹ç¼©å‰ï¼š$sim_{before}(q, s_{relevant})$ï¼Œ$sim_{before}(q, s_{irrelevant})$<br>å‹ç¼©åï¼š$sim_{after}(q, sâ€™<em>{relevant})$ï¼Œ$sim</em>{after}(q, sâ€™_{irrelevant})$</p><p>å®éªŒç»“æœæ˜¾ç¤ºï¼š</p><ul><li>$sim_{after}(q, sâ€™<em>{relevant}) &gt; sim</em>{before}(q, s_{relevant})$ ï¼ˆç›¸å…³æ®µè½ç›¸ä¼¼æ€§æå‡ï¼‰</li><li>$sim_{after}(q, sâ€™<em>{irrelevant}) &lt; sim</em>{before}(q, s_{irrelevant})$ ï¼ˆæ— å…³æ®µè½ç›¸ä¼¼æ€§é™ä½ï¼‰</li></ul><h3 id="2-5-å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿ"><a href="#2-5-å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿ" class="headerlink" title="2.5 å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿ"></a>2.5 å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿ</h3><h4 id="2-5-1-æ£€ç´¢å™¨é€‰æ‹©ä¸é…ç½®"><a href="#2-5-1-æ£€ç´¢å™¨é€‰æ‹©ä¸é…ç½®" class="headerlink" title="2.5.1 æ£€ç´¢å™¨é€‰æ‹©ä¸é…ç½®"></a>2.5.1 æ£€ç´¢å™¨é€‰æ‹©ä¸é…ç½®</h4><p><strong>BM25æ£€ç´¢å™¨</strong>ï¼š<br>$$BM25(q, d) = \sum_{i=1}^{|q|} IDF(q_i) \cdot \frac{tf(q_i, d) \cdot (k_1 + 1)}{tf(q_i, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}$$</p><p>å‚æ•°è®¾ç½®ï¼š$k_1 = 1.2$ï¼Œ$b = 0.75$</p><p><strong>MPNetæ£€ç´¢å™¨</strong>ï¼š<br>åŸºäºMPNetæ¨¡å‹çš„å¯†é›†æ£€ç´¢ï¼š<br>$$score = \cos(\mathbf{e}_q, \mathbf{e}_d)$$<br>å…¶ä¸­ $\mathbf{e}_q$ å’Œ $\mathbf{e}_d$ åˆ†åˆ«ä¸ºæŸ¥è¯¢å’Œæ–‡æ¡£çš„å‘é‡è¡¨ç¤º</p><h4 id="2-5-2-æ··åˆæ£€ç´¢ç­–ç•¥"><a href="#2-5-2-æ··åˆæ£€ç´¢ç­–ç•¥" class="headerlink" title="2.5.2 æ··åˆæ£€ç´¢ç­–ç•¥"></a>2.5.2 æ··åˆæ£€ç´¢ç­–ç•¥</h4><p>ç»“åˆç¨€ç–æ£€ç´¢å’Œå¯†é›†æ£€ç´¢çš„ä¼˜åŠ¿ï¼š<br>$$score_{hybrid} = \alpha \cdot score_{BM25} + (1-\alpha) \cdot score_{MPNet}$$</p><p>é€šè¿‡å®éªŒç¡®å®šæœ€ä¼˜æƒé‡ $\alpha = 0.6$</p><h2 id="3-å†™åœ¨æœ€åï¼šä¸€äº›æ€è€ƒ"><a href="#3-å†™åœ¨æœ€åï¼šä¸€äº›æ€è€ƒ" class="headerlink" title="3. å†™åœ¨æœ€åï¼šä¸€äº›æ€è€ƒ"></a>3. å†™åœ¨æœ€åï¼šä¸€äº›æ€è€ƒ</h2><h3 id="3-1-SeComç»™æˆ‘ä»¬çš„å¯å‘"><a href="#3-1-SeComç»™æˆ‘ä»¬çš„å¯å‘" class="headerlink" title="3.1 SeComç»™æˆ‘ä»¬çš„å¯å‘"></a>3.1 SeComç»™æˆ‘ä»¬çš„å¯å‘</h3><p>ç ”è¯»è¿™ç¯‡è®ºæ–‡åï¼Œç¬”è€…æœ‰å‡ ç‚¹æ·±åˆ»çš„æ„Ÿæ‚Ÿï¼š</p><p><strong>ç®€å•å¾€å¾€æ˜¯æœ€æœ‰æ•ˆçš„</strong>ï¼šSeComçš„æ ¸å¿ƒæ€æƒ³å…¶å®å¾ˆç®€å•â€”â€”åˆ†æ®µ+å‹ç¼©ï¼Œä½†æ­£æ˜¯è¿™ç§ç®€å•çš„ç»„åˆè§£å†³äº†å¤æ‚çš„é—®é¢˜ã€‚è¿™æé†’æˆ‘ä»¬ï¼Œåœ¨é¢å¯¹æŠ€æœ¯æŒ‘æˆ˜æ—¶ï¼Œæœ‰æ—¶å€™æœ€æœ´ç´ çš„æƒ³æ³•åè€Œæ˜¯æœ€æœ‰æ•ˆçš„ã€‚</p><p><strong>ç†è§£é—®é¢˜æ¯”è§£å†³é—®é¢˜æ›´é‡è¦</strong>ï¼šä½œè€…å›¢é˜Ÿæ·±å…¥åˆ†æäº†å†…å­˜ç²’åº¦é—®é¢˜çš„æœ¬è´¨ï¼Œå‘ç°äº†æ®µè½çº§å†…å­˜çš„æœ€ä¼˜æ€§ã€‚è¿™ç§å¯¹é—®é¢˜æœ¬è´¨çš„æ·±åˆ»ç†è§£æ˜¯æŠ€æœ¯åˆ›æ–°çš„åŸºç¡€ã€‚</p><p>ç¬”è€…è®¤ä¸ºæœªæ¥å¯èƒ½çš„å‘å±•æ–¹å‘åŒ…æ‹¬ï¼š</p><ul><li><strong>ä¸ªæ€§åŒ–åˆ†æ®µç­–ç•¥</strong>ï¼šä¸åŒç”¨æˆ·çš„å¯¹è¯æ¨¡å¼ä¸åŒï¼Œèƒ½å¦å­¦ä¹ ä¸ªæ€§åŒ–çš„åˆ†æ®µæ–¹å¼ï¼Ÿ</li><li><strong>å®æ—¶ä¼˜åŒ–æœºåˆ¶</strong>ï¼šèƒ½å¦æ ¹æ®å¯¹è¯è´¨é‡åŠ¨æ€è°ƒæ•´å‹ç¼©ç‡å’Œåˆ†æ®µç­–ç•¥ï¼Ÿ</li></ul><hr><h2 id="å‚è€ƒèµ„æº"><a href="#å‚è€ƒèµ„æº" class="headerlink" title="å‚è€ƒèµ„æº"></a>å‚è€ƒèµ„æº</h2><ul><li><strong>è®ºæ–‡é“¾æ¥</strong>ï¼š<a href="https://www.arxiv.org/abs/2502.05589">SeCom: On Memory Construction and Retrieval for Personalized Conversational Agents (ICLR 2025)</a></li><li><strong>é¡¹ç›®ä¸»é¡µ</strong>ï¼š<a href="https://llmlingua.com/secom.html">https://llmlingua.com/secom.html</a></li><li><strong>ä»£ç ä»“åº“</strong>ï¼šSeCom-mainé¡¹ç›®</li><li><strong>æ•°æ®é›†</strong>ï¼šLOCOMOã€Long-MT-Bench+ã€DialSeg711ã€TIAGEã€SuperDialSeg</li></ul><p><em>æœ¬æ–‡åŸºäºMicrosoftå’Œæ¸…åå¤§å­¦è”åˆç ”ç©¶å›¢é˜Ÿåœ¨ICLR 2025å‘è¡¨çš„è®ºæ–‡æ’°å†™ï¼Œè¯¦ç»†æŠ€æœ¯å®ç°è¯·å‚è€ƒåŸå§‹è®ºæ–‡å’Œå¼€æºä»£ç ã€‚</em> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SeCom-é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†&quot;&gt;&lt;a href=&quot;#SeCom-é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†&quot; class=&quot;headerlink&quot; title=&quot;SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†&quot;&gt;&lt;/a&gt;SeCom: é‡æ–°å®šä¹‰å¯¹è¯AIçš„è®°å¿†ç®¡ç†&lt;/h1&gt;&lt;h2</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="Conversational AI" scheme="https://chenhuiyu.github.io/tags/Conversational-AI/"/>
    
    <category term="Memory Management" scheme="https://chenhuiyu.github.io/tags/Memory-Management/"/>
    
    <category term="SeCom" scheme="https://chenhuiyu.github.io/tags/SeCom/"/>
    
    <category term="RAG" scheme="https://chenhuiyu.github.io/tags/RAG/"/>
    
  </entry>
  
  <entry>
    <title>Decoder-onlyä¸Encoder-onlyæ¨¡å‹Paddingç­–ç•¥çš„å·®å¼‚</title>
    <link href="https://chenhuiyu.github.io/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C/"/>
    <id>https://chenhuiyu.github.io/2025/03/06/NLP%20Insights/Decoder%E6%A8%A1%E5%9E%8B%E5%92%8CEncoder%E6%A8%A1%E5%9E%8B%E5%9C%A8Padding%E4%B8%AD%E7%9A%84%E4%B8%8D%E5%90%8C/</id>
    <published>2025-03-06T09:43:10.000Z</published>
    <updated>2026-02-20T21:56:22.871Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ“Œ-Padding-çš„å«ä¹‰"><a href="#ğŸ“Œ-Padding-çš„å«ä¹‰" class="headerlink" title="ğŸ“Œ Padding çš„å«ä¹‰"></a>ğŸ“Œ <strong>Padding çš„å«ä¹‰</strong></h2><p>åœ¨å¤§æ¨¡å‹ (<strong>LLM</strong>) ä¸­ï¼Œ<strong>padding</strong> æ˜¯ç”¨äºå°†ä¸åŒé•¿åº¦çš„åºåˆ—è°ƒæ•´ä¸ºåŒä¸€é•¿åº¦çš„æ–¹æ³•ï¼Œä»¥ä¾¿äºæ‰¹é‡ (<strong>batch</strong>) å¤„ç†ã€‚</p><p>ä¾‹å¦‚ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">å¥å­1: "I love NLP"</span><br><span class="line">å¥å­2: "Padding is useful in LLM training"</span><br></pre></td></tr></tbody></table></figure><p>ä½¿ç”¨ <code>&lt;pad&gt;</code> token è¿›è¡Œå¯¹é½ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">"I love NLP &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;"</span><br><span class="line">"Padding is useful in LLM training"</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="ğŸ“Œ-Padding-ä½ç½®çš„é€‰æ‹©ï¼šLeft-vs-Right"><a href="#ğŸ“Œ-Padding-ä½ç½®çš„é€‰æ‹©ï¼šLeft-vs-Right" class="headerlink" title="ğŸ“Œ Padding ä½ç½®çš„é€‰æ‹©ï¼šLeft vs Right"></a>ğŸ“Œ <strong>Padding ä½ç½®çš„é€‰æ‹©ï¼šLeft vs Right</strong></h2><p>Padding æœ‰ä¸¤ç§å¸¸è§æ–¹å¼ï¼š</p><ul><li><p><strong>Right padding</strong>ï¼ˆå³å¡«å……ï¼‰ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">"I love NLP &lt;pad&gt; &lt;pad&gt;"</span><br></pre></td></tr></tbody></table></figure></li><li><p><strong>Left padding</strong>ï¼ˆå·¦å¡«å……ï¼‰ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">"&lt;pad&gt; &lt;pad&gt; I love NLP"</span><br></pre></td></tr></tbody></table></figure></li></ul><p>é€šå¸¸ï¼š</p><ul><li><strong>Decoder-only æ¨¡å‹</strong>ï¼ˆå¦‚ GPT, Llamaï¼‰ï¼šé‡‡ç”¨ <strong>Left padding</strong></li><li><strong>Encoder-only æ¨¡å‹</strong>ï¼ˆå¦‚ BERTï¼‰ï¼šé‡‡ç”¨ <strong>Right padding</strong></li></ul><p>å…·ä½“è€Œè¨€ï¼ŒTransformer æ¨¡å‹é€šå¸¸åˆ†ä¸ºä¸‰ç±»ç»“æ„ï¼š</p><table><thead><tr><th>æ¨¡å‹ç±»å‹</th><th>ä»£è¡¨æ¨¡å‹</th><th>ç‰¹å¾</th><th>å¸¸è§ç”¨é€”</th></tr></thead><tbody><tr><td><strong>Encoder-only</strong></td><td><strong>BERT</strong>ã€RoBERTaã€ALBERTã€ELECTRA</td><td>åŒå‘æ³¨æ„åŠ›ï¼ˆBidirectional Attentionï¼‰</td><td>è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€åºåˆ—æ ‡æ³¨</td></tr><tr><td><strong>Decoder-only</strong></td><td>GPTã€GPT-2ã€GPT-3ã€GPT-4ã€LLaMAã€Mistral</td><td>å•å‘è‡ªå›å½’æ³¨æ„åŠ›ï¼ˆCausal Attentionï¼‰</td><td>æ–‡æœ¬ç”Ÿæˆã€èŠå¤©ã€å†™ä½œ</td></tr><tr><td><strong>Encoder-Decoder</strong></td><td>TransformeråŸå§‹è®ºæ–‡ä¸­çš„æ¨¡å‹ã€T5ã€BARTã€mT5ã€PEGASUS</td><td>Encoderä¸ºåŒå‘æ³¨æ„åŠ›ï¼ŒDecoderä¸ºå•å‘è‡ªå›å½’æ³¨æ„åŠ›</td><td>æœºå™¨ç¿»è¯‘ã€æ‘˜è¦ç”Ÿæˆã€å¯¹è¯</td></tr></tbody></table><hr><h2 id="ğŸ“Œ-ä¸ºä»€ä¹ˆ-Encoder-only-æ¨¡å‹ï¼ˆå¦‚BERTï¼‰é‡‡ç”¨-Right-paddingï¼Ÿ"><a href="#ğŸ“Œ-ä¸ºä»€ä¹ˆ-Encoder-only-æ¨¡å‹ï¼ˆå¦‚BERTï¼‰é‡‡ç”¨-Right-paddingï¼Ÿ" class="headerlink" title="ğŸ“Œ ä¸ºä»€ä¹ˆ Encoder-only æ¨¡å‹ï¼ˆå¦‚BERTï¼‰é‡‡ç”¨ Right paddingï¼Ÿ"></a>ğŸ“Œ ä¸ºä»€ä¹ˆ Encoder-only æ¨¡å‹ï¼ˆå¦‚BERTï¼‰é‡‡ç”¨ Right paddingï¼Ÿ</h2><ul><li><strong>Encoder-only æ¨¡å‹</strong>ï¼ˆå¦‚ BERTï¼‰çš„æ ¸å¿ƒç›®æ ‡æ˜¯è·å¾—<strong>æ¯ä¸ª token çš„åµŒå…¥è¡¨ç¤º</strong>ï¼ˆEmbedding representationï¼‰ã€‚</li><li>æ­¤ç±»æ¨¡å‹ä¸º<strong>åŒå‘æ³¨æ„åŠ›ï¼ˆBidirectional Attentionï¼‰</strong>ï¼Œæ¯ä¸ª token å¯åŒæ—¶å…³æ³¨ä¸Šä¸‹æ–‡ï¼Œå› æ­¤<strong>ä½ç½®çš„è½»å¾®å˜åŒ–ä¸ä¼šå¯¹ç»“æœé€ æˆä¸¥é‡å¹²æ‰°</strong>ã€‚</li><li>æ­¤å¤–ï¼Œencoder-only æ¨¡å‹ä¸­é€šå¸¸æœ‰ç‰¹æ®Š tokenï¼ˆå¦‚ <code>[CLS]</code>ï¼‰ï¼Œä½ç½®ç›¸å¯¹ç¨³å®šï¼Œç”¨äºå¥å­åˆ†ç±»æˆ–è¡¨ç¤ºï¼Œå› æ­¤é‡‡ç”¨ <strong>right padding</strong> æ›´è‡ªç„¶ï¼Œä¹Ÿæ›´åˆç†ã€‚</li></ul><p>ç¤ºä¾‹è¯´æ˜ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CLS] Hello I love NLP [SEP] &lt;pad&gt; &lt;pad&gt;</span><br></pre></td></tr></tbody></table></figure><ul><li>å³å¡«å……åï¼Œ<code>[CLS]</code> å’Œ <code>[SEP]</code> token ä½ç½®ç¨³å®šï¼Œä¸”ä¾¿äºæ¨¡å‹ä¸“æ³¨äºå‰é¢çš„æœ‰æ•ˆä¿¡æ¯ã€‚</li></ul><hr><h2 id="ğŸ“Œ-ä¸ºä»€ä¹ˆ-Decoder-only-LLM-é‡‡ç”¨-Left-paddingï¼Ÿ"><a href="#ğŸ“Œ-ä¸ºä»€ä¹ˆ-Decoder-only-LLM-é‡‡ç”¨-Left-paddingï¼Ÿ" class="headerlink" title="ğŸ“Œ ä¸ºä»€ä¹ˆ Decoder-only LLM é‡‡ç”¨ Left paddingï¼Ÿ"></a>ğŸ“Œ ä¸ºä»€ä¹ˆ Decoder-only LLM é‡‡ç”¨ Left paddingï¼Ÿ</h2><p>ä»¥ GPT ä¸ºä»£è¡¨çš„ <strong>Decoder-only æ¨¡å‹</strong> æ˜¯è‡ªå›å½’ï¼ˆ<strong>Autoregressive</strong>ï¼‰æ¨¡å‹ï¼Œæ¯ä¸ªè¯çš„ç”Ÿæˆä»…ä¾èµ–äºå½“å‰åŠä¹‹å‰çš„è¯ï¼Œæœªæ¥è¯ä¸å¯è§ã€‚å› æ­¤ï¼š</p><ul><li><strong>ä½ç½®ç¼–ç çš„ç¨³å®šæ€§</strong>ï¼š<br>å·¦å¡«å……ç¡®ä¿çœŸå® token çš„ç›¸å¯¹ä½ç½®ç¨³å®šï¼Œæ¨¡å‹ç”Ÿæˆæ–° token æ—¶ä½ç½®ç¼–ç å§‹ç»ˆç¨³å®šäºåºåˆ—æœ«å°¾ã€‚<ul><li>å½“é‡‡ç”¨<strong>ç»å¯¹ä½ç½®ç¼–ç </strong>ï¼ˆAbsolute Positional Encodingï¼‰æ—¶ï¼Œæ¯ä¸ª tokenï¼ˆåŒ…æ‹¬ <code>&lt;pad&gt;</code>ï¼‰éƒ½æœ‰å¯¹åº”çš„ä½ç½®ç¼–å·ã€‚</li><li>å¯¹äºå·¦å¡«å……çš„ padding tokensï¼Œè™½ç„¶å®ƒä»¬å æ®äº†ä½ç½®ç¼–å·ï¼ˆå¦‚ 1ã€2ï¼‰ï¼Œä½†æ¨¡å‹é€šè¿‡<strong>æ©ç æœºåˆ¶</strong>å¿½ç•¥å…¶å¯¹æ³¨æ„åŠ›å’Œè¾“å‡ºç»“æœçš„å½±å“ã€‚<br>ç¤ºä¾‹ï¼š</li></ul></li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ä½ç½®ç¼–ç : [ 1      2      3      4      5      6 ]</span><br><span class="line">Token:   [ &lt;pad&gt;, &lt;pad&gt;, Hello,  I,   love,  NLP ]</span><br><span class="line">æ©ç :     [  0,     0,     1,     1,     1,    1 ]</span><br></pre></td></tr></tbody></table></figure><ul><li>æ¨¡å‹åªå…³æ³¨æ©ç ä¸º 1 çš„æœ‰æ•ˆ tokenï¼Œè€Œå¿½ç•¥æ©ç ä¸º 0 çš„ padding tokensã€‚</li><li><strong>æ³¨æ„åŠ›æ©ç ï¼ˆAttention Maskï¼‰</strong>ï¼š<br>å·¦ä¾§çš„ <code>&lt;pad&gt;</code> ä¼šè¢«<strong>æ³¨æ„åŠ›æ©ç ï¼ˆattention maskï¼‰å¿½ç•¥</strong>ï¼Œä»è€Œé¿å… padding token å¹²æ‰°æœ‰æ•ˆ token çš„ä½ç½®ç¼–ç å’Œæ³¨æ„åŠ›è®¡ç®—ã€‚</li></ul><p>ç¤ºä¾‹è¯´æ˜ï¼š</p><table><thead><tr><th>Token</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>Left</td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td><td>Hello</td><td>I</td><td>love</td><td>NLP</td></tr><tr><td>Right</td><td>Hello</td><td>I</td><td>love</td><td>NLP</td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr></tbody></table><ul><li><strong>Left padding</strong> ä¸‹ï¼Œæœ€åæœ‰æ•ˆ token å§‹ç»ˆåœ¨åŒä¸€ä½ç½®ï¼ˆ6ï¼‰ã€‚</li><li><strong>Right padding</strong> ä¸‹ï¼Œtoken çš„ä½ç½®éšåºåˆ—é•¿åº¦å˜åŒ–ï¼Œå½±å“ä½ç½®ç¼–ç çš„ç¨³å®šæ€§ã€‚</li></ul><hr><h2 id="ğŸ“Œ-Padding-åœ¨è®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„å·®å¼‚"><a href="#ğŸ“Œ-Padding-åœ¨è®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„å·®å¼‚" class="headerlink" title="ğŸ“Œ Padding åœ¨è®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„å·®å¼‚"></a>ğŸ“Œ <strong>Padding åœ¨è®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„å·®å¼‚</strong></h2><table><thead><tr><th>é˜¶æ®µ (Phase)</th><th>Padding ç­–ç•¥</th><th>åŸå› </th></tr></thead><tbody><tr><td><strong>è®­ç»ƒ (Training)</strong></td><td>æ‰¹é‡å¤„ç†æ—¶ï¼ŒDecoder-only å¸¸ç”¨å·¦å¡«å……ï¼›Encoder-only æ¨¡å‹åˆ™å¸¸ç”¨å³å¡«å……</td><td>æ‰¹é‡å¤„ç†ï¼ŒåŠ å¿«è®¡ç®—æ•ˆç‡</td></tr><tr><td><strong>æ¨ç† (Inference)</strong></td><td>é€šå¸¸å•æ¡åºåˆ—ï¼Œæ— éœ€ paddingï¼›è‹¥éœ€è¦æ‰¹é‡æ¨ç†ï¼Œä»é‡‡ç”¨å·¦å¡«å……</td><td>ç¨³å®šä½ç½®ç¼–ç </td></tr></tbody></table><hr><h2 id="ğŸ“Œ-æ€»ç»“ä¸å…³é”®è¦ç‚¹ï¼ˆTL-DRï¼‰"><a href="#ğŸ“Œ-æ€»ç»“ä¸å…³é”®è¦ç‚¹ï¼ˆTL-DRï¼‰" class="headerlink" title="ğŸ“Œ æ€»ç»“ä¸å…³é”®è¦ç‚¹ï¼ˆTL;DRï¼‰"></a>ğŸ“Œ <strong>æ€»ç»“ä¸å…³é”®è¦ç‚¹ï¼ˆTL;DRï¼‰</strong></h2><ul><li><strong>Padding</strong> ç”¨äºåºåˆ—é•¿åº¦æ ‡å‡†åŒ–ã€‚</li><li><strong>Decoder-only LLMs (GPT, Llama)</strong> é€šå¸¸é‡‡ç”¨<strong>å·¦å¡«å……ï¼ˆLeft paddingï¼‰</strong>ï¼Œç›®çš„æ˜¯<strong>ç¨³å®šä½ç½®ç¼–ç å¹¶é¿å…æœªæ¥ä¿¡æ¯æ³„æ¼</strong>ï¼›å·¦ä¾§ padding ä¼šè¢«æ©ç å¿½ç•¥ï¼Œä¸å¹²æ‰°æ¨¡å‹é¢„æµ‹ã€‚</li><li><strong>Encoder-only æ¨¡å‹ï¼ˆå¦‚BERTç³»åˆ—ï¼‰</strong>é€šå¸¸é‡‡ç”¨<strong>å³å¡«å……ï¼ˆRight paddingï¼‰</strong>ï¼Œå› ä¸ºæ¨¡å‹ä¸ºåŒå‘æ³¨æ„åŠ›ï¼Œä¸”ç‰¹æ®Štokenï¼ˆå¦‚<code>[CLS]</code>ï¼‰ä½ç½®éœ€è¦ä¿æŒç¨³å®šã€‚</li><li>ä½ç½®ç¼–ç ä¸­è™½ç„¶ padding token å ä½ï¼Œä½†ä¼šè¢«<strong>æ³¨æ„åŠ›æ©ç </strong>æœ‰æ•ˆå±è”½ï¼Œä¸å½±å“æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºã€‚</li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ“Œ-Padding-çš„å«ä¹‰&quot;&gt;&lt;a href=&quot;#ğŸ“Œ-Padding-çš„å«ä¹‰&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“Œ Padding çš„å«ä¹‰&quot;&gt;&lt;/a&gt;ğŸ“Œ &lt;strong&gt;Padding çš„å«ä¹‰&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;åœ¨å¤§æ¨¡å‹ </summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="LLM" scheme="https://chenhuiyu.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>Differences in Padding Strategies Between Decoder-only and Encoder-only Models</title>
    <link href="https://chenhuiyu.github.io/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models/"/>
    <id>https://chenhuiyu.github.io/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models/</id>
    <published>2025-03-06T09:43:10.000Z</published>
    <updated>2026-02-20T21:56:22.871Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ“Œ-What-is-Padding"><a href="#ğŸ“Œ-What-is-Padding" class="headerlink" title="ğŸ“Œ What is Padding?"></a>ğŸ“Œ <strong>What is Padding?</strong></h2><p>In <strong>Large Language Models (LLMs)</strong>, <strong>padding</strong> is a method used to standardize sequence lengths for <strong>batch processing</strong>.</p><p>For example:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sentence 1: "I love NLP"</span><br><span class="line">Sentence 2: "Padding is useful in LLM training"</span><br></pre></td></tr></tbody></table></figure><p>Using the <code>&lt;pad&gt;</code> token for alignment:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">"I love NLP &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;"</span><br><span class="line">"Padding is useful in LLM training"</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="ğŸ“Œ-Padding-Positioning-Left-vs-Right"><a href="#ğŸ“Œ-Padding-Positioning-Left-vs-Right" class="headerlink" title="ğŸ“Œ Padding Positioning: Left vs Right"></a>ğŸ“Œ <strong>Padding Positioning: Left vs Right</strong></h2><p>There are two common padding strategies:</p><ul><li><p><strong>Right padding</strong>:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">"I love NLP &lt;pad&gt; &lt;pad&gt;"</span><br></pre></td></tr></tbody></table></figure></li><li><p><strong>Left padding</strong>:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">"&lt;pad&gt; &lt;pad&gt; I love NLP"</span><br></pre></td></tr></tbody></table></figure></li></ul><p>Typically:</p><ul><li><strong>Decoder-only models</strong> (e.g., GPT, Llama): Use <strong>Left padding</strong>.</li><li><strong>Encoder-only models</strong> (e.g., BERT): Use <strong>Right padding</strong>.</li></ul><p>Transformers can be categorized into three main architectures:</p><table><thead><tr><th>Model Type</th><th>Representative Models</th><th>Characteristics</th><th>Common Applications</th></tr></thead><tbody><tr><td><strong>Encoder-only</strong></td><td><strong>BERT</strong>, RoBERTa, ALBERT, ELECTRA</td><td><strong>Bidirectional attention</strong></td><td>NLP tasks like text classification, named entity recognition</td></tr><tr><td><strong>Decoder-only</strong></td><td>GPT, GPT-2, GPT-3, GPT-4, LLaMA, Mistral</td><td><strong>Causal attention (Autoregressive)</strong></td><td>Text generation, chatbots, writing assistance</td></tr><tr><td><strong>Encoder-Decoder</strong></td><td>Transformer (original), T5, BART, mT5, PEGASUS</td><td><strong>Encoder: bidirectional, Decoder: autoregressive</strong></td><td>Machine translation, summarization, dialogue systems</td></tr></tbody></table><hr><h2 id="ğŸ“Œ-Why-Do-Encoder-only-Models-e-g-BERT-Use-Right-Padding"><a href="#ğŸ“Œ-Why-Do-Encoder-only-Models-e-g-BERT-Use-Right-Padding" class="headerlink" title="ğŸ“Œ Why Do Encoder-only Models (e.g., BERT) Use Right Padding?"></a>ğŸ“Œ <strong>Why Do Encoder-only Models (e.g., BERT) Use Right Padding?</strong></h2><ul><li><strong>Encoder-only models</strong> (like BERT) aim to obtain <strong>representations for each token</strong>.</li><li>These models use <strong>bidirectional attention</strong>, meaning each token attends to <strong>both past and future tokens</strong>.</li><li><strong>Slight shifts in position do not significantly impact model performance</strong>.</li><li>Special tokens (e.g., <code>[CLS]</code>) in BERT maintain a <strong>fixed position</strong> for tasks like classification, making <strong>right padding more natural</strong>.</li></ul><p>Example:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CLS] Hello I love NLP [SEP] &lt;pad&gt; &lt;pad&gt;</span><br></pre></td></tr></tbody></table></figure><ul><li>Right padding keeps <code>[CLS]</code> and <code>[SEP]</code> in stable positions, allowing the model to focus on meaningful tokens.</li></ul><hr><h2 id="ğŸ“Œ-Why-Do-Decoder-only-LLMs-Use-Left-Padding"><a href="#ğŸ“Œ-Why-Do-Decoder-only-LLMs-Use-Left-Padding" class="headerlink" title="ğŸ“Œ Why Do Decoder-only LLMs Use Left Padding?"></a>ğŸ“Œ <strong>Why Do Decoder-only LLMs Use Left Padding?</strong></h2><p><strong>Decoder-only models</strong> (like GPT) are <strong>autoregressive</strong>, meaning each token is generated based only on <strong>previous tokens</strong>, and future tokens are <strong>masked</strong>.</p><ul><li><strong>Positional Encoding Stability</strong>:<br>Left padding ensures that meaningful tokens have a <strong>consistent relative position</strong>, preventing <strong>position encoding misalignment</strong>.<ul><li>When using <strong>absolute positional encoding</strong>, every token (including <code>&lt;pad&gt;</code>) gets a unique position index.</li><li>Padding tokens at the beginning <strong>do not affect the modelâ€™s attention mechanism</strong> due to <strong>masking</strong>.</li></ul></li></ul><p>Example:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Position Index: [ 1      2      3      4      5      6 ]</span><br><span class="line">Token:         [ &lt;pad&gt;, &lt;pad&gt;, Hello,  I,   love,  NLP ]</span><br><span class="line">Mask:          [  0,     0,     1,     1,     1,    1 ]</span><br></pre></td></tr></tbody></table></figure><ul><li><p>The model <strong>only attends to tokens where the mask is 1</strong>, ignoring padding tokens.</p></li><li><p><strong>Attention Masking</strong>:<br>Left padding ensures that <code>&lt;pad&gt;</code> tokens <strong>do not interfere with token position encoding</strong>.</p></li></ul><p>Illustration:</p><table><thead><tr><th>Token</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>Left</td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td><td>Hello</td><td>I</td><td>love</td><td>NLP</td></tr><tr><td>Right</td><td>Hello</td><td>I</td><td>love</td><td>NLP</td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr></tbody></table><ul><li><strong>With Left padding</strong>, the last valid token <strong>always remains in the same position</strong>.</li><li><strong>With Right padding</strong>, token positions shift, affecting positional encoding stability.</li></ul><hr><h2 id="ğŸ“Œ-Padding-Differences-in-Training-vs-Inference"><a href="#ğŸ“Œ-Padding-Differences-in-Training-vs-Inference" class="headerlink" title="ğŸ“Œ Padding Differences in Training vs Inference"></a>ğŸ“Œ <strong>Padding Differences in Training vs Inference</strong></h2><table><thead><tr><th>Phase</th><th>Padding Strategy</th><th>Reason</th></tr></thead><tbody><tr><td><strong>Training</strong></td><td>Left padding for decoder-only; Right padding for encoder-only</td><td>Optimized for batch processing efficiency</td></tr><tr><td><strong>Inference</strong></td><td>Typically, no padding for single sequences; Left padding for batched inference</td><td>Ensures stable positional encoding</td></tr></tbody></table><hr><h2 id="ğŸ“Œ-Summary-amp-Key-Takeaways-TL-DR"><a href="#ğŸ“Œ-Summary-amp-Key-Takeaways-TL-DR" class="headerlink" title="ğŸ“Œ Summary &amp; Key Takeaways (TL;DR)"></a>ğŸ“Œ <strong>Summary &amp; Key Takeaways (TL;DR)</strong></h2><ul><li><strong>Padding</strong> standardizes sequence lengths for batch processing.</li><li><strong>Decoder-only models (GPT, Llama)</strong> use <strong>Left padding</strong> to <strong>stabilize positional encoding and prevent future token leakage</strong>. Left padding tokens are masked out.</li><li><strong>Encoder-only models (BERT, RoBERTa)</strong> use <strong>Right padding</strong> since they employ <strong>bidirectional attention</strong> and rely on stable special token positions (e.g., <code>[CLS]</code>).</li><li>Although padding tokens occupy positions in <strong>positional encoding</strong>, <strong>attention masks</strong> effectively filter them out, ensuring they do not affect model predictions.</li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ“Œ-What-is-Padding&quot;&gt;&lt;a href=&quot;#ğŸ“Œ-What-is-Padding&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“Œ What is Padding?&quot;&gt;&lt;/a&gt;ğŸ“Œ &lt;strong&gt;What is Padding?&lt;/st</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="LLM" scheme="https://chenhuiyu.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</title>
    <link href="https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/"/>
    <id>https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/</id>
    <published>2025-02-11T03:50:29.000Z</published>
    <updated>2026-02-20T21:56:22.873Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MoE-æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜-MoE-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²"><a href="#MoE-æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜-MoE-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²" class="headerlink" title="MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²"></a>MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</h1><p><strong>åŸæ–‡åœ°å€</strong>ï¼š<a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts">A Visual Guide to Mixture of Experts (MoE)</a></p><p>ğŸ“… ä½œè€…ï¼šMaarten Grootendorst</p><p>ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥</p><hr><h1 id="æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—"><a href="#æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—" class="headerlink" title="æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—"></a>æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—</h1><h2 id="ç›®å½•"><a href="#ç›®å½•" class="headerlink" title="ç›®å½•"></a>ç›®å½•</h2><ul><li><a href="#moe-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%E6%8F%AD%E7%A7%98-moe-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</a></li><li><a href="#%E6%8E%A2%E7%B4%A2%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8Bmoe%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97">æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—</a><ul><li><a href="#%E7%9B%AE%E5%BD%95">ç›®å½•</a></li><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6moe%E6%A8%A1%E5%9E%8B">ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ</a></li><li><a href="#experts">Experts</a><ul><li><a href="#dense-layers">Dense Layers</a></li><li><a href="#sparse-layers">Sparse Layers</a></li><li><a href="#what-does-an-expert-learn">What does an Expert Learn?</a></li><li><a href="#%E4%B8%93%E5%AE%B6%E7%9A%84%E6%9E%B6%E6%9E%84architecture-of-experts">ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰</a></li></ul></li></ul></li></ul><p>å½“æˆ‘ä»¬æŸ¥çœ‹æœ€æ–°å‘å¸ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆ<strong>LLMs</strong>ï¼ŒLarge Language Modelsï¼‰æ—¶ï¼Œå¸¸å¸¸ä¼šåœ¨æ ‡é¢˜ä¸­çœ‹åˆ° â€œ<strong>MoE</strong>â€ã€‚è¿™ä¸ª â€œMoEâ€ ä»£è¡¨ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¿™ä¹ˆå¤š LLM éƒ½åœ¨ä½¿ç”¨å®ƒï¼Ÿ</p><p>åœ¨è¿™ä»½å¯è§†åŒ–æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ 50 å¤šä¸ªå¯è§†åŒ–å›¾ç¤ºï¼Œé€æ­¥æ¢ç´¢è¿™ä¸€å…³é”®ç»„ä»¶ï¼š**Mixture of Experts (MoE)**ã€‚</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_145859.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šåœ¨è¿™å¼ å›¾ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¸€ä¸ªå…¸å‹ <strong>MoE</strong> ç»“æ„çš„ä¸¤ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š<strong>Experts</strong>ï¼ˆä¸“å®¶ï¼‰å’Œ <strong>Router</strong>ï¼ˆè·¯ç”±å™¨æˆ–é—¨æ§ç½‘ç»œï¼‰ã€‚å›¾ä¸­æ˜¾ç¤ºäº†ä¸€ä¸ª <strong>Router</strong>ï¼Œä»¥åŠä¸‹æ–¹å¹¶åˆ—çš„å¤šä¸ª <strong>Experts</strong>ï¼Œè¡¨æ˜åœ¨ <strong>LLM</strong> æ¶æ„ä¸­ï¼ŒMoE ä¼šå°†è¾“å…¥æ ¹æ®éœ€è¦è·¯ç”±åˆ°åˆé€‚çš„ä¸“å®¶ã€‚<br><strong>å›¾ 1 è¯¦ç»†è¯´æ˜</strong>ï¼š</p><ol><li><strong>Router</strong>ï¼šå†³å®šå°†è¾“å…¥ï¼ˆä¾‹å¦‚ tokenï¼‰å‘é€ç»™å“ªä¸€ä¸ªæˆ–å“ªå‡ ä¸ªä¸“å®¶ã€‚</li><li><strong>Experts</strong>ï¼šè‹¥å¹²ä¸ªä¸åŒçš„å­æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ <strong>FFNN</strong> ç»“æ„ï¼‰ï¼Œæ¯ä¸ªä¸“å®¶å¯èƒ½åœ¨ä¸åŒæ–¹é¢å…·æœ‰ä¸“é•¿ã€‚</li><li><strong>å·¥ä½œæµç¨‹</strong>ï¼šè¾“å…¥å…ˆé€šè¿‡ <strong>Router</strong>ï¼Œå†è¢«åˆ†é…åˆ°ä¸åŒçš„ä¸“å®¶è¿›è¡Œå¤„ç†ï¼Œæœ€åæ±‡æ€»ç»“æœã€‚</li></ol><h2 id="ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ</h2><p><strong>Mixture of Experts (MoE)</strong> æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨è®¸å¤šä¸åŒçš„å­æ¨¡å‹ï¼ˆæˆ–â€œ<strong>experts</strong>â€ï¼‰æ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è´¨é‡ã€‚</p><p>åœ¨ MoE ä¸­ï¼Œæœ‰ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š</p><ol><li><strong>Experts</strong><ul><li>æ¯ä¸ª <strong>FFNN</strong> å±‚éƒ½ä¸å†æ˜¯ä¸€ä¸ªå•ç‹¬çš„ç½‘ç»œï¼Œè€Œæ˜¯æœ‰ä¸€ç»„â€œä¸“å®¶â€å¯ä¾›é€‰æ‹©ã€‚</li><li>è¿™äº›â€œä¸“å®¶â€é€šå¸¸ä¹Ÿæ˜¯ <strong>FFNN</strong>ï¼ˆFeedforward Neural Networkï¼‰ç»“æ„ã€‚</li></ul></li><li><strong>Router</strong> æˆ– <strong>gate network</strong><ul><li>è´Ÿè´£å†³å®šå“ªäº› <strong>tokens</strong> è¢«å‘é€åˆ°å“ªäº›ä¸“å®¶ã€‚</li></ul></li></ol><p>åœ¨ä¸€ä¸ªå¸¦æœ‰ MoE çš„ <strong>LLM</strong> çš„æ¯ä¸€å±‚ï¼Œæˆ‘ä»¬éƒ½èƒ½çœ‹åˆ°ï¼ˆåœ¨æŸç§ç¨‹åº¦ä¸Šï¼‰æœ‰æ‰€ä¸“é—¨åŒ–çš„ä¸“å®¶ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_150409.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†åœ¨ <strong>LLM</strong> çš„æ¯ä¸€å±‚éƒ½å¯ä»¥æ‹¥æœ‰å¤šä¸ª <strong>Experts</strong>ã€‚å®ƒå¼ºè°ƒäº†è¿™äº›ä¸“å®¶åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­èƒ½å¤Ÿå¤„ç†ä¸åŒçš„è¾“å…¥ tokenã€‚<br><strong>å›¾2è¯¦ç»†è¯´æ˜</strong>ï¼š  </p><ol><li><strong>å±‚ç»“æ„</strong>ï¼šå›¾ä¸­ç”¨ä¸åŒçš„å±‚çº§ï¼ˆLayer 1ã€Layer 2ã€Layer 3â€¦â€¦ï¼‰è¡¨ç¤ºå¤šå±‚æ¨¡å‹ã€‚  </li><li><strong>Experts</strong>ï¼šåœ¨æ¯ä¸€å±‚ï¼Œéƒ½æœ‰è‹¥å¹²ä¸ªä¸“å®¶ï¼ˆExpert 1ã€Expert 2ã€Expert 3ã€Expert 4ï¼‰ï¼Œè¿™äº›ä¸“å®¶å¹¶è¡Œå­˜åœ¨ã€‚  </li><li><strong>ç›®æ ‡</strong>ï¼šå¼ºè°ƒä¸“å®¶åœ¨ç‰¹å®šä¸Šä¸‹æ–‡æˆ–ç‰¹å®šè¾“å…¥æ—¶æ›´å…·å¤‡â€œä¸“ä¸šæ€§â€ï¼Œä»è€Œè¢«é€‰ä¸­æ¥å¤„ç†è¯¥è¾“å…¥ã€‚</li></ol><p>å°½ç®¡ MoE å¹¶ä¸ä¼šåœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚å¿ƒç†å­¦æˆ–ç”Ÿç‰©å­¦ï¼‰ä¸Šä¸“é—¨è®­ç»ƒä¸“å®¶ï¼Œä½†å®ƒä»¬ä»å¯èƒ½åœ¨è¯æ³•æˆ–å¥æ³•çº§åˆ«ä¸Šå½¢æˆä¸€å®šçš„åå‘ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_153715.png" class=""><ul><li><strong>MoE ä¸“å®¶å¯èƒ½å­¦ä¹ åˆ°ä¸åŒçš„è¯­è¨€ç‰¹å¾</strong><ul><li><strong>Expert 1</strong> å¤„ç†<strong>æ ‡ç‚¹ç¬¦å·</strong>ï¼ˆPunctuationï¼‰ï¼šå¦‚ <code>, . : &amp; - ?</code> ç­‰ã€‚</li><li><strong>Expert 2</strong> å¤„ç†<strong>åŠ¨è¯</strong>ï¼ˆVerbsï¼‰ï¼šå¦‚ <code>said, read, miss</code> ç­‰ã€‚</li><li><strong>Expert 3</strong> å¤„ç†<strong>è¿æ¥è¯</strong>ï¼ˆConjunctionsï¼‰ï¼šå¦‚ <code>the, and, if, not</code> ç­‰ã€‚</li><li><strong>Expert 4</strong> å¤„ç†<strong>è§†è§‰æè¿°è¯</strong>ï¼ˆVisual Descriptionsï¼‰ï¼šå¦‚ <code>dark, outer, yellow</code> ç­‰ã€‚</li></ul></li></ul><p>æ›´å…·ä½“åœ°è¯´ï¼Œä»–ä»¬çš„ä¸“é•¿æ˜¯åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­å¤„ç†ç‰¹å®šçš„æ ‡è®°ï¼ˆtokensï¼‰ã€‚</p><hr><p><strong>Router (gate network)</strong> é€‰æ‹©æœ€é€‚åˆç»™å®šè¾“å…¥çš„ä¸“å®¶æˆ–ä¸“å®¶ç»„åˆï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_153924.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº† <strong>Router</strong> å¦‚ä½•åœ¨æ¯ä¸€å±‚æ ¹æ®è¾“å…¥é€‰æ‹©åˆé€‚çš„ä¸“å®¶ã€‚å›¾ä¸­é«˜äº®äº†è¢«é€‰ä¸­çš„ä¸“å®¶ï¼Œä»¥åŠè¾“å…¥ token çš„æµåŠ¨è¿‡ç¨‹ã€‚<br><strong>å›¾3è¯¦ç»†è¯´æ˜</strong>ï¼š  </p><ol><li><strong>è¾“å…¥</strong>ï¼šå›¾é¡¶éƒ¨çš„ Input ä»£è¡¨æ¨¡å‹æ¥æ”¶åˆ°çš„ token æˆ–å‘é‡è¡¨ç¤ºã€‚  </li><li><strong>Router</strong>ï¼šä½äºç½‘ç»œç»“æ„ä¸­ï¼Œèµ·åˆ°å†³ç­–ä½œç”¨ã€‚  </li><li><strong>ä¸“å®¶é€‰æ‹©</strong>ï¼šè¢«é€‰ä¸­çš„ä¸“å®¶ä¼šæ¥æ”¶è¾“å…¥ï¼Œå…¶ä½™ä¸“å®¶åˆ™ä¸è¢«æ¿€æ´»ã€‚  </li><li><strong>è¾“å‡º</strong>ï¼šæ¥è‡ªè¢«æ¿€æ´»ä¸“å®¶çš„ç»“æœè¢«æ±‡æ€»æˆ–ç»§ç»­æµå‘ä¸‹æ¸¸å±‚ã€‚</li></ol><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ¯ä¸ªä¸“å®¶å¹¶ä¸æ˜¯æ•´ä¸ª LLMï¼Œè€Œæ˜¯ <strong>LLM</strong> æ¶æ„ä¸­çš„ä¸€ä¸ªå­æ¨¡å‹éƒ¨åˆ†ã€‚</p><hr><h2 id="Experts"><a href="#Experts" class="headerlink" title="Experts"></a>Experts</h2><p>ä¸ºäº†ç†è§£ä¸“å®¶ï¼ˆ<strong>Experts</strong>ï¼‰æ˜¯ä»€ä¹ˆä»¥åŠå®ƒä»¬å¦‚ä½•å·¥ä½œï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ MoE å¸Œæœ›æ›¿ä»£çš„ä¸œè¥¿ï¼š<strong>dense layers</strong>ã€‚</p><h3 id="Dense-Layers"><a href="#Dense-Layers" class="headerlink" title="Dense Layers"></a>Dense Layers</h3><p>æ‰€æœ‰çš„ <strong>Mixture of Experts (MoE)</strong> éƒ½åŸºäº LLM ä¸­ä¸€ä¸ªç›¸å¯¹åŸºç¡€çš„åŠŸèƒ½ï¼š**Feedforward Neural Network (FFNN)**ã€‚</p><p>å›å¿†ä¸€ä¸‹ï¼Œä¸€ä¸ªæ ‡å‡†çš„ <strong>decoder-only Transformer</strong> æ¶æ„ä¸­ï¼Œ<strong>FFNN</strong> é€šå¸¸æ˜¯åœ¨ <strong>layer normalization</strong> ä¹‹ååº”ç”¨çš„ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_154729.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªå…¸å‹çš„ <strong>decoder</strong> ç»“æ„ï¼Œæ¯ä¸ª <strong>decoder block</strong> åŒ…å« <strong>Masked Self-Attention</strong> å’Œ <strong>FFNN</strong>ï¼ˆä¸­é—´ä¼šæœ‰ <strong>Layer Norm</strong>ï¼‰ã€‚  </p><ol><li><strong>Position Embedding</strong>ï¼šåœ¨è¾“å…¥ token ä¹‹å‰æˆ–åŒæ—¶åŠ å…¥ä½ç½®ç¼–ç ä¿¡æ¯ã€‚  </li><li><strong>Decoder Block</strong>ï¼šåŒ…å« <strong>Masked Self-Attention</strong>ã€<strong>Layer Norm</strong> å’Œ <strong>FFNN</strong>ã€‚  </li><li><strong>FFNN</strong>ï¼šåœ¨å›¾ä¸­ç”¨ç´«è‰²æ–¹å—è¡¨ç¤ºï¼Œæ˜¯è¯¥å±‚å¯¹è¾“å…¥è¿›ä¸€æ­¥å˜æ¢ä»¥æ•æ‰æ›´å¤æ‚å…³ç³»çš„å…³é”®ç»„ä»¶ã€‚</li></ol><p><strong>FFNN</strong> å¯ä»¥åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶äº§ç”Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¹å…¶è¿›è¡Œè¿›ä¸€æ­¥çš„è½¬æ¢ï¼Œä»¥æ•æ‰æ•°æ®ä¸­æ›´å¤æ‚çš„å…³ç³»ã€‚</p><p>ä¸è¿‡ï¼Œä¸ºäº†å­¦ä¹ è¿™äº›å¤æ‚å…³ç³»ï¼Œ<strong>FFNN</strong> çš„è§„æ¨¡ä¼šéšä¹‹å¢é•¿ï¼Œé€šå¸¸ä¼šåœ¨è¾“å…¥ä¸Šè¿›è¡Œæ‰©å¼ ï¼ˆä¾‹å¦‚ï¼Œä¸­é—´å±‚ç»´åº¦ä¼šå˜å¤§ï¼‰ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_154923.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ª <strong>FFNN</strong> çš„ç»“æ„ï¼Œè¾“å…¥å…ˆè¢«æ˜ å°„åˆ°æ›´é«˜ç»´åº¦ï¼Œç„¶åå†è¢«æ˜ å°„å›è¾“å‡ºç»´åº¦ã€‚  </p><ol><li><strong>è¾“å…¥ç»´åº¦</strong>ï¼šå›¾ä¸­æ˜¾ç¤ºæœ‰ 512 ä¸ªè¾“å…¥å•å…ƒã€‚  </li><li><strong>éšè—å±‚</strong>ï¼šé€šå¸¸ä¼šæœ‰ 4 å€æˆ–æ›´å¤šçš„æ‰©å¼ ï¼ˆå›¾ä¸­ç¤ºä¾‹ä¸º 4 å€æ‰©å¼ åˆ° 2048 ç»´ï¼‰ã€‚  </li><li><strong>è¾“å‡ºç»´åº¦</strong>ï¼šå†æ˜ å°„å› 512 ç»´çš„è¾“å‡ºã€‚</li></ol><h3 id="Sparse-Layers"><a href="#Sparse-Layers" class="headerlink" title="Sparse Layers"></a>Sparse Layers</h3><p>åœ¨ä¼ ç»Ÿçš„ Transformer ä¸­ï¼Œ<strong>FFNN</strong> ç§°ä¸º <strong>dense model</strong>ï¼Œå› ä¸ºå®ƒçš„æ‰€æœ‰å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰éƒ½ä¼šè¢«æ¿€æ´»ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹çš„å…¨éƒ¨å‚æ•°éƒ½å‚ä¸è®¡ç®—è¾“å‡ºã€‚</p><p>å¦‚æœæˆ‘ä»¬ä»”ç»†è§‚å¯Ÿ <strong>dense model</strong>ï¼Œå¯ä»¥çœ‹åˆ°è¾“å…¥ä¼šæ¿€æ´»æ‰€æœ‰çš„å‚æ•°ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_163850.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªâ€œå¯†é›†â€æ¨¡å‹ï¼Œè¾“å…¥å±‚çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä¸éšè—å±‚æ‰€æœ‰ç¥ç»å…ƒç›¸è¿ï¼Œéšè—å±‚æ‰€æœ‰ç¥ç»å…ƒåˆä¸è¾“å‡ºå±‚ç¥ç»å…ƒç›¸è¿ã€‚<br><strong>å›¾6è¯¦ç»†è¯´æ˜</strong>ï¼š  </p><ol><li><strong>å…¨è¿æ¥</strong>ï¼šå›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹éƒ½è¿æ¥åˆ°ä¸‹ä¸€å±‚çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œè¡¨ç¤ºæ— ç¨€ç–æ€§ã€‚  </li><li><strong>æ‰€æœ‰å‚æ•°è¢«æ¿€æ´»</strong>ï¼šæ²¡æœ‰ä»»ä½•â€œé—²ç½®â€æˆ–â€œæœªæ¿€æ´»â€çš„å‚æ•°ã€‚</li></ol><p>ä¸ä¹‹å¯¹æ¯”ï¼Œ<strong>sparse models</strong>ï¼ˆç¨€ç–æ¨¡å‹ï¼‰åªæ¿€æ´»ä¸€éƒ¨åˆ†æ€»å‚æ•°ï¼Œè¿™ä¸ <strong>Mixture of Experts</strong> å¯†åˆ‡ç›¸å…³ã€‚</p><p>ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ <strong>dense model</strong> åˆ‡åˆ†æˆå¤šä¸ªéƒ¨åˆ†ï¼ˆå³ä¸“å®¶ï¼Œ<strong>experts</strong>ï¼‰ï¼Œé‡æ–°è®­ç»ƒå®ƒï¼Œå¹¶ä¸”åœ¨æ¨ç†ï¼ˆinferenceï¼‰æ—¶åªæ¿€æ´»å…¶ä¸­ä¸€éƒ¨åˆ†ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_164042.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå°†åŸæœ¬çš„å¯†é›†æ¨¡å‹åˆ†å‰²æˆå¤šä¸ªä¸“å®¶ï¼ˆExpert 1ã€Expert 2ã€Expert 3ã€Expert 4ï¼‰ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œåªé€‰æ‹©ä¸€éƒ¨åˆ†ä¸“å®¶è¿›è¡Œæ¿€æ´»ã€‚  </p><ol><li><strong>æ¨¡å‹åˆ‡åˆ†</strong>ï¼šåŸæœ‰çš„å¤§ç½‘ç»œè¢«æ‹†åˆ†æˆå¤šä¸ªè¾ƒå°çš„â€œä¸“å®¶â€ã€‚  </li><li><strong>ç¨€ç–æ¿€æ´»</strong>ï¼šå¹¶ä¸æ˜¯æ‰€æœ‰ä¸“å®¶éƒ½è¢«æ¿€æ´»ï¼Œåªæœ‰éƒ¨åˆ†ä¸“å®¶åœ¨æŸäº›è¾“å…¥ä¸‹è¢«æ¿€æ´»ã€‚  </li><li><strong>å¥½å¤„</strong>ï¼šé€šè¿‡ç¨€ç–æ¿€æ´»ï¼Œå¯ä»¥åœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œæ‹¥æœ‰æ›´å¤šçš„æ½œåœ¨å‚æ•°å®¹é‡ã€‚</li></ol><p>å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨è®­ç»ƒæœŸé—´ï¼Œæ¯ä¸ªä¸“å®¶å­¦ä¹ ä¸åŒçš„ä¿¡æ¯ï¼›åœ¨æ¨ç†æ—¶ï¼Œåªç”¨åˆ°ä¸å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„é‚£äº›ä¸“å®¶ã€‚</p><p>å½“æˆ‘ä»¬æå‡ºä¸€ä¸ªé—®é¢˜æ—¶ï¼Œå°±ä¼šé€‰æ‹©æœ€é€‚åˆè¯¥ä»»åŠ¡çš„ä¸“å®¶ï¼š</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_170127.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼šå½“è¾“å…¥æ˜¯ â€œWhat is 1 + 1?â€ è¿™æ ·çš„æ•°å­—ç›¸å…³é—®é¢˜æ—¶ï¼Œè·¯ç”±å™¨åªæ¿€æ´»ä¸æ•°å­—ç›¸å…³çš„ä¸“å®¶ã€‚  </p><ol><li><strong>è¾“å…¥</strong>ï¼šä¸€ä¸ªè¡¨ç¤ºç®—æœ¯é—®é¢˜çš„å¥å­æˆ– tokenã€‚  </li><li><strong>ä¸“å®¶é€‰æ‹©</strong>ï¼šåªæ¿€æ´» â€œNumbersâ€ é¢†åŸŸçš„ä¸“å®¶ã€‚  </li><li><strong>è¾“å‡º</strong>ï¼šä¸“å®¶ç»™å‡ºç»“æœ â€œ2â€ã€‚</li></ol><h3 id="What-does-an-Expert-Learn"><a href="#What-does-an-Expert-Learn" class="headerlink" title="What does an Expert Learn?"></a>What does an Expert Learn?</h3><p>æ­£å¦‚å‰é¢æ‰€æåˆ°çš„ï¼Œä¸“å®¶ï¼ˆ<strong>Experts</strong>ï¼‰å¾€å¾€å­¦ä¹ åˆ°æ¯”æ•´ä¸ªé¢†åŸŸæ›´ç»†è‡´çš„çŸ¥è¯†ã€‚æœ‰äººä¼šè§‰å¾—ç§°å®ƒä»¬ä¸ºâ€œä¸“å®¶â€å¯èƒ½ä¼šå¸¦æ¥è¯¯è§£ï¼Œä½†è¿™æ˜¯å› ä¸ºæ¯ä¸ªä¸“å®¶å¾€å¾€åªä¸“æ³¨äºæŸäº›ç‰¹å®šç±»å‹çš„è¾“å…¥ç‰¹å¾æˆ–ä¸Šä¸‹æ–‡ã€‚</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_170229.png" class=""><p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªè¡¨æ ¼æˆ–å¯¹ç…§ï¼Œè¯´æ˜åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¸åŒçš„ä¸“å®¶å¯èƒ½å­¦ä¹ åˆ°ä¸åŒçš„ç‰¹å¾ï¼ˆæ¯”å¦‚æ ‡ç‚¹ç¬¦å·ã€åŠ¨è¯ã€æ•°å­—ç­‰ï¼‰ã€‚  </p><ol><li><strong>ç¤ºä¾‹åŒ–ä¸“å®¶</strong>ï¼šPunctuationã€Conjunctionsã€Verbsã€Numbers ç­‰ã€‚  </li><li><strong>åˆ†å±‚ä½ç½®</strong>ï¼šä¸åŒä¸“å®¶å¯èƒ½å‡ºç°åœ¨æ¨¡å‹çš„ä¸åŒå±‚ã€‚  </li><li><strong>åˆ†é…</strong>ï¼šæŸäº› token ä¼šè·¯ç”±åˆ°æŸäº›ä¸“å®¶ï¼Œä»¥è·å¾—æ›´æœ‰æ•ˆçš„å¤„ç†ã€‚</li></ol><p>åœ¨ <strong>decoder</strong> æ¨¡å‹ä¸­ï¼Œä¸“å®¶ä¹‹é—´å¯èƒ½æ²¡æœ‰é‚£ä¹ˆæ˜æ˜¾çš„é¢†åŸŸåˆ†å·¥ã€‚ç„¶è€Œï¼Œè¿™å¹¶ä¸æ„å‘³ç€æ‰€æœ‰ä¸“å®¶éƒ½å®Œå…¨ç›¸åŒã€‚<br>åœ¨ <strong>Mixtral 8x7B</strong> è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæœ‰ä¸€ä¸ªå¾ˆå¥½çš„ç¤ºä¾‹ï¼šæ¯ä¸ª token ä¼šè¢«æ ‡è®°ä¸ºå…¶é¦–é€‰ä¸“å®¶ï¼Œè¿™äº›ä¸“å®¶å¹¶ä¸ä¸€å®šå¯¹åº”ç›´è§‚çš„è¯­ä¹‰é¢†åŸŸï¼Œä½†åœ¨ç»Ÿè®¡ä¸Šè¡¨ç°å‡ºæŸäº›å€¾å‘ã€‚</p><img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_182219.png" class=""><p>è¿™å¼ å¯è§†åŒ–ç¤ºä¾‹è¿˜å±•ç¤ºäº†ï¼Œexpertsï¼ˆä¸“å®¶ï¼‰æ›´å€¾å‘äºå…³æ³¨å¥æ³•ï¼ˆsyntaxï¼‰ï¼Œè€Œä¸æ˜¯ç‰¹å®šçš„é¢†åŸŸï¼ˆdomainï¼‰ã€‚å› æ­¤ï¼Œè™½ç„¶ decoder expertsï¼ˆè§£ç å™¨ä¸“å®¶ï¼‰ä¼¼ä¹å¹¶æ²¡æœ‰æ˜ç¡®çš„â€œä¸“ä¸šé¢†åŸŸï¼ˆspecialismï¼‰â€ï¼Œä½†å®ƒä»¬ä¼¼ä¹ä¼šåœ¨æŸäº›ç‰¹å®šç±»å‹çš„ tokensï¼ˆæ ‡è®°ï¼‰ä¸Šè¢«æŒç»­åœ°ä½¿ç”¨ã€‚</p><p>åœ¨[å›¾1]ä¸­ï¼Œå±•ç¤ºäº†ä¸€æ®µå…³äº MoELayer çš„ç¤ºä¾‹ä»£ç æˆ–å¯è§†åŒ–ç»“æœï¼Œè‰²å—åŒºåˆ†äº†ä¸åŒéƒ¨åˆ†ï¼Œå¼ºè°ƒäº†<strong>ä¸“å®¶ï¼ˆexpertsï¼‰ä¸è·¯ç”±å™¨ï¼ˆrouterï¼‰</strong>ä¹‹é—´çš„å…³ç³»ã€‚é€šè¿‡è‰²å—å¯ä»¥çœ‹å‡ºï¼š</p><ul><li>experts åˆ—è¡¨ï¼ˆåœ¨ä»£ç ä¸­ç”¨ nn.ModuleList è¡¨ç¤ºï¼‰åŒ…å«äº†å¤šä¸ªå­ç½‘ç»œï¼ˆå³å¤šä¸ª FFNNï¼ŒFeed-Forward Neural Networkï¼Œå‰é¦ˆç¥ç»ç½‘ç»œï¼‰ã€‚</li><li>gateï¼ˆé—¨æ§ç½‘ç»œï¼Œä¹Ÿç§° routerï¼‰è´Ÿè´£é€‰æ‹©å“ªäº›ä¸“å®¶ä¼šè¢«æ¿€æ´»ã€‚</li><li>æ•´ä½“ä¸Šå¯ä»¥çœ‹åˆ°ï¼Œè¿™äº›ä¸“å®¶é€šå¸¸å…³æ³¨åˆ°è¾“å…¥å¥å­çš„å¥æ³•å±‚é¢ï¼Œè€Œéç‰¹å®šä¸»é¢˜æˆ–é¢†åŸŸã€‚</li></ul><h3 id="ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture-of-Expertsï¼‰"><a href="#ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture-of-Expertsï¼‰" class="headerlink" title="ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰"></a>ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MoE-æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜-MoE-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²&quot;&gt;&lt;a href=&quot;#MoE-æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜-MoE-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²&quot; class=&quot;headerlink&quot; title=&quot;MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="LLM" scheme="https://chenhuiyu.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1</title>
    <link href="https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/"/>
    <id>https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/</id>
    <published>2025-02-11T03:50:29.000Z</published>
    <updated>2026-02-20T21:56:22.875Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ¨ç†-LLM-çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸-DeepSeek-R1"><a href="#æ¨ç†-LLM-çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸-DeepSeek-R1" class="headerlink" title="æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1"></a>æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸ DeepSeek-R1</h1><p><strong>åŸæ–‡åœ°å€</strong>ï¼š<a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms">A Visual Guide to Reasoning LLMs</a></p><p>ğŸ“… ä½œè€…ï¼šMaarten Grootendorst</p><p>ğŸ“† æ—¥æœŸï¼š2025 å¹´ 2 æœˆ 3 æ—¥</p><hr><h2 id="ğŸ“Œ-å¼•è¨€"><a href="#ğŸ“Œ-å¼•è¨€" class="headerlink" title="ğŸ“Œ å¼•è¨€"></a>ğŸ“Œ å¼•è¨€</h2><p>DeepSeek-R1ã€OpenAI o3-mini å’Œ Google Gemini 2.0 Flash Thinking æ˜¯å¦‚ä½•é€šè¿‡â€œæ¨ç†â€æ¡†æ¶å°† <strong>LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹, Large Language Modelsï¼‰</strong> æ‰©å±•åˆ°æ–°é«˜åº¦çš„å…¸å‹ç¤ºä¾‹ã€‚</p><p>å®ƒä»¬æ ‡å¿—ç€ä» <strong>æ‰©å±•è®­ç»ƒæ—¶è®¡ç®—ï¼ˆtrain-time computeï¼‰</strong> åˆ° <strong>æ‰©å±•æ¨ç†æ—¶è®¡ç®—ï¼ˆtest-time computeï¼‰</strong> çš„èŒƒå¼è½¬å˜ã€‚</p><p>åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æä¾›äº† <strong>è¶…è¿‡ 40 å¼ å®šåˆ¶å¯è§†åŒ–å›¾è¡¨</strong>ï¼Œå¸¦ä½ æ·±å…¥æ¢ç´¢ï¼š</p><ul><li><strong>æ¨ç† LLMï¼ˆReasoning LLMsï¼‰</strong> é¢†åŸŸ</li><li><strong>æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-Time Computeï¼‰</strong> æœºåˆ¶</li><li><strong>DeepSeek-R1</strong> çš„æ ¸å¿ƒæ€æƒ³</li></ul><p>æˆ‘ä»¬å°†é€æ­¥ä»‹ç»ç›¸å…³æ¦‚å¿µï¼Œå¸®åŠ©ä½ å»ºç«‹å¯¹è¿™ä¸€æ–°èŒƒå¼çš„ç›´è§‰ç†è§£ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/i24pmg2.png" class=""><hr><h2 id="ğŸ“–-ä»€ä¹ˆæ˜¯æ¨ç†-LLMï¼Ÿ"><a href="#ğŸ“–-ä»€ä¹ˆæ˜¯æ¨ç†-LLMï¼Ÿ" class="headerlink" title="ğŸ“– ä»€ä¹ˆæ˜¯æ¨ç† LLMï¼Ÿ"></a>ğŸ“– ä»€ä¹ˆæ˜¯æ¨ç† LLMï¼Ÿ</h2><p>ä¸æ™®é€š <strong>LLMï¼ˆLarge Language Modelsï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰</strong> ç›¸æ¯”ï¼Œ<strong>æ¨ç† LLM</strong> åœ¨å›ç­”é—®é¢˜ä¹‹å‰ï¼Œå¾€å¾€ä¼šå°†é—®é¢˜ <strong>åˆ†è§£ä¸ºæ›´å°çš„æ­¥éª¤</strong>ï¼ˆé€šå¸¸ç§°ä¸º <strong>æ¨ç†æ­¥éª¤ï¼ˆReasoning Stepsï¼‰</strong> æˆ– <strong>æ€è€ƒè¿‡ç¨‹ï¼ˆThought Processï¼‰</strong>ï¼‰ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_143007.png" class=""><h3 id="ğŸ§ -â€œæ¨ç†æ­¥éª¤â€-æˆ–-â€œæ€è€ƒè¿‡ç¨‹â€-æ˜¯ä»€ä¹ˆï¼Ÿ"><a href="#ğŸ§ -â€œæ¨ç†æ­¥éª¤â€-æˆ–-â€œæ€è€ƒè¿‡ç¨‹â€-æ˜¯ä»€ä¹ˆï¼Ÿ" class="headerlink" title="ğŸ§  â€œæ¨ç†æ­¥éª¤â€ æˆ– â€œæ€è€ƒè¿‡ç¨‹â€ æ˜¯ä»€ä¹ˆï¼Ÿ"></a>ğŸ§  â€œæ¨ç†æ­¥éª¤â€ æˆ– â€œæ€è€ƒè¿‡ç¨‹â€ æ˜¯ä»€ä¹ˆï¼Ÿ</h3><p>å°½ç®¡æˆ‘ä»¬å¯ä»¥å“²å­¦åŒ–åœ°æ¢è®¨ LLM æ˜¯å¦çœŸçš„èƒ½å¤Ÿåƒäººç±»ä¸€æ ·æ€è€ƒï¼Œä½†è¿™äº›æ¨ç†æ­¥éª¤å®é™…ä¸Šæ˜¯å°†æ¨ç†è¿‡ç¨‹ åˆ†è§£ä¸ºæ›´å°ã€æ›´ç»“æ„åŒ–çš„æ¨æ–­ã€‚<strong>æ¨ç† LLM é‡‡ç”¨çš„æ˜¯ç»“æ„åŒ–æ¨ç†æ–¹å¼</strong>ï¼Œå³ï¼š</p><ul><li><strong>æ™®é€š LLM</strong>ï¼šç›´æ¥è¾“å‡ºç­”æ¡ˆ</li><li><strong>æ¨ç† LLM</strong>ï¼šé€šè¿‡ç³»ç»Ÿæ€§æ¨ç†ç”Ÿæˆç­”æ¡ˆ</li></ul><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_143054.png" class=""><p>æ¢å¥è¯è¯´ï¼Œæ¨ç† LLM ä¸æ˜¯<strong>å­¦ä¹ â€œå›ç­”ä»€ä¹ˆâ€</strong>ï¼Œè€Œæ˜¯<strong>å­¦ä¹ â€œå¦‚ä½•å›ç­”â€</strong>ï¼</p><p>è¦ç†è§£æ¨ç† LLM çš„æ„å»ºåŸç†ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ¢è®¨ <strong>è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-Time Computeï¼‰</strong> å’Œ <strong>æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-Time Computeï¼‰</strong> ä¹‹é—´çš„å·®å¼‚ã€‚</p><hr><h2 id="ğŸ”-ä»€ä¹ˆæ˜¯è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-time-Computeï¼‰ï¼Ÿ"><a href="#ğŸ”-ä»€ä¹ˆæ˜¯è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-time-Computeï¼‰ï¼Ÿ" class="headerlink" title="ğŸ” ä»€ä¹ˆæ˜¯è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-time Computeï¼‰ï¼Ÿ"></a>ğŸ” ä»€ä¹ˆæ˜¯è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-time Computeï¼‰ï¼Ÿ</h2><p>ç›´åˆ° 2024 å¹´å¹´ä¸­ï¼Œä¸ºäº†åœ¨ <strong>é¢„è®­ç»ƒï¼ˆPretrainingï¼‰</strong> æœŸé—´æé«˜ LLM çš„æ€§èƒ½ï¼Œç ”ç©¶äººå‘˜é€šå¸¸ä¼šæ‰©å¤§ä»¥ä¸‹è§„æ¨¡ï¼š</p><ul><li><strong>æ¨¡å‹å‚æ•°æ•°é‡ï¼ˆ# of Parametersï¼‰</strong></li><li><strong>æ•°æ®é›†è§„æ¨¡ï¼ˆ# of Tokensï¼‰</strong></li><li><strong>è®¡ç®—é‡ï¼ˆ# of FLOPs, Floating Point Operationsï¼‰</strong></li></ul><p>è¿™äº›åˆç§°ä¸º <strong>è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-time Computeï¼‰</strong>ï¼Œå³ <strong>â€œAI çš„åŒ–çŸ³ç‡ƒæ–™â€</strong>ï¼ŒæŒ‡çš„æ˜¯ï¼š</p><blockquote><p><strong>é¢„è®­ç»ƒé¢„ç®—è¶Šå¤§ï¼Œæœ€ç»ˆå¾—åˆ°çš„æ¨¡å‹å°±è¶Šå¥½ã€‚</strong></p><p>è®­ç»ƒæ—¶è®¡ç®—ï¼ˆTrain-Time Computeï¼‰åŒ…æ‹¬<strong>è®­ç»ƒï¼ˆtrainingï¼‰</strong>æ‰€éœ€çš„è®¡ç®—ï¼Œä»¥åŠ<strong>å¾®è°ƒï¼ˆfine-tuningï¼‰</strong>æ‰€éœ€çš„è®¡ç®—ã€‚é•¿æœŸä»¥æ¥ï¼Œä¸€ç›´æ˜¯æé«˜ LLM æ€§èƒ½çš„ä¸»è¦å…³æ³¨ç‚¹ã€‚</p></blockquote><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_143927.png" class=""><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_144121.png" class=""><h3 id="ğŸ”¢-è§„æ¨¡å®šå¾‹ï¼ˆScaling-Lawsï¼‰"><a href="#ğŸ”¢-è§„æ¨¡å®šå¾‹ï¼ˆScaling-Lawsï¼‰" class="headerlink" title="ğŸ”¢ è§„æ¨¡å®šå¾‹ï¼ˆScaling Lawsï¼‰"></a>ğŸ”¢ è§„æ¨¡å®šå¾‹ï¼ˆScaling Lawsï¼‰</h3><p>åœ¨ <strong>LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰</strong> ç ”ç©¶é¢†åŸŸï¼Œ<strong>æ¨¡å‹è§„æ¨¡ï¼ˆScaleï¼‰</strong> ä¸ <strong>æ¨¡å‹æ€§èƒ½ï¼ˆPerformanceï¼‰</strong> ä¹‹é—´çš„å…³ç³»è¢«ç§°ä¸º <strong>è§„æ¨¡å®šå¾‹ï¼ˆScaling Lawsï¼‰</strong>ã€‚è¿™äº›å®šå¾‹é€šå¸¸ç”¨äºæè¿° <strong>è®¡ç®—èµ„æºã€æ•°æ®è§„æ¨¡å’Œæ¨¡å‹å‚æ•°</strong> å¦‚ä½•å½±å“æ¨¡å‹çš„æ•´ä½“è¡¨ç°ã€‚</p><p>è¿™äº›å…³ç³»é€šå¸¸ä»¥ <strong>å¯¹æ•°-å¯¹æ•°ï¼ˆlog-logï¼‰</strong> æ–¹å¼å‘ˆç°ï¼Œå¹¶ä¸”åœ¨å›¾è¡¨ä¸Šé€šå¸¸æ˜¾ç¤ºä¸ºä¸€æ¡ <strong>è¿‘ä¼¼ç›´çº¿</strong>ï¼Œä»¥çªå‡ºè®¡ç®—é‡çš„å·¨å¤§å¢é•¿ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_144846.png" class=""><p>è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†<strong>ä¸åŒåæ ‡å°ºåº¦ï¼ˆçº¿æ€§ vs. å¯¹æ•°ï¼‰å¯¹è®¡ç®—èµ„æºï¼ˆComputeï¼‰å’Œæ¨¡å‹æ€§èƒ½ï¼ˆPerformanceï¼‰ä¹‹é—´å…³ç³»çš„å½±å“</strong>ï¼Œå¼ºè°ƒäº†å¤§æ¨¡å‹å¢é•¿çš„å¹‚å¾‹å…³ç³»ï¼ˆPower Lawï¼‰ã€‚</p><ul><li><p><strong>å·¦å›¾ï¼ˆæ™®é€šçº¿æ€§å°ºåº¦ - Normal Scaleï¼‰</strong></p><ul><li>æ¨ªè½´ï¼ˆX è½´ï¼‰ï¼šè®¡ç®—èµ„æºï¼ˆComputeï¼‰ï¼Œ<strong>çº¿æ€§åˆ»åº¦</strong>ã€‚</li><li>çºµè½´ï¼ˆY è½´ï¼‰ï¼šæ€§èƒ½ï¼ˆPerformanceï¼‰ï¼Œ<strong>çº¿æ€§åˆ»åº¦</strong>ã€‚</li><li>æ›²çº¿æ˜¾ç¤º<strong>é€’å‡æ”¶ç›Šï¼ˆDiminishing Returnsï¼‰</strong>ï¼Œå³ï¼š<strong>éšç€è®¡ç®—èµ„æºçš„å¢åŠ ï¼Œæ€§èƒ½å¢é•¿è¶‹ç¼“</strong>ï¼Œä½†ä»ç„¶åœ¨ä¸Šå‡ã€‚</li></ul></li><li><p><strong>å³å›¾ï¼ˆå¯¹æ•°-å¯¹æ•°å°ºåº¦ - Log-log Scaleï¼‰</strong></p><ul><li>æ¨ªè½´ï¼ˆX è½´ï¼‰ï¼šè®¡ç®—èµ„æºï¼ˆComputeï¼‰ï¼Œ<strong>å¯¹æ•°åˆ»åº¦</strong>ã€‚</li><li>çºµè½´ï¼ˆY è½´ï¼‰ï¼šæ€§èƒ½ï¼ˆPerformanceï¼‰ï¼Œ<strong>å¯¹æ•°åˆ»åº¦</strong>ã€‚</li><li>åœ¨å¯¹æ•°-å¯¹æ•°å°ºåº¦ä¸‹ï¼ŒåŸæœ¬å¼¯æ›²çš„æ›²çº¿å˜æˆ<strong>ä¸€æ¡ç›´çº¿</strong>ï¼Œè¯´æ˜è®¡ç®—èµ„æºå’Œæ€§èƒ½ä¹‹é—´å‘ˆ<strong>å¹‚å¾‹å…³ç³»ï¼ˆPower Law Relationshipï¼‰</strong>ã€‚</li></ul></li></ul><p>è¿™äº›å®šå¾‹é€šå¸¸éµå¾ª <strong>å¹‚å¾‹ï¼ˆPower Lawsï¼‰</strong>ï¼Œå³ï¼š</p><blockquote><p><strong>æŸä¸ªå˜é‡ï¼ˆå¦‚è®¡ç®—é‡ï¼‰å¢åŠ ï¼Œä¼šå¯¼è‡´å¦ä¸€ä¸ªå˜é‡ï¼ˆå¦‚æ€§èƒ½ï¼‰æŒ‰ä¸€å®šæ¯”ä¾‹å˜åŒ–ã€‚</strong></p></blockquote><p>æœ€è‘—åçš„ <strong>è§„æ¨¡å®šå¾‹</strong> åŒ…æ‹¬ï¼š</p><ul><li><strong>Kaplan è§„æ¨¡å®šå¾‹</strong>ï¼ˆKaplan Scaling Lawï¼‰ï¼šå½“è®¡ç®—èµ„æºä¸€å®šæ—¶ï¼Œ<strong>å¢åŠ æ¨¡å‹çš„å‚æ•°è§„æ¨¡æ¯”å¢åŠ æ•°æ®è§„æ¨¡æ›´æœ‰æ•ˆ</strong>ã€‚è¡¨æ˜æ¨¡å‹æ€§èƒ½ä¸å‚æ•°é‡ã€è®¡ç®—é‡å’Œè®­ç»ƒæ•°æ®ï¼ˆTokensï¼‰ä¹‹é—´å­˜åœ¨å¹‚å¾‹å…³ç³»ï¼Œå³ æ›´å¤šå‚æ•°ã€æ›´å¤šè®¡ç®—èµ„æºèƒ½æå‡æ€§èƒ½ï¼ˆGPT-3 è®ºæ–‡æå‡ºï¼‰ã€‚</li><li><strong>Chinchilla è§„æ¨¡å®šå¾‹</strong>ï¼ˆChinchilla Scaling Lawï¼‰ï¼šæ¨¡å‹çš„å¤§å°å’Œæ•°æ®è§„æ¨¡åŒæ ·é‡è¦ï¼ŒäºŒè€…éœ€ <strong>åŒæ­¥æ‰©å±•</strong> æ‰èƒ½å®ç°æœ€ä½³æ€§èƒ½ï¼ˆDeepMind æå‡ºï¼‰ã€‚</li></ul><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_145639.png" class=""><p>è¿™å¼ å›¾å±•ç¤ºäº†<strong>å¤§è§„æ¨¡ AI è®­ç»ƒä¸­çš„ Scaling Lawsï¼ˆç¼©æ”¾å®šå¾‹ï¼‰</strong>ï¼Œè¡¨æ˜<strong>è®¡ç®—èµ„æºï¼ˆComputeï¼‰ã€æ•°æ®é›†è§„æ¨¡ï¼ˆDataset Sizeï¼‰å’Œå‚æ•°é‡ï¼ˆParametersï¼‰</strong>å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚å…³é”®ä¿¡æ¯å¦‚ä¸‹ï¼š</p><hr><p><strong>1. çºµè½´ï¼ˆYè½´ï¼‰ï¼šæµ‹è¯•æŸå¤±ï¼ˆTest Lossï¼‰</strong></p><ul><li><strong>ç›®æ ‡æ˜¯é™ä½æµ‹è¯•æŸå¤±ï¼ˆTest Lossï¼‰</strong>ï¼Œå³æé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚</li><li><strong>æŸå¤±ï¼ˆLï¼‰è¶Šå°ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½</strong>ã€‚</li></ul><p><strong>2. æ¨ªè½´ï¼ˆXè½´ï¼‰ï¼šä¸‰ç§å…³é”®å˜é‡</strong></p><ul><li><p><strong>å·¦å›¾ï¼ˆComputeï¼Œè®¡ç®—èµ„æºï¼‰</strong>ï¼š</p><ul><li>X è½´æ˜¯è®¡ç®—èµ„æºï¼ˆPF-days, é embeddingï¼‰ã€‚</li><li>è®¡ç®—èµ„æºè¶Šå¤šï¼Œæµ‹è¯•æŸå¤±é™ä½ï¼ˆæ€§èƒ½æå‡ï¼‰ã€‚</li><li>å…¬å¼ï¼š<br>$$<br>L = \left( \frac{C_{\text{min}}}{2.3 \times 10^8} \right)^{-0.050}<br>$$</li><li><strong>ä½“ç°è®¡ç®—èµ„æºçš„å¹‚å¾‹å…³ç³»</strong>ï¼šè®¡ç®—èµ„æºå¢åŠ ï¼ŒæŸå¤±å‡å°‘ï¼Œä½†æ”¶ç›Šé€’å‡ï¼ˆæŒ‡æ•° -0.050ï¼‰ã€‚</li></ul></li><li><p><strong>ä¸­å›¾ï¼ˆDataset Sizeï¼Œæ•°æ®é›†è§„æ¨¡ï¼‰</strong>ï¼š</p><ul><li>X è½´æ˜¯è®­ç»ƒæ•°æ®çš„ Token æ•°é‡ã€‚</li><li>æ•°æ®è§„æ¨¡è¶Šå¤§ï¼Œæµ‹è¯•æŸå¤±é™ä½ï¼ˆæ€§èƒ½æå‡ï¼‰ã€‚</li><li>å…¬å¼ï¼š<br>$$<br>L = \left( \frac{D}{5.4 \times 10^{13}} \right)^{-0.095}<br>$$</li><li><strong>æ•°æ®è§„æ¨¡å¯¹æŸå¤±çš„å½±å“è¾ƒå¤§</strong>ï¼ˆæŒ‡æ•° -0.095ï¼‰ã€‚</li></ul></li><li><p><strong>å³å›¾ï¼ˆParametersï¼Œå‚æ•°é‡ï¼‰</strong>ï¼š</p><ul><li>X è½´æ˜¯æ¨¡å‹å‚æ•°é‡ï¼ˆé embeddingï¼‰ã€‚</li><li>å‚æ•°æ•°é‡è¶Šå¤§ï¼Œæµ‹è¯•æŸå¤±é™ä½ï¼ˆæ€§èƒ½æå‡ï¼‰ã€‚</li><li>å…¬å¼ï¼š<br>$$<br>L = \left( \frac{N}{8.8 \times 10^{13}} \right)^{-0.076}<br>$$</li><li><strong>å‚æ•°å¯¹æŸå¤±çš„å½±å“ä»‹äºè®¡ç®—èµ„æºå’Œæ•°æ®è§„æ¨¡ä¹‹é—´</strong>ï¼ˆæŒ‡æ•° -0.076ï¼‰ã€‚</li></ul></li></ul><p>è¿™äº›ç ”ç©¶è¡¨æ˜ï¼Œ<strong>æ¨¡å‹è§„æ¨¡ã€æ•°æ®è§„æ¨¡å’Œè®¡ç®—èµ„æºå¿…é¡»ååŒæ‰©å±•ï¼Œæ‰èƒ½æœ€å¤§åŒ–æ¨¡å‹çš„æ€§èƒ½</strong>ã€‚</p><ul><li><strong>è®¡ç®—èµ„æºå¢åŠ  â†’ è®­ç»ƒæ›´å¼ºå¤§æ¨¡å‹</strong></li><li><strong>æ›´å¤š Tokens â†’ æ›´å¥½æ³›åŒ–èƒ½åŠ›</strong></li><li><strong>å‚æ•°å¢åŠ  â†’ ä½†éœ€è¦ä¸æ•°æ®åŒ¹é…ï¼Œå¦åˆ™è¿‡æ‹Ÿåˆ</strong></li></ul><p>Kaplan è§„æ¨¡å®šå¾‹è®¤ä¸ºï¼Œåœ¨ <strong>å›ºå®šè®¡ç®—èµ„æº</strong> çš„æƒ…å†µä¸‹ï¼Œ<strong>ä¼˜å…ˆå¢åŠ æ¨¡å‹å‚æ•°</strong> é€šå¸¸æ¯”å¢åŠ æ•°æ®è§„æ¨¡æ›´æœ‰æ•ˆã€‚è€Œ Chinchilla è§„æ¨¡å®šå¾‹åˆ™æŒ‡å‡ºï¼Œ<strong>æ¨¡å‹å‚æ•°å’Œæ•°æ®è§„æ¨¡éƒ½åº”åŒæ­¥å¢é•¿</strong>ï¼Œä»¥è·å¾—æ›´ä¼˜çš„æ¨¡å‹æ€§èƒ½ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_145814.png" class=""><p>ç„¶è€Œï¼Œåœ¨ <strong>2024 å¹´</strong>ï¼Œç ”ç©¶äººå‘˜å‘ç°ï¼Œå°½ç®¡è®¡ç®—èµ„æºã€æ•°æ®è§„æ¨¡å’Œæ¨¡å‹å‚æ•° <strong>æŒç»­å¢é•¿</strong>ï¼Œä½†æ€§èƒ½æå‡çš„ <strong>è¾¹é™…æ”¶ç›Šï¼ˆMarginal Returnï¼‰</strong> å´åœ¨ <strong>é€æ¸é™ä½</strong>ã€‚</p><p>è¿™å¼•å‘äº†ä¸€ä¸ªé‡è¦çš„é—®é¢˜ï¼š</p><p>â“ <strong>â€œæˆ‘ä»¬æ˜¯å¦å·²ç»é‡åˆ°äº† LLM å‘å±•çš„ç“¶é¢ˆï¼Ÿâ€</strong></p><hr><h2 id="ğŸš€-ä»€ä¹ˆæ˜¯æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-time-Computeï¼‰ï¼Ÿ"><a href="#ğŸš€-ä»€ä¹ˆæ˜¯æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-time-Computeï¼‰ï¼Ÿ" class="headerlink" title="ğŸš€ ä»€ä¹ˆæ˜¯æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-time Computeï¼‰ï¼Ÿ"></a>ğŸš€ ä»€ä¹ˆæ˜¯æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-time Computeï¼‰ï¼Ÿ</h2><p>ç”±äº <strong>è®­ç»ƒæ—¶è®¡ç®—çš„æˆæœ¬æå…¶æ˜‚è´µ</strong>ï¼Œç ”ç©¶äººå‘˜å¼€å§‹å…³æ³¨ <strong>æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-time Computeï¼‰</strong>ï¼Œå³ï¼š</p><blockquote><p><strong>è®© LLM åœ¨æ¨ç†æ—¶â€œæ€è€ƒæ›´é•¿æ—¶é—´â€</strong>ï¼Œè€Œéå•çº¯ä¾èµ–æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚</p></blockquote><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_145856.png" class=""><p>å¯¹äº<strong>éæ¨ç†æ¨¡å‹</strong>ï¼Œå®ƒä»¬é€šå¸¸ <strong>ç›´æ¥è¾“å‡ºç­”æ¡ˆ</strong>ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q: 8 + 5 = ?</span><br><span class="line">A: 13</span><br></pre></td></tr></tbody></table></figure><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_145936.png" class=""><p>è€Œ<strong>æ¨ç†æ¨¡å‹</strong>åˆ™ä¼š <strong>ä½¿ç”¨æ›´å¤š token è¿›è¡Œæ¨ç†</strong>ï¼Œå½¢æˆç³»ç»ŸåŒ–çš„â€œæ€è€ƒâ€è¿‡ç¨‹ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q: 8 + 5 = ?</span><br><span class="line">A: 8 + 5 å¯æ‹†è§£ä¸º 8 + 2 + 3 = 10 + 3 = 13</span><br></pre></td></tr></tbody></table></figure><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_150033.png" class=""><p>LLM éœ€è¦æ¶ˆè€—è®¡ç®—èµ„æºï¼ˆå¦‚æ˜¾å­˜è®¡ç®—ï¼‰æ¥ç”Ÿæˆç­”æ¡ˆã€‚ç„¶è€Œï¼Œå¦‚æœæ‰€æœ‰è®¡ç®—èµ„æºéƒ½ç”¨äºç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œé‚£å°†ä¼šæ˜¯ä½æ•ˆçš„ï¼</p><p>ç›¸åï¼Œé€šè¿‡æå‰ç”ŸæˆåŒ…å«é¢å¤–ä¿¡æ¯ã€å…³ç³»å’Œæ–°æ€è€ƒçš„æ›´å¤š tokenï¼Œæ¨¡å‹å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­åˆ†é…æ›´å¤šè®¡ç®—èµ„æºä»¥ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_151252.png" class=""><p>è¿™å¼ å›¾ç‰‡å±•ç¤ºäº† <strong>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰</strong> åœ¨è®¡ç®—è¿‡ç¨‹ä¸­å¦‚ä½•åˆ†é… <strong>token</strong>ï¼ˆæ ‡è®°ï¼‰æ¥ä¼˜åŒ–æ¨ç†èƒ½åŠ›å’Œæœ€ç»ˆçš„å›ç­”è´¨é‡ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š<strong>å¦‚æœè®¡ç®—èµ„æºï¼ˆå¦‚ GPU/VRAM è®¡ç®—é‡ï¼‰å…¨éƒ¨ç”¨äºç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œè€Œæ²¡æœ‰ç”¨äºæ€è€ƒï¼Œé‚£ä¹ˆæ•ˆç‡ä¼šå—åˆ°å½±å“</strong>ã€‚ç›¸åï¼Œå¢åŠ  <strong>æ€è€ƒè¿‡ç¨‹</strong>ï¼ˆå³ç”Ÿæˆæ›´å¤šçš„ä¸­é—´ tokenï¼‰ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„ <strong>æ¨ç†èƒ½åŠ›</strong>ï¼Œä»è€Œæå‡ <strong>æœ€ç»ˆçš„å›ç­”è´¨é‡</strong>ã€‚</p><p><strong>1. Token çš„ä½¿ç”¨ä¸è®¡ç®—é‡</strong></p><ul><li><strong>LLM ç”Ÿæˆç­”æ¡ˆæ˜¯æŒ‰ token é€æ­¥è¾“å‡ºçš„</strong>ï¼Œæ¯ä¸ª token éƒ½ä¼šå ç”¨è®¡ç®—èµ„æºã€‚</li><li><strong>åˆ†é…æ›´å¤šçš„ token è¿›è¡Œæ€è€ƒ</strong>ï¼Œæ„å‘³ç€æ¨¡å‹å¯ä»¥åœ¨å¾—å‡ºæœ€ç»ˆç­”æ¡ˆä¹‹å‰æœ‰æ›´å¤šçš„æ¨ç†æ­¥éª¤ï¼Œä»è€Œæé«˜æ­£ç¡®ç‡ã€‚</li></ul><p> <strong>2. ä¸‰ç§ä¸åŒçš„è®¡ç®—æ–¹å¼</strong></p><ul><li><p><strong>åœºæ™¯ 1ï¼ˆ1 ä¸ª tokenï¼šæœ€å°‘è®¡ç®—ï¼‰</strong></p><ul><li>ç›´æ¥è¾“å‡º <strong>â€œ5â€</strong> ä½œä¸ºç­”æ¡ˆã€‚</li><li><strong>è®¡ç®—é‡æœ€å°‘</strong>ï¼Œé€Ÿåº¦æœ€å¿«ã€‚</li><li><strong>å¦‚æœé—®é¢˜è¾ƒå¤æ‚ï¼Œå¯èƒ½ä¼šå‡ºé”™</strong>ï¼Œå› ä¸ºæ¨¡å‹æ²¡æœ‰è¶³å¤Ÿçš„è®¡ç®—æ—¶é—´æ¥æ€è€ƒã€‚</li></ul></li><li><p><strong>åœºæ™¯ 2ï¼ˆ6 ä¸ª tokenï¼šä¸­ç­‰è®¡ç®—ï¼‰</strong></p><ul><li>æ¨¡å‹ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ¨ç†è¿‡ç¨‹ï¼š<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Adding 3 and 2 gives 5</span><br></pre></td></tr></tbody></table></figure></li><li><strong>æ¯”ç¬¬ä¸€ç§æ–¹æ³•å¤šäº†ä¸€äº›è®¡ç®—é‡</strong>ï¼Œä½†ä»ç„¶è¾ƒä¸ºç®€æ´ã€‚</li><li>è¿™ç§æ–¹å¼é€‚ç”¨äº<strong>ç®€å•çš„æ•°å­¦è¿ç®—æˆ–é€»è¾‘æ¨ç†</strong>ï¼Œä½†åœ¨æ›´å¤æ‚çš„æƒ…å†µä¸‹ä»å¯èƒ½å‡ºç°é”™è¯¯ã€‚</li></ul></li><li><p><strong>åœºæ™¯ 3ï¼ˆ15 ä¸ª tokenï¼šå®Œæ•´æ¨ç†ï¼‰</strong></p><ul><li>æ¨¡å‹å…ˆè¿›è¡Œè¯¦ç»†çš„é€æ­¥æ¨ç†ï¼š<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3 + 1 = 4 , 4 + 1 = 5</span><br></pre></td></tr></tbody></table></figure>ç„¶åï¼Œæ¨¡å‹å†æ˜ç¡®åœ°æ€»ç»“ï¼š<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">the total is 5</span><br></pre></td></tr></tbody></table></figure></li><li><strong>æ¨ç†è¿‡ç¨‹æ›´è¯¦ç»†ï¼Œå ç”¨çš„è®¡ç®—é‡æœ€å¤§</strong>ã€‚</li><li><strong>é€‚ç”¨äºéœ€è¦å¤šæ­¥æ¨ç†çš„ä»»åŠ¡ï¼Œå¦‚æ•°å­¦é¢˜ã€é€»è¾‘æ¨ç†é¢˜ç­‰</strong>ã€‚</li></ul></li></ul><h3 id="ğŸ”¢-è§„æ¨¡å®šå¾‹ï¼ˆScaling-Lawsï¼‰-1"><a href="#ğŸ”¢-è§„æ¨¡å®šå¾‹ï¼ˆScaling-Lawsï¼‰-1" class="headerlink" title="ğŸ”¢ è§„æ¨¡å®šå¾‹ï¼ˆScaling Lawsï¼‰"></a>ğŸ”¢ è§„æ¨¡å®šå¾‹ï¼ˆScaling Lawsï¼‰</h3><p>ç›¸æ¯”äºè®­ç»ƒæ—¶è®¡ç®—ï¼Œæ¨ç†æ—¶è®¡ç®—çš„è§„æ¨¡å®šå¾‹ä»ç„¶è¾ƒä¸ºæ–°é¢–ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ‰ä¸¤é¡¹ç ”ç©¶æ­ç¤ºäº†æ¨ç†æ—¶è®¡ç®—è§„æ¨¡ä¸è®­ç»ƒæ—¶è®¡ç®—è§„æ¨¡çš„å…³ç³»ã€‚</p><p>é¦–å…ˆï¼ŒOpenAI å‘è¡¨çš„ä¸€ç¯‡æ–‡ç« è¡¨æ˜ï¼Œæ¨ç†æ—¶è®¡ç®—å¯èƒ½éµå¾ªä¸è®­ç»ƒæ—¶è®¡ç®—ç›¸åŒçš„æ‰©å±•è¶‹åŠ¿ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_151722.png" class=""><blockquote><p><strong>æ¥è‡ªâ€œå­¦ä¹ å¦‚ä½•æ¨ç†çš„ LLMâ€ä¸€æ–‡çš„æ³¨é‡Šå›¾</strong>ï¼šçº¢è‰²è™šçº¿æ˜¾ç¤ºäº† OpenAI æå‡ºçš„æ–°èŒƒå¼å¯èƒ½æ˜¯æ¨ç†æ—¶è®¡ç®—ã€‚<br>è¿™å¼ å›¾å±•ç¤ºäº† <strong>è®­ç»ƒæ—¶é—´è®¡ç®—ï¼ˆtrain-time computeï¼‰å’Œæµ‹è¯•æ—¶é—´è®¡ç®—ï¼ˆtest-time computeï¼‰</strong> å¯¹æ¨¡å‹ <strong>pass@1 å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰</strong> çš„å½±å“ï¼Œå…·ä½“æ¥è¯´ï¼Œå®ƒå¼ºè°ƒäº† <strong>æµ‹è¯•æ—¶é—´è®¡ç®—å¯èƒ½æ¯”è®­ç»ƒæ—¶é—´è®¡ç®—æ›´æœ‰åˆ©äºæ‰©å±•æ¨¡å‹æ€§èƒ½</strong>ã€‚</p></blockquote><ol><li><p><strong>å·¦å›¾ï¼šè®­ç»ƒæ—¶é—´è®¡ç®— vs. å‡†ç¡®ç‡</strong></p><ul><li><strong>X è½´ï¼ˆæ¨ªè½´ï¼‰ï¼šè®­ç»ƒæ—¶é—´è®¡ç®—ï¼ˆlog scaleï¼ŒæŒ‡æ•°åˆ»åº¦ï¼‰</strong>ã€‚</li><li><strong>Y è½´ï¼ˆçºµè½´ï¼‰ï¼špass@1 å‡†ç¡®ç‡</strong>ï¼ˆå³æ¨¡å‹åœ¨ä¸€æ¬¡å°è¯•ä¸­å¾—åˆ°æ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ï¼‰ã€‚</li><li><strong>é»‘è‰²ç‚¹</strong> ä»£è¡¨ä¸åŒè®¡ç®—é‡ä¸‹çš„æ¨¡å‹è¡¨ç°ï¼Œç²‰è‰²è™šçº¿å±•ç¤ºäº†å¤§è‡´çš„è¶‹åŠ¿ã€‚</li><li>å¯ä»¥çœ‹åˆ°ï¼Œéšç€ <strong>è®­ç»ƒè®¡ç®—é‡çš„å¢åŠ ï¼Œå‡†ç¡®ç‡é€æ¸æé«˜</strong>ï¼Œä½†å¢é•¿è¶‹åŠ¿ç›¸å¯¹å¹³ç¨³ã€‚</li></ul></li><li><p><strong>å³å›¾ï¼šæµ‹è¯•æ—¶é—´è®¡ç®— vs. å‡†ç¡®ç‡</strong></p><ul><li><strong>X è½´ï¼ˆæ¨ªè½´ï¼‰ï¼šæµ‹è¯•æ—¶é—´è®¡ç®—ï¼ˆlog scaleï¼‰</strong>ã€‚</li><li><strong>Y è½´ï¼ˆçºµè½´ï¼‰ï¼špass@1 å‡†ç¡®ç‡</strong>ã€‚</li><li>åŒæ ·ï¼Œé»‘è‰²ç‚¹ä»£è¡¨ä¸åŒè®¡ç®—é‡ä¸‹çš„æ¨¡å‹è¡¨ç°ï¼Œç²‰è‰²è™šçº¿å±•ç¤ºäº†å¤§è‡´çš„è¶‹åŠ¿ã€‚</li><li>è¿™é‡Œå¯ä»¥çœ‹åˆ°ï¼Œéšç€ <strong>æµ‹è¯•æ—¶è®¡ç®—é‡å¢åŠ ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡å¢é•¿æ›´æ˜¾è‘—ï¼Œç”šè‡³è¶…è¿‡äº†è®­ç»ƒè®¡ç®—é‡çš„æ•ˆæœ</strong>ã€‚<br>å› æ­¤ï¼Œä»–ä»¬è®¤ä¸ºï¼Œæ¨ç†æ—¶è®¡ç®—çš„æ‰©å±•å¯èƒ½ä»£è¡¨ç€æ–°çš„ç ”ç©¶èŒƒå¼ã€‚</li></ul></li></ol><p>å…¶æ¬¡ï¼Œä¸€ç¯‡åä¸ºã€ŠScaling Scaling Laws with Board Gamesã€‹çš„è®ºæ–‡ç ”ç©¶äº† AlphaZero åœ¨ä¸åŒè®¡ç®—é‡ä¸‹ç© Hex æ¸¸æˆçš„è¡¨ç°ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_152050.png" class=""><blockquote><p><strong>æ¥è‡ªâ€œScaling Scaling Laws with Board Gamesâ€ä¸€æ–‡çš„æ³¨é‡Šå›¾</strong>ï¼šè¯¥å›¾å±•ç¤ºäº†ä»–ä»¬å¦‚ä½•æ„å»ºä¸åŒè§„æ¨¡çš„è®­ç»ƒæ—¶è®¡ç®—å’Œæ¨ç†æ—¶è®¡ç®—ã€‚- <strong>AlphaZero</strong> æ˜¯ <strong>DeepMind</strong> å¼€å‘çš„ä¸€ä¸ª <strong>å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰</strong> è®­ç»ƒçš„ AIã€‚</p></blockquote><ul><li>è¯¥ç®—æ³•é€šè¿‡ <strong>è‡ªæˆ‘å¯¹å¼ˆï¼ˆself-playï¼‰</strong> è®­ç»ƒï¼Œæ— éœ€äººä¸ºè§„åˆ™è¾“å…¥ï¼Œå³å¯æŒæ¡<strong>å›´æ£‹ã€å›½é™…è±¡æ£‹ã€å°†æ£‹ç­‰æ¸¸æˆ</strong>ã€‚</li><li>å®ƒç»“åˆäº† <strong>ç¥ç»ç½‘ç»œé¢„æµ‹</strong> å’Œ <strong>è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTS, Monte Carlo Tree Searchï¼‰</strong> æ¥è¿›è¡Œå†³ç­–ã€‚</li></ul><p>è¿™å¼ å›¾ç‰‡å±•ç¤ºäº† <strong>AlphaZero ç®—æ³•</strong> åœ¨<strong>è®­ç»ƒé˜¶æ®µï¼ˆtrain-time computeï¼‰å’Œæµ‹è¯•é˜¶æ®µï¼ˆtest-time computeï¼‰</strong>è®¡ç®—èµ„æºçš„ä¸åŒåº”ç”¨ã€‚ä¸»è¦å¼ºè°ƒäº†ï¼š</p><ul><li><strong>è®­ç»ƒæ—¶</strong>ï¼šä¾èµ–äº<strong>æ›´å¤šå‚æ•°å’Œæ›´é•¿çš„è®­ç»ƒæ—¶é—´</strong>æ¥ä¼˜åŒ–æ¨¡å‹ã€‚</li><li><strong>æµ‹è¯•æ—¶</strong>ï¼šä¾é  <strong>æ›´æ·±å…¥çš„æ ‘æœç´¢ï¼ˆtree searchï¼‰</strong> æ¥æå‡å†³ç­–èƒ½åŠ›ã€‚</li></ul><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_152430.png" class=""><blockquote><p>æ¥è‡ªâ€œScaling Scaling Laws with Board Gamesâ€ä¸€æ–‡çš„æ³¨é‡Šå›¾ï¼šè¯¥å›¾å±•ç¤ºäº†è®­ç»ƒæ—¶è®¡ç®—ä¸æ¨ç†æ—¶è®¡ç®—ä¹‹é—´çš„å…³ç³»ã€‚<br>ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè®­ç»ƒæ—¶è®¡ç®—å’Œæ¨ç†æ—¶è®¡ç®—ç´§å¯†ç›¸å…³ã€‚æ¯æ¡è™šçº¿è¡¨ç¤ºè¾¾åˆ°ç‰¹å®š ELO åˆ†æ•°æ‰€éœ€çš„æœ€å°è®¡ç®—é‡ã€‚<br><strong>1. åæ ‡è½´å«ä¹‰</strong></p></blockquote><ul><li><strong>X è½´ï¼ˆæ¨ªè½´ï¼‰ï¼šè®­ç»ƒæ—¶è®¡ç®—é‡ï¼ˆTrain-time Computeï¼ŒFLOP-secondsï¼‰</strong></li><li><strong>Y è½´ï¼ˆçºµè½´ï¼‰ï¼šæ¨ç†æ—¶è®¡ç®—é‡ï¼ˆTest-time Computeï¼ŒFLOP-secondsï¼‰</strong></li><li><strong>å¯¹æ•°åˆ»åº¦ï¼ˆlog scaleï¼‰ï¼šè®¡ç®—é‡çš„å¢é•¿å‘ˆæŒ‡æ•°çº§ï¼Œè€Œä¸æ˜¯çº¿æ€§å¢é•¿ã€‚</strong></li></ul><p><strong>2. å…³é”®æ•°æ®è¶‹åŠ¿</strong></p><ul><li>ä¸åŒé¢œè‰²çš„æ›²çº¿åˆ†åˆ«è¡¨ç¤º<strong>ä¸åŒçš„ ELO åˆ†æ•°æ°´å¹³</strong>ï¼ˆ-1500ã€-1250ã€-1000ã€-750ã€-500ã€-250ï¼‰ã€‚</li><li><strong>è™šçº¿å’Œå®çº¿</strong>ï¼š<ul><li><strong>è™šçº¿</strong> è¡¨ç¤ºæŸä¸ª ELO åˆ†æ•°ä¸‹çš„æœ€ä¼˜è®¡ç®—è¾¹ç•Œã€‚</li><li><strong>å®çº¿</strong> ä»£è¡¨å®é™…æ•°æ®è¶‹åŠ¿ã€‚</li></ul></li></ul><ol><li><p><strong>è®­ç»ƒè®¡ç®—å’Œæ¨ç†è®¡ç®—å¯ä»¥äº’ç›¸æ›¿ä»£</strong></p><ul><li><strong>å¦‚æœæ¨ç†è®¡ç®—é‡å¢åŠ ï¼ˆå·¦ä¸ŠåŒºåŸŸï¼‰</strong>ï¼Œé‚£ä¹ˆæ‰€éœ€çš„è®­ç»ƒè®¡ç®—é‡å‡å°‘ã€‚</li><li><strong>å¦‚æœè®­ç»ƒè®¡ç®—é‡å¢åŠ ï¼ˆå³ä¸‹åŒºåŸŸï¼‰</strong>ï¼Œé‚£ä¹ˆæ‰€éœ€çš„æ¨ç†è®¡ç®—é‡å‡å°‘ã€‚</li><li><strong>ä¸¤è€…å‘ˆç°è´Ÿç›¸å…³å…³ç³»</strong>ã€‚</li></ul></li><li><p><strong>ä½è®­ç»ƒè®¡ç®— vs. é«˜æ¨ç†è®¡ç®—</strong></p><ul><li>åœ¨ <strong>è®­ç»ƒè®¡ç®—è¾ƒå°‘</strong> çš„æƒ…å†µä¸‹ï¼ˆå¦‚å·¦ä¾§çš„çº¢è‰²åœˆï¼‰ï¼Œæ¨¡å‹ä»ç„¶å¯ä»¥è¾¾åˆ°ç›¸åŒçš„ ELO æ°´å¹³ï¼Œä½†éœ€è¦ <strong>åœ¨æ¨ç†æ—¶å¢åŠ è®¡ç®—é‡</strong>ï¼ˆå¦‚æ›´æ·±çš„æœç´¢æ ‘ã€æ›´é•¿çš„æ€è€ƒè·¯å¾„ï¼‰ã€‚</li></ul></li><li><p><strong>é«˜è®­ç»ƒè®¡ç®— vs. ä½æ¨ç†è®¡ç®—</strong></p><ul><li>åœ¨ <strong>è®­ç»ƒè®¡ç®—å……è¶³</strong> çš„æƒ…å†µä¸‹ï¼ˆå¦‚å³ä¾§çš„çº¢è‰²åœˆï¼‰ï¼Œæ¨¡å‹å¯ä»¥<strong>å‡å°‘æ¨ç†è®¡ç®—éœ€æ±‚</strong>ï¼Œå³ <strong>å³ä½¿ä½¿ç”¨è¾ƒå°‘çš„æœç´¢æ·±åº¦ï¼Œä»ç„¶èƒ½è·å¾—è¾ƒé«˜çš„æ€§èƒ½</strong>ã€‚</li></ul></li><li><p><strong>å…¬å¼è§£é‡Š</strong></p><ul><li>å…¬å¼ï¼š<br>$$<br>\log_{10}(\text{test compute}) = -1.2 \cdot \log_{10}(\text{train compute}) + 0.004 \cdot \text{elo} + 29<br>$$</li><li>è¿™è¯´æ˜ï¼š<ul><li><strong>è®­ç»ƒè®¡ç®—ï¼ˆtrain computeï¼‰å¢åŠ æ—¶ï¼Œæ¨ç†è®¡ç®—ï¼ˆtest computeï¼‰å‡å°‘ï¼ˆç³»æ•° -1.2ï¼‰</strong>ã€‚</li><li><strong>æ›´é«˜çš„ ELOï¼ˆæ›´å¼ºçš„ AIï¼‰éœ€è¦é¢å¤–çš„è®¡ç®—ï¼ˆç³»æ•° 0.004ï¼‰</strong>ã€‚</li></ul></li></ul></li></ol><p>éšç€æ¨ç†æ—¶è®¡ç®—æ‰©å±•ç±»ä¼¼äºè®­ç»ƒæ—¶è®¡ç®—ï¼Œç ”ç©¶èŒƒå¼æ­£æœç€â€œæ¨ç†â€æ¨¡å‹åˆ©ç”¨æ›´å¤šæ¨ç†æ—¶è®¡ç®—çš„æ–¹å‘å‘å±•ã€‚é€šè¿‡è¿™ç§èŒƒå¼è½¬å˜ï¼Œè¿™äº›â€œæ¨ç†â€æ¨¡å‹ä¸å†å•çº¯å…³æ³¨è®­ç»ƒæ—¶è®¡ç®—ï¼ˆé¢„è®­ç»ƒå’Œå¾®è°ƒï¼‰ï¼Œè€Œæ˜¯å¹³è¡¡è®­ç»ƒä¸æ¨ç†ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_152824.png" class=""><p>æ¨ç†æ—¶è®¡ç®—ç”šè‡³å¯ä»¥éšé•¿åº¦æ‰©å±•ï¼š</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_153922.png" class=""><p>è¿™æ˜¯æˆ‘ä»¬åœ¨ DeepSeek-R1 ç ”ç©¶ä¸­ä¹Ÿå°†æ¢è®¨çš„å†…å®¹ï¼</p><h3 id="ğŸ“Œ-æ¨ç†æ—¶è®¡ç®—çš„ç±»åˆ«ï¼ˆCategories-of-Test-time-Computeï¼‰"><a href="#ğŸ“Œ-æ¨ç†æ—¶è®¡ç®—çš„ç±»åˆ«ï¼ˆCategories-of-Test-time-Computeï¼‰" class="headerlink" title="ğŸ“Œ æ¨ç†æ—¶è®¡ç®—çš„ç±»åˆ«ï¼ˆCategories of Test-time Computeï¼‰"></a>ğŸ“Œ æ¨ç†æ—¶è®¡ç®—çš„ç±»åˆ«ï¼ˆCategories of Test-time Computeï¼‰</h3><p>æ¨ç†æ¨¡å‹ï¼ˆå¦‚ <strong>DeepSeek-R1</strong> å’Œ <strong>OpenAI o1</strong>ï¼‰çš„æˆåŠŸè¡¨æ˜ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œé™¤äº†ç®€å•åœ°â€œæ€è€ƒæ›´é•¿æ—¶é—´â€ä¹‹å¤–ï¼Œè¿˜æœ‰æ›´å¤šçš„ä¼˜åŒ–æŠ€æœ¯ã€‚</p><p>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ <strong>æ¨ç†æ—¶è®¡ç®—ï¼ˆTest-time Computeï¼‰</strong> çš„å¤šç§å®ç°æ–¹å¼ï¼ŒåŒ…æ‹¬ï¼š</p><ul><li><strong>é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰</strong></li><li><strong>ç­”æ¡ˆä¿®è®¢ï¼ˆRevising Answersï¼‰</strong></li><li><strong>å›æº¯æ¨ç†ï¼ˆBacktrackingï¼‰</strong></li><li><strong>å¤šæ ·æ€§é‡‡æ ·ï¼ˆSamplingï¼‰</strong></li><li><strong>å…¶ä»–æ–¹æ³•</strong></li></ul><p>æ€»ä½“è€Œè¨€ï¼Œæ¨ç†æ—¶è®¡ç®—å¯å½’çº³ä¸ºä»¥ä¸‹ <strong>ä¸¤å¤§ç±»åˆ«</strong>ï¼š</p><ol><li><p><strong>åŸºäºéªŒè¯å™¨çš„æœç´¢ï¼ˆSearch against Verifiersï¼‰</strong>  </p><ul><li>é€šè¿‡ <strong>é‡‡æ ·å¤šä¸ªç­”æ¡ˆ</strong> å¹¶ <strong>é€‰æ‹©æœ€ä½³ç­”æ¡ˆ</strong> æ¥ä¼˜åŒ–æ¨ç†ã€‚</li></ul></li><li><p><strong>ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying Proposal Distributionï¼‰</strong>  </p><ul><li>é€šè¿‡è®­ç»ƒ <strong>â€œæ€è€ƒâ€è¿‡ç¨‹</strong> æ¥æé«˜æ¨ç†èƒ½åŠ›ã€‚Proposal Distributionï¼ˆæè®®åˆ†å¸ƒï¼ŒæŒ‡åœ¨æ¨¡å‹ç”Ÿæˆç­”æ¡ˆæ—¶ï¼Œå¯¹ä¸åŒå¯èƒ½ç­”æ¡ˆçš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼‰</li></ul></li></ol><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_154456.png" class=""><p>ä»æœ¬è´¨ä¸Šè®²ï¼š</p><ul><li><strong>åŸºäºéªŒè¯å™¨çš„æœç´¢</strong> æ›´å…³æ³¨ <strong>è¾“å‡ºè´¨é‡</strong>ï¼ˆOutput-focusedï¼‰ã€‚</li><li><strong>ä¿®æ”¹æè®®åˆ†å¸ƒ</strong> å…³æ³¨ <strong>è¾“å…¥ç»“æ„</strong>ï¼ˆInput-focusedï¼‰ã€‚</li></ul><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_154547.png" class=""><h3 id="ğŸ”-ä¸¤ç§ä¸»è¦éªŒè¯å™¨ç±»å‹"><a href="#ğŸ”-ä¸¤ç§ä¸»è¦éªŒè¯å™¨ç±»å‹" class="headerlink" title="ğŸ” ä¸¤ç§ä¸»è¦éªŒè¯å™¨ç±»å‹"></a>ğŸ” ä¸¤ç§ä¸»è¦éªŒè¯å™¨ç±»å‹</h3><p>ä¸ºäº†æ›´å¥½åœ°ç­›é€‰å’Œè¯„ä¼°æ¨ç†ç­”æ¡ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ç§ <strong>éªŒè¯å™¨ï¼ˆVerifiersï¼‰</strong>ï¼š</p><ol><li><p><strong>ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆOutcome Reward Models, ORMï¼‰</strong>  </p><ul><li>ä»…å¯¹æœ€ç»ˆç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼Œè€Œä¸è€ƒè™‘æ¨ç†è¿‡ç¨‹ã€‚</li></ul></li><li><p><strong>è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆProcess Reward Models, PRMï¼‰</strong>  </p><ul><li>æ—¢è¯„ä¼°æœ€ç»ˆç­”æ¡ˆï¼Œä¹Ÿå¯¹æ¨ç†è¿‡ç¨‹è¿›è¡Œè¯„åˆ†ã€‚</li></ul></li></ol><p>åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è¯¦ç»†æ¢è®¨ <strong>å¦‚ä½•å°† ORM å’Œ PRM åº”ç”¨äºä¸åŒçš„éªŒè¯æ–¹æ³•</strong>ï¼</p><p>é¡¾åæ€ä¹‰ï¼Œ<strong>ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆOutcome Reward Model, ORMï¼‰</strong> ä»…è¯„ä¼°æœ€ç»ˆçš„ç­”æ¡ˆè´¨é‡ï¼Œè€Œä¸å…³æ³¨ç­”æ¡ˆèƒŒåçš„æ¨ç†è¿‡ç¨‹ï¼š</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_160242.png" class=""><ul><li>ORM åªçœ‹æœ€ç»ˆè¾“å‡ºï¼Œè€Œä¸å…³å¿ƒæ¨¡å‹æ˜¯å¦‚ä½•å¾—å‡ºè¿™ä¸ªç­”æ¡ˆçš„ã€‚</li></ul><p>ç›¸æ¯”ä¹‹ä¸‹ï¼Œ<strong>è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆProcess Reward Model, PRMï¼‰</strong> åˆ™ä¼šè¯„ä¼°æ¨ç†è¿‡ç¨‹æœ¬èº«ï¼š</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_160258.png" class=""><ul><li>PRM æ—¢è¯„ä¼°ç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼Œä¹Ÿå…³æ³¨æ¨ç†è·¯å¾„çš„åˆç†æ€§ã€‚</li></ul><h3 id="ğŸ§-PRM-å¦‚ä½•è¯„ä¼°æ¨ç†è¿‡ç¨‹ï¼Ÿ"><a href="#ğŸ§-PRM-å¦‚ä½•è¯„ä¼°æ¨ç†è¿‡ç¨‹ï¼Ÿ" class="headerlink" title="ğŸ§ PRM å¦‚ä½•è¯„ä¼°æ¨ç†è¿‡ç¨‹ï¼Ÿ"></a>ğŸ§ PRM å¦‚ä½•è¯„ä¼°æ¨ç†è¿‡ç¨‹ï¼Ÿ</h3><p>ä¸ºäº†æ›´æ¸…æ¥šåœ°è¯´æ˜æ¨ç†æ­¥éª¤çš„é‡è¦æ€§ï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">é—®é¢˜ï¼šæŸä¸ªæ–¹ç¨‹çš„è§£æ˜¯å¤šå°‘ï¼Ÿ</span><br><span class="line"></span><br><span class="line">æ¨ç†æ­¥éª¤ 1ï¼šé¦–å…ˆå±•å¼€æ–¹ç¨‹ï¼Œå¾—åˆ° x = 3ã€‚</span><br><span class="line">æ¨ç†æ­¥éª¤ 2ï¼šé”™è¯¯åœ°å°† x = 3 æ”¹å†™ä¸º x = 5ã€‚</span><br><span class="line">æ¨ç†æ­¥éª¤ 3ï¼šæœ€ç»ˆè¾“å‡º x = 5ã€‚</span><br></pre></td></tr></tbody></table></figure><p>åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œè™½ç„¶æœ€ç»ˆç­”æ¡ˆï¼ˆx = 5ï¼‰æ˜¯é”™è¯¯çš„ï¼Œä½† ORM ä»…è¯„ä¼°æœ€ç»ˆè¾“å‡ºï¼Œä¸ä¼šå…³æ³¨ä¸­é—´çš„é”™è¯¯æ¨ç†ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_160332.png" class=""><p>æˆ–è€…åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒPRM ä¼šå‘ç° <strong>æ¨ç†æ­¥éª¤ 2 æ˜¯é”™è¯¯çš„</strong>ï¼Œå¹¶å¯¹æ­¤æ­¥éª¤ç»™äºˆä½åˆ†ï¼Œä»è€Œé¿å…é”™è¯¯ç­”æ¡ˆçš„å‡ºç°ã€‚</p><hr><h3 id="ğŸ”-ORM-vs-PRM-åœ¨æ¨ç†ä¸­çš„åº”ç”¨"><a href="#ğŸ”-ORM-vs-PRM-åœ¨æ¨ç†ä¸­çš„åº”ç”¨" class="headerlink" title="ğŸ” ORM vs. PRM åœ¨æ¨ç†ä¸­çš„åº”ç”¨"></a>ğŸ” ORM vs. PRM åœ¨æ¨ç†ä¸­çš„åº”ç”¨</h3><p>ç°åœ¨ä½ å·²ç»æŒæ¡äº† <strong>ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆORMï¼‰</strong> å’Œ <strong>è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰</strong> ä¹‹é—´çš„åŒºåˆ«ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥æ¢è®¨å¦‚ä½•å°†å®ƒä»¬åº”ç”¨äºå„ç§ <strong>éªŒè¯æŠ€æœ¯ï¼ˆVerification Techniquesï¼‰</strong>ã€‚</p><h2 id="ğŸ“Œ-åŸºäºéªŒè¯å™¨çš„æœç´¢ï¼ˆSearch-against-Verifiersï¼‰"><a href="#ğŸ“Œ-åŸºäºéªŒè¯å™¨çš„æœç´¢ï¼ˆSearch-against-Verifiersï¼‰" class="headerlink" title="ğŸ“Œ åŸºäºéªŒè¯å™¨çš„æœç´¢ï¼ˆSearch against Verifiersï¼‰"></a>ğŸ“Œ åŸºäºéªŒè¯å™¨çš„æœç´¢ï¼ˆSearch against Verifiersï¼‰</h2><p>æ¨ç†æ—¶è®¡ç®—çš„ç¬¬ä¸€å¤§ç±»åˆ«æ˜¯ <strong>åŸºäºéªŒè¯å™¨çš„æœç´¢</strong>ï¼Œå®ƒé€šå¸¸åŒ…å«ä¸¤ä¸ªæ­¥éª¤ï¼š</p><ol><li><strong>ç”Ÿæˆå¤šä¸ªæ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆæ ·æœ¬</strong></li><li><strong>ä½¿ç”¨éªŒè¯å™¨ï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰å¯¹ç”Ÿæˆçš„è¾“å‡ºè¿›è¡Œè¯„åˆ†</strong><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_160918.png" class=""></li></ol><h3 id="ğŸ¤–-éªŒè¯å™¨çš„ä½œç”¨"><a href="#ğŸ¤–-éªŒè¯å™¨çš„ä½œç”¨" class="headerlink" title="ğŸ¤– éªŒè¯å™¨çš„ä½œç”¨"></a>ğŸ¤– éªŒè¯å™¨çš„ä½œç”¨</h3><p>éªŒè¯å™¨é€šå¸¸æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œç»è¿‡å¾®è°ƒä»¥è¯„ä¼°ç»“æœï¼ˆORMï¼‰æˆ–è¿‡ç¨‹ï¼ˆPRMï¼‰ã€‚ ä½¿ç”¨éªŒè¯å™¨çš„ä¸€ä¸ªä¸»è¦ä¼˜åŠ¿æ˜¯ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒç”¨äºå›ç­”é—®é¢˜çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»…é€šè¿‡è¯„åˆ†æœºåˆ¶é€‰æ‹©æœ€ä½³ç­”æ¡ˆã€‚</p><hr><h3 id="âœ…-å¤šæ•°æŠ•ç¥¨æ³•ï¼ˆMajority-Votingï¼‰"><a href="#âœ…-å¤šæ•°æŠ•ç¥¨æ³•ï¼ˆMajority-Votingï¼‰" class="headerlink" title="âœ… å¤šæ•°æŠ•ç¥¨æ³•ï¼ˆMajority Votingï¼‰"></a>âœ… å¤šæ•°æŠ•ç¥¨æ³•ï¼ˆMajority Votingï¼‰</h3><p>æœ€ç®€å•çš„æ–¹æ³•æ˜¯ <strong>ä¸ä½¿ç”¨å¥–åŠ±æ¨¡å‹æˆ–éªŒè¯å™¨</strong>ï¼Œè€Œæ˜¯æ‰§è¡Œ <strong>å¤šæ•°æŠ•ç¥¨ï¼ˆMajority Votingï¼‰</strong>ã€‚</p><p>ğŸ“Œ <strong>æ–¹æ³•ï¼š</strong> è®© LLM ç”Ÿæˆå¤šä¸ªç­”æ¡ˆï¼Œé€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„ç­”æ¡ˆä½œä¸ºæœ€ç»ˆç­”æ¡ˆã€‚</p><p>ğŸ“Œ <strong>ç¤ºä¾‹ï¼š</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Q: 15 Ã— 3 = ?</span><br><span class="line">A1: 45</span><br><span class="line">A2: 42</span><br><span class="line">A3: 45</span><br><span class="line">æœ€ç»ˆç­”æ¡ˆ: 45ï¼ˆå› å…¶å‡ºç°é¢‘ç‡æœ€é«˜ï¼‰</span><br></pre></td></tr></tbody></table></figure><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_161249.png" class=""><p>è¿™ç§æ–¹æ³•ä¹Ÿç§°ä¸º <strong>è‡ªä¸€è‡´æ€§ï¼ˆSelf-Consistencyï¼‰</strong>ï¼Œå¼ºè°ƒ <strong>ç”Ÿæˆå¤šä¸ªç­”æ¡ˆå’Œæ¨ç†æ­¥éª¤</strong> çš„é‡è¦æ€§ã€‚</p><hr><h3 id="ğŸ”¢-Best-of-N-é‡‡æ ·æ³•ï¼ˆBest-of-N-Samplesï¼‰"><a href="#ğŸ”¢-Best-of-N-é‡‡æ ·æ³•ï¼ˆBest-of-N-Samplesï¼‰" class="headerlink" title="ğŸ”¢ Best-of-N é‡‡æ ·æ³•ï¼ˆBest-of-N Samplesï¼‰"></a>ğŸ”¢ Best-of-N é‡‡æ ·æ³•ï¼ˆBest-of-N Samplesï¼‰</h3><p>Best-of-N é‡‡æ ·æ˜¯ç¬¬ä¸€ä¸ªæ¶‰åŠéªŒè¯å™¨ï¼ˆVerifierï¼‰çš„æ–¹æ³•ï¼Œå®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯ç”Ÿæˆ N ä¸ªæ ·æœ¬ç­”æ¡ˆï¼Œç„¶åä½¿ç”¨ å¥–åŠ±æ¨¡å‹ï¼ˆReward Model, RMï¼‰ å¯¹è¿™äº›ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼Œå¹¶é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç­”æ¡ˆã€‚</p><p>ğŸ“Œ <strong>æ­¥éª¤ï¼š</strong></p><ol><li><strong>ç”Ÿæˆå¤šä¸ªç­”æ¡ˆ</strong>ï¼ˆä½¿ç”¨è¾ƒé«˜æˆ–è€…ä¸åŒçš„æ¸©åº¦å‚æ•°ç”Ÿæˆ N ä¸ªæ ·æœ¬ï¼‰ã€‚<img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_161825.png" class=""></li><li><strong>ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆORM, Outcome Reward Modelï¼‰</strong>ï¼Œæ¯ä¸ªç­”æ¡ˆéƒ½ä¼šé€šè¿‡ ORM è¿›è¡Œè¯„åˆ†ã€‚é€‰å–å¾—åˆ†æœ€é«˜çš„ç­”æ¡ˆä½œä¸ºæœ€ç»ˆè¾“å‡ºã€‚<img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_161833.png" class="">ğŸ“Œ <strong>ç¤ºä¾‹ï¼š</strong></li></ol><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Q: 8 + 5 = ?</span><br><span class="line">A1: 12 (å¾—åˆ† 0.2)</span><br><span class="line">A2: 13 (å¾—åˆ† 0.9)</span><br><span class="line">A3: 14 (å¾—åˆ† 0.4)</span><br><span class="line">æœ€ç»ˆé€‰æ‹©: A2ï¼ˆå› å…¶å¾—åˆ†æœ€é«˜ï¼‰</span><br></pre></td></tr></tbody></table></figure><h2 id="ğŸ“Œ-è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š-è‹¥ä½¿ç”¨-PRMï¼Œåˆ™ä¸åªè¯„ä¼°ç­”æ¡ˆï¼Œè¿˜è¯„ä¼°æ•´ä¸ªæ¨ç†è¿‡ç¨‹ã€‚ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆORMï¼‰ä¸åŒï¼Œè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ä¼šè¯„ä¼°æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚PRM-å…³æ³¨æ¨ç†çš„æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹åˆç†ã€è¿è´¯ï¼Œå¹¶æœ€ç»ˆé€‰æ‹©æ€»è¯„åˆ†æœ€é«˜çš„å€™é€‰ç­”æ¡ˆã€‚-åŠ æƒ-Best-of-N-é‡‡æ ·ï¼ˆWeighted-Best-of-N-samplesï¼‰-ç»“åˆ-ORM-å’Œ-PRM-ä¸¤ç§éªŒè¯æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ‰€æœ‰å€™é€‰ç­”æ¡ˆè¿›è¡ŒåŠ æƒè¯„åˆ†ï¼Œå¹¶é€‰æ‹©æ€»æƒé‡æœ€é«˜çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•ç§°ä¸º-åŠ æƒ-Best-of-N-é‡‡æ ·ï¼ˆWeighted-Best-of-N-samplesï¼‰ï¼šã€‚"><a href="#ğŸ“Œ-è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š-è‹¥ä½¿ç”¨-PRMï¼Œåˆ™ä¸åªè¯„ä¼°ç­”æ¡ˆï¼Œè¿˜è¯„ä¼°æ•´ä¸ªæ¨ç†è¿‡ç¨‹ã€‚ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆORMï¼‰ä¸åŒï¼Œè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ä¼šè¯„ä¼°æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚PRM-å…³æ³¨æ¨ç†çš„æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹åˆç†ã€è¿è´¯ï¼Œå¹¶æœ€ç»ˆé€‰æ‹©æ€»è¯„åˆ†æœ€é«˜çš„å€™é€‰ç­”æ¡ˆã€‚-åŠ æƒ-Best-of-N-é‡‡æ ·ï¼ˆWeighted-Best-of-N-samplesï¼‰-ç»“åˆ-ORM-å’Œ-PRM-ä¸¤ç§éªŒè¯æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ‰€æœ‰å€™é€‰ç­”æ¡ˆè¿›è¡ŒåŠ æƒè¯„åˆ†ï¼Œå¹¶é€‰æ‹©æ€»æƒé‡æœ€é«˜çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•ç§°ä¸º-åŠ æƒ-Best-of-N-é‡‡æ ·ï¼ˆWeighted-Best-of-N-samplesï¼‰ï¼šã€‚" class="headerlink" title="ğŸ“Œ è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š- è‹¥ä½¿ç”¨ PRMï¼Œåˆ™ä¸åªè¯„ä¼°ç­”æ¡ˆï¼Œè¿˜è¯„ä¼°æ•´ä¸ªæ¨ç†è¿‡ç¨‹ã€‚ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆORMï¼‰ä¸åŒï¼Œè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ä¼šè¯„ä¼°æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚PRM å…³æ³¨æ¨ç†çš„æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹åˆç†ã€è¿è´¯ï¼Œå¹¶æœ€ç»ˆé€‰æ‹©æ€»è¯„åˆ†æœ€é«˜çš„å€™é€‰ç­”æ¡ˆã€‚- åŠ æƒ Best-of-N é‡‡æ ·ï¼ˆWeighted Best-of-N samplesï¼‰:ç»“åˆ ORM å’Œ PRM ä¸¤ç§éªŒè¯æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ‰€æœ‰å€™é€‰ç­”æ¡ˆè¿›è¡ŒåŠ æƒè¯„åˆ†ï¼Œå¹¶é€‰æ‹©æ€»æƒé‡æœ€é«˜çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•ç§°ä¸º åŠ æƒ Best-of-N é‡‡æ ·ï¼ˆWeighted Best-of-N samplesï¼‰ï¼šã€‚"></a>ğŸ“Œ <strong>è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š</strong><br>- è‹¥ä½¿ç”¨ <strong>PRM</strong>ï¼Œåˆ™ä¸åªè¯„ä¼°ç­”æ¡ˆï¼Œè¿˜è¯„ä¼°æ•´ä¸ªæ¨ç†è¿‡ç¨‹ã€‚ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„ç»“æœå¥–åŠ±æ¨¡å‹ï¼ˆORMï¼‰ä¸åŒï¼Œè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ä¼šè¯„ä¼°æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚PRM å…³æ³¨æ¨ç†çš„æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹åˆç†ã€è¿è´¯ï¼Œå¹¶æœ€ç»ˆé€‰æ‹©æ€»è¯„åˆ†æœ€é«˜çš„å€™é€‰ç­”æ¡ˆã€‚<br><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_161922.png" class=""><br>- <strong>åŠ æƒ Best-of-N é‡‡æ ·ï¼ˆWeighted Best-of-N samplesï¼‰</strong>:ç»“åˆ ORM å’Œ PRM ä¸¤ç§éªŒè¯æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ‰€æœ‰å€™é€‰ç­”æ¡ˆè¿›è¡ŒåŠ æƒè¯„åˆ†ï¼Œå¹¶é€‰æ‹©æ€»æƒé‡æœ€é«˜çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•ç§°ä¸º åŠ æƒ Best-of-N é‡‡æ ·ï¼ˆWeighted Best-of-N samplesï¼‰ï¼šã€‚<br><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_162139.png" class=""></h2><h3 id="ğŸš€-ä½¿ç”¨è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰çš„æŸæœç´¢ï¼ˆBeam-Searchï¼‰"><a href="#ğŸš€-ä½¿ç”¨è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰çš„æŸæœç´¢ï¼ˆBeam-Searchï¼‰" class="headerlink" title="ğŸš€ ä½¿ç”¨è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰çš„æŸæœç´¢ï¼ˆBeam Searchï¼‰"></a>ğŸš€ ä½¿ç”¨è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰çš„æŸæœç´¢ï¼ˆBeam Searchï¼‰</h3><p>åœ¨ç”Ÿæˆç­”æ¡ˆåŠå…¶ä¸­é—´æ¨ç†æ­¥éª¤çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <strong>æŸæœç´¢ï¼ˆBeam Searchï¼‰</strong> è¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†è·¯å¾„ã€‚</p><p>ğŸ“Œ <strong>æŸæœç´¢çš„æ ¸å¿ƒæ€æƒ³ï¼š</strong></p><ul><li>åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç”Ÿæˆå¤šä¸ªå¯èƒ½çš„æ¨ç†è·¯å¾„ï¼ˆç§°ä¸ºâ€œæŸâ€ï¼‰ã€‚</li><li>ä½¿ç”¨ <strong>è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRM, Process Reward Modelï¼‰</strong> å¯¹æ¯æ¡è·¯å¾„è¿›è¡Œè¯„åˆ†ã€‚</li><li>ç±»ä¼¼äº <strong>Tree of Thought</strong> æ–¹æ³•ï¼Œå§‹ç»ˆä¿ç•™å¾—åˆ†æœ€é«˜çš„ <strong>å‰ 3 æ¡æ¨ç†è·¯å¾„</strong>ï¼Œå¹¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­æŒç»­è·Ÿè¸ªè¿™äº›è·¯å¾„ã€‚</li><li>å¦‚æœæŸæ¡è·¯å¾„çš„å¾—åˆ†è¾ƒä½ï¼ˆPRM è¯„åˆ†ä½ï¼‰ï¼Œåˆ™æå‰åœæ­¢è¯¥æ¨ç†è·¯å¾„ï¼Œä»¥é¿å…ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ã€‚</li></ul><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_162508.png" class=""><p>ğŸ“Œ <strong>ä¼˜åŒ–åçš„ç­”æ¡ˆç­›é€‰æ–¹å¼ï¼š</strong><br>æœ€ç»ˆï¼Œç”Ÿæˆçš„æ‰€æœ‰ç­”æ¡ˆå°†ä½¿ç”¨ <strong>Best-of-N é‡‡æ ·</strong> æ–¹æ³•è¿›è¡ŒåŠ æƒè¯„åˆ†ï¼Œç¡®ä¿é€‰å‡ºæœ€ä½³æ¨ç†è·¯å¾„çš„æœ€ç»ˆç­”æ¡ˆã€‚</p><p>ğŸš€ <strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>é¿å…è®¡ç®—èµ„æºæµªè´¹ï¼Œå¿«é€Ÿæ·˜æ±°ä½è´¨é‡æ¨ç†è·¯å¾„ã€‚</li><li>ç»“åˆ PRMï¼Œå¯ä»¥ç¡®ä¿æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ›´è¿è´¯ã€æ›´ç¬¦åˆé€»è¾‘ã€‚</li><li>é€šè¿‡ Best-of-N æ–¹æ³•è¿›ä¸€æ­¥ä¼˜åŒ–ç­”æ¡ˆè´¨é‡ï¼Œä½¿æœ€ç»ˆç­”æ¡ˆæ›´åŠ å¯é ã€‚</li></ul><hr><h3 id="ğŸ²-è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte-Carlo-Tree-Search-MCTSï¼‰"><a href="#ğŸ²-è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte-Carlo-Tree-Search-MCTSï¼‰" class="headerlink" title="ğŸ² è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carlo Tree Search, MCTSï¼‰"></a>ğŸ² è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carlo Tree Search, MCTSï¼‰</h3><p>è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carlo Tree Search, <strong>MCTS</strong>ï¼‰æ˜¯ä¸€ç§å¸¸ç”¨äºå†³ç­–æ ‘æœç´¢çš„ç®—æ³•ï¼Œåœ¨ LLM çš„æ¨ç†ä¼˜åŒ–ä¸­ä¹Ÿå¯ä»¥é‡‡ç”¨è¯¥æ–¹æ³•ã€‚MCTS é€šè¿‡å››ä¸ªæ­¥éª¤æ¥ä¼˜åŒ–æ¨ç†è·¯å¾„ï¼š<br>ğŸ“Œ <strong>ä¸»è¦æ­¥éª¤ï¼š</strong></p><ol><li><strong>é€‰æ‹©ï¼ˆSelectionï¼‰ï¼š</strong> æ ¹æ®é¢„å®šä¹‰çš„å…¬å¼ï¼Œä»å½“å‰æœç´¢æ ‘ä¸­é€‰æ‹©ä¸€ä¸ªå¶èŠ‚ç‚¹ è¿›è¡Œæ‰©å±•ã€‚</li><li><strong>æ‰©å±•ï¼ˆExpandï¼‰ï¼š</strong> åœ¨æ‰€é€‰å¶èŠ‚ç‚¹çš„åŸºç¡€ä¸Š åˆ›å»ºæ–°çš„å­èŠ‚ç‚¹ï¼Œä»¥æ¢ç´¢æ›´å¤šå¯èƒ½çš„æ¨ç†è·¯å¾„ã€‚</li><li><strong>æ¨¡æ‹Ÿï¼ˆRolloutsï¼‰ï¼š</strong> é€šè¿‡éšæœºç”Ÿæˆæ–°çš„æ¨ç†è·¯å¾„ï¼ŒæŒç»­æ‰©å±•èŠ‚ç‚¹ï¼Œç›´åˆ°è¾¾åˆ°ç»ˆç‚¹ï¼ˆå³å¾—åˆ°æœ€ç»ˆç­”æ¡ˆï¼‰ã€‚</li><li><strong>å›æº¯ï¼ˆBackpropagationï¼‰ï¼š</strong> æ ¹æ®æœ€ç»ˆè¾“å‡ºç»“æœ æ›´æ–°çˆ¶èŠ‚ç‚¹çš„è¯„åˆ†ï¼Œä»è€Œä¼˜åŒ–æœªæ¥çš„æœç´¢å†³ç­–ã€‚</li></ol><p>åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›æ‰¾åˆ°æœ€ä½³çš„æ¨ç†è·¯å¾„ï¼Œä½¿å…¶æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆæœ€ä¼˜ã€‚ä½†åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œéœ€è¦åœ¨ <strong>æ¢ç´¢ï¼ˆExplorationï¼‰</strong> å’Œ <strong>åˆ©ç”¨ï¼ˆExploitationï¼‰</strong> ä¹‹é—´å–å¾—å¹³è¡¡ï¼š</p><ul><li><strong>åˆ©ç”¨ï¼ˆExploitationï¼‰</strong>ï¼šé€‰æ‹©å½“å‰çœ‹èµ·æ¥æœ€ä¼˜çš„è·¯å¾„ï¼Œä»¥åˆ©ç”¨å·²çŸ¥çš„é«˜è´¨é‡æ¨ç†æ­¥éª¤ã€‚</li><li><strong>æ¢ç´¢ï¼ˆExplorationï¼‰</strong>ï¼šé€‰æ‹©è®¿é—®æ¬¡æ•°è¾ƒå°‘çš„è·¯å¾„ï¼Œä»¥å‘ç°å¯èƒ½æ›´ä¼˜çš„æ¨ç†æ­¥éª¤ã€‚</li></ul><h4 id="é€‰æ‹©åˆ†æ•°ï¼ˆSelection-Scoreï¼‰"><a href="#é€‰æ‹©åˆ†æ•°ï¼ˆSelection-Scoreï¼‰" class="headerlink" title="é€‰æ‹©åˆ†æ•°ï¼ˆSelection Scoreï¼‰"></a>é€‰æ‹©åˆ†æ•°ï¼ˆSelection Scoreï¼‰</h4><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_163149.png" class=""><p>åœ¨é€‰æ‹©æ¨ç†è·¯å¾„æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ <strong>é€‰æ‹©åˆ†æ•°ï¼ˆSelection Scoreï¼‰</strong> è®¡ç®—æ¯ä¸ªæ¨ç†æ­¥éª¤ï¼ˆå³æ ‘çš„èŠ‚ç‚¹ï¼‰çš„ä¼˜å…ˆçº§ï¼Œå…¬å¼å¦‚ä¸‹ï¼š</p><p>$$<br>\text{Selection Score} = \frac{\text{Total Node Reward}}{\text{Number of Node Visits}} + C \times \sqrt{\frac{\text{Number of Parent Node Visits}}{\text{Number of Node Visits}}}<br>$$</p><p>å…¶ä¸­ï¼š</p><ul><li><p><strong>ç¬¬ä¸€é¡¹</strong>ï¼š$$\frac{\text{Total Node Reward}}{\text{Number of Node Visits}}$$ï¼ˆåˆ©ç”¨é¡¹ï¼ŒExploitation Termï¼‰</p><ul><li><strong>Total Node Reward</strong>ï¼šè¯¥èŠ‚ç‚¹ç´¯è®¡è·å¾—çš„å¥–åŠ±å€¼ï¼ˆè¡¨ç¤ºå…¶å†å²è¡¨ç°ï¼‰ã€‚</li><li><strong>Number of Node Visits</strong>ï¼šè¯¥èŠ‚ç‚¹è¢«è®¿é—®çš„æ¬¡æ•°ã€‚</li><li>è¿™é¡¹è®¡ç®—çš„æ˜¯è¯¥èŠ‚ç‚¹çš„ <strong>å¹³å‡å¥–åŠ±å€¼</strong>ï¼Œé«˜å¥–åŠ±çš„èŠ‚ç‚¹ä¼šè¢«ä¼˜å…ˆé€‰æ‹©ã€‚</li></ul></li><li><p><strong>ç¬¬äºŒé¡¹</strong>ï¼š$$C \times \sqrt{\frac{\text{Number of Parent Node Visits}}{\text{Number of Node Visits}}}$$ï¼ˆæ¢ç´¢é¡¹ï¼ŒExploration Termï¼‰</p><ul><li><strong># of Parent Node Visits</strong>ï¼šçˆ¶èŠ‚ç‚¹è¢«è®¿é—®çš„æ¬¡æ•°ã€‚</li><li><strong># of Node Visits</strong>ï¼šå½“å‰èŠ‚ç‚¹è¢«è®¿é—®çš„æ¬¡æ•°ã€‚</li><li><strong>C</strong>ï¼šä¸€ä¸ªè¶…å‚æ•°ï¼Œæ§åˆ¶æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡ã€‚</li><li>è¿™é¡¹é¼“åŠ±æ¢ç´¢è®¿é—®æ¬¡æ•°è¾ƒå°‘çš„èŠ‚ç‚¹ï¼Œä»¥é˜²æ­¢è¿‡æ—©é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚</li></ul></li></ul><p>æ€»ç»“ï¼š</p><ul><li><strong>ç¬¬ä¸€é¡¹ï¼ˆExploitation Termï¼‰</strong> è®©ç®—æ³•å€¾å‘äºé€‰æ‹© <strong>å†å²è¡¨ç°è¾ƒå¥½çš„è·¯å¾„</strong>ã€‚</li><li><strong>ç¬¬äºŒé¡¹ï¼ˆExploration Termï¼‰</strong> è®©ç®—æ³•å€¾å‘äº <strong>æ¢ç´¢è®¿é—®è¾ƒå°‘çš„è·¯å¾„</strong>ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚</li><li><strong>å‚æ•° C</strong> æ§åˆ¶è¿™ä¸¤è€…çš„å¹³è¡¡ã€‚</li></ul><h4 id="2-é€‰æ‹©ï¼ˆSelectionï¼‰ä¸æ‰©å±•ï¼ˆExpandï¼‰"><a href="#2-é€‰æ‹©ï¼ˆSelectionï¼‰ä¸æ‰©å±•ï¼ˆExpandï¼‰" class="headerlink" title="2. é€‰æ‹©ï¼ˆSelectionï¼‰ä¸æ‰©å±•ï¼ˆExpandï¼‰"></a><strong>2. é€‰æ‹©ï¼ˆSelectionï¼‰ä¸æ‰©å±•ï¼ˆExpandï¼‰</strong></h4><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_164346.png" class=""><p>è¿™ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨ <strong>é€‰æ‹©åˆ†æ•°</strong> æ¥å†³å®šå“ªæ¡æ¨ç†è·¯å¾„å€¼å¾—ç»§ç»­æ‰©å±•ï¼š</p><p><strong>ï¼ˆ1ï¼‰é€‰æ‹©ï¼ˆSelectionï¼‰</strong></p><ul><li><strong>è¾“å…¥ï¼šé—®é¢˜ï¼ˆQuestionï¼‰</strong></li><li><strong>LLM ç”Ÿæˆå¤šä¸ªæ¨ç†æ­¥éª¤ï¼ˆReasoning Stepsï¼‰</strong><ul><li>ä¾‹å¦‚ï¼Œåœ¨å›¾ç‰‡ä¸­ï¼ŒLLM ç”Ÿæˆäº† 3 ä¸ªæ¨ç†æ­¥éª¤ï¼š<ul><li><strong>Thought 1</strong>ï¼ˆè¯„åˆ† 0.4ï¼‰</li><li><strong>Thought 2</strong>ï¼ˆè¯„åˆ† 0.2ï¼‰</li><li><strong>Thought 3</strong>ï¼ˆè¯„åˆ† 0.1ï¼‰</li></ul></li></ul></li><li><strong>ä½¿ç”¨é€‰æ‹©åˆ†æ•°ï¼ˆSelection Scoreï¼‰é€‰æ‹©æœ€ä¼˜è·¯å¾„</strong>ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰<ul><li>åœ¨ç¤ºä¾‹ä¸­ï¼Œè¯„åˆ†æœ€é«˜çš„ <strong>Thought 1ï¼ˆ0.4ï¼‰</strong> è¢«é€‰ä¸­ã€‚</li></ul></li></ul><p><strong>ï¼ˆ2ï¼‰æ‰©å±•ï¼ˆExpandï¼‰</strong></p><ul><li><strong>åœ¨é€‰ä¸­çš„æ¨ç†è·¯å¾„ä¸Šï¼Œç”Ÿæˆæ–°çš„æ¨ç†æ­¥éª¤</strong></li><li>è¿™äº›æ–°æ¨ç†æ­¥éª¤çš„åˆå§‹å€¼è®¾ä¸º 0ï¼Œè¡¨ç¤ºå®ƒä»¬è¿˜æ²¡æœ‰ç»è¿‡è¯„ä¼°ã€‚</li></ul><p>è¿™ä¸ªè¿‡ç¨‹ç±»ä¼¼äº <strong>MCTS çš„æ‹“å±•ï¼ˆExpansionï¼‰é˜¶æ®µ</strong>ï¼Œå³ï¼š</p><ol><li>é€‰æ‹©å½“å‰æœ€ä¼˜è·¯å¾„ï¼ˆä½¿ç”¨ <strong>é€‰æ‹©åˆ†æ•°</strong>ï¼‰ã€‚</li><li>åœ¨è¯¥è·¯å¾„ä¸‹ï¼Œæ‰©å±•æ–°çš„æ¨ç†æ­¥éª¤ï¼ˆæœªè¯„åˆ†çš„å­èŠ‚ç‚¹ï¼‰ã€‚</li></ol><h4 id="3-Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰ä¸-Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰"><a href="#3-Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰ä¸-Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰" class="headerlink" title="3. Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰ä¸ Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰"></a><strong>3. Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰ä¸ Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰</strong></h4><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_165052.png" class=""><p>ä¸€æ—¦æ‰©å±•äº†æ¨ç†æ­¥éª¤ï¼Œæˆ‘ä»¬éœ€è¦ç»§ç»­æ¢ç´¢ï¼Œå¹¶åˆ©ç”¨ <strong>æ¨¡æ‹Ÿï¼ˆRolloutsï¼‰</strong> å’Œ <strong>åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰</strong> æ¥ä¼˜åŒ–æ•´ä¸ªæœç´¢è¿‡ç¨‹ã€‚</p><h3 id="ï¼ˆ3ï¼‰Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰"><a href="#ï¼ˆ3ï¼‰Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰" class="headerlink" title="ï¼ˆ3ï¼‰Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰"></a><strong>ï¼ˆ3ï¼‰Rolloutsï¼ˆæ¨¡æ‹Ÿï¼‰</strong></h3><ul><li>é€‰å®šè·¯å¾„åï¼Œæˆ‘ä»¬ç»§ç»­å±•å¼€æ¨ç†æ­¥éª¤ï¼Œç›´åˆ° <strong>ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ</strong>ã€‚</li><li>è¿™ä¸ªè¿‡ç¨‹ç±»ä¼¼äº <strong>åœ¨ MCTS ä¸­éšæœºæ¨¡æ‹Ÿæ¸¸æˆåˆ°ç»“æŸ</strong>ï¼š<ul><li>æˆ‘ä»¬ä»å½“å‰èŠ‚ç‚¹å‡ºå‘ï¼Œè¿›è¡Œä¸€ç³»åˆ—æ¨ç†ï¼Œç›´åˆ°æ¨¡å‹ç”Ÿæˆæœ€ç»ˆçš„ç­”æ¡ˆã€‚</li><li>åœ¨å›¾ç‰‡ä¸­ï¼Œæˆ‘ä»¬æ²¿ç€ Thought 1ï¼ˆ0.4ï¼‰ ç»§ç»­å±•å¼€æ¨ç†æ­¥éª¤ã€‚</li><li>è¿™äº›æ¨ç†æ­¥éª¤æœ€ç»ˆä¼š <strong>ç”Ÿæˆå¤šä¸ªç­”æ¡ˆ</strong>ï¼ˆå›¾ç‰‡ä¸­ç´«è‰²æ¡†ï¼‰ã€‚</li></ul></li></ul><h3 id="ï¼ˆ4ï¼‰Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰"><a href="#ï¼ˆ4ï¼‰Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰" class="headerlink" title="ï¼ˆ4ï¼‰Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰"></a><strong>ï¼ˆ4ï¼‰Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰</strong></h3><ul><li>é€šè¿‡å¯¹ <strong>æœ€ç»ˆç­”æ¡ˆ</strong> è¿›è¡Œè¯„åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ–°å‰é¢æ‰€æœ‰å‚ä¸æ¨ç†çš„èŠ‚ç‚¹åˆ†æ•°ï¼š<ul><li><strong>PRMï¼ˆProcess Reward Modelï¼‰</strong>ï¼šå¯¹æ¨ç†æ­¥éª¤æœ¬èº«è¿›è¡Œè¯„åˆ†ï¼Œè¡¡é‡å…¶åˆç†æ€§ã€‚</li><li><strong>ORMï¼ˆOutput Reward Modelï¼‰</strong>ï¼šå¯¹æœ€ç»ˆç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼Œè¡¡é‡å…¶æ­£ç¡®æ€§ã€‚</li><li>è¿™äº›è¯„åˆ† <strong>å‘ä¸Šä¼ æ’­</strong>ï¼Œæ›´æ–° <strong>æ‰€æœ‰ç»è¿‡çš„èŠ‚ç‚¹</strong> çš„å¥–åŠ±å€¼ã€‚</li></ul></li><li>ä¾‹å¦‚ï¼š<ul><li>åœ¨å›¾ç‰‡ä¸­ï¼Œæœ€ç»ˆç­”æ¡ˆçš„è¯„åˆ†å¯¼è‡´ <strong>Thought 1</strong> çš„è¯„åˆ†ä» 0.4 æé«˜åˆ° <strong>0.8</strong>ã€‚</li><li>è¿›ä¸€æ­¥å‘ä¸Šä¼ æ’­ï¼Œä½¿å¾— <strong>çˆ¶èŠ‚ç‚¹çš„é€‰æ‹©åˆ†æ•°ä¹Ÿéšä¹‹æ›´æ–°</strong>ã€‚</li></ul></li></ul><p>è¿™ä¸ªè¿‡ç¨‹ä¿è¯äº†ï¼š</p><ul><li><strong>è¾ƒå¥½çš„æ¨ç†è·¯å¾„ä¼šé€æ¸è·å¾—æ›´é«˜çš„åˆ†æ•°</strong>ï¼Œæé«˜è¢«é€‰ä¸­çš„æ¦‚ç‡ã€‚</li><li><strong>è¾ƒå·®çš„æ¨ç†è·¯å¾„ä¼šè¢«é€æ¸æ·˜æ±°</strong>ï¼Œé¿å…æµªè´¹è®¡ç®—èµ„æºã€‚</li></ul><hr><h2 id="ğŸ“Œ-ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying-Proposal-Distributionï¼‰"><a href="#ğŸ“Œ-ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying-Proposal-Distributionï¼‰" class="headerlink" title="ğŸ“Œ ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying Proposal Distributionï¼‰"></a>ğŸ“Œ ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying Proposal Distributionï¼‰</h2><p><strong>ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying Proposal Distributionï¼‰</strong></p><p>åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying Proposal Distributionï¼‰æ¥ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š</p><ul><li><strong>ä¸å†å•çº¯ä¾èµ–æ¨¡å‹æœç´¢æ­£ç¡®æ¨ç†æ­¥éª¤</strong>ï¼ˆåŸºäºè¾“å‡ºçš„ä¼˜åŒ–ï¼‰ï¼Œ</li><li><strong>è€Œæ˜¯è®©æ¨¡å‹ä¸»åŠ¨ç”Ÿæˆæ›´ä¼˜çš„æ¨ç†æ­¥éª¤</strong>ï¼ˆåŸºäºè¾“å…¥çš„ä¼˜åŒ–ï¼‰ã€‚</li></ul><p>æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬ä¸æ˜¯åœ¨è¾“å‡ºç»“æœåè¿›è¡Œæ£€éªŒï¼Œè€Œæ˜¯ç›´æ¥ä¿®æ”¹æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¦‚ä½•é€‰æ‹© tokenï¼Œè®©å®ƒæ›´å€¾å‘äºé€‰æ‹©èƒ½å¤Ÿå¼•å¯¼æ¨ç†çš„ tokenï¼Œè€Œä¸æ˜¯ç«‹å³è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚ä¿®æ”¹äº†ç”¨äºé‡‡æ ·è¡¥å…¨ï¼ˆcompletionsï¼‰ã€æ€ç»´ï¼ˆthoughtsï¼‰æˆ–æ ‡è®°ï¼ˆtokensï¼‰çš„æ¦‚ç‡åˆ†å¸ƒã€‚è¿™ç§æ–¹æ³•å¯ä»¥è®©æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆæ›´åŠ å‡†ç¡®ã€å¯è§£é‡Šï¼Œå¹¶ä¸”åœ¨é¢å¯¹å¤æ‚é—®é¢˜æ—¶æ›´å…·æœ‰é²æ£’æ€§ï¼ˆrobustnessï¼‰ã€‚</p><p><strong>1. ç›´æ¥é€‰æ‹©æœ€é«˜æ¦‚ç‡ Tokenï¼ˆGreedy é€‰æ‹©ï¼‰</strong></p><p>åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒLLM ç”Ÿæˆå¤šä¸ªå¯èƒ½çš„ token ä½œä¸ºè¾“å‡ºå€™é€‰é¡¹ï¼Œå¹¶æ ¹æ®å…¶æ¦‚ç‡è¿›è¡Œæ’åºï¼Œæœ€ç»ˆé€‰æ‹©æœ€é«˜æ¦‚ç‡çš„ token è¿›è¡Œè¾“å‡ºã€‚è¿™ç§æ–¹æ³•ç§°ä¸º<strong>è´ªå¿ƒé€‰æ‹©ï¼ˆGreedy Selectionï¼‰</strong>ã€‚</p><p>ä½ å¯ä»¥æƒ³è±¡ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªé—®é¢˜ï¼ˆquestionï¼‰å’Œä¸€ä¸ªç”¨äºé‡‡æ · token çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆdistributionï¼‰ã€‚å¸¸è§çš„ç­–ç•¥æ˜¯é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ tokenã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_170357.png" class=""><ul><li>ä¾‹å¦‚ï¼Œç»™å®šé—®é¢˜ <code>What is 3 + 2?</code>ï¼ŒLLM å¯èƒ½ä¼šç”Ÿæˆå¦‚ä¸‹å€™é€‰ tokenï¼š<ul><li><code>5</code>ï¼ˆæœ€é«˜æ¦‚ç‡ï¼‰</li><li><code>3</code></li><li><code>Adding</code></li><li><code>4</code></li><li><code>If</code></li></ul></li><li>åœ¨è´ªå¿ƒç­–ç•¥ä¸‹ï¼Œæ¨¡å‹ä¼šç›´æ¥é€‰æ‹© <code>5</code> ä½œä¸ºæœ€ç»ˆç­”æ¡ˆï¼Œè€Œä¸ä¼šè¿›è¡Œæ¨ç†ã€‚</li></ul><p>è¿™ç§æ–¹æ³•è™½ç„¶å¿«é€Ÿï¼Œä½†å­˜åœ¨å¦‚ä¸‹é—®é¢˜ï¼š</p><ul><li><strong>ç¼ºä¹æ¨ç†èƒ½åŠ›</strong>ï¼šæ¨¡å‹å¯èƒ½ç›´æ¥è¾“å‡ºé”™è¯¯ç­”æ¡ˆï¼Œå› ä¸ºå®ƒæ²¡æœ‰è¿›è¡Œæ¨ç†ã€‚</li><li><strong>å¯è§£é‡Šæ€§å·®</strong>ï¼šå¯¹äºå¤æ‚é—®é¢˜ï¼Œç”¨æˆ·æ— æ³•ç†è§£æ¨¡å‹æ˜¯å¦‚ä½•å¾—å‡ºç­”æ¡ˆçš„ã€‚</li></ul><p><strong>2. é€šè¿‡æ¨ç†ï¼ˆReasoning Before Answeringï¼‰æé«˜ç­”æ¡ˆè´¨é‡</strong></p><p>ç„¶è€Œï¼Œè¯·æ³¨æ„ä¸Šå›¾ä¸­æœ‰ä¸€äº›<strong>æ ‡è®°ï¼ˆtokens</strong>è¢«æ ‡çº¢ã€‚è¿™äº›tokenæ›´æœ‰å¯èƒ½å¼•å¯¼æ¨¡å‹è¿›å…¥ä¸€ä¸ªåˆç†çš„æ¨ç†è¿‡ç¨‹ã€‚è™½ç„¶é€‰æ‹©è´ªå¿ƒï¼ˆgreedyï¼‰ç­–ç•¥ä¸‹å¾—åˆ†æœ€é«˜çš„ token ä¸ä¸€å®šæ˜¯é”™è¯¯çš„ï¼Œä½†é€‰æ‹©é‚£äº›èƒ½å¼•å¯¼æ¨¡å‹è¿›å…¥æ¨ç†è¿‡ç¨‹çš„ tokenï¼Œé€šå¸¸ä¼šå¾—åˆ°æ›´å¥½çš„ç­”æ¡ˆã€‚<br>è®© LLM <strong>å…ˆè¿›è¡Œæ¨ç†ï¼Œå†ç»™å‡ºç­”æ¡ˆ</strong>ï¼Œå³ï¼š</p><ul><li>é€‰æ‹©æ¨ç† tokenï¼ˆå¦‚ <code>Adding</code>ï¼‰</li><li>é€æ­¥ç”Ÿæˆæ¨ç†è¿‡ç¨‹ï¼Œå¦‚ï¼š<ul><li><code>Adding â†’ 3 and 2 gives â†’ 5</code></li><li><code>If â†’ 3 + 1 = 4, 4 + 1 = 5 â†’ 5</code></li><li><code>The total is â†’ 5</code></li></ul></li><li>é€šè¿‡æ¨ç†é“¾æ¡é€æ­¥æ¨å¯¼å‡º <code>5</code>ï¼Œç›¸æ¯”ç›´æ¥é€‰æ‹© <code>5</code>ï¼Œè¿™ç§æ–¹æ³•æ›´åŠ å¯è§£é‡Šï¼Œå¹¶ä¸”èƒ½åœ¨å¤æ‚é—®é¢˜ä¸Šè¡¨ç°æ›´å¥½ã€‚</li></ul><p><strong>3. é€šè¿‡ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆRe-Ranking Token Probabilitiesï¼‰å¼•å¯¼æ¨ç†è¿‡ç¨‹</strong></p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_171002.png" class=""><p>å½“æˆ‘ä»¬<strong>ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆproposal distributionï¼Œå³ token çš„æ¦‚ç‡åˆ†å¸ƒï¼‰</strong>æ—¶ï¼Œå®é™…ä¸Šæ˜¯åœ¨<strong>é‡æ–°æ’åºï¼ˆre-rankï¼‰</strong>è¿™ä¸ªåˆ†å¸ƒï¼Œä½¿å¾—â€œæ¨ç†ç›¸å…³â€çš„ token è¢«é€‰ä¸­çš„æ¦‚ç‡æ›´é«˜ã€‚<br>åœ¨è¿™ç§æ–¹æ³•ä¸‹ï¼Œæˆ‘ä»¬è°ƒæ•´ LLM çš„æè®®åˆ†å¸ƒï¼Œä½¿å…¶æ›´å€¾å‘äºé€‰æ‹©æ¨ç† tokenï¼Œè€Œéç›´æ¥é€‰æ‹©ç­”æ¡ˆï¼š</p><ul><li>é»˜è®¤æƒ…å†µä¸‹ï¼Œ<code>5</code> å…·æœ‰æœ€é«˜æ¦‚ç‡ï¼Œè€Œ <code>Adding</code>ã€<code>If</code> ç­‰æ¨ç† token çš„æ¦‚ç‡è¾ƒä½ã€‚</li><li>é€šè¿‡ä¿®æ”¹æè®®åˆ†å¸ƒï¼Œæˆ‘ä»¬æé«˜ <code>Adding</code>ã€<code>If</code> çš„æ¦‚ç‡ï¼Œä½¿æ¨¡å‹å€¾å‘äºè¿›è¡Œæ¨ç†ã€‚</li></ul><p><strong>4. å¦‚ä½•å®ç°ä¿®æ”¹æè®®åˆ†å¸ƒï¼Ÿ</strong></p><p>ä¸»è¦æœ‰ä¸¤ç§æ–¹å¼ï¼š</p><ol><li><strong>é€šè¿‡ Prompt Engineering</strong><ul><li>ä¿®æ”¹ Promptï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ¨ç†æ­¥éª¤ã€‚</li><li>ä¾‹å¦‚ï¼š<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q: What is 3 + 2?</span><br><span class="line">A: Let's think step by step.</span><br></pre></td></tr></tbody></table></figure></li></ul></li><li><strong>è®­ç»ƒæ¨¡å‹æ›´å€¾å‘äºæ¨ç†</strong><ul><li>åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæä¾›æ›´å¤šå…·æœ‰æ¨ç†é“¾çš„è®­ç»ƒæ•°æ®ï¼Œè®©æ¨¡å‹ä¹ æƒ¯ç”Ÿæˆæ¨ç† tokenã€‚</li></ul></li></ol><p><strong>æ€»ç»“</strong></p><ul><li><strong>è´ªå¿ƒé€‰æ‹©ï¼ˆGreedy Selectionï¼‰</strong>ï¼šå¿«é€Ÿï¼Œä½†ç¼ºä¹æ¨ç†ï¼Œå¯è§£é‡Šæ€§å·®ã€‚</li><li><strong>æ¨ç†åå›ç­”ï¼ˆReasoning Before Answeringï¼‰</strong>ï¼šæé«˜ç­”æ¡ˆè´¨é‡å’Œå¯è§£é‡Šæ€§ã€‚</li><li><strong>ä¿®æ”¹æè®®åˆ†å¸ƒï¼ˆModifying Proposal Distributionï¼‰</strong>ï¼šè°ƒæ•´ token é€‰æ‹©çš„æ¦‚ç‡ï¼Œä½¿æ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©æ¨ç† tokenï¼Œæé«˜æ•´ä½“ç­”æ¡ˆçš„åˆç†æ€§ã€‚</li></ul><p>è¿™ç§æ–¹æ³•åœ¨<strong>æ•°å­¦è®¡ç®—ã€é€»è¾‘æ¨ç†ã€æ³•å¾‹æ¨ç†ç­‰ä»»åŠ¡</strong>ä¸Šå°¤ä¸ºé‡è¦ï¼Œä½¿å¾— LLM <strong>ä¸ä»…èƒ½â€œç­”å¯¹â€ï¼Œè¿˜èƒ½â€œè¯´æ˜ç™½â€</strong>ã€‚</p><h3 id="Prompting"><a href="#Prompting" class="headerlink" title="Prompting"></a><strong>Prompting</strong></h3><p>éšç€æˆ‘ä»¬ä½¿ç”¨ <strong>prompt engineering</strong>ï¼ˆæç¤ºå·¥ç¨‹ï¼‰æ¥æ”¹è¿›è¾“å‡ºï¼Œæˆ‘ä»¬ä¼šé€šè¿‡æ›´æ–°æç¤ºï¼ˆpromptï¼‰æ¥å°è¯•æå‡æ¨¡å‹çš„è¡¨ç°ã€‚è¿™ä¸ªè¿‡ç¨‹ä¹Ÿå¯èƒ½æ¨åŠ¨æ¨¡å‹å»å±•ç¤ºå…ˆå‰æˆ‘ä»¬çœ‹åˆ°çš„ä¸€äº›<strong>reasoning</strong>ï¼ˆæ¨ç†ï¼‰è¿‡ç¨‹ã€‚</p><p><strong>1. æ”¹å˜ Proposal Distribution</strong></p><p>åœ¨æ›´æ”¹ <strong>proposal distribution</strong>æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç»™æ¨¡å‹æä¾›ç¤ºä¾‹ï¼ˆä¹Ÿå«åš <strong>in-context learning</strong>ï¼‰ï¼Œè®©å®ƒåœ¨ç”Ÿæˆç­”æ¡ˆæ—¶æ¨¡ä»¿ç±»ä¼¼çš„æ¨ç†é£æ ¼ã€‚ä¸‹é¢çš„å›¾å°±å±•ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹çš„æƒ…å½¢ï¼š</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_172130.png" class=""><blockquote><ul><li><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå·¦ä¾§æ˜¯ä¸€ä¸ªç®€å•çš„é—®é¢˜ â€œWhat is 3 + 2?â€ï¼Œæ¨¡å‹å†…éƒ¨ç”¨ â€œThoughtsâ€ è¡¨ç¤ºéšè—çš„æ€è€ƒè¿‡ç¨‹ï¼Œæ¯”å¦‚ï¼š<ol><li>First, 3 and 1 gives 4.</li><li>Then, 4 and 1 gives 5.</li><li>I believe the answer is 5.</li></ol></li><li><strong>Answer</strong>ï¼ˆç­”æ¡ˆï¼‰ï¼š5</li><li>å³ä¾§ç”¨çº¢è‰²ã€è“è‰²ç­‰ä¸åŒé¢œè‰²çš„æ¡å½¢æˆ–æ–¹å—è¡¨ç¤ºæ¨ç†è¿‡ç¨‹çš„ä¸åŒéƒ¨åˆ†ï¼Œç¤ºæ„æœ‰ä¸€éƒ¨åˆ†å±äºéšè—çš„æ¨ç†è¿‡ç¨‹ï¼ˆçº¢è‰²ï¼‰ï¼Œä»¥åŠè¾“å‡ºç»“æœæˆ–è‹¥å¹²ä¸­é—´æ­¥éª¤ï¼ˆè“è‰²ï¼‰ã€‚</li></ul></blockquote><p>é€šè¿‡ç±»ä¼¼çš„ç¤ºä¾‹ï¼Œæ¨¡å‹åœ¨æ¨ç†æ—¶å°±å¯èƒ½æ¨¡ä»¿ç±»ä¼¼çš„æ ¼å¼æ¥è¿›è¡Œ<strong>reasoning</strong>å¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚</p><p><strong>2. â€œLetâ€™s think step-by-stepâ€ çš„å½±å“</strong></p><p>æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­ç›´æ¥ä½¿ç”¨ â€œLetâ€™s think step-by-stepâ€ æ¥ç®€åŒ–ä¸Šè¿°æµç¨‹ã€‚è¿™ä¼šæ”¹å˜æ¨¡å‹çš„ <strong>proposal distribution</strong>ï¼Œè®© <strong>LLM</strong>ï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰å€¾å‘äºåœ¨å›ç­”ä¹‹å‰åˆ†æ­¥éª¤æ€è€ƒã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_172232.png" class=""><blockquote><ul><li><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šè¿™é‡Œå°†æç¤ºæ¢æˆ â€œLetâ€™s think step-by-stepâ€ï¼Œé—®é¢˜ä»ç„¶æ˜¯ â€œWhat is 3 + 2?â€ã€‚</li><li>æ¨¡å‹äº§ç”Ÿæ›´æ˜¾å¼çš„æ¨ç†è¿‡ç¨‹ï¼ˆç”¨çº¢è‰²å—ç¤ºæ„ï¼‰ï¼Œå†è¾“å‡ºæ­£ç¡®ç­”æ¡ˆ 5ã€‚</li><li>æ•´ä¸ªæ€è·¯ç±»ä¼¼å›¾1ï¼Œä½†æ›´åŠ çªå‡ºâ€œåˆ†æ­¥éª¤æ€è€ƒâ€å¯¹æœ€ç»ˆç­”æ¡ˆç”Ÿæˆçš„å½±å“ã€‚</li></ul></blockquote><p>ç„¶è€Œï¼Œè¿™å¹¶ä¸æ„å‘³ç€æ¨¡å‹æœ¬èº«å·²ç»å†…åŒ–äº†è¿™ç§æ¨ç†èƒ½åŠ›â€”â€”å®ƒ<strong>å¹¶æ²¡æœ‰ä»æ ¹æœ¬ä¸Šå­¦ä¼š</strong>å»â€œåæ€â€æˆ–â€œä¿®æ­£â€é”™è¯¯ã€‚å¦‚æœæ¨¡å‹ä¸€å¼€å§‹çš„æ¨ç†è¿‡ç¨‹æ˜¯é”™è¯¯çš„ï¼Œé‚£ä¹ˆåœ¨è¿™ç§é™æ€ä¸”çº¿æ€§çš„æµç¨‹ä¸­ï¼Œå®ƒå¾€å¾€ä¼šä¸€ç›´å»¶ç»­è¿™ä¸ªé”™è¯¯ï¼Œè€Œä¸æ˜¯å¯¹è‡ªèº«æ¨ç†è¿›è¡Œä¿®æ­£ã€‚</p><hr><h3 id="STaRï¼ˆSelf-Taught-Reasonerï¼‰"><a href="#STaRï¼ˆSelf-Taught-Reasonerï¼‰" class="headerlink" title="STaRï¼ˆSelf-Taught Reasonerï¼‰"></a><strong>STaRï¼ˆSelf-Taught Reasonerï¼‰</strong></h3><p>é™¤äº†é€šè¿‡ <strong>prompting</strong>ï¼ˆæç¤ºï¼‰è®©æ¨¡å‹ä¸´æ—¶å±•ç¤ºæ¨ç†æ­¥éª¤ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®©æ¨¡å‹åœ¨è®­ç»ƒä¸­å› ä¸ºâ€œäº§ç”Ÿæ­£ç¡®æ¨ç†æ­¥éª¤â€è€Œå¾—åˆ°å¥–åŠ±ï¼Œä»è€Œè®©å®ƒçœŸæ­£â€œå­¦ä¼šâ€æ¨ç†ã€‚è¿™é€šå¸¸éœ€è¦åœ¨<strong>å¤§é‡å¸¦æœ‰æ¨ç†è¿‡ç¨‹çš„æ•°æ®</strong>ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ç»“åˆ <strong>reinforcement learning</strong>ï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰æ¥å¥–åŠ±ç‰¹å®šçš„è¡Œä¸ºã€‚</p><p>ä¸€ä¸ªé¢‡å—äº‰è®®ï¼ˆâ€œmuch-debatedâ€ï¼‰çš„æŠ€æœ¯å°±æ˜¯ <strong>STaR</strong>ï¼Œå³ <strong>Self-Taught Reasoner</strong>ã€‚å®ƒæ˜¯è®© <strong>LLM</strong> ç”Ÿæˆè‡ªå·±çš„æ¨ç†æ•°æ®ï¼Œå†æŠŠè¿™äº›æ•°æ®ç”¨äºå¯¹æ¨¡å‹è¿›è¡Œ<strong>ç²¾è°ƒ</strong>ï¼ˆ<em>fine-tuning</em>ï¼‰çš„è¿‡ç¨‹ã€‚</p><p><strong>1. STaR çš„æµç¨‹æ¦‚è¿°</strong></p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_172455.png" class=""><ul><li>è¿™å¹…å›¾æ¦‚æ‹¬äº† STaR çš„å·¥ä½œåŸç†ï¼š<ol><li><strong>Generate reasoning + answer</strong>ï¼šæ¨¡å‹å…ˆé’ˆå¯¹è¾“å…¥é—®é¢˜ç”Ÿæˆä¸€æ®µ <strong>reasoning</strong>ï¼ˆæ¨ç†ï¼‰å’Œä¸€ä¸ª <strong>answer</strong>ï¼ˆç­”æ¡ˆï¼‰ï¼›<br>2a. å¦‚æœç­”æ¡ˆæ­£ç¡®ï¼ˆCorrect answerï¼‰ï¼Œåˆ™å°† <strong>Question, Reasoning, Answer</strong> ä½œä¸ºè®­ç»ƒæ ·æœ¬æ·»åŠ åˆ°ä¸‰å…ƒç»„æ•°æ®é›†ä¸­ï¼ˆ3aï¼‰ï¼›<br>  3b. åˆ©ç”¨è¿™äº›ä¸‰å…ƒç»„æ•°æ®è¿›è¡Œ <strong>supervised fine-tuning</strong>ï¼ˆç›‘ç£å¾®è°ƒï¼‰ï¼Œè®©æ¨¡å‹å­¦ä¼šåœ¨ç±»ä¼¼æƒ…å½¢ä¸‹äº§å‡ºæ­£ç¡®æ¨ç†ä¸ç­”æ¡ˆã€‚</li></ol></li></ul><p>å¦‚æœæ¨¡å‹ç»™å‡ºäº†é”™è¯¯ç­”æ¡ˆï¼Œåˆ™ä¼šè§¦å‘å¦ä¸€æ¡è·¯å¾„ï¼š</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_172608.png" class=""><ul><li>å½“ (2b) æ¨¡å‹ç­”æ¡ˆé”™è¯¯æ—¶ï¼Œæˆ‘ä»¬æä¾›æ­£ç¡®ç­”æ¡ˆä½œä¸º <strong>hint</strong>ï¼ˆæç¤ºï¼‰ï¼Œå¹¶è®©æ¨¡å‹å»æ€è€ƒâ€œä¸ºä»€ä¹ˆè¿™ä¸ªç­”æ¡ˆæ˜¯æ­£ç¡®çš„â€ï¼›</li><li>ä¹Ÿå°±æ˜¯ <strong>Generate reasoning only</strong> (why this answer is correct?)ï¼›</li><li>å¾—åˆ°çš„è¿™æ®µæ–°çš„æ¨ç†ä¾æ—§ä¼šè¢«åŠ å…¥åˆ°ä¸‰å…ƒç»„æ•°æ®ä¸­ï¼Œç„¶åå†è¿›è¡Œ <strong>supervised fine-tuning</strong>ã€‚</li></ul><p>è¿™é‡Œçš„å…³é”®è¦ç‚¹æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ç§æ–¹æ³•<strong>æ˜¾å¼</strong>åœ°è®­ç»ƒæ¨¡å‹â€œåº”è¯¥å¦‚ä½•è¿›è¡Œæ¨ç†â€ï¼Œè€Œä¸ä»…ä»…æ˜¯è®©å®ƒä¸´æ—¶åœ°æ¨¡ä»¿æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬è¦å¯¹æ¨¡å‹çš„æ¨ç†æ–¹å¼è¿›è¡Œ<strong>ç›‘ç£</strong>ï¼ˆ<em>supervised fine-tuning</em>ï¼‰ï¼Œä»è€ŒæŠŠæˆ‘ä»¬æƒ³è¦çš„æ¨ç†æ¨¡å¼â€œçŒè¾“â€ç»™æ¨¡å‹ã€‚</p><p><strong>2. è‡ªåŠ¨ç”Ÿæˆåˆæˆè®­ç»ƒæ ·æœ¬</strong></p><p>STaR çš„æ•´ä¸ªæµç¨‹éå¸¸æœ‰è¶£ï¼Œå› ä¸ºå®ƒä¼š<strong>è‡ªåŠ¨ç”Ÿæˆåˆæˆè®­ç»ƒæ ·æœ¬</strong>ï¼ˆ<em>synthetic training examples</em>ï¼‰ã€‚è¿™äº›æ ·æœ¬ä¸ä»…åŒ…å«é—®é¢˜å’Œç­”æ¡ˆï¼Œè¿˜åŒ…å«ä¸€ç³»åˆ—æ¨ç†æ­¥éª¤ï¼Œèƒ½å¤Ÿå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ å¦‚ä½•â€œæ€è€ƒâ€ã€‚åœ¨å…¶ä»–ç ”ç©¶ä¸­ï¼ˆä¾‹å¦‚ <strong>DeepSeek R-1</strong>ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™äº›åˆæˆæ ·æœ¬æ¥<strong>è’¸é¦</strong>ï¼ˆ<em>distill</em>ï¼Œæ„ä¸ºâ€œæç‚¼å’Œä¿ç•™å…³é”®ä¿¡æ¯â€ï¼‰æ¨ç†è¿‡ç¨‹åˆ°å…¶å®ƒæ¨¡å‹ä¸Šã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€ä¸ªæŒæ¡äº†æ¨ç†èƒ½åŠ›çš„æ¨¡å‹å¯ä»¥å¸®åŠ©å¦ä¸€ä¸ªæ¨¡å‹æ›´å¿«åœ°å­¦ä¼šç±»ä¼¼çš„æ¨ç†ã€‚</p><hr><p><strong>é‡ç‚¹ï¼š</strong></p><ul><li><strong>Prompting</strong>ï¼ˆæç¤ºï¼‰èƒ½å¤Ÿå½±å“æ¨¡å‹çš„è¾“å‡ºé£æ ¼å’Œæ€ç»´è¿‡ç¨‹ï¼Œæ¯”å¦‚ä½¿ç”¨ â€œLetâ€™s think step-by-stepâ€ è®©æ¨¡å‹æ˜¾å¼ç»™å‡ºæ¨ç†æ­¥éª¤ï¼Œä½†å¹¶ä¸ä¿è¯æ¨¡å‹è‡ªåŠ¨çº æ­£é”™è¯¯ã€‚</li><li><strong>STaR</strong>ï¼ˆ<strong>Self-Taught Reasoner</strong>ï¼‰ç­‰æ–¹æ³•åˆ™é€šè¿‡<strong>ç”Ÿæˆæ¨ç†æ•°æ®ã€ç›‘ç£å¾®è°ƒå’Œå¥–åŠ±æœºåˆ¶</strong>ï¼Œå¸®åŠ©æ¨¡å‹çœŸæ­£å­¦ä¼šæŒ‰ç…§æŒ‡å®šçš„æ¨ç†æ–¹å¼å»æ€è€ƒå’Œå›ç­”é—®é¢˜ã€‚</li><li>æ— è®ºæ˜¯å“ªä¸€ç§æ–¹æ³•ï¼Œéƒ½å¯ä»¥è§†ä¸ºå¯¹ <strong>proposal distribution</strong> çš„è°ƒèŠ‚ï¼šè¦ä¹ˆæ˜¯æç¤ºæ—¶ä¸´æ—¶<strong>nudge</strong>ï¼ˆå¼•å¯¼ï¼‰ï¼Œè¦ä¹ˆæ˜¯ä»è®­ç»ƒæ ¹æºä¸Šè¿›è¡Œè°ƒæ•™ï¼Œè®©æ¨¡å‹å†…åŒ–è¿™ç§æ¨ç†è¿‡ç¨‹ã€‚</li><li>åˆ©ç”¨ <strong>in-context learning</strong> æä¾›ç¤ºä¾‹ï¼Œèƒ½å¤Ÿè®©æ¨¡å‹æ¨¡ä»¿æ¨ç†é£æ ¼ã€‚</li><li>ç”¨ <strong>reinforcement learning</strong> æˆ–<strong>ç›‘ç£å¾®è°ƒ</strong>ï¼ˆ<strong>supervised fine-tuning</strong>ï¼‰å¯ä»¥ä½¿æ¨¡å‹é€æ¸æŒæ¡æˆ‘ä»¬æœŸæœ›çš„æ¨ç†æ¨¡å¼ã€‚</li><li><strong>STaR</strong> æ–¹æ³•ä¼šè‡ªåŠ¨æ”¶é›†â€œæ­£ç¡®æ¨ç†â€æ•°æ®å¹¶è¿›è¡Œè®­ç»ƒï¼Œä½¿å¾—æ¨¡å‹åœ¨åç»­å›ç­”ä¸­æ›´å¯èƒ½äº§ç”Ÿæ­£ç¡®ä¸”ç¬¦åˆè¦æ±‚çš„æ¨ç†æ­¥éª¤ã€‚</li></ul><hr><h2 id="DeepSeek-R1"><a href="#DeepSeek-R1" class="headerlink" title="DeepSeek-R1"></a>DeepSeek-R1</h2><hr><h3 id="1-ç®€ä»‹"><a href="#1-ç®€ä»‹" class="headerlink" title="1. ç®€ä»‹"></a>1. ç®€ä»‹</h3><p><strong>DeepSeek-R1</strong> æ˜¯ä¸€ä¸ªåœ¨æ¨ç†ï¼ˆreasoningï¼‰æ¨¡å‹é¢†åŸŸçš„é‡å¤§ç‰ˆæœ¬ï¼Œå…¶æƒé‡å·²ç»å¼€æºã€‚å®ƒç›´æ¥ä¸ OpenAI çš„ <strong>o1</strong> æ¨ç†æ¨¡å‹å±•å¼€ç«äº‰ï¼Œå¹¶åœ¨è¿™ä¸€é¢†åŸŸäº§ç”Ÿäº†é‡å¤§å½±å“ã€‚</p><p>DeepSeek é¡¹ç›®åœ¨å°†æ¨ç†åŠŸèƒ½ä¼˜é›…åœ°æ•´åˆè¿›å…¶åŸºç¡€æ¨¡å‹ï¼ˆ<strong>DeepSeek-V3-Base</strong>ï¼‰æ–¹é¢æˆå°±å“è‘—ï¼Œé‡‡ç”¨äº†å¤šç§æŠ€æœ¯æ¥å®Œæˆè¿™ä¸€ç›®æ ‡ã€‚</p><p>æœ‰è¶£çš„æ˜¯ï¼Œè¯¥é¡¹ç›®åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¹¶æœªä¾èµ–é¢å¤–çš„éªŒè¯å™¨ï¼ˆverifierï¼‰ï¼Œè€Œä¸”å¹¶ä¸æ˜¯å•çº¯åœ°ä¾é ç›‘ç£å¾®è°ƒï¼ˆsupervised fine-tuningï¼‰æ¥æç‚¼æ¨ç†è¡Œä¸ºã€‚ç›¸åï¼Œ<strong>å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰</strong> åœ¨å…¶ä¸­æ‰®æ¼”äº†é‡è¦è§’è‰²ã€‚</p><p>ä»¥ä¸‹æˆ‘ä»¬å°†ä¸€èµ·æ¢ç©¶ä»–ä»¬æ˜¯å¦‚ä½•åœ¨æ¨¡å‹ä¸­è®­ç»ƒå‡ºæ¨ç†è¡Œä¸ºçš„ï¼</p><hr><h3 id="2-DeepSeek-R1-Zeroï¼šæ¨ç†çš„å…³é”®æ¢ç´¢"><a href="#2-DeepSeek-R1-Zeroï¼šæ¨ç†çš„å…³é”®æ¢ç´¢" class="headerlink" title="2. DeepSeek-R1 Zeroï¼šæ¨ç†çš„å…³é”®æ¢ç´¢"></a>2. DeepSeek-R1 Zeroï¼šæ¨ç†çš„å…³é”®æ¢ç´¢</h3><p>åœ¨é€šå¾€ <strong>DeepSeek-R1</strong> çš„é“è·¯ä¸Šï¼Œæœ‰ä¸€ä¸ªåä¸º <strong>DeepSeek-R1 Zero</strong> çš„å®éªŒæ€§æ¨¡å‹ä¸ºè¿™æ¬¡çªç ´æ‰“ä¸‹äº†åŸºç¡€ã€‚å®ƒä» <strong>DeepSeek-V3-Base</strong> å‡ºå‘ï¼Œå®Œå…¨ä¸ä½¿ç”¨å¤§è§„æ¨¡ç›‘ç£å¾®è°ƒæ¥åŠ å…¥æ¨ç†æ•°æ®ï¼Œè€Œæ˜¯åªä¾é  <strong>å¼ºåŒ–å­¦ä¹ </strong> æ¥è·å¾—æ¨ç†èƒ½åŠ›ã€‚</p><h4 id="è®­ç»ƒè¿‡ç¨‹ä¸ç³»ç»Ÿæç¤ºï¼ˆPromptï¼‰"><a href="#è®­ç»ƒè¿‡ç¨‹ä¸ç³»ç»Ÿæç¤ºï¼ˆPromptï¼‰" class="headerlink" title="è®­ç»ƒè¿‡ç¨‹ä¸ç³»ç»Ÿæç¤ºï¼ˆPromptï¼‰"></a>è®­ç»ƒè¿‡ç¨‹ä¸ç³»ç»Ÿæç¤ºï¼ˆPromptï¼‰</h4><p>åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä»–ä»¬é¦–å…ˆå‡†å¤‡äº†ä¸€ä¸ªéå¸¸ç›´æ¥çš„æç¤ºï¼ˆpromptï¼‰ï¼Œå…¶å½¢å¼ç±»ä¼¼äºç³»ç»Ÿæç¤ºï¼ˆsystem promptï¼‰ï¼Œç”¨æ¥ä½œä¸ºæ¨ç†ç®¡çº¿çš„ä¸€éƒ¨åˆ†ã€‚ä¸‹æ–‡å³å±•ç¤ºäº†ç›¸å…³æç¤ºã€‚è¯·æ³¨æ„ï¼Œå…¶ä¸­æ˜ç¡®æŒ‡å‡ºäº†æ¨ç†è¿‡ç¨‹è¦å†™åœ¨ <code>&lt;think&gt;</code> æ ‡ç­¾å†…ã€ç­”æ¡ˆè¦å†™åœ¨ <code>&lt;answer&gt;</code> æ ‡ç­¾å†…ï¼Œä½†æ²¡æœ‰è¿›ä¸€æ­¥è§„å®šæ¨ç†è¿‡ç¨‹åº”å¦‚ä½•å…·ä½“å‘ˆç°æˆ–ç»„ç»‡ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_183150.png" class=""><p>åœ¨ä¸Šå›¾ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¸€ä¸ªç®€åŒ–ç‰ˆçš„å¯¹è¯ç¤ºä¾‹ï¼ˆSystem prompt ä¸ User promptï¼‰ä»¥åŠæ¨¡å‹å¦‚ä½•å°†<strong>æ¨ç†</strong>ï¼ˆreasoningï¼‰æ”¾åœ¨ <code>&lt;think&gt;</code> æ ‡ç­¾å†…ã€å°†<strong>ç­”æ¡ˆ</strong>ï¼ˆanswerï¼‰æ”¾åœ¨ <code>&lt;answer&gt;</code> æ ‡ç­¾å†…ã€‚è¯¥å›¾çªå‡ºå±•ç¤ºäº†åœ¨æç¤ºï¼ˆpromptï¼‰ä¸­å¯¹æ¨¡å‹çš„çº¦æŸï¼š</p><ul><li><em>â€œThe assistant first thinks about the reasoning process in the mind and then provides the user with the answer.â€</em></li><li>è¦æ±‚ä½¿ç”¨ <code>&lt;think&gt;</code> è¿›è¡Œæ¨ç†ï¼Œä½¿ç”¨ <code>&lt;answer&gt;</code> è¿›è¡Œå›ç­”ã€‚</li></ul><p>è¿™é‡Œå¹¶æœªæä¾›å…³äºâ€œæ¨ç†è¿‡ç¨‹â€æ ¼å¼çš„å…¶ä»–ä¾‹å­æˆ–æ¨¡æ¿â€”â€”å®Œå…¨ç”±æ¨¡å‹è‡ªå·±åœ¨è®­ç»ƒä¸­æ‘¸ç´¢å‡ºè¦å¦‚ä½•è¾“å‡ºâ€œChain-of-Thoughtâ€å¼çš„æ¨ç†æ–‡å­—ã€‚</p><h4 id="å¼ºåŒ–å­¦ä¹ å¥–åŠ±"><a href="#å¼ºåŒ–å­¦ä¹ å¥–åŠ±" class="headerlink" title="å¼ºåŒ–å­¦ä¹ å¥–åŠ±"></a>å¼ºåŒ–å­¦ä¹ å¥–åŠ±</h4><p>åœ¨è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ä¸¤ä¸ªåŸºäºè§„åˆ™ï¼ˆrule-basedï¼‰çš„å¥–åŠ±æœºåˆ¶ï¼š</p><ol><li><strong>å‡†ç¡®æ€§å¥–åŠ±ï¼ˆAccuracy rewardsï¼‰</strong><br>é€šè¿‡æµ‹è¯•ç»™å‡ºçš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®æ¥è¿›è¡Œå¥–åŠ±ã€‚è‹¥æ¨¡å‹è¾“å‡ºçš„ç­”æ¡ˆæ­£ç¡®ï¼Œå°±ä¼šå¢åŠ å¥–åŠ±ã€‚</li><li><strong>æ ¼å¼å¥–åŠ±ï¼ˆFormat rewardsï¼‰</strong><br>å¥–åŠ±æ¨¡å‹å¯¹ <code>&lt;think&gt;</code> å’Œ <code>&lt;answer&gt;</code> æ ‡ç­¾çš„æ­£ç¡®ä½¿ç”¨ã€‚</li></ol><p>ä»–ä»¬æ‰€ä½¿ç”¨çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•åä¸º <strong>Group Relative Policy Optimizationï¼ˆGRPOï¼‰</strong>ã€‚æ­¤ç®—æ³•çš„ç›´è§‚æƒ³æ³•åœ¨äºï¼šä½¿æ‰€æœ‰å¯¼è‡´æ­£ç¡®æˆ–é”™è¯¯ç­”æ¡ˆçš„å†³ç­–æ›´æ˜“æˆ–æ›´éš¾å†æ¬¡å‡ºç°ã€‚è¿™äº›å†³ç­–å¯èƒ½åŒ…æ‹¬æ¨¡å‹ç”Ÿæˆçš„æŸäº›æ ‡è®°ï¼ˆtokenï¼‰åºåˆ—ï¼Œä¹Ÿå¯èƒ½åŒ…æ‹¬æ¨ç†æ­¥éª¤æœ¬èº«ï¼ˆå³æ€è€ƒè¿‡ç¨‹ï¼‰ã€‚ä¸‹æ–‡ç»™å‡ºäº†è¿™ä¸€è®­ç»ƒé˜¶æ®µçš„ç¤ºæ„å›¾ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_183402.png" class=""><p>åœ¨å›¾ä¸­ï¼Œé‡ç‚¹å±•ç¤ºäº†åœ¨ RLï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰è¿‡ç¨‹ä¸­æ‰€ä½¿ç”¨çš„ä¸¤ç±»å¥–åŠ±ï¼š</p><ul><li>â€œis <code>&lt;think&gt;</code> used?â€ â€”â€” ä¸ºä½¿ç”¨ <code>&lt;think&gt;</code> æ ‡ç­¾è€Œæ‰“åˆ†ã€‚</li><li>â€œis <code>&lt;answer&gt;</code> used?â€ â€”â€” ä¸ºä½¿ç”¨ <code>&lt;answer&gt;</code> æ ‡ç­¾è€Œæ‰“åˆ†ã€‚</li></ul><p>é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰å¯¹ç­”æ¡ˆ<strong>æ­£ç¡®æ€§</strong>çš„å¥–åŠ±ï¼ˆaccuracy rewardï¼‰ã€‚å›¾ä¸­ç®­å¤´æ‰€ç¤ºçš„å¾ªç¯ä»£è¡¨äº†åœ¨è®­ç»ƒä¸­ä¸æ–­è¿­ä»£æ›´æ–°æ¨¡å‹ï¼Œä½¿ä¹‹è¶Šæ¥è¶Šå€¾å‘äºæ­£ç¡®çš„æ¨ç†æ–¹å¼å¹¶åˆä¹æ ¼å¼è¦æ±‚ã€‚</p><h4 id="è‡ªå‘æ¨ç†è¡Œä¸ºçš„å‡ºç°"><a href="#è‡ªå‘æ¨ç†è¡Œä¸ºçš„å‡ºç°" class="headerlink" title="è‡ªå‘æ¨ç†è¡Œä¸ºçš„å‡ºç°"></a>è‡ªå‘æ¨ç†è¡Œä¸ºçš„å‡ºç°</h4><p>å€¼å¾—ä¸€æçš„æ˜¯ï¼Œç ”ç©¶äººå‘˜å¹¶æ²¡æœ‰å‘æ¨¡å‹æä¾›ä»»ä½•ç¤ºä¾‹æ¥å‘Šè¯‰å®ƒ <code>&lt;think&gt;</code> æ ‡ç­¾ä¸­çš„å†…å®¹åº”è¯¥å¦‚ä½•ä¹¦å†™æˆ–å±•å¼€ã€‚ä»–ä»¬ä»…ä»…å‘Šè¯‰æ¨¡å‹ï¼š</p><blockquote><p>â€œIt should use <code>&lt;think&gt;</code> tags, and nothing more!â€</p></blockquote><p>é€šè¿‡å¯¹â€œChain-of-Thoughtâ€ç›¸å…³è¡Œä¸ºè¿›è¡Œ<strong>é—´æ¥å¥–åŠ±</strong>ï¼ˆå³åªè¦æ¨ç†æ­£ç¡®ã€ä½¿ç”¨æ­£ç¡®æ ¼å¼ï¼Œå°±é¼“åŠ±è¾“å‡ºæ›´å®Œæ•´çš„æ¨ç†å†…å®¹ï¼‰ï¼Œæ¨¡å‹åœ¨è®­ç»ƒä¸­è‡ªå‘åœ°å­¦ä¼šäº†è¶Šå†™è¶Šé•¿çš„æ¨ç†è¿‡ç¨‹ï¼Œä¹Ÿæ›´æ˜“äº§ç”Ÿæ­£ç¡®ç­”æ¡ˆã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_183551.png" class=""><p>ä¸Šå›¾å‘ˆç°äº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¾“å‡ºçš„æ¨ç†é•¿åº¦éšè®­ç»ƒæ­¥æ•°å¢åŠ è€Œé€æ¸å˜é•¿çš„è¶‹åŠ¿ã€‚çºµè½´æ˜¯æ¯ä¸ªå“åº”çš„å¹³å‡é•¿åº¦ï¼Œæ¨ªè½´æ˜¯è®­ç»ƒæ­¥æ•°ã€‚å¯ä»¥çœ‹åˆ°ï¼Œæ›²çº¿æ•´ä½“æ˜¯å‘ä¸Šæ”€å‡çš„ï¼Œè¿™è¡¨æ˜æ¨¡å‹ä¸æ–­å€¾å‘äºè¾“å‡ºæ›´é•¿ã€æ›´è¯¦ç»†çš„æ€è€ƒå†…å®¹ï¼ˆChain-of-Thoughtï¼‰ï¼Œå¹¶å› æ­¤è·å¾—æ›´é«˜å¥–åŠ±ã€‚è¿™ç§åšæ³•å°†å¤§éƒ¨åˆ†è®¡ç®—æ¶ˆè€—ä»è®­ç»ƒé˜¶æ®µï¼ˆtrain-time computeï¼‰è½¬ç§»åˆ°äº†æ¨ç†é˜¶æ®µï¼ˆtest-time computeï¼‰ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¨ç†æ—¶æ‰ç”Ÿæˆæ›´é•¿çš„æ€è€ƒè¿‡ç¨‹ã€‚</p><p>æ ¹æ®ç ”ç©¶ï¼Œä»–ä»¬å‘ç°é€šè¿‡è¿™ç§è®­ç»ƒç­–ç•¥ï¼Œæ¨¡å‹èƒ½å¤Ÿè‡ªè¡Œå‘ç°æœ€ä¼˜çš„ Chain-of-Thought é£æ ¼çš„æ€è€ƒæ–¹å¼ï¼Œå¹¶å±•ç°å‡ºé«˜çº§çš„æ¨ç†èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼š<strong>è‡ªæˆ‘åæ€ï¼ˆself-reflectionï¼‰</strong> å’Œ <strong>è‡ªæˆ‘éªŒè¯ï¼ˆself-verificationï¼‰</strong>ã€‚</p><p>ä¸è¿‡ï¼ŒDeepSeek-R1 Zero çš„æ¨¡å‹è¾“å‡ºä»å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚å¯è¯»æ€§æ¬ ä½³ï¼Œä¸”æœ‰æ—¶ä¼šæ··ç”¨å¤šç§è¯­è¨€ã€‚ä¸ºäº†åœ¨äº§å“åŒ–æˆ–å‘å¸ƒçº§åˆ«è¿›ä¸€æ­¥å®Œå–„ï¼Œç ”ç©¶äººå‘˜æå‡ºäº†å¦ä¸€ä¸ªé€‰é¡¹ï¼Œä¹Ÿå°±æ˜¯åœ¨æ­£å¼ç‰ˆæœ¬ä¸­ä½¿ç”¨çš„ <strong>DeepSeek R1</strong>ã€‚</p><hr><h3 id="3-æ·±å…¥äº†è§£-DeepSeek-R1"><a href="#3-æ·±å…¥äº†è§£-DeepSeek-R1" class="headerlink" title="3. æ·±å…¥äº†è§£ DeepSeek-R1"></a>3. æ·±å…¥äº†è§£ DeepSeek-R1</h3><p>è¦æ„å»º <strong>DeepSeek-R1</strong>ï¼Œä½œè€…å…±è¿›è¡Œäº†ä»¥ä¸‹äº”ä¸ªå…³é”®æ­¥éª¤ï¼š</p><ol><li><strong>å†·å¯åŠ¨ï¼ˆCold Startï¼‰</strong></li><li><strong>ä»¥æ¨ç†ä¸ºå¯¼å‘çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReasoning-oriented Reinforcement Learningï¼‰</strong></li><li><strong>æ‹’ç»é‡‡æ ·ï¼ˆRejection Samplingï¼‰</strong></li><li><strong>ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰</strong></li><li><strong>åœ¨æ‰€æœ‰åœºæ™¯ä¸‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning for all Scenariosï¼‰</strong></li></ol><p>æ¥ä¸‹æ¥æˆ‘ä»¬ä¾æ¬¡å±•å¼€è¯´æ˜ã€‚</p><hr><h4 id="ç¬¬ä¸€æ­¥ï¼šå†·å¯åŠ¨"><a href="#ç¬¬ä¸€æ­¥ï¼šå†·å¯åŠ¨" class="headerlink" title="ç¬¬ä¸€æ­¥ï¼šå†·å¯åŠ¨"></a>ç¬¬ä¸€æ­¥ï¼šå†·å¯åŠ¨</h4><p>åœ¨ç¬¬ä¸€æ­¥ä¸­ï¼Œç ”ç©¶äººå‘˜å…ˆä½¿ç”¨äº†ä¸€ä¸ªçº¦ 5000 ä¸ªtokensçš„é«˜è´¨é‡æ¨ç†æ•°æ®é›†å¯¹ <strong>DeepSeek-V3-Base</strong> è¿›è¡Œå¾®è°ƒï¼Œä»¥é¿å…äº§ç”Ÿå¯è¯»æ€§ä¸ä½³çš„<strong>å†·å¯åŠ¨é—®é¢˜ï¼ˆcold start problemï¼‰</strong>ã€‚è¿™ä¸ªå¾®è°ƒæ­¥éª¤å¯ä»¥è®©æ¨¡å‹çš„è¾“å‡ºæ›´åŠ å¯è¯»ï¼Œä¸è‡³äºåœ¨ä¸€å¼€å§‹å°±äº§ç”Ÿæ··ä¹±çš„æ¨ç†æ–‡æœ¬ã€‚ä¸‹æ–‡å±•ç¤ºäº†è¿™ä¸€è¿‡ç¨‹çš„ç¤ºæ„å›¾ã€‚</p><hr><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_184058.png" class=""><p>åœ¨å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼š</p><ul><li>â€œDeepSeek-V3-Baseâ€ é€šè¿‡<strong>ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰</strong>çš„æ–¹å¼ï¼Œå¼•å…¥äº†çº¦ 5000 æ¡é«˜è´¨é‡æ¨ç†æ ·æœ¬ã€‚</li><li>è¿™äº›æ ·æœ¬åŒ…å«äº†<strong>Reasoning</strong>ï¼ˆæ¨ç†ï¼‰å’Œ<strong>Answer</strong>ï¼ˆç­”æ¡ˆï¼‰ä¸¤ç§éƒ¨åˆ†ã€‚</li><li>è¯¥æ­¥éª¤ç›®çš„æ˜¯â€œé˜²æ­¢å†·å¯åŠ¨â€ï¼Œå³è®©æ¨¡å‹åœ¨ä¸€å¼€å§‹å°±æŒæ¡åŸºç¡€çš„å¯è¯»æ€§æ¨ç†ã€‚</li></ul><hr><h4 id="ç¬¬äºŒæ­¥ï¼šæ¨ç†å¯¼å‘çš„å¼ºåŒ–å­¦ä¹ "><a href="#ç¬¬äºŒæ­¥ï¼šæ¨ç†å¯¼å‘çš„å¼ºåŒ–å­¦ä¹ " class="headerlink" title="ç¬¬äºŒæ­¥ï¼šæ¨ç†å¯¼å‘çš„å¼ºåŒ–å­¦ä¹ "></a>ç¬¬äºŒæ­¥ï¼šæ¨ç†å¯¼å‘çš„å¼ºåŒ–å­¦ä¹ </h4><p>åœ¨å¾—åˆ°ä¸€ä¸ªåˆæ­¥å¾®è°ƒåçš„æ¨¡å‹åï¼ˆä¸Šä¸€æ­¥çš„æˆæœï¼‰ï¼Œä½œè€…ä½¿ç”¨ä¸ <strong>DeepSeek-V3-Zero</strong> ç±»ä¼¼çš„å¼ºåŒ–å­¦ä¹ æµç¨‹å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œä½†é¢å¤–åŠ å…¥äº†<strong>ç›®æ ‡è¯­è¨€ä¸€è‡´æ€§</strong>çš„å¥–åŠ±ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨æ¨ç†å’Œå›ç­”æ—¶ä¸ä¼šæ··ç”¨å¤šç§è¯­è¨€ã€‚</p><p>é™¤äº†ä¹‹å‰æåˆ°çš„å‡†ç¡®æ€§ï¼ˆaccuracy rewardï¼‰å’Œæ ¼å¼ï¼ˆformat rewardï¼‰ç­‰ï¼Œè¿˜å¢åŠ äº†<strong>è¯­è¨€å¥–åŠ±ï¼ˆlanguage rewardï¼‰</strong>æ¥ä¿è¯ç”Ÿæˆçš„è¯­è¨€é£æ ¼æˆ–è¯­è¨€ç±»å‹ä¿æŒä¸€è‡´ï¼Œä¸è‡³äºå‡ºç°â€œä¸­è‹±æ–‡æ··æ‚â€æˆ–â€œé£æ ¼ä¸ç¨³â€çš„ç°è±¡ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_184229.png" class=""><ul><li><strong>Format reward</strong>ï¼šä¾æ—§å…³æ³¨ <code>&lt;think&gt;</code> å’Œ <code>&lt;answer&gt;</code> çš„ä½¿ç”¨ã€‚</li><li><strong>Accuracy reward</strong>ï¼šæ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ˜¯å¦èƒ½é€šè¿‡ç›¸åº”çš„â€œå•å…ƒæµ‹è¯•â€ã€‚</li><li><strong>Language reward</strong>ï¼šæ£€æŸ¥è¯­è¨€æ˜¯å¦ä¸€è‡´ã€é€šé¡ºä»¥åŠæ˜¯å¦ç¬¦åˆç›®æ ‡è¯­è¨€è¦æ±‚ã€‚</li></ul><p>è¿™äº›å¥–åŠ±ç»¼åˆèµ·æ¥ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾ªç¯ä½¿æ¨¡å‹çš„æ¨ç†å’Œç­”æ¡ˆåœ¨å¯è¯»æ€§ã€å‡†ç¡®åº¦å’Œè¯­è¨€é£æ ¼æ–¹é¢é€æ¸ä¼˜åŒ–ã€‚</p><hr><h4 id="ç¬¬ä¸‰æ­¥ï¼šæ‹’ç»é‡‡æ ·"><a href="#ç¬¬ä¸‰æ­¥ï¼šæ‹’ç»é‡‡æ ·" class="headerlink" title="ç¬¬ä¸‰æ­¥ï¼šæ‹’ç»é‡‡æ ·"></a>ç¬¬ä¸‰æ­¥ï¼šæ‹’ç»é‡‡æ ·</h4><p>åœ¨è¿™ä¸€é˜¶æ®µï¼Œä½œè€…ç”¨<strong>ç¬¬ 2 æ­¥</strong>å¼ºåŒ–å­¦ä¹ åå¾—åˆ°çš„æ¨¡å‹ï¼Œæ¥å¤§è§„æ¨¡ç”Ÿæˆ<strong>åˆæˆæ¨ç†æ•°æ®</strong>ï¼Œå¹¶é…åˆ <strong>DeepSeek-V3-Base</strong> æ¨¡å‹æ¥è¿›è¡Œâ€œè¯„ä¼°â€å’Œâ€œè§„åˆ™è¿‡æ»¤â€ï¼Œæœ€ç»ˆäº§ç”Ÿçº¦ 60 ä¸‡æ¡é«˜è´¨é‡çš„æ¨ç†æ ·æœ¬å¯ç”¨äºåç»­ç›‘ç£å¾®è°ƒã€‚åŒæ—¶ï¼Œä»–ä»¬è¿˜å¦å¤–ç”Ÿæˆäº†çº¦ 20 ä¸‡æ¡<strong>éæ¨ç†æ ·æœ¬</strong>ï¼ŒåŒ…å«äº†å†™ä½œã€ç®€å•é—®ç­”ã€è‡ªæˆ‘è®¤çŸ¥ã€ç¿»è¯‘ç­‰å¤šç§ä»»åŠ¡æ•°æ®ã€‚ä¸‹æ–‡æ€»ç»“äº†è¿™ä¸€è¿‡ç¨‹ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_184407.png" class=""><ul><li>å·¦è¾¹å±•ç¤ºäº†<strong>DeepSeek-V3-2</strong> å¦‚ä½•é‡‡æ ·åˆ°å¤§é‡<strong>Reasoning</strong>ï¼ˆæ¨ç†ï¼‰å’Œ<strong>Answer</strong>ï¼ˆç­”æ¡ˆï¼‰ï¼Œå†åˆ©ç”¨åŸºäºè§„åˆ™çš„ç­›é€‰å’Œ <strong>DeepSeek-V3-Base</strong> çš„åˆ¤æ–­ï¼ˆåˆ¤æ–­ç”Ÿæˆçš„å†…å®¹è´¨é‡ï¼‰ï¼Œä¿ç•™è´¨é‡æ›´å¥½çš„æ¨ç†æ•°æ®ï¼ˆçº¦ 600,000 æ¡ï¼‰ã€‚</li><li>å³è¾¹å±•ç¤ºäº†<strong>éæ¨ç†</strong>ï¼ˆnon-reasoningï¼‰æ•°æ®é‡‡æ ·æµç¨‹ï¼Œæ¥è‡ª DeepSeek-V3-Base æ‰€ä½¿ç”¨çš„ä¸€éƒ¨åˆ†æ•°æ®ï¼Œæ€»å…±çº¦ 200,000 æ¡ï¼Œè¿™äº›æ•°æ®ä¸»è¦æ¶‰åŠå†™ä½œã€äº‹å®æ€§é—®ç­”ï¼ˆfactual QAï¼‰ã€è‡ªæˆ‘è®¤çŸ¥ã€ç¿»è¯‘ç­‰æ–¹é¢ã€‚</li></ul><p>ç”±æ­¤ï¼Œç ”ç©¶äººå‘˜å¾—åˆ°è§„æ¨¡çº¦ 80 ä¸‡æ¡çš„â€œæ··åˆâ€æ•°æ®ï¼Œå…¶ä¸­æ—¢æœ‰æ¨ç†æ ·æœ¬ï¼Œä¹Ÿæœ‰éæ¨ç†æ ·æœ¬ã€‚</p><hr><h4 id="ç¬¬å››æ­¥ï¼šç›‘ç£å¾®è°ƒ"><a href="#ç¬¬å››æ­¥ï¼šç›‘ç£å¾®è°ƒ" class="headerlink" title="ç¬¬å››æ­¥ï¼šç›‘ç£å¾®è°ƒ"></a>ç¬¬å››æ­¥ï¼šç›‘ç£å¾®è°ƒ</h4><p>åœ¨å¾—åˆ°ä¸Šè¿° 80 ä¸‡æ¡æ•°æ®åï¼Œç ”ç©¶äººå‘˜å†æ¬¡å¯¹ <strong>DeepSeek-V3-Base</strong> è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œå…·ä½“è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_184526.png" class=""><ul><li>åœ¨å›¾ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°â€œDeepSeek-V3-Baseâ€è¢«ç”¨äºæ‰§è¡Œ<strong>ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰</strong>ï¼Œä½¿ç”¨çš„æ­£æ˜¯å‰æ–‡æ‰€æåˆ°çš„ 800,000 æ¡<strong>é«˜è´¨é‡æ¨ç†ä¸éæ¨ç†æ ·æœ¬</strong>ã€‚</li><li>è¿™ä¸€é˜¶æ®µä½¿å¾—æ¨¡å‹åœ¨æ›´å¤§è§„æ¨¡çš„æ•°æ®åŸºç¡€ä¸Šï¼Œå­¦ä¹ åˆ°æ›´å¹¿æ³›ã€æ›´å¤šæ ·çš„æ¨ç†å½¢å¼å’Œä»»åŠ¡å½¢å¼ã€‚</li></ul><hr><h4 id="ç¬¬äº”æ­¥ï¼šåœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„å¼ºåŒ–å­¦ä¹ "><a href="#ç¬¬äº”æ­¥ï¼šåœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„å¼ºåŒ–å­¦ä¹ " class="headerlink" title="ç¬¬äº”æ­¥ï¼šåœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„å¼ºåŒ–å­¦ä¹ "></a>ç¬¬äº”æ­¥ï¼šåœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„å¼ºåŒ–å­¦ä¹ </h4><p>åœ¨ç›‘ç£å¾®è°ƒå®Œæˆåï¼Œç ”ç©¶äººå‘˜ç»§ç»­é‡‡ç”¨ç±»ä¼¼ <strong>DeepSeek-R1-Zero</strong> çš„æ–¹æ³•è¿›è¡Œ <strong>RLï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰</strong> è®­ç»ƒã€‚ä½†æ˜¯ï¼Œä¸ºäº†è®©æ¨¡å‹æ›´ç¬¦åˆäººç±»åå¥½ï¼Œä»–ä»¬åœ¨è¿™ä¸ªé˜¶æ®µå¼•å…¥äº†æ›´å¤šçš„ <strong>â€œæœ‰ç›Šä¸æ— å®³â€ï¼ˆhelpfulness and harmlessnessï¼‰</strong> å¥–åŠ±ä¿¡å·ï¼Œç”¨æ¥çº¦æŸæ¨¡å‹çš„å›ç­”ã€‚</p><p>åŒæ—¶ï¼Œæ¨¡å‹ä¹Ÿè¢«è¦æ±‚<strong>å¯¹æ¨ç†è¿‡ç¨‹è¿›è¡Œæ€»ç»“ï¼ˆsummarizeï¼‰</strong>ï¼Œä»¥é˜²æ­¢åœ¨æœ€ç»ˆè¾“å‡ºæ—¶æ˜¾ç¤ºå‡ºè¿‡é•¿ã€éš¾ä»¥é˜…è¯»çš„æ¨ç†æ–‡æœ¬ã€‚è¿™ä¸€æ­¥éª¤è§£å†³äº†å‰è¿°æåˆ°çš„å¯è¯»æ€§é—®é¢˜ã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_184907.png" class=""><ol><li><strong>Format rewardï¼ˆæ ¼å¼å¥–åŠ±ï¼‰</strong>  <ul><li>æ˜¯å¦æ­£ç¡®ä½¿ç”¨ <code>&lt;think&gt;</code> æ ‡ç­¾ä¹¦å†™æ¨ç†å†…å®¹  </li><li>æ˜¯å¦æ­£ç¡®ä½¿ç”¨ <code>&lt;answer&gt;</code> æ ‡ç­¾è¾“å‡ºç­”æ¡ˆ</li></ul></li><li><strong>Accuracy rewardï¼ˆå‡†ç¡®æ€§å¥–åŠ±ï¼‰</strong>  <ul><li>æµ‹è¯•è¾“å‡ºæ˜¯å¦èƒ½ç¼–è¯‘ï¼ˆâ€œdoes it compile?â€ï¼‰  </li><li>æ˜¯å¦èƒ½é€šè¿‡å•å…ƒæµ‹è¯•ï¼ˆâ€œdoes it pass unit tests?â€ï¼‰</li></ul></li><li><strong>Preference rewardsï¼ˆåå¥½å¥–åŠ±ï¼‰</strong>  <ul><li>å…³æ³¨ <strong>Helpfulnessï¼ˆæœ‰ç›Šï¼‰</strong>ã€<strong>Harmlessnessï¼ˆæ— å®³ï¼‰</strong>ã€<strong>Human preferenceï¼ˆäººç±»åå¥½ï¼‰</strong> ç­‰  </li><li>ç”± RMï¼ˆReward Modelï¼‰ æ¨¡å—æ¥è¯„ä¼°è¿™äº›åå¥½æŒ‡æ ‡</li></ul></li></ol><p>å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œ<strong>Reasoning</strong>ï¼ˆæ¨ç†ï¼‰é˜¶æ®µå’Œ <strong>Answer</strong>ï¼ˆç­”æ¡ˆï¼‰é˜¶æ®µéœ€è¦åˆ†åˆ«ç”¨ <code>&lt;think&gt;</code> å’Œ <code>&lt;answer&gt;</code> æ ‡ç­¾è¿›è¡Œæ˜ç¡®åŒºåˆ†ã€‚åŒæ—¶ï¼Œä¸ºäº†è¾“å‡ºæ›´ä¸ºç²¾ç®€ã€å¯è¯»çš„å†…å®¹ï¼Œæ¨¡å‹ä¹Ÿå¯èƒ½äº§ç”Ÿä¸€ä¸ª <strong>Summary</strong>ï¼ˆæ€»ç»“ï¼‰ç‰‡æ®µã€‚å¼ºåŒ–å­¦ä¹ çš„è¿­ä»£è¿‡ç¨‹ä¼šåŒæ—¶è€ƒè™‘å¤šç§å¥–åŠ±ä¿¡å·ï¼Œä»è€Œä¸æ–­æ›´æ–°æ¨¡å‹å¹¶å¾—åˆ°æœ€ç»ˆç‰ˆæœ¬çš„ <strong>DeepSeek-R1</strong>ã€‚</p><p>ä¸Šå›¾ä¸­ï¼Œâ€œRMâ€ å³ Reward Modelï¼Œç”¨äºå¯¹åå¥½è¿›è¡Œæ‰“åˆ†ï¼ˆå¦‚å¯¹è¯æ˜¯å¦å‹å–„ã€æ˜¯å¦ç¬¦åˆä¼¦ç†è¦æ±‚ç­‰ï¼‰ï¼Œå†æŠŠç»“æœåé¦ˆç»™æ¨¡å‹ã€‚</p><p>â€œ<strong>And thatâ€™s it!<strong>â€è¿™æ„å‘³ç€ <strong>DeepSeek-R1</strong> å®é™…ä¸Šæ˜¯ <strong>DeepSeek-V3-Base</strong> ç»è¿‡ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–è€Œæˆã€‚å¤§é‡çš„å·¥ä½œéƒ½ç”¨äºä¿è¯</strong>é«˜è´¨é‡æ•°æ®</strong>çš„ç”Ÿæˆä¸ä½¿ç”¨ï¼Œè¿›è€Œè®­ç»ƒå‡ºè¿™æ ·ä¸€ä¸ªå…·å¤‡å¼ºå¤§æ¨ç†èƒ½åŠ›çš„æ¨¡å‹ã€‚</p><hr><h2 id="å°†æ¨ç†çŸ¥è¯†ä»-DeepSeek-R1-è’¸é¦åˆ°å…¶ä»–æ¨¡å‹"><a href="#å°†æ¨ç†çŸ¥è¯†ä»-DeepSeek-R1-è’¸é¦åˆ°å…¶ä»–æ¨¡å‹" class="headerlink" title="å°†æ¨ç†çŸ¥è¯†ä» DeepSeek-R1 è’¸é¦åˆ°å…¶ä»–æ¨¡å‹"></a>å°†æ¨ç†çŸ¥è¯†ä» DeepSeek-R1 è’¸é¦åˆ°å…¶ä»–æ¨¡å‹</h2><p><strong>DeepSeek-R1</strong> æ‹¥æœ‰ <strong>6710 äº¿ï¼ˆ671Bï¼‰</strong> å‚æ•°ã€‚è¿™ä¸€è§„æ¨¡çš„æ¨¡å‹åœ¨æ™®é€šæ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œå­˜åœ¨è¾ƒå¤§éš¾åº¦ã€‚å‡ºäºå®ç”¨æ€§è€ƒè™‘ï¼Œä½œè€…ä»¬ç ”ç©¶äº†å¦‚ä½•å°† <strong>DeepSeek-R1</strong> çš„æ¨ç†èƒ½åŠ›â€œè’¸é¦ï¼ˆdistillï¼‰â€åˆ°æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ <strong>Qwen-32B</strong>ï¼‰ä¸Šï¼Œä»¥ä¾¿èƒ½åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šéƒ¨ç½²å’Œä½¿ç”¨ã€‚</p><h3 id="è’¸é¦è¿‡ç¨‹ï¼šTeacher-Student-æ¡†æ¶"><a href="#è’¸é¦è¿‡ç¨‹ï¼šTeacher-Student-æ¡†æ¶" class="headerlink" title="è’¸é¦è¿‡ç¨‹ï¼šTeacher-Student æ¡†æ¶"></a>è’¸é¦è¿‡ç¨‹ï¼šTeacher-Student æ¡†æ¶</h3><p>åœ¨è’¸é¦è¿‡ç¨‹ä¸­ï¼Œ<strong>DeepSeek-R1</strong> ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼ˆTeacherï¼‰ï¼Œè€Œè§„æ¨¡æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ Qwen-32Bï¼‰ä½œä¸ºå­¦ç”Ÿæ¨¡å‹ï¼ˆStudentï¼‰ã€‚äºŒè€…é¢å¯¹ç›¸åŒçš„æç¤ºï¼ˆpromptï¼‰æ—¶ï¼Œåˆ†åˆ«ä¼šè¾“å‡ºä¸€ç»„<strong>è¯å…ƒæ¦‚ç‡åˆ†å¸ƒï¼ˆtoken probability distributionï¼‰</strong>ã€‚è®­ç»ƒæ—¶ï¼Œå­¦ç”Ÿæ¨¡å‹ä¼šå°½é‡å­¦ä¹ å¹¶æ¥è¿‘æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºåˆ†å¸ƒã€‚</p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_185245.png" class=""><ul><li>æ•™å¸ˆï¼ˆDeepSeek-R1ï¼‰ç»™å‡ºè‡ªå·±çš„â€œproposal distributionâ€ã€‚ä¾‹å¦‚åœ¨å›ç­”â€œWhat is 3 + 2?â€æ—¶ï¼Œæ•™å¸ˆæ¨¡å‹å¯èƒ½å€¾å‘è¾“å‡ºâ€œAddingâ€â€œIfâ€â€œ5â€â€œ3â€â€œ4â€ç­‰æ ‡è®°ï¼Œå¹¶èµ‹äºˆå„è‡ªä¸åŒçš„æ¦‚ç‡ã€‚  </li><li>å­¦ç”Ÿï¼ˆQwen-32Bï¼‰åˆ™ä¼šåœ¨è®­ç»ƒä¸­ä¸æ–­æ›´æ–°è‡ªå·±çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿ä¹‹æ›´æ¥è¿‘æ•™å¸ˆçš„åˆ†å¸ƒã€‚</li></ul><blockquote><p><strong>é¢å¤–è§£é‡Š</strong>ï¼š  </p><ol><li><strong>æ¦‚ç‡åˆ†å¸ƒï¼ˆproposal distributionï¼‰</strong>ï¼šè¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆä¸‹ä¸€ä¸ªè¯å…ƒï¼ˆtokenï¼‰æ—¶ï¼Œä¼šè¾“å‡ºå¯¹æ‰€æœ‰å¯èƒ½è¯å…ƒçš„æ¦‚ç‡ä¼°è®¡ã€‚  </li><li><strong>è’¸é¦ï¼ˆdistillationï¼‰</strong>ï¼šé€šè¿‡æ¯”è¾ƒæ•™å¸ˆå’Œå­¦ç”Ÿçš„åˆ†å¸ƒå·®å¼‚ï¼Œå­¦ç”Ÿä¼šé€æ­¥è°ƒæ•´è‡ªèº«å‚æ•°ï¼Œä½¿å…¶è¾“å‡ºæ›´æ¥è¿‘æ•™å¸ˆæ¨¡å‹çš„é£æ ¼å’Œæ¨ç†å€¾å‘ã€‚</li></ol></blockquote><p>è®­ç»ƒæ‰€ä½¿ç”¨çš„æ•°æ®ï¼Œæ­£æ˜¯ä¹‹å‰æåˆ°çš„é‚£ <strong>80 ä¸‡æ¡é«˜è´¨é‡æ ·æœ¬</strong>â€”â€”å…¶ä¸­åŒ…å«çº¦ 60 ä¸‡æ¨ç†æ ·æœ¬å’Œ 20 ä¸‡éæ¨ç†æ ·æœ¬ã€‚ä¸‹å›¾å±•ç¤ºäº†è¿™ä¸€æ•°æ®æµå‘ï¼š </p><img src="/2025/02/11/NLP%20Insights/%E6%8E%A8%E7%90%86%20LLM%20%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8E%A2%E7%B4%A2%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E4%B8%8E%20DeepSeek-R1/20250211_185323.png" class=""><ul><li>å·¦ä¾§çš„ <strong>Reasoning</strong>ï¼ˆæ¨ç†ï¼‰å’Œ <strong>Answer</strong>ï¼ˆç­”æ¡ˆï¼‰æ•°æ®ï¼Œåˆè®¡ 80 ä¸‡æ¡ã€‚  </li><li>ç”± <strong>DeepSeek-R1</strong>ï¼ˆTeacherï¼‰ç”Ÿæˆæˆ–è¯„ä¼°ï¼Œå¾—åˆ°å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒã€‚  </li><li>å­¦ç”Ÿæ¨¡å‹ <strong>Qwen-32B</strong> åˆ™æ ¹æ®æ•™å¸ˆçš„åˆ†å¸ƒè¿›è¡Œå­¦ä¹ ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªè’¸é¦ç‰ˆæœ¬ <strong>DeepSeek-R1-Distill-Qwen-32B</strong>ã€‚</li></ul><p><img src="https://user-images.githubusercontent.com/your-image-url.png" alt="ä½¿ç”¨ 80 ä¸‡æ¡é«˜è´¨é‡æ ·æœ¬è’¸é¦çš„æµç¨‹ï¼ˆå›¾10ï¼‰"></p><blockquote><p><strong>é¢å¤–è§£é‡Š</strong>ï¼š  </p><ul><li>å­¦ç”Ÿæ¨¡å‹ä¸ä»…ä»…å­¦ä¹ äº†é‚£ 80 ä¸‡æ¡æ ·æœ¬æœ¬èº«çš„è¾“å…¥-è¾“å‡ºæ¨¡å¼ï¼Œä¹Ÿå­¦ä¹ åˆ° <strong>DeepSeek-R1</strong> åœ¨é¢å¯¹è¿™äº›æ•°æ®æ—¶æ‰€â€œå€¾å‘â€é‡‡ç”¨çš„æ¨ç†ç­–ç•¥å’Œæ¦‚ç‡åˆ†å¸ƒï¼Œä»è€Œåœ¨æ›´å°æ¨¡å‹ä¸Šå¤ç°ç±»ä¼¼çš„æ¨ç†èƒ½åŠ›ã€‚  </li><li>â€œDistilledâ€ æ¨¡å‹å¾€å¾€ä¼šåœ¨æ¨ç†è´¨é‡ä¸è®¡ç®—èµ„æºä¹‹é—´æ‰¾åˆ°æ›´å¥½çš„å¹³è¡¡ï¼šè™½ç„¶å¯èƒ½åœ¨æ€§èƒ½ä¸Šç•¥é€Šè‰²äºè€å¸ˆæ¨¡å‹ï¼Œä½†ä¾ç„¶èƒ½åœ¨å¤§å¤šæ•°å¸¸è§ä»»åŠ¡ä¸Šè¾¾åˆ°ä»¤äººæ»¡æ„çš„ç»“æœï¼Œå¹¶ä¸”æ‰€éœ€èµ„æºæ›´ä½ã€‚</li></ul></blockquote><hr><h2 id="å…¶ä»–æœªæˆåŠŸçš„å°è¯•"><a href="#å…¶ä»–æœªæˆåŠŸçš„å°è¯•" class="headerlink" title="å…¶ä»–æœªæˆåŠŸçš„å°è¯•"></a>å…¶ä»–æœªæˆåŠŸçš„å°è¯•</h2><p>åœ¨ç ”ç©¶è¿‡ç¨‹ä¸­ï¼ŒDeepSeek å›¢é˜Ÿä¹Ÿæ›¾å°è¯•è¿‡ <strong>Process Reward Modelsï¼ˆPRMsï¼‰</strong> å’Œ <strong>Monte Carlo Tree Searchï¼ˆMCTSï¼‰</strong> ç­‰æ–¹æ³•æ¥æ³¨å…¥æ¨ç†èƒ½åŠ›ï¼Œä½†ç»“æœå¹¶ä¸ç†æƒ³ï¼š</p><ol><li><p><strong>ä½¿ç”¨ MCTS</strong>  </p><ul><li>é¢ä¸´çš„ä¸»è¦é—®é¢˜æ˜¯æœç´¢ç©ºé—´è¿‡äºåºå¤§ï¼Œåªèƒ½å¯¹èŠ‚ç‚¹å±•å¼€è¿›è¡Œä¸¥æ ¼é™åˆ¶ã€‚è¿™æ ·ä¸€æ¥ï¼Œæ•ˆæœå°±å¤§æ‰“æŠ˜æ‰£ã€‚  </li><li>æ­¤å¤–ï¼Œç²¾ç»†åŒ–è®­ç»ƒ Reward Model ä¹Ÿç›¸å½“å›°éš¾ã€‚</li></ul></li><li><p><strong>ä½¿ç”¨ PRMs è¿›è¡Œ Best-of-N ç­–ç•¥</strong>  </p><ul><li>å¦‚æœä¸æ–­é‡è®­ç»ƒ Reward Model ä»¥é˜²æ­¢æ¨¡å‹å‡ºç°â€œæŠ•æœºå–å·§â€ï¼ˆreward hackingï¼‰è¡Œä¸ºï¼Œä¼šå¸¦æ¥é«˜æ˜‚çš„è®¡ç®—å¼€é”€ã€‚</li></ul></li></ol><p>è¿™äº›ç»“æœå¹¶ä¸æ„å‘³ç€è¿™äº›æŠ€æœ¯æ— æ•ˆï¼Œè€Œæ˜¯è¯´æ˜å®ƒä»¬åœ¨å½“å‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸Šçš„å®è·µè¿˜æœ‰è¯¸å¤šé™åˆ¶ä¸éš¾ç‚¹ã€‚<strong>DeepSeek-R1</strong> ä¹‹æ‰€ä»¥å–å¾—æˆåŠŸï¼Œæ›´å¤šä¾èµ–äº<strong>å¼ºåŒ–å­¦ä¹  + ç›‘ç£å¾®è°ƒ</strong>çš„ç»„åˆï¼Œä»¥åŠå¯¹å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®çš„æŒ–æ˜ä¸åˆ©ç”¨ã€‚</p><hr><h2 id="æ€»ç»“ä¸å±•æœ›"><a href="#æ€»ç»“ä¸å±•æœ›" class="headerlink" title="æ€»ç»“ä¸å±•æœ›"></a>æ€»ç»“ä¸å±•æœ›</h2><p>è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å¤§è‡´å›é¡¾äº† <strong>DeepSeek-R1</strong> çš„æ¨ç†è®­ç»ƒä¹‹æ—…ã€‚å¸Œæœ›ä»¥ä¸Šå†…å®¹èƒ½å¤Ÿè®©ä½ æ›´å¥½åœ°ç†è§£ï¼š  </p><ul><li><strong>Test-time computeï¼ˆæ¨ç†æ—¶è®¡ç®—ï¼‰</strong> å¯ä»¥é€šè¿‡æ¨¡å‹è¾“å‡ºæ›´é•¿ã€æ›´ç²¾ç»†çš„æ€è€ƒè¿‡ç¨‹ï¼ˆChain-of-Thoughtï¼‰æ¥å–å¾—æ›´ä½³æ•ˆæœã€‚  </li><li>å¤§è§„æ¨¡â€œ<strong>å…ˆç›‘ç£å¾®è°ƒï¼Œå†å¼ºåŒ–å­¦ä¹ </strong>â€çš„è®­ç»ƒæµç¨‹ï¼Œä»¥åŠ<strong>è’¸é¦</strong>åˆ°æ›´å°æ¨¡å‹çš„æŠ€æœ¯è·¯çº¿ï¼Œä¹Ÿå±•ç°äº†åœ¨ç¡¬ä»¶èµ„æºå’Œæ¨ç†æ€§èƒ½é—´å–å¾—å¹³è¡¡çš„æ–¹æ³•ã€‚</li></ul><p>å¦‚å‰æ‰€è¿°ï¼Œ<strong>DeepSeek-R1</strong> å¼•å…¥äº†å¤šç§å¥–åŠ±æœºåˆ¶ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹æ ¼å¼å’Œäººç±»åå¥½çš„å¥–åŠ±ï¼Œæ¥ä¿è¯å›ç­”æ—¢æ­£ç¡®åˆæ˜“è¯»ã€‚â€œæ€»ç»“æ¨ç†è¿‡ç¨‹â€ï¼ˆSummaryï¼‰çš„åšæ³•ä¹Ÿåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ”¹å–„äº†çº¯æ–‡æœ¬Chain-of-Thoughtè¿‡é•¿è€Œå¯¼è‡´çš„å¯è¯»æ€§é—®é¢˜ã€‚</p><hr><h2 id="æ›´å¤šèµ„æº"><a href="#æ›´å¤šèµ„æº" class="headerlink" title="æ›´å¤šèµ„æº"></a>æ›´å¤šèµ„æº</h2><p>å¦‚æœä½ å¯¹ <strong>Large Language Modelsï¼ˆLLMsï¼‰</strong> ä¸­çš„æ¨ç†è¯é¢˜æ„Ÿå…´è¶£ï¼Œä»¥ä¸‹èµ„æºå€¼å¾—å‚è€ƒï¼š</p><ol><li><a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1"><strong>The Illustrated DeepSeek-R1</strong></a>  <ul><li>Jay Alammar åˆ¶ä½œçš„é«˜è´¨é‡å¯è§†åŒ–æŒ‡å—ï¼Œè¯¦ç»†ä»‹ç»äº† DeepSeek-R1 æ¨¡å‹èƒŒåçš„åŸç†ä¸å®ç°ç»†èŠ‚ã€‚</li></ul></li><li><a href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute"><strong>Hugging Face çš„ä¸€ç¯‡åšæ–‡</strong></a>  <ul><li>é‡ç‚¹è®¨è®ºäº†åœ¨æ¨ç†é˜¶æ®µå¦‚ä½•å¯¹è®¡ç®—é‡è¿›è¡Œæ‰©å±•ï¼Œå¹¶ç»™å‡ºäº†æœ‰è¶£çš„å®éªŒã€‚</li></ul></li><li><a href="https://www.youtube.com/watch?v=6PEJ96k1kiw"><strong>è§†é¢‘ â€œSpeculations on Test-Time Scalingâ€</strong></a>  <ul><li>æ·±å…¥æ¢è®¨äº†åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œå„ç§è®¡ç®—æ‰©å±•çš„å¸¸ç”¨æŠ€æœ¯ç»†èŠ‚ã€‚</li></ul></li></ol><p>æ­¤å¤–ï¼Œä½œè€…åœ¨æ–‡ä¸­ä¹Ÿæåˆ°äº†ä¸€æœ¬å…³äºå¤§å‹è¯­è¨€æ¨¡å‹çš„è‘—ä½œï¼Œå†…å«æ›´å¤šå¯è§†åŒ–å’Œå®éªŒç»“æœï¼Œæ˜¯æƒ³è¿›ä¸€æ­¥ç ”ç©¶æ¨ç† LLMs çš„æœ‹å‹å¯ä»¥æ·±å…¥é˜…è¯»çš„å¥½èµ„æ–™ã€‚</p><ul><li><strong>Official Website of the Book</strong>: <a href="https://www.llm-book.com/">llm-book.com</a>  </li><li><strong>Amazon è´­ä¹°é“¾æ¥</strong>: <a href="https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961">Hands-On Large Language Models: Understanding, Building, and Optimizing LLMs</a>  </li><li><strong>GitHub ä»£ç ä»“åº“</strong>: <a href="https://github.com/handsOnLLM/Hands-On-Large-Language-Models">handsOnLLM/Hands-On-Large-Language-Models</a></li></ul><hr><h3 id="è‡´è°¢"><a href="#è‡´è°¢" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h3><p>æ„Ÿè°¢ä½ é˜…è¯»æœ¬ç¯‡å…³äº <strong>DeepSeek-R1</strong> çš„ä»‹ç»æ–‡æ¡£ã€‚é€šè¿‡å¯¹æ‰€æœ‰å›¾ç‰‡ä¸æ–‡å­—å†…å®¹çš„ä¾æ¬¡è§£è¯»ï¼Œä»¥åŠå¯¹æ¯ä¸ªç¯èŠ‚æ‰€æ¶‰åŠçš„å…³é”®æŠ€æœ¯è¿›è¡Œäº†æ›´å¤šè§£é‡Šï¼Œæˆ‘ä»¬å¸Œæœ›è®©ä½ å¯¹ <strong>DeepSeek-R1</strong> çš„è®­ç»ƒæµç¨‹ã€è’¸é¦æ–¹æ³•å’ŒæœªæˆåŠŸçš„å°è¯•éƒ½æœ‰æ›´åŠ å…¨é¢çš„äº†è§£ã€‚</p><p>åœ¨æœªæ¥ï¼Œéšç€ç¡¬ä»¶æ€§èƒ½çš„æå‡ä¸æ›´æˆç†Ÿçš„è®­ç»ƒæŠ€æœ¯å‡ºç°ï¼Œ<strong>æ·±åº¦æ¨ç†</strong>ä¸<strong>æ¨¡å‹è’¸é¦</strong>å¿…å°†åœ¨æ›´å¤šå®é™…åº”ç”¨åœºæ™¯ä¸­å‘æŒ¥å·¨å¤§ä½œç”¨ã€‚è®©æˆ‘ä»¬æ‹­ç›®ä»¥å¾…ï¼</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;æ¨ç†-LLM-çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸-DeepSeek-R1&quot;&gt;&lt;a href=&quot;#æ¨ç†-LLM-çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡ç®—æŠ€æœ¯ä¸-DeepSeek-R1&quot; class=&quot;headerlink&quot; title=&quot;æ¨ç† LLM çš„å¯è§†åŒ–æŒ‡å—ï¼šæ¢ç´¢æ¨ç†æ—¶è®¡</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="LLM" scheme="https://chenhuiyu.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>è¿½é€ä¸å€’å½±</title>
    <link href="https://chenhuiyu.github.io/2024/12/11/Life%20Reflections/%E8%BF%BD%E9%80%90%E4%B8%8E%E5%80%92%E5%BD%B1/"/>
    <id>https://chenhuiyu.github.io/2024/12/11/Life%20Reflections/%E8%BF%BD%E9%80%90%E4%B8%8E%E5%80%92%E5%BD%B1/</id>
    <published>2024-12-10T18:29:06.000Z</published>
    <updated>2026-02-20T21:56:22.869Z</updated>
    
    <content type="html"><![CDATA[<h3 id="è¿½é€ä¸å€’å½±"><a href="#è¿½é€ä¸å€’å½±" class="headerlink" title="è¿½é€ä¸å€’å½±"></a>è¿½é€ä¸å€’å½±</h3><p>åœ¨æ¸…æ™¨çš„ç¬¬ä¸€ç¼•å…‰æ´’ä¸‹ä¹‹å‰ï¼Œä¸–é—´ä¸€åˆ‡å°šæœªæ˜¾å½¢ã€‚å…‰ä¸å½±çš„è¾¹ç•Œæ¨¡ç³Šï¼Œå½·ä½›å¯ä»¥äº¤å ï¼Œåˆå½·ä½›æ³¨å®šåˆ†ç¦»ã€‚äººä»¬å¸¸è¯´ï¼Œæœé˜³æ˜¯å¸Œæœ›çš„è±¡å¾ï¼Œå¯å®ƒå‡èµ·æ—¶ï¼Œå¿…å°†æŠ›ä¸‹ä¸€åœ°å½±å­ã€‚å…‰å’Œå½±ä¹‹é—´ï¼Œç©¶ç«Ÿæ˜¯è¿½é€è¿˜æ˜¯ç›¸ä¼´ï¼Ÿè¿™æ ·çš„æ€è€ƒè®©æˆ‘æƒ³èµ·ä¸€åˆ™å¤è€çš„å¯“è¨€ï¼šä¸€åŒ¹é©¬åœ¨æ²™æ¼ ä¸­è¿½é€è¿œæ–¹çš„ç»¿æ´²ï¼Œå´ä¸çŸ¥é“é‚£ä¸è¿‡æ˜¯æµ·å¸‚èœƒæ¥¼ï¼Œå®ƒæ¯å‰è¿›ä¸€æ­¥ï¼Œç»¿æ´²ä¹Ÿéšä¹‹è¿œå»ã€‚</p><p>æœ‰æ—¶æˆ‘ä»¬è¿½å¯»çš„ç›®æ ‡ï¼Œå¦‚åŒæ²™æ¼ ä¸­çš„ç»¿æ´²ä¸€èˆ¬ï¼Œå®ƒå¹¶éè™šæ— ï¼Œä½†ä¹Ÿä¸å®Œå…¨çœŸå®ã€‚å®ƒæ˜¯ä¸€ç§å­˜åœ¨äºå¿ƒä¸­çš„æ˜ åƒï¼Œä¸€ä¸ªæ— æ³•ä¼åŠçš„å½¼å²¸ã€‚æ— è®ºæˆ‘ä»¬æ€æ ·é è¿‘ï¼Œé‚£ä»½è·ç¦»ä¼¼ä¹æ€»æ˜¯æ’å®šï¼Œç”šè‡³åœ¨æˆ‘ä»¬ä¼¸æ‰‹è§¦ç¢°çš„ä¸€åˆ¹é‚£ï¼Œå®ƒä¾¿å¦‚çƒŸé›¾èˆ¬æ¶ˆæ•£ã€‚æ˜¯ç›®æ ‡å˜äº†ï¼Œè¿˜æ˜¯æˆ‘ä»¬çš„æ‰§å¿µè®©å®ƒæ„ˆåŠ æ¨¡ç³Šï¼Ÿ</p><p>é•œä¸­çš„å€’å½±ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å½“ä½ ç«™åœ¨é•œå‰å‡è§†è‡ªå·±æ—¶ï¼Œä½ çœ‹è§çš„é‚£ä¸ªâ€œä½ â€ï¼Œç©¶ç«Ÿæ˜¯è°ï¼Ÿæ˜¯ä¸€ä¸ªå¿ å®çš„å†ç°ï¼Œè¿˜æ˜¯ä¸€åœºæ¸©æŸ”çš„æ¬ºéª—ï¼Ÿé•œä¸­çš„å€’å½±æ€»ä¼šå›åº”ä½ çš„åŠ¨ä½œï¼Œå¯æ˜¯ä½ æ°¸è¿œæ— æ³•æ‹¥æŠ±å®ƒï¼Œç”šè‡³è¿ç¢°è§¦éƒ½æ— æ³•åšåˆ°ã€‚è¿™ç§è§¦ä¸å¯åŠçš„å…³ç³»ï¼Œæ—¢ä»¤äººæƒ‹æƒœï¼Œåˆæ•™äººæ€ç´¢ã€‚å€˜è‹¥ç”Ÿå‘½ä¸­è®¸å¤šäº‹ç‰©éƒ½åƒè¿™é¢é•œå­ï¼Œæ˜¯å¦æ„å‘³ç€æˆ‘ä»¬æ³¨å®šåªèƒ½é¥æœ›ï¼Œå´æ— æ³•çœŸæ­£æ‹¥æœ‰ï¼Ÿ</p><p>â€œäººç±»æœ€å¤§çš„æ‚²å‰§åœ¨äºï¼Œä»–ä»¬æ³¨å®šè¦è¿½æ±‚é‚£äº›ä¸å¯å¾—ä¹‹ç‰©ã€‚â€èµ·åˆï¼Œæˆ‘å¯¹è¿™å¥è¯å—¤ä¹‹ä»¥é¼»ã€‚ä¸–ç•Œè¿™ä¹ˆå¤§ï¼Œæ€ä¹ˆå¯èƒ½æ‰€æœ‰çš„è¿½æ±‚éƒ½æ˜¯å¾’åŠ³ï¼Ÿç„¶è€Œï¼Œå½“ç»å†äº†ä¸€äº›æ— æ³•è¨€è¯´çš„æ„Ÿå—åï¼Œæˆ‘é€æ¸æ˜ç™½ï¼Œè¿™ç§â€œä¸å¯å¾—â€å¹¶éæŒ‡ç»å¯¹çš„å¤±è´¥ï¼Œè€Œæ˜¯ä¸€ç§ä¸ç›®æ ‡é—´æ— æ³•æ¶ˆå¼­çš„é—´éš™ã€‚å®ƒå¯èƒ½æ˜¯æ—¶é—´çš„é”™ä½ï¼Œä¹Ÿå¯èƒ½æ˜¯ç©ºé—´çš„ç–ç¦»ï¼Œç”šè‡³å¯èƒ½åªæ˜¯å¿ƒå¢ƒçš„ä¸åŒã€‚</p><p>ä¹Ÿè®¸ï¼Œæ­£æ˜¯è¿™ç§æ— æ³•å½»åº•æ¡ä½çš„æ„Ÿè§‰ï¼Œèµ‹äºˆäº†è¿½é€çš„è¿‡ç¨‹ä»¥æ„ä¹‰ã€‚å€˜è‹¥ä¸€åˆ‡è§¦æ‰‹å¯å¾—ï¼Œç”Ÿå‘½æ˜¯å¦ä¼šå› å°‘äº†äº›è®¸é—æ†¾è€Œå¤±å»è‰²å½©ï¼Ÿå…‰å› ä¸ºæœ‰å½±å­æ‰å¾—ä»¥åˆ†æ˜ï¼Œçˆ±å› ä¸ºä¸å¯å¾—æ‰æ˜¾å¾—æ·±åˆ»ã€‚æˆ‘ä»¬åœ¨é—æ†¾ä¸­ä½“ä¼šåˆ°å¸Œæœ›ï¼Œåœ¨è·ç¦»ä¸­å‘ç°è‡ªæˆ‘ï¼Œè¿™æ˜¯å¦æ˜¯ä¸€ç§éšç§˜çš„å¹³è¡¡ï¼Ÿ</p><p>å¤œå¹•é™ä¸´æ—¶ï¼Œæ¸…æ™¨çš„å½±å­ä¼šè¢«é»‘æš—åæ²¡ï¼Œä½†å®ƒå¹¶æœªçœŸæ­£æ¶ˆå¤±ï¼Œåªæ˜¯æ¢äº†ä¸€ç§å½¢æ€ï¼Œæˆä¸ºå¿ƒåº•ä¸€æŸæ— æ³•ç†„ç­çš„å¾®å…‰ã€‚è¿™å…‰æŒ‡å¼•ç€æˆ‘ä»¬ï¼Œè™½ä¸å¯æ‰æ‘¸ï¼Œå´åˆçœŸå®å­˜åœ¨ã€‚æˆ–è®¸ï¼Œæˆ‘ä»¬æ— éœ€æ‰§ç€äºæ˜¯å¦èƒ½å¾—åˆ°ï¼Œè€Œæ˜¯å­¦ä¼šåœ¨è¿½é€çš„è¿‡ç¨‹ä¸­ï¼Œæ¥å—å…‰ä¸å½±äº¤ç»‡çš„ç¾ã€‚</p><p>ä¸–é—´çš„ä¸€åˆ‡ï¼Œçš†æ˜¯å€’å½±ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;è¿½é€ä¸å€’å½±&quot;&gt;&lt;a href=&quot;#è¿½é€ä¸å€’å½±&quot; class=&quot;headerlink&quot; title=&quot;è¿½é€ä¸å€’å½±&quot;&gt;&lt;/a&gt;è¿½é€ä¸å€’å½±&lt;/h3&gt;&lt;p&gt;åœ¨æ¸…æ™¨çš„ç¬¬ä¸€ç¼•å…‰æ´’ä¸‹ä¹‹å‰ï¼Œä¸–é—´ä¸€åˆ‡å°šæœªæ˜¾å½¢ã€‚å…‰ä¸å½±çš„è¾¹ç•Œæ¨¡ç³Šï¼Œå½·ä½›å¯ä»¥äº¤å ï¼Œåˆå½·ä½›æ³¨å®šåˆ†ç¦»ã€‚äººä»¬å¸¸è¯´ï¼Œæœé˜³æ˜¯å¸Œæœ›çš„è±¡</summary>
      
    
    
    
    <category term="Life Reflections" scheme="https://chenhuiyu.github.io/categories/Life-Reflections/"/>
    
    
    <category term="æ‚è°ˆ" scheme="https://chenhuiyu.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜</title>
    <link href="https://chenhuiyu.github.io/2024/12/06/NLP%20Insights/%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E8%AF%84%E4%BC%B0%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%88%90%E5%88%B0%E5%88%A4%E6%96%AD%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E6%8C%91%E6%88%98/"/>
    <id>https://chenhuiyu.github.io/2024/12/06/NLP%20Insights/%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E8%AF%84%E4%BC%B0%EF%BC%9A%E4%BB%8E%E7%94%9F%E6%88%90%E5%88%B0%E5%88%A4%E6%96%AD%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E6%8C%91%E6%88%98/</id>
    <published>2024-12-06T06:34:18.000Z</published>
    <updated>2026-02-20T21:56:22.875Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜"><a href="#åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜" class="headerlink" title="åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜"></a>åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜</h1><h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä¸è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸä¸­çš„è¯„ä¼°ä»»åŠ¡é•¿æœŸé¢ä¸´æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„è¯„ä¼°æ–¹æ³•ï¼ˆå¦‚åŸºäºåŒ¹é…æˆ–åµŒå…¥çš„æŠ€æœ¯ï¼‰åœ¨åˆ¤æ–­å¤æ‚å±æ€§æ—¶æ•ˆæœæœ‰é™ã€‚è¿‘æœŸå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•å‚¬ç”Ÿäº†â€œLLM-as-a-Judgeâ€èŒƒå¼ï¼Œåˆ©ç”¨LLMå¯¹ä»»åŠ¡è¿›è¡Œè¯„åˆ†ã€æ’åºæˆ–é€‰æ‹©ã€‚æœ¬è®ºæ–‡å¯¹LLMè¯„ä¼°æ–¹æ³•è¿›è¡Œäº†å…¨é¢ç»¼è¿°ï¼ŒåŒ…æ‹¬å…¶å®šä¹‰ã€åˆ†ç±»æ¡†æ¶ã€è¯„ä¼°åŸºå‡†ï¼Œä»¥åŠæœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</p><hr><h2 id="1-å¼•è¨€"><a href="#1-å¼•è¨€" class="headerlink" title="1. å¼•è¨€"></a>1. å¼•è¨€</h2><h3 id="1-1-èƒŒæ™¯"><a href="#1-1-èƒŒæ™¯" class="headerlink" title="1.1 èƒŒæ™¯"></a>1.1 èƒŒæ™¯</h3><p>è¯„ä¼°æ˜¯æœºå™¨å­¦ä¹ å’ŒNLPçš„æ ¸å¿ƒé—®é¢˜ä¹‹ä¸€ï¼Œä¼ ç»Ÿè¯„ä¼°æ–¹æ³•å¦‚BLEUå’ŒROUGEé€šå¸¸åŸºäºæ–‡æœ¬é‡å ï¼Œç¼ºä¹å¯¹å¤æ‚åœºæ™¯çš„é€‚ç”¨æ€§ã€‚éšç€æ·±åº¦å­¦ä¹ å’ŒLLMçš„å‘å±•ï¼ˆå¦‚GPT-4ï¼‰ï¼Œç ”ç©¶è€…æå‡ºäº†â€œLLM-as-a-Judgeâ€æ¨¡å¼ï¼Œä»¥è§£å†³ä¼ ç»Ÿè¯„ä¼°çš„å±€é™ã€‚</p><h3 id="1-2-ç ”ç©¶é—®é¢˜"><a href="#1-2-ç ”ç©¶é—®é¢˜" class="headerlink" title="1.2 ç ”ç©¶é—®é¢˜"></a>1.2 ç ”ç©¶é—®é¢˜</h3><p>æœ¬è®ºæ–‡æ—¨åœ¨æ¢è®¨ä»¥ä¸‹é—®é¢˜ï¼š</p><ul><li><strong>è¯„ä¼°å†…å®¹ï¼šLLMè¯„ä¼°ä»€ä¹ˆï¼Ÿ</strong></li><li><strong>è¯„ä¼°æ–¹æ³•ï¼šå¦‚ä½•è¿›è¡Œè¯„ä¼°ï¼Ÿ</strong></li><li><strong>åº”ç”¨åœºæ™¯ï¼šLLMåœ¨å“ªé‡Œè¯„ä¼°ï¼Ÿ</strong></li></ul><hr><h2 id="2-é¢„å¤‡çŸ¥è¯†"><a href="#2-é¢„å¤‡çŸ¥è¯†" class="headerlink" title="2. é¢„å¤‡çŸ¥è¯†"></a>2. é¢„å¤‡çŸ¥è¯†</h2><h3 id="2-1-è¾“å…¥æ ¼å¼"><a href="#2-1-è¾“å…¥æ ¼å¼" class="headerlink" title="2.1 è¾“å…¥æ ¼å¼"></a>2.1 è¾“å…¥æ ¼å¼</h3><p>è¯„ä¼°è¾“å…¥å¯åˆ†ä¸ºï¼š</p><ul><li><strong>ç‚¹å¯¹ç‚¹ï¼ˆPoint-Wiseï¼‰</strong>ï¼šå•ä¸ªæ ·æœ¬è¯„ä¼°ã€‚</li><li><strong>å¯¹/åˆ—è¡¨è¯„ä¼°ï¼ˆPair/List-Wiseï¼‰</strong>ï¼šå¤šä¸ªæ ·æœ¬çš„æ¯”è¾ƒè¯„ä¼°ã€‚</li></ul><h3 id="2-2-è¾“å‡ºæ ¼å¼"><a href="#2-2-è¾“å‡ºæ ¼å¼" class="headerlink" title="2.2 è¾“å‡ºæ ¼å¼"></a>2.2 è¾“å‡ºæ ¼å¼</h3><p>è¯„ä¼°è¾“å‡ºåŒ…æ‹¬ï¼š</p><ul><li><strong>è¯„åˆ†ï¼ˆScoreï¼‰</strong>ï¼šå¯¹æ ·æœ¬è¿›è¡Œé‡åŒ–è¯„åˆ†ã€‚</li><li><strong>æ’åºï¼ˆRankingï¼‰</strong>ï¼šæ ¹æ®ä¼˜åŠ£æ’åºã€‚</li><li><strong>é€‰æ‹©ï¼ˆSelectionï¼‰</strong>ï¼šä»å¤šä¸ªå€™é€‰ä¸­é€‰å–æœ€ä½³æ–¹æ¡ˆã€‚</li></ul><hr><h2 id="3-è¯„ä¼°å±æ€§"><a href="#3-è¯„ä¼°å±æ€§" class="headerlink" title="3. è¯„ä¼°å±æ€§"></a>3. è¯„ä¼°å±æ€§</h2><h3 id="3-1-æœ‰ç”¨æ€§ï¼ˆHelpfulnessï¼‰"><a href="#3-1-æœ‰ç”¨æ€§ï¼ˆHelpfulnessï¼‰" class="headerlink" title="3.1 æœ‰ç”¨æ€§ï¼ˆHelpfulnessï¼‰"></a>3.1 æœ‰ç”¨æ€§ï¼ˆHelpfulnessï¼‰</h3><p>LLMé€šè¿‡æŒ‡å¯¼ç”¨æˆ·ä»»åŠ¡å’Œç”Ÿæˆåé¦ˆï¼Œå¯¹å“åº”çš„æœ‰ç”¨æ€§è¿›è¡Œè¯„ä¼°ã€‚è¿™åœ¨AIå¯¹é½ï¼ˆAlignmentï¼‰ä¸­å°¤ä¸ºé‡è¦ã€‚</p><h3 id="3-2-æ— å®³æ€§ï¼ˆHarmlessnessï¼‰"><a href="#3-2-æ— å®³æ€§ï¼ˆHarmlessnessï¼‰" class="headerlink" title="3.2 æ— å®³æ€§ï¼ˆHarmlessnessï¼‰"></a>3.2 æ— å®³æ€§ï¼ˆHarmlessnessï¼‰</h3><p>è¯„ä¼°æ–‡æœ¬çš„æ— å®³æ€§æ˜¯ç”Ÿæˆå®‰å…¨å†…å®¹çš„å…³é”®ã€‚LLMå¯è¾…åŠ©æ•°æ®æ ‡æ³¨æˆ–ç›´æ¥è¯„ä¼°æ½œåœ¨çš„æœ‰å®³å†…å®¹ã€‚</p><h3 id="3-3-å¯é æ€§ï¼ˆReliabilityï¼‰"><a href="#3-3-å¯é æ€§ï¼ˆReliabilityï¼‰" class="headerlink" title="3.3 å¯é æ€§ï¼ˆReliabilityï¼‰"></a>3.3 å¯é æ€§ï¼ˆReliabilityï¼‰</h3><p>LLMå¯æ£€æµ‹äº‹å®æ€§å’Œä¸€è‡´æ€§ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡ç”Ÿæˆè¾…åŠ©è¯æ®æˆ–è¿›è¡Œå¯¹è¯çº§åˆ«çš„å¯é æ€§è¯„ä¼°ã€‚</p><h3 id="3-4-ç›¸å…³æ€§ï¼ˆRelevanceï¼‰"><a href="#3-4-ç›¸å…³æ€§ï¼ˆRelevanceï¼‰" class="headerlink" title="3.4 ç›¸å…³æ€§ï¼ˆRelevanceï¼‰"></a>3.4 ç›¸å…³æ€§ï¼ˆRelevanceï¼‰</h3><p>LLMå¯è¯„ä¼°ç”Ÿæˆæˆ–æ£€ç´¢å†…å®¹çš„ç›¸å…³æ€§ï¼Œé€‚ç”¨äºä¼šè¯ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰åœºæ™¯ã€‚</p><h3 id="3-5-å¯è¡Œæ€§ï¼ˆFeasibilityï¼‰"><a href="#3-5-å¯è¡Œæ€§ï¼ˆFeasibilityï¼‰" class="headerlink" title="3.5 å¯è¡Œæ€§ï¼ˆFeasibilityï¼‰"></a>3.5 å¯è¡Œæ€§ï¼ˆFeasibilityï¼‰</h3><p>åœ¨å¤æ‚ä»»åŠ¡ä¸­ï¼ŒLLMå¯å¯¹å€™é€‰æ­¥éª¤æˆ–è¡ŒåŠ¨è¿›è¡Œå¯è¡Œæ€§åˆ¤æ–­ï¼Œä»è€Œä¼˜åŒ–å†³ç­–è·¯å¾„ã€‚</p><h3 id="3-6-æ€»ä½“è´¨é‡ï¼ˆOverall-Qualityï¼‰"><a href="#3-6-æ€»ä½“è´¨é‡ï¼ˆOverall-Qualityï¼‰" class="headerlink" title="3.6 æ€»ä½“è´¨é‡ï¼ˆOverall Qualityï¼‰"></a>3.6 æ€»ä½“è´¨é‡ï¼ˆOverall Qualityï¼‰</h3><p>LLMé€šè¿‡å¤šç»´åº¦è¯„åˆ†ç”Ÿæˆæ•´ä½“è¯„ä»·ï¼Œé€‚ç”¨äºç”Ÿæˆä»»åŠ¡çš„ç»¼åˆæ¯”è¾ƒã€‚</p><hr><h3 id="4-æ–¹æ³•è®º"><a href="#4-æ–¹æ³•è®º" class="headerlink" title="4. æ–¹æ³•è®º"></a>4. æ–¹æ³•è®º</h3><h4 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h4><p>æ–¹æ³•è®ºéƒ¨åˆ†ä¸»è¦æ¢è®¨å¦‚ä½•ä¼˜åŒ–LLMä½œä¸ºè¯„ä¼°è€…ï¼ˆLLM-as-a-Judgeï¼‰çš„èƒ½åŠ›ï¼Œä»è°ƒä¼˜å’Œæç¤ºæŠ€æœ¯ä¸¤ä¸ªæ–¹é¢è¿›è¡Œé˜è¿°ï¼š</p><ol><li><strong>è°ƒä¼˜æŠ€æœ¯</strong>ï¼šé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œåå¥½å­¦ä¹ ç­‰æ–¹æ³•ï¼Œåˆ©ç”¨äººå·¥æ ‡æ³¨æ•°æ®æˆ–åˆæˆåé¦ˆæ¥å¢å¼ºLLMçš„åˆ¤æ–­èƒ½åŠ›ã€‚</li><li><strong>æç¤ºæŠ€æœ¯</strong>ï¼šè®¾è®¡é«˜æ•ˆçš„æç¤ºç­–ç•¥ï¼ˆå¦‚æ“ä½œäº¤æ¢ã€è§„åˆ™å¢å¼ºã€å¤šä»£ç†åä½œç­‰ï¼‰ä»¥æå‡LLMåœ¨æ¨ç†å’Œè¯„ä¼°è¿‡ç¨‹ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</li></ol><hr><h4 id="4-1-è°ƒä¼˜æŠ€æœ¯"><a href="#4-1-è°ƒä¼˜æŠ€æœ¯" class="headerlink" title="4.1 è°ƒä¼˜æŠ€æœ¯"></a>4.1 è°ƒä¼˜æŠ€æœ¯</h4><h5 id="æ•°æ®æ¥æº"><a href="#æ•°æ®æ¥æº" class="headerlink" title="æ•°æ®æ¥æº"></a>æ•°æ®æ¥æº</h5><h6 id="1-äººå·¥æ ‡æ³¨æ•°æ®"><a href="#1-äººå·¥æ ‡æ³¨æ•°æ®" class="headerlink" title="1. äººå·¥æ ‡æ³¨æ•°æ®"></a>1. <strong>äººå·¥æ ‡æ³¨æ•°æ®</strong></h6><p>äººå·¥æ ‡æ³¨æ•°æ®æä¾›äº†é«˜è´¨é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œå¸®åŠ©LLMå­¦ä¹ äººç±»åå¥½ã€‚ä»¥ä¸‹æ˜¯æ ¸å¿ƒç ”ç©¶åŠå…¶åˆ›æ–°ç‚¹ï¼š</p><ol><li><p><strong>PandaLM</strong>ã€Wang et al., 2024hã€‘ï¼š</p><ul><li>PandaLMé¡¹ç›®æ”¶é›†äº†å¤šæ ·åŒ–çš„äººå·¥æ ‡æ³¨æ•°æ®é›†ï¼Œæ¶µç›–æŒ‡ä»¤ç”Ÿæˆä»»åŠ¡çš„300,000ä¸ªæ ·æœ¬ã€‚</li><li>ä½œè€…é€šè¿‡æ•´åˆå¤šç§æ•°æ®æºï¼ˆå¦‚å¼€æ”¾é¢†åŸŸé—®ç­”å’Œå¯¹è¯ç”Ÿæˆï¼‰æ¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li><li>è¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†æ ‡å‡†åŒ–çš„æ ‡æ³¨æµç¨‹ï¼Œä»¥ç¡®ä¿æ•°æ®è´¨é‡ä¸ä¸€è‡´æ€§ã€‚</li><li>æ­¤å¤–ï¼ŒPandaLMå¼ºè°ƒå¤šè¯­è¨€æ”¯æŒï¼Œé€šè¿‡è·¨æ–‡åŒ–çš„æ•°æ®æ ‡æ³¨æé«˜æ¨¡å‹çš„é€‚ç”¨æ€§ã€‚</li><li>æœ€ç»ˆï¼ŒPandaLMè¢«è¯æ˜åœ¨å¤šä¸ªè¯„ä¼°ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…¶è¾“å‡ºä¸äººå·¥è¯„ä¼°é«˜åº¦ç›¸å…³ã€‚</li></ul></li><li><p><strong>AspectInstruct</strong>ã€Liu et al., 2024aã€‘ï¼š</p><ul><li>è¯¥ç ”ç©¶é¦–æ¬¡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å¤šç»´åº¦è¯„ä¼°çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œæ¶µç›–65ä¸ªä»»åŠ¡å’Œ27ä¸ªè¯„ä¼°ç»´åº¦ã€‚</li><li>æ•°æ®é›†ä¸­åŒ…å«å¯¹è¯ç”Ÿæˆã€æ‘˜è¦å’Œæ•°æ®åˆ°æ–‡æœ¬è½¬æ¢ç­‰å¤æ‚ä»»åŠ¡çš„å¤šæ–¹é¢è¯„åˆ†ã€‚</li><li>ä½œè€…è®¾è®¡äº†ç‹¬ç‰¹çš„ä»»åŠ¡åˆ†å‰²æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å¹¶ä¼˜å…ˆè¯„ä¼°ç‰¹å®šç»´åº¦ã€‚</li><li>ç ”ç©¶çš„äº®ç‚¹åœ¨äºæ•°æ®é›†çš„å¤šæ ·æ€§å’Œå…¨é¢æ€§ï¼Œä¸ºå¤šä»»åŠ¡è¯„ä¼°æä¾›äº†æ–°çš„åŸºå‡†ã€‚</li><li>æœ€ç»ˆï¼Œè¯¥æ•°æ®é›†æ˜¾è‘—æå‡äº†LLMåœ¨ä¸åŒè¯„ä¼°åœºæ™¯ä¸­çš„å¤šç»´åº¦ç†è§£å’Œè¯„ä¼°èƒ½åŠ›ã€‚</li></ul></li></ol><h6 id="2-åˆæˆæ•°æ®"><a href="#2-åˆæˆæ•°æ®" class="headerlink" title="2. åˆæˆæ•°æ®"></a>2. <strong>åˆæˆæ•°æ®</strong></h6><p>åˆæˆæ•°æ®é€šè¿‡LLMç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼Œå‡å°‘äº†å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼ŒåŒæ—¶æ‰©å±•äº†æ•°æ®è¦†ç›–èŒƒå›´ã€‚ä»¥ä¸‹æ˜¯æ ¸å¿ƒç ”ç©¶åŠå…¶åˆ›æ–°ç‚¹ï¼š</p><ol><li><p><strong>JudgeLM</strong>ã€Zhu et al., 2023ã€‘ï¼š</p><ul><li>ç ”ç©¶è€…åˆ©ç”¨GPT-4ç”ŸæˆåŒ…å«ä»»åŠ¡ç§å­ã€ç”Ÿæˆç­”æ¡ˆåŠç›¸å…³è¯„ä¼°çš„é«˜è´¨é‡æ•°æ®é›†ã€‚</li><li>æ•°æ®é›†ä¸­åŒ…å«10ä¸‡ä¸ªæ ·æœ¬ï¼Œè¦†ç›–äº†æŒ‡ä»¤ç”Ÿæˆä»»åŠ¡çš„å¤šç§åœºæ™¯ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ç”Ÿæˆä»»åŠ¡ç§å­çš„æ–¹æ³•ï¼Œç¡®ä¿ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§å’Œé’ˆå¯¹æ€§ã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†ä¸€ç§åŸºäºåå¥½å­¦ä¹ çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æé«˜LLMå¯¹ç»†ç²’åº¦ä»»åŠ¡çš„åˆ¤æ–­èƒ½åŠ›ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼Œç»è¿‡è¿™ç§ä¼˜åŒ–åçš„JudgeLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ä¼ ç»Ÿæ–¹æ³•ã€‚</li></ul></li><li><p><strong>Meta-Rewarding</strong>ã€Wu et al., 2024ã€‘ï¼š</p><ul><li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„â€œå…ƒå¥–åŠ±â€ï¼ˆMeta-Rewardingï¼‰æ–¹æ³•ï¼Œé€šè¿‡LLMè‡ªæˆ‘è¯„ä¼°ç”Ÿæˆçš„åˆ¤æ–­ä¿¡å·å¢å¼ºè®­ç»ƒæ•ˆæœã€‚</li><li>è¯¥æ–¹æ³•è¦æ±‚æ¨¡å‹åœ¨ç”Ÿæˆç­”æ¡ˆåå¯¹è‡ªå·±çš„è¾“å‡ºè¿›è¡Œè¯„åˆ†ï¼Œä»è€Œç”Ÿæˆåå¥½æ•°æ®ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé‡‡ç”¨ç­–ç•¥æ¨¡å‹ä½œä¸ºè¯„ä¼°è€…ï¼Œæ˜¾è‘—æé«˜äº†æ•°æ®ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚</li><li>æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡é€æ­¥æ”¹è¿›çš„åå¥½æ•°æ®è®­ç»ƒLLMï¼Œæé«˜äº†å…¶è¯„ä¼°ä»»åŠ¡çš„é²æ£’æ€§ã€‚</li><li>æœ€ç»ˆï¼ŒMeta-Rewardingå±•ç¤ºäº†LLMè‡ªæˆ‘å¢å¼ºèƒ½åŠ›çš„æ½œåŠ›ï¼Œæˆä¸ºåå¥½å­¦ä¹ é¢†åŸŸçš„é‡è¦è¿›å±•ã€‚</li></ul></li></ol><h5 id="è°ƒä¼˜æ–¹æ³•"><a href="#è°ƒä¼˜æ–¹æ³•" class="headerlink" title="è°ƒä¼˜æ–¹æ³•"></a>è°ƒä¼˜æ–¹æ³•</h5><h6 id="1-ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰"><a href="#1-ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰" class="headerlink" title="1. ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰"></a>1. <strong>ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰</strong></h6><p>ç›‘ç£å¾®è°ƒé€šè¿‡ä½¿ç”¨äººå·¥æ ‡æ³¨æˆ–åˆæˆæ•°æ®ï¼Œè®©LLMä»ç¤ºä¾‹ä¸­å­¦ä¹ åˆ¤æ–­æ ‡å‡†ã€‚ä»¥ä¸‹æ˜¯æ ¸å¿ƒç ”ç©¶åŠå…¶åˆ›æ–°ç‚¹ï¼š</p><ol><li><p><strong>FLAMe</strong>ã€Vu et al., 2024ã€‘ï¼š</p><ul><li>è¯¥ç ”ç©¶æå‡ºäº†Foundational Large Autorater Models (FLAMe)ï¼Œåˆ©ç”¨è¶…è¿‡500ä¸‡ä¸ªæ ·æœ¬è¿›è¡Œå¤§è§„æ¨¡å¤šä»»åŠ¡ç›‘ç£å¾®è°ƒã€‚</li><li>FLAMeåœ¨å¤šä»»åŠ¡æ•°æ®ä¸­å¼•å…¥äº†ç»Ÿä¸€çš„è¯„ä»·æ ‡å‡†ï¼Œæé«˜äº†æ¨¡å‹åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„è¯„ä¼°èƒ½åŠ›ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œå°†å¤šä¸ªè¯„ä¼°ç»´åº¦é›†æˆåˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†ä»»åŠ¡åˆ†å±‚è®­ç»ƒç­–ç•¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€æ­¥æŒæ¡å¤æ‚çš„è¯„ä¼°ä»»åŠ¡ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼ŒFLAMeåœ¨å¤šä¸ªç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿè¯„ä¼°æŒ‡æ ‡ã€‚</li></ul></li><li><p><strong>JSFT</strong>ã€Lee et al., 2024ã€‘ï¼š</p><ul><li>æå‡ºäº†Judge-augmented Supervised Fine-Tuningï¼ˆJSFTï¼‰æ–¹æ³•ï¼Œé€šè¿‡æ‰©å±•åå¥½å­¦ä¹ æ•°æ®å¢å¼ºå¾®è°ƒæ•ˆæœã€‚</li><li>æ•°æ®é›†ä¸­åŒ…å«ç‚¹å¯¹ç‚¹å’Œå¯¹æ¯”è¯„ä¼°ä»»åŠ¡ï¼Œä»¥å…¨é¢è¦†ç›–å¤šç§è¯„ä¼°åœºæ™¯ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œç»“åˆç›‘ç£å­¦ä¹ å’Œåå¥½å­¦ä¹ ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚</li><li>æ­¤å¤–ï¼Œç ”ç©¶è€…è®¾è®¡äº†ç®€åŒ–æç¤ºæœºåˆ¶ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹å¤„ç†å¤æ‚è¾“å…¥çš„èƒ½åŠ›ã€‚</li><li>JSFTçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶ç”Ÿæˆçš„è¯„ä¼°ç»“æœåœ¨å¤šä¸ªåŸºå‡†ä¸Šè¶…è¿‡äº†ç°æœ‰æ–¹æ³•ã€‚</li></ul></li></ol><h6 id="2-åå¥½å­¦ä¹ "><a href="#2-åå¥½å­¦ä¹ " class="headerlink" title="2. åå¥½å­¦ä¹ "></a>2. <strong>åå¥½å­¦ä¹ </strong></h6><p>åå¥½å­¦ä¹ é€šè¿‡ä¼˜åŒ–LLMçš„æ¯”è¾ƒå’Œæ’åºèƒ½åŠ›ï¼Œé€‚ç”¨äºå¤æ‚è¯„ä¼°ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯æ ¸å¿ƒç ”ç©¶åŠå…¶åˆ›æ–°ç‚¹ï¼š</p><ol><li><p><strong>HALU-J</strong>ã€Wang et al., 2024aã€‘ï¼š</p><ul><li>æå‡ºäº†ä¸€ç§åŸºäºæ‰¹è¯„çš„åå¥½å­¦ä¹ æ–¹æ³•ï¼Œä¸“æ³¨äºé€‰æ‹©ç›¸å…³è¯æ®å¹¶ç”Ÿæˆè¯¦ç»†æ‰¹è¯„ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†å¤šè¯æ®é€‰æ‹©æœºåˆ¶ï¼Œæé«˜äº†LLMçš„å¯é æ€§è¯„ä¼°èƒ½åŠ›ã€‚</li><li>è¯¥æ–¹æ³•é€šè¿‡Directed Preference Optimizationï¼ˆDPOï¼‰è¿›è¡Œä¼˜åŒ–ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åˆ¤æ–­ä»»åŠ¡é—´çš„ä¼˜åŠ£ã€‚</li><li>HALU-Jè¿˜ç»“åˆäº†ä¸Šä¸‹æ–‡æ¨ç†ï¼Œæ‰©å±•äº†åå¥½å­¦ä¹ çš„åº”ç”¨åœºæ™¯ã€‚</li><li>å®éªŒè¡¨æ˜ï¼ŒHALU-Jæ˜¾è‘—æå‡äº†å¤æ‚ä»»åŠ¡çš„è¯„ä¼°å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨äº‹å®æ€§å’Œé€»è¾‘æ€§åˆ¤æ–­ä¸Šã€‚</li></ul></li><li><p><strong>Self-Taught Evaluators</strong>ã€Wang et al., 2024fã€‘ï¼š</p><ul><li>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªå­¦ä¹ çš„è¯„ä¼°è€…æ–¹æ³•ï¼Œåˆ©ç”¨è¢«æ‰°ä¹±çš„æŒ‡ä»¤ç”Ÿæˆä½è´¨é‡æ•°æ®ä½œä¸ºåå¥½å­¦ä¹ çš„è´Ÿæ ·æœ¬ã€‚</li><li>è‡ªå­¦ä¹ æ–¹æ³•é€šè¿‡è‡ªåŠ¨ç”Ÿæˆçš„æ¬¡ä¼˜å“åº”ï¼Œæä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæ•°æ®ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡åŠ¨æ€è°ƒæ•´åå¥½ä¿¡å·ï¼Œæå‡äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œé€šç”¨æ€§ã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†åŸºäºå¤šè½®äº¤äº’çš„å­¦ä¹ ç­–ç•¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­è‡ªæˆ‘ä¼˜åŒ–ã€‚</li><li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSelf-Taught Evaluatorsåœ¨å¤šä¸ªå¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li></ul></li></ol><h3 id="4-2-æç¤ºæŠ€æœ¯"><a href="#4-2-æç¤ºæŠ€æœ¯" class="headerlink" title="4.2 æç¤ºæŠ€æœ¯"></a>4.2 æç¤ºæŠ€æœ¯</h3><h4 id="æ¦‚è¿°-1"><a href="#æ¦‚è¿°-1" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h4><p>æç¤ºæŠ€æœ¯ï¼ˆPromptingï¼‰é€šè¿‡è®¾è®¡é«˜æ•ˆçš„æç¤ºç­–ç•¥å’Œæ¨ç†æµç¨‹ä¼˜åŒ–LLMçš„è¯„ä¼°èƒ½åŠ›ã€‚è¿™éƒ¨åˆ†æ¢è®¨å¦‚ä½•åœ¨æ¨ç†é˜¶æ®µåˆ©ç”¨æç¤ºæŠ€æœ¯æå‡åˆ¤æ–­ç²¾åº¦ï¼Œå‡å°‘åå·®ï¼Œå¹¶å¢å¼ºæ¨¡å‹çš„è¯„ä¼°é²æ£’æ€§ã€‚ä¸»è¦æ–¹æ³•åŒ…æ‹¬æ“ä½œäº¤æ¢ã€è§„åˆ™å¢å¼ºã€å¤šä»£ç†åä½œã€æ¼”ç¤ºã€å¤šè½®äº¤äº’ä»¥åŠæ¯”è¾ƒåŠ é€Ÿã€‚</p><hr><h4 id="4-2-1-æ“ä½œäº¤æ¢ï¼ˆSwapping-Operationï¼‰"><a href="#4-2-1-æ“ä½œäº¤æ¢ï¼ˆSwapping-Operationï¼‰" class="headerlink" title="4.2.1 æ“ä½œäº¤æ¢ï¼ˆSwapping Operationï¼‰"></a>4.2.1 æ“ä½œäº¤æ¢ï¼ˆSwapping Operationï¼‰</h4><h5 id="æ¦‚è¿°-2"><a href="#æ¦‚è¿°-2" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>æ“ä½œäº¤æ¢æŠ€æœ¯é€šè¿‡æ›´æ”¹å€™é€‰é¡¹é¡ºåºå‡å°‘è¯„ä¼°çš„åç½®æ€§ï¼Œç¡®ä¿LLMå¯¹è¾“å…¥é¡ºåºä¸æ•æ„Ÿï¼Œä»è€Œæé«˜è¯„ä¼°çš„å…¬å¹³æ€§å’Œå¯é æ€§ã€‚</p><h6 id="1-MT-Benchã€Zheng-et-al-2023ã€‘ï¼š"><a href="#1-MT-Benchã€Zheng-et-al-2023ã€‘ï¼š" class="headerlink" title="1. MT-Benchã€Zheng et al., 2023ã€‘ï¼š"></a>1. <strong>MT-Bench</strong>ã€Zheng et al., 2023ã€‘ï¼š</h6><ul><li>æœ¬ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æå‡ºæ“ä½œäº¤æ¢æŠ€æœ¯ï¼Œé€šè¿‡å¤šè½®è¯„ä¼°å‡å°‘LLMçš„é¡ºåºæ•æ„Ÿæ€§ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥â€œå¯¹ç§°æ€§æ£€æŸ¥â€æœºåˆ¶ï¼šå°†å€™é€‰é¡¹é¡ºåºäº’æ¢ï¼Œè‹¥è¯„åˆ†ç»“æœä¸€è‡´ï¼Œåˆ™æ ‡è®°ä¸ºç¨³å®šï¼Œå¦åˆ™æ ‡è®°ä¸ºä¸ç¨³å®šã€‚</li><li>ä½œè€…å‘ç°æ“ä½œäº¤æ¢èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘ç”±äºä½ç½®åå·®å¯¼è‡´çš„é”™è¯¯åˆ¤æ–­ã€‚</li><li>è¯¥æŠ€æœ¯åº”ç”¨äºå¤šä»»åŠ¡è¯„ä¼°ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç”Ÿæˆä»»åŠ¡çš„æ’åºä¸­è¡¨ç°çªå‡ºã€‚</li><li>MT-Benchä¸ºåç»­çš„LLMè¯„ä¼°æŠ€æœ¯æä¾›äº†ä¸€ä¸ªé‡è¦çš„å…¬å¹³æ€§åŸºå‡†ã€‚</li></ul><h6 id="2-Starlingã€Zhu-et-al-2024aã€‘ï¼š"><a href="#2-Starlingã€Zhu-et-al-2024aã€‘ï¼š" class="headerlink" title="2. Starlingã€Zhu et al., 2024aã€‘ï¼š"></a>2. <strong>Starling</strong>ã€Zhu et al., 2024aã€‘ï¼š</h6><ul><li>æå‡ºä¸€ç§ç±»ä¼¼é“¾å¼æ¨ç†ï¼ˆChain-of-Thought, CoTï¼‰çš„æç¤ºæŠ€æœ¯ï¼Œé€šè¿‡å…¨é¢è¯„ä¼°æ‰€æœ‰å€™é€‰é¡¹çš„ä¸¤ä¸¤å…³ç³»ï¼Œå†æ€»ç»“ä¸ºæœ€ç»ˆæ’åºã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼ºåˆ¶æ¨¡å‹ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å¯¹æ¯”ç»“æœï¼Œç¡®ä¿è¯„ä¼°å…¨é¢ä¸”æ— åã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†ä¸€ç§äº¤å‰éªŒè¯æœºåˆ¶ï¼Œè¿›ä¸€æ­¥æé«˜è¯„ä¼°ç¨³å®šæ€§ã€‚</li><li>å®éªŒæ˜¾ç¤ºï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—å‡å°‘äº†ä½ç½®åå·®å¸¦æ¥çš„è¯¯å·®ï¼Œç‰¹åˆ«æ˜¯åœ¨æ’åºä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li><li>StarlingéªŒè¯äº†é“¾å¼æ€ç»´ç»“åˆæ“ä½œäº¤æ¢æŠ€æœ¯çš„æ½œåŠ›ï¼Œå°¤å…¶åœ¨å¤æ‚å¯¹æ¯”ä»»åŠ¡ä¸­çš„æ•ˆæœæ˜¾è‘—ã€‚</li></ul><hr><h4 id="4-2-2-è§„åˆ™å¢å¼ºï¼ˆRule-Augmentationï¼‰"><a href="#4-2-2-è§„åˆ™å¢å¼ºï¼ˆRule-Augmentationï¼‰" class="headerlink" title="4.2.2 è§„åˆ™å¢å¼ºï¼ˆRule Augmentationï¼‰"></a>4.2.2 è§„åˆ™å¢å¼ºï¼ˆRule Augmentationï¼‰</h4><h5 id="æ¦‚è¿°-3"><a href="#æ¦‚è¿°-3" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>è§„åˆ™å¢å¼ºæŠ€æœ¯é€šè¿‡åœ¨æç¤ºä¸­åµŒå…¥æ˜ç¡®çš„åŸåˆ™ã€æ ‡å‡†æˆ–å‚è€ƒå†…å®¹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´åŠ ç³»ç»Ÿåœ°è¯„ä¼°ä»»åŠ¡ï¼Œä»è€Œæå‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚</p><h6 id="1-Constitutional-AIã€Bai-et-al-2022ã€‘ï¼š"><a href="#1-Constitutional-AIã€Bai-et-al-2022ã€‘ï¼š" class="headerlink" title="1. Constitutional AIã€Bai et al., 2022ã€‘ï¼š"></a>1. <strong>Constitutional AI</strong>ã€Bai et al., 2022ã€‘ï¼š</h6><ul><li>æœ¬ç ”ç©¶å¼•å…¥äº†â€œåŸåˆ™é©±åŠ¨â€çš„è§„åˆ™å¢å¼ºæ–¹æ³•ï¼Œåˆ©ç”¨å¸®åŠ©æ€§ã€æ— å®³æ€§å’Œè¯šå®æ€§ç­‰æ ‡å‡†æŒ‡å¯¼æ¨¡å‹è¯„ä¼°ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºä¸ºæ¯ä¸ªè¯„ä¼°ç»´åº¦å®šä¹‰è¯¦ç»†çš„è¯„åˆ†æ ‡å‡†ï¼Œå¹¶é€šè¿‡åŸåˆ™çº¦æŸç”Ÿæˆå†…å®¹ã€‚</li><li>ä½œè€…é‡‡ç”¨å¤šå±‚æç¤ºè®¾è®¡ï¼Œä½¿LLMèƒ½å¤Ÿé€æ­¥æ¨ç†å¹¶ç»™å‡ºæœ€ç»ˆè¯„ä¼°ã€‚</li><li>å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸­çš„åˆ¤æ–­ä¸€è‡´æ€§ã€‚</li><li>Constitutional AIæˆä¸ºåç»­ç ”ç©¶çš„é‡è¦åŸºçŸ³ï¼Œä¸ºåŸºäºè§„åˆ™çš„è¯„ä¼°æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚</li></ul><h6 id="2-OAIFã€Guo-et-al-2024ã€‘ï¼š"><a href="#2-OAIFã€Guo-et-al-2024ã€‘ï¼š" class="headerlink" title="2. OAIFã€Guo et al., 2024ã€‘ï¼š"></a>2. <strong>OAIF</strong>ã€Guo et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†åœ¨çº¿AIåé¦ˆï¼ˆOnline AI Feedback, OAIFï¼‰æ¡†æ¶ï¼Œé€šè¿‡å®æ—¶åŸåˆ™æŒ‡å¯¼æå‡æ¨¡å‹è¯„ä¼°çš„çµæ´»æ€§ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºåŠ¨æ€è°ƒæ•´è¯„ä¼°è§„åˆ™ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”å¤šå˜çš„ä»»åŠ¡éœ€æ±‚ã€‚</li><li>OAIFå¼•å…¥äº†ç»†ç²’åº¦çš„å¤šç»´è¯„åˆ†ç­–ç•¥ï¼Œä¸ºæ¯ä¸ªå€™é€‰é¡¹ç”Ÿæˆç‹¬ç«‹çš„è¯„ä¼°æŠ¥å‘Šã€‚</li><li>ä½œè€…éªŒè¯äº†è¿™ç§æ–¹æ³•åœ¨å®æ—¶å†³ç­–ä¸­çš„æ½œåŠ›ï¼Œå°¤å…¶åœ¨å¯¹è¯å’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚</li><li>OAIFå±•ç°äº†è§„åˆ™å¢å¼ºçš„å®æ—¶é€‚åº”èƒ½åŠ›ï¼Œä¸ºå®æ—¶è¯„ä¼°ä»»åŠ¡æä¾›äº†æ–°æ–¹å‘ã€‚</li></ul><hr><h4 id="4-2-3-å¤šä»£ç†åä½œï¼ˆMulti-agent-Collaborationï¼‰"><a href="#4-2-3-å¤šä»£ç†åä½œï¼ˆMulti-agent-Collaborationï¼‰" class="headerlink" title="4.2.3 å¤šä»£ç†åä½œï¼ˆMulti-agent Collaborationï¼‰"></a>4.2.3 å¤šä»£ç†åä½œï¼ˆMulti-agent Collaborationï¼‰</h4><h5 id="æ¦‚è¿°-4"><a href="#æ¦‚è¿°-4" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>å¤šä»£ç†åä½œé€šè¿‡ç»„åˆå¤šä¸ªLLMçš„è¯„ä¼°ç»“æœï¼Œå‡å°‘å•ä¸€æ¨¡å‹çš„åå·®ï¼Œæé«˜è¯„ä¼°çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•å¼ºè°ƒæ¨¡å‹ä¹‹é—´çš„è§’è‰²åˆ†å·¥å’Œåˆä½œã€‚</p><h6 id="1-Peer-Rank-PR-ã€Li-et-al-2023ã€‘ï¼š"><a href="#1-Peer-Rank-PR-ã€Li-et-al-2023ã€‘ï¼š" class="headerlink" title="1. **Peer Rank (PR)**ã€Li et al., 2023ã€‘ï¼š"></a>1. **Peer Rank (PR)**ã€Li et al., 2023ã€‘ï¼š</h6><ul><li>æå‡ºäº†åŒè¡Œæ’åç®—æ³•ï¼Œæ•´åˆå¤šä¸ªLLMçš„å¯¹æ¯”åå¥½ç”Ÿæˆæœ€ç»ˆæ’åºã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†â€œåŠ æƒæŠ•ç¥¨â€æœºåˆ¶ï¼Œæ ¹æ®æ¨¡å‹ä¹‹é—´çš„è¯„åˆ†ä¸€è‡´æ€§è°ƒæ•´æƒé‡ã€‚</li><li>è¯¥ç ”ç©¶è¿˜æ¢è®¨äº†ä»£ç†é—´çš„åä½œæ•ˆç‡å’Œé²æ£’æ€§ï¼Œæå‡ºäº†ä¼˜åŒ–åä½œè·¯å¾„çš„æ–¹æ³•ã€‚</li><li>PRçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶ç”Ÿæˆçš„è¯„ä¼°ç»“æœåœ¨æ’åºå‡†ç¡®æ€§ä¸Šä¼˜äºä¼ ç»Ÿå•æ¨¡å‹æ–¹æ³•ã€‚</li><li>è¯¥ç ”ç©¶ä¸ºå¤šæ¨¡å‹åä½œæŠ€æœ¯å¥ å®šäº†ç†è®ºåŸºç¡€ï¼Œæ˜¯åç»­ç ”ç©¶çš„é‡è¦å‚è€ƒã€‚</li></ul><h6 id="2-Cascaded-Selective-Evaluationã€Jung-et-al-2024ã€‘ï¼š"><a href="#2-Cascaded-Selective-Evaluationã€Jung-et-al-2024ã€‘ï¼š" class="headerlink" title="2. Cascaded Selective Evaluationã€Jung et al., 2024ã€‘ï¼š"></a>2. <strong>Cascaded Selective Evaluation</strong>ã€Jung et al., 2024ã€‘ï¼š</h6><ul><li>è®¾è®¡äº†çº§è”é€‰æ‹©è¯„ä¼°æ¡†æ¶ï¼Œé¦–å…ˆç”±è¾ƒå¼±çš„æ¨¡å‹è¿›è¡Œåˆæ­¥è¯„ä¼°ï¼Œä»…åœ¨éœ€è¦æ—¶è°ƒç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡åˆ†çº§ç­–ç•¥ä¼˜åŒ–è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶ç¡®ä¿è¯„ä¼°ç»“æœçš„é«˜è´¨é‡ã€‚</li><li>ä½œè€…æå‡ºäº†ä¸€ç§äº¤å‰éªŒè¯æœºåˆ¶ï¼Œç»“åˆå¤šä¸ªä»£ç†çš„ç»“æœç”Ÿæˆæœ€ç»ˆåˆ¤æ–­ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§çº§è”ç­–ç•¥åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„èµ„æºæ•ˆç‡æå‡ã€‚</li><li>Cascaded Selective Evaluationå±•ç¤ºäº†å¤šä»£ç†åä½œåœ¨èµ„æºæœ‰é™æƒ…å†µä¸‹çš„æ½œåŠ›ã€‚</li></ul><hr><h4 id="4-2-4-æ¼”ç¤ºï¼ˆDemonstrationï¼‰"><a href="#4-2-4-æ¼”ç¤ºï¼ˆDemonstrationï¼‰" class="headerlink" title="4.2.4 æ¼”ç¤ºï¼ˆDemonstrationï¼‰"></a>4.2.4 æ¼”ç¤ºï¼ˆDemonstrationï¼‰</h4><h5 id="æ¦‚è¿°-5"><a href="#æ¦‚è¿°-5" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>æ¼”ç¤ºæŠ€æœ¯åˆ©ç”¨å…·ä½“çš„ç¤ºä¾‹ä½œä¸ºæç¤ºï¼Œå¸®åŠ©LLMå­¦ä¹ è¯„ä¼°æ ‡å‡†ã€‚è¿™ç§æ–¹æ³•é€šè¿‡å°‘é‡é«˜è´¨é‡æ ·ä¾‹æ˜¾è‘—æé«˜æ¨¡å‹çš„è¯„ä¼°èƒ½åŠ›ã€‚</p><h6 id="1-ALLUREã€Hasanbeig-et-al-2023ã€‘ï¼š"><a href="#1-ALLUREã€Hasanbeig-et-al-2023ã€‘ï¼š" class="headerlink" title="1. ALLUREã€Hasanbeig et al., 2023ã€‘ï¼š"></a>1. <strong>ALLURE</strong>ã€Hasanbeig et al., 2023ã€‘ï¼š</h6><ul><li>æå‡ºäº†è¿­ä»£æ¼”ç¤ºæŠ€æœ¯ï¼Œé€šè¿‡åœ¨æç¤ºä¸­åŠ å…¥æ˜¾è‘—åå·®çš„ç¤ºä¾‹æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé‡‡ç”¨åŠ¨æ€æ¼”ç¤ºæ–¹æ³•ï¼Œé€æ­¥æ›´æ–°æç¤ºä»¥é€‚åº”ä¸åŒçš„è¯„ä¼°ä»»åŠ¡ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨ä½èµ„æºåœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨æ–°ä»»åŠ¡çš„é€‚åº”æ€§ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚</li><li>ä½œè€…è¿˜æ¢è®¨äº†å¦‚ä½•é€‰æ‹©ä»£è¡¨æ€§æ ·ä¾‹ä»¥æœ€å¤§åŒ–æ¼”ç¤ºæ•ˆæœã€‚</li><li>ALLUREéªŒè¯äº†é«˜è´¨é‡æ¼”ç¤ºæ ·ä¾‹åœ¨æå‡è¯„ä¼°èƒ½åŠ›æ–¹é¢çš„é‡è¦æ€§ã€‚</li></ul><h6 id="2-ICEã€Jain-et-al-2023bã€‘ï¼š"><a href="#2-ICEã€Jain-et-al-2023bã€‘ï¼š" class="headerlink" title="2. ICEã€Jain et al., 2023bã€‘ï¼š"></a>2. <strong>ICE</strong>ã€Jain et al., 2023bã€‘ï¼š</h6><ul><li>æå‡ºäº†äº¤äº’å¼å¤šç»´è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å°‘é‡ä¸Šä¸‹æ–‡ç¤ºä¾‹æŒ‡å¯¼LLMè¯„ä¼°ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå°†è¯„ä¼°ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªç‹¬ç«‹ç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦éƒ½æœ‰é’ˆå¯¹æ€§çš„ç¤ºä¾‹æ”¯æŒã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒICEæ¡†æ¶æ˜¾è‘—å‡å°‘äº†æ¨¡å‹åœ¨å¤šç»´ä»»åŠ¡ä¸­çš„è¯„ä¼°åå·®ã€‚</li><li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶ç”Ÿæˆçš„è¯„ä¼°ç»“æœåœ¨ä¸äººå·¥è¯„ä»·çš„ä¸€è‡´æ€§ä¸Šè¾¾åˆ°é«˜æ°´å¹³ã€‚</li><li>ICEä¸ºå¤šç»´åº¦è¯„ä¼°ä»»åŠ¡çš„æç¤ºè®¾è®¡æä¾›äº†æ–°æ€è·¯ã€‚</li></ul><hr><h4 id="4-2-5-å¤šè½®äº¤äº’ï¼ˆMulti-turn-Interactionï¼‰"><a href="#4-2-5-å¤šè½®äº¤äº’ï¼ˆMulti-turn-Interactionï¼‰" class="headerlink" title="4.2.5 å¤šè½®äº¤äº’ï¼ˆMulti-turn Interactionï¼‰"></a>4.2.5 å¤šè½®äº¤äº’ï¼ˆMulti-turn Interactionï¼‰</h4><h5 id="æ¦‚è¿°-6"><a href="#æ¦‚è¿°-6" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>å¤šè½®äº¤äº’é€šè¿‡åŠ¨æ€è°ƒæ•´æç¤ºå’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸ºLLMæä¾›æ›´å…¨é¢çš„è¯„ä¼°ä¾æ®ï¼Œé€‚ç”¨äºéœ€è¦å¤šæ­¥æ¨ç†çš„å¤æ‚ä»»åŠ¡ã€‚</p><h6 id="1-KIEvalã€Yu-et-al-2024ã€‘ï¼š"><a href="#1-KIEvalã€Yu-et-al-2024ã€‘ï¼š" class="headerlink" title="1. KIEvalã€Yu et al., 2024ã€‘ï¼š"></a>1. <strong>KIEval</strong>ã€Yu et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†çŸ¥è¯†äº¤äº’å¼è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€é—®ç­”ç”Ÿæˆä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†â€œäº¤äº’è€…â€è§’è‰²ï¼Œæ¨¡æ‹Ÿç”¨æˆ·å’Œæ¨¡å‹ä¹‹é—´çš„åŠ¨æ€äº¤äº’ã€‚</li><li>ä½œè€…è®¾è®¡äº†ä¸€ç§é²æ£’æ€§æ£€æµ‹æœºåˆ¶ï¼Œé¿å…å› ä¸Šä¸‹æ–‡æ±¡æŸ“å¯¼è‡´çš„é”™è¯¯è¯„ä¼°ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒKIEvalåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿé™æ€è¯„ä¼°æ–¹æ³•ã€‚</li><li>æ­¤æ¡†æ¶é€‚ç”¨äºå¤šç»´åº¦è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦åŠ¨æ€è°ƒæ•´ä¸Šä¸‹æ–‡çš„åœºæ™¯ä¸­ã€‚</li></ul><h6 id="2-Auto-Arenaã€Zhao-et-al-2024cã€‘ï¼š"><a href="#2-Auto-Arenaã€Zhao-et-al-2024cã€‘ï¼š" class="headerlink" title="2. Auto-Arenaã€Zhao et al., 2024cã€‘ï¼š"></a>2. <strong>Auto-Arena</strong>ã€Zhao et al., 2024cã€‘ï¼š</h6><ul><li>è®¾è®¡äº†ä¸€ç§å¤šè½®è¾©è®ºæ¡†æ¶ï¼Œå…è®¸å¤šä¸ªæ¨¡å‹å›´ç»•ç‰¹å®šä»»åŠ¡è¿›è¡Œäº¤äº’è®¨è®ºã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºç»“åˆå¤šè½®é—®ç­”å’ŒåŠ¨æ€è¯„åˆ†æœºåˆ¶ï¼Œä»ä¸åŒè§’åº¦å¯¹å€™é€‰ç­”æ¡ˆè¿›è¡Œè¯„ä¼°ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿæ­ç¤ºå€™é€‰ç­”æ¡ˆé—´çš„æ·±å±‚æ¬¡å·®å¼‚ã€‚</li><li>ä½œè€…è¿˜æ¢è®¨äº†å¦‚ä½•é€šè¿‡åŠ¨æ€è°ƒæ•´è¾©è®ºå†…å®¹æé«˜è¯„ä¼°æ•ˆç‡ã€‚</li><li>Auto-Arenaå±•ç¤ºäº†å¤šè½®äº¤äº’åœ¨å¤æ‚è¯„ä¼°ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚</li></ul><hr><h4 id="4-2-6-æ¯”è¾ƒåŠ é€Ÿï¼ˆComparison-Accelerationï¼‰"><a href="#4-2-6-æ¯”è¾ƒåŠ é€Ÿï¼ˆComparison-Accelerationï¼‰" class="headerlink" title="4.2.6 æ¯”è¾ƒåŠ é€Ÿï¼ˆComparison Accelerationï¼‰"></a>4.2.6 æ¯”è¾ƒåŠ é€Ÿï¼ˆComparison Accelerationï¼‰</h4><h5 id="æ¦‚è¿°-7"><a href="#æ¦‚è¿°-7" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>æ¯”è¾ƒåŠ é€ŸæŠ€æœ¯é€šè¿‡ä¼˜åŒ–æ¯”è¾ƒæµç¨‹ï¼Œå‡å°‘å¤šå€™é€‰æ’åºä»»åŠ¡çš„è®¡ç®—æˆæœ¬ï¼Œæé«˜è¯„ä¼°æ•ˆç‡ã€‚</p><h6 id="1-Ranked-Pairingã€Zhai-et-al-2024ã€‘ï¼š"><a href="#1-Ranked-Pairingã€Zhai-et-al-2024ã€‘ï¼š" class="headerlink" title="1. Ranked Pairingã€Zhai et al., 2024ã€‘ï¼š"></a>1. <strong>Ranked Pairing</strong>ã€Zhai et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ç§åŸºäºåŸºçº¿æ¯”è¾ƒçš„æ’åºæ–¹æ³•ï¼Œé€šè¿‡å¯¹æ‰€æœ‰å€™é€‰é¡¹ä¸åŸºçº¿è¿›è¡Œæ¯”è¾ƒç¡®å®šä¼˜åŠ£ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé¿å…ä¼ ç»Ÿä¸¤ä¸¤æ¯”è¾ƒçš„é«˜è®¡ç®—å¼€é”€ï¼Œæ˜¾è‘—æé«˜äº†è¯„ä¼°æ•ˆç‡ã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”æ¯”è¾ƒç­–ç•¥ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ’åºæ€§èƒ½ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒRanked Pairingåœ¨å¤§è§„æ¨¡æ’åºä»»åŠ¡ä¸­è¡¨ç°å‡ºæé«˜çš„æ•ˆç‡ã€‚</li><li>æ­¤æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºéœ€è¦å¿«é€Ÿç”Ÿæˆæ’åºç»“æœçš„åœºæ™¯ã€‚</li></ul><h6 id="2-Tournament-based-Comparisonã€Lee-et-al-2024ã€‘ï¼š"><a href="#2-Tournament-based-Comparisonã€Lee-et-al-2024ã€‘ï¼š" class="headerlink" title="2. Tournament-based Comparisonã€Lee et al., 2024ã€‘ï¼š"></a>2. <strong>Tournament-based Comparison</strong>ã€Lee et al., 2024ã€‘ï¼š</h6><ul><li>é‡‡ç”¨é”¦æ ‡èµ›å¼çš„æ¯”è¾ƒæ–¹æ³•ï¼Œæ„å»ºæ ‘çŠ¶ç»“æ„é€å±‚ç­›é€‰æœ€ä½³</li></ul><p>å€™é€‰ã€‚</p><ul><li>åˆ›æ–°ç‚¹åœ¨äºç»“åˆæ‹’ç»é‡‡æ ·å’Œå¤šè½®æ¯”è¾ƒï¼Œå‡å°‘äº†ä½è´¨é‡å€™é€‰çš„å½±å“ã€‚</li><li>ä½œè€…æ¢è®¨äº†ä¸åŒæ ‘ç»“æ„è®¾è®¡å¯¹è¯„ä¼°æ•ˆç‡å’Œå‡†ç¡®æ€§çš„å½±å“ã€‚</li><li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šå€™é€‰ä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚</li><li>Tournament-based Comparisonå±•ç¤ºäº†åŸºäºç»“æ„åŒ–æ¯”è¾ƒçš„æ½œåœ¨ä¼˜åŠ¿ã€‚</li></ul><hr><h3 id="5-åº”ç”¨åœºæ™¯"><a href="#5-åº”ç”¨åœºæ™¯" class="headerlink" title="5. åº”ç”¨åœºæ™¯"></a>5. åº”ç”¨åœºæ™¯</h3><h4 id="æ¦‚è¿°-8"><a href="#æ¦‚è¿°-8" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h4><p>LLM-as-a-Judgeçš„åº”ç”¨åœºæ™¯å·²ä»æœ€åˆçš„ç”Ÿæˆä»»åŠ¡è¯„ä¼°æ‰©å±•åˆ°å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬è¯„ä¼°ã€å¯¹é½ï¼ˆAlignmentï¼‰ã€æ£€ç´¢å’Œæ¨ç†ï¼ˆReasoningï¼‰ã€‚è¿™ä¸€éƒ¨åˆ†ç³»ç»Ÿæ€§åœ°ä»‹ç»è¿™äº›åº”ç”¨åœºæ™¯ï¼Œè®¨è®ºæ¯ç§åº”ç”¨çš„å…·ä½“ä»»åŠ¡å’Œä»£è¡¨æ€§ç ”ç©¶ã€‚</p><hr><h4 id="5-1-è¯„ä¼°"><a href="#5-1-è¯„ä¼°" class="headerlink" title="5.1 è¯„ä¼°"></a>5.1 è¯„ä¼°</h4><h5 id="æ¦‚è¿°-9"><a href="#æ¦‚è¿°-9" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>LLM-as-a-Judgeæœ€åˆçš„æ ¸å¿ƒåº”ç”¨æ˜¯è¯„ä¼°ä»»åŠ¡ï¼ŒåŒ…æ‹¬å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚å¯¹è¯ç”Ÿæˆã€æ‘˜è¦ç”Ÿæˆï¼‰ã€æ¨ç†ä»»åŠ¡ï¼Œä»¥åŠå…¶ä»–æ–°å…´ä»»åŠ¡ã€‚é€šè¿‡LLMè¯„ä¼°ï¼Œèƒ½å¤Ÿæ›´ç²¾å‡†åœ°æ•æ‰å¤æ‚ç”Ÿæˆä»»åŠ¡ä¸­çš„è´¨é‡ã€ç›¸å…³æ€§åŠé€»è¾‘æ€§ç­‰ç»´åº¦ã€‚</p><h6 id="1-MD-Judgeã€Li-et-al-2024fã€‘ï¼š"><a href="#1-MD-Judgeã€Li-et-al-2024fã€‘ï¼š" class="headerlink" title="1. MD-Judgeã€Li et al., 2024fã€‘ï¼š"></a>1. <strong>MD-Judge</strong>ã€Li et al., 2024fã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸“é—¨é’ˆå¯¹å®‰å…¨æ€§ç›¸å…³é—®ç­”çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºæ£€æµ‹LLMåœ¨ç”Ÿæˆæ•æ„Ÿå†…å®¹æ—¶çš„å¯é æ€§ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†å¤šç»´åº¦çš„å®‰å…¨æ€§è¯„ä¼°æ ‡å‡†ï¼ŒåŒ…æ‹¬æ½œåœ¨ä¼¤å®³æ€§ã€é“å¾·é£é™©ä»¥åŠè¯­è¨€è¯¯å¯¼æ€§ã€‚</li><li>ä½œè€…é€šè¿‡å¯¹æ¯”å¤šä¸ªLLMçš„è¯„ä¼°èƒ½åŠ›ï¼ŒéªŒè¯äº†MD-Judgeæ¡†æ¶çš„é²æ£’æ€§ã€‚</li><li>æ­¤æ¡†æ¶åœ¨è¯„ä¼°å¤æ‚åœºæ™¯ï¼ˆå¦‚æ¶æ„é—®é¢˜ï¼‰çš„ç”Ÿæˆæ•ˆæœæ–¹é¢è¡¨ç°çªå‡ºã€‚</li><li>MD-Judgeä¸ºç”Ÿæˆæ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°æä¾›äº†ä¸€ä¸ªæ–°çš„åŸºå‡†ã€‚</li></ul><h6 id="2-Chanæ¡†æ¶ã€Chan-et-al-2023ã€‘ï¼š"><a href="#2-Chanæ¡†æ¶ã€Chan-et-al-2023ã€‘ï¼š" class="headerlink" title="2. Chanæ¡†æ¶ã€Chan et al., 2023ã€‘ï¼š"></a>2. <strong>Chanæ¡†æ¶</strong>ã€Chan et al., 2023ã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ä¸ªå¤šä»£ç†è¾©è®ºæ¡†æ¶ï¼Œé€šè¿‡è®©å¤šä¸ªLLMè§’è‰²åˆ†åˆ«ç”Ÿæˆç­”æ¡ˆå¹¶å½¼æ­¤è¯„ä¼°ï¼Œæå‡ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°è´¨é‡ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†è§’è‰²åˆ†å·¥æœºåˆ¶ï¼Œä¸åŒæ¨¡å‹åœ¨è¾©è®ºä¸­æ‰®æ¼”ä¸åŒçš„ç«‹åœºï¼Œä»å¤šè§’åº¦è¯„ä¼°å€™é€‰ç­”æ¡ˆã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—æå‡è¯„ä¼°ç»“æœçš„ç»†ç²’åº¦å’Œå¤šæ ·æ€§ã€‚</li><li>ä½œè€…è¿˜æ¢è®¨äº†æ¨¡å‹é—´çš„äº¤äº’å¦‚ä½•å½±å“è¯„ä¼°çš„ä¸€è‡´æ€§å’Œå…¬å¹³æ€§ã€‚</li><li>Chanæ¡†æ¶åœ¨å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„åº”ç”¨è¡¨æ˜ï¼Œæ¨¡å‹ä¹‹é—´çš„åä½œèƒ½å¤Ÿæ˜¾è‘—æ”¹è¿›è¯„ä¼°è´¨é‡ã€‚</li></ul><h6 id="3-ICEã€Jain-et-al-2023bã€‘ï¼š"><a href="#3-ICEã€Jain-et-al-2023bã€‘ï¼š" class="headerlink" title="3. ICEã€Jain et al., 2023bã€‘ï¼š"></a>3. <strong>ICE</strong>ã€Jain et al., 2023bã€‘ï¼š</h6><ul><li>æå‡ºäº†äº¤äº’å¼å¤šç»´è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å°‘é‡ä¸Šä¸‹æ–‡ç¤ºä¾‹æŒ‡å¯¼LLMè¯„ä¼°ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå°†è¯„ä¼°ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªç‹¬ç«‹ç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦éƒ½æœ‰é’ˆå¯¹æ€§çš„ç¤ºä¾‹æ”¯æŒã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒICEæ¡†æ¶æ˜¾è‘—å‡å°‘äº†æ¨¡å‹åœ¨å¤šç»´ä»»åŠ¡ä¸­çš„è¯„ä¼°åå·®ã€‚</li><li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶ç”Ÿæˆçš„è¯„ä¼°ç»“æœåœ¨ä¸äººå·¥è¯„ä»·çš„ä¸€è‡´æ€§ä¸Šè¾¾åˆ°é«˜æ°´å¹³ã€‚</li><li>ICEä¸ºå¤šç»´åº¦è¯„ä¼°ä»»åŠ¡çš„æç¤ºè®¾è®¡æä¾›äº†æ–°æ€è·¯ã€‚</li></ul><hr><h4 id="5-2-å¯¹é½ï¼ˆAlignmentï¼‰"><a href="#5-2-å¯¹é½ï¼ˆAlignmentï¼‰" class="headerlink" title="5.2 å¯¹é½ï¼ˆAlignmentï¼‰"></a>5.2 å¯¹é½ï¼ˆAlignmentï¼‰</h4><h5 id="æ¦‚è¿°-10"><a href="#æ¦‚è¿°-10" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>å¯¹é½ä»»åŠ¡çš„ç›®æ ‡æ˜¯é€šè¿‡è®­ç»ƒæˆ–å¾®è°ƒä½¿LLMçš„ç”Ÿæˆå†…å®¹æ›´ç¬¦åˆäººç±»çš„ä»·å€¼è§‚å’Œåå¥½ã€‚LLM-as-a-Judgeè¢«å¹¿æ³›ç”¨äºç”Ÿæˆå¯¹é½æ•°æ®å’Œè¯„ä¼°å¯¹é½æ•ˆæœã€‚</p><h6 id="1-Constitutional-AIã€Bai-et-al-2022ã€‘ï¼š-1"><a href="#1-Constitutional-AIã€Bai-et-al-2022ã€‘ï¼š-1" class="headerlink" title="1. Constitutional AIã€Bai et al., 2022ã€‘ï¼š"></a>1. <strong>Constitutional AI</strong>ã€Bai et al., 2022ã€‘ï¼š</h6><ul><li>æå‡ºäº†åŸºäºåŸåˆ™å¯¹é½çš„æ¡†æ¶ï¼Œé€šè¿‡å®šä¹‰å¸®åŠ©æ€§ã€æ— å®³æ€§å’Œè¯šå®æ€§ç­‰åŸåˆ™ï¼Œä¼˜åŒ–ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå°†åŸåˆ™èå…¥å¥–åŠ±å»ºæ¨¡è¿‡ç¨‹ï¼Œåˆ©ç”¨LLMç”Ÿæˆçš„åå¥½ä¿¡å·æ„å»ºå¯¹é½æ•°æ®é›†ã€‚</li><li>ä½œè€…é€šè¿‡å¤šè½®å®éªŒéªŒè¯äº†è¿™ç§åŸºäºè§„åˆ™çš„å¯¹é½æ–¹æ³•å¯¹ç”Ÿæˆè´¨é‡çš„æ˜¾è‘—æå‡ã€‚</li><li>æ­¤æ¡†æ¶é€‚ç”¨äºå„ç§ç”Ÿæˆä»»åŠ¡ï¼Œå°¤å…¶åœ¨å‡å°‘æœ‰å®³è¾“å‡ºæ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚</li><li>Constitutional AIçš„æˆåŠŸå±•ç¤ºäº†åŸºäºè§„åˆ™çš„å¯¹é½æ–¹æ³•çš„æ½œåŠ›ã€‚</li></ul><h6 id="2-DIRECT-RLAIFã€Lee-et-al-2023ã€‘ï¼š"><a href="#2-DIRECT-RLAIFã€Lee-et-al-2023ã€‘ï¼š" class="headerlink" title="2. DIRECT-RLAIFã€Lee et al., 2023ã€‘ï¼š"></a>2. <strong>DIRECT-RLAIF</strong>ã€Lee et al., 2023ã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ç§ç›´æ¥å¼ºåŒ–å­¦ä¹ å¯¹é½åé¦ˆï¼ˆDIRECT-RLAIFï¼‰æ–¹æ³•ï¼Œé€šè¿‡è¾ƒå¤§çš„LLMç”Ÿæˆåå¥½ä¿¡å·æŒ‡å¯¼è¾ƒå°æ¨¡å‹ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨è¾ƒå¼ºçš„LLMæ¨¡å‹ä½œä¸ºåŠ¨æ€è¯„ä¼°è€…ï¼Œé¿å…ä¼ ç»Ÿå¥–åŠ±æ¨¡å‹ä¸­å­˜åœ¨çš„â€œå¥–åŠ±é™ˆæ—§æ€§â€é—®é¢˜ã€‚</li><li>ä½œè€…éªŒè¯äº†è¿™ç§æ–¹æ³•åœ¨å¯¹é½ç”Ÿæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¼€æ”¾å¼å¯¹è¯ä¸­çš„æ˜¾è‘—æ”¹è¿›ã€‚</li><li>DIRECT-RLAIFä¸ºæ›´é«˜æ•ˆçš„å¯¹é½æ–¹æ³•æä¾›äº†ç†è®ºåŸºç¡€ã€‚</li><li>ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥åœ¨è¾ƒå°‘äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ç”Ÿæˆç¬¦åˆäººç±»åå¥½çš„å†…å®¹ã€‚</li></ul><h6 id="3-OAIFã€Guo-et-al-2024ã€‘ï¼š"><a href="#3-OAIFã€Guo-et-al-2024ã€‘ï¼š" class="headerlink" title="3. OAIFã€Guo et al., 2024ã€‘ï¼š"></a>3. <strong>OAIF</strong>ã€Guo et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†åœ¨çº¿AIåé¦ˆï¼ˆOnline AI Feedback, OAIFï¼‰æ¡†æ¶ï¼Œé€šè¿‡å®æ—¶åŸåˆ™æŒ‡å¯¼æå‡æ¨¡å‹è¯„ä¼°çš„çµæ´»æ€§ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºåŠ¨æ€è°ƒæ•´è¯„ä¼°è§„åˆ™ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”å¤šå˜çš„ä»»åŠ¡éœ€æ±‚ã€‚</li><li>OAIFå¼•å…¥äº†ç»†ç²’åº¦çš„å¤šç»´è¯„åˆ†ç­–ç•¥ï¼Œä¸ºæ¯ä¸ªå€™é€‰é¡¹ç”Ÿæˆç‹¬ç«‹çš„è¯„ä¼°æŠ¥å‘Šã€‚</li><li>ä½œè€…éªŒè¯äº†è¿™ç§æ–¹æ³•åœ¨å®æ—¶å†³ç­–ä¸­çš„æ½œåŠ›ï¼Œå°¤å…¶åœ¨å¯¹è¯å’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚</li><li>OAIFå±•ç°äº†è§„åˆ™å¢å¼ºçš„å®æ—¶é€‚åº”èƒ½åŠ›ï¼Œä¸ºå®æ—¶è¯„ä¼°ä»»åŠ¡æä¾›äº†æ–°æ–¹å‘ã€‚</li></ul><hr><h4 id="5-3-æ£€ç´¢ï¼ˆRetrievalï¼‰"><a href="#5-3-æ£€ç´¢ï¼ˆRetrievalï¼‰" class="headerlink" title="5.3 æ£€ç´¢ï¼ˆRetrievalï¼‰"></a>5.3 æ£€ç´¢ï¼ˆRetrievalï¼‰</h4><h5 id="æ¦‚è¿°-11"><a href="#æ¦‚è¿°-11" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>åœ¨æ£€ç´¢åœºæ™¯ä¸­ï¼ŒLLM-as-a-Judgeä¸»è¦ç”¨äºæå‡æ–‡æ¡£æ’åºçš„ç²¾åº¦å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æ•ˆæœã€‚é€šè¿‡æ›´é«˜æ•ˆçš„æ’åºç®—æ³•ï¼ŒLLMèƒ½å¤Ÿåœ¨ä¼ ç»Ÿæ£€ç´¢å’Œå¤æ‚ç”Ÿæˆä»»åŠ¡ä¸­æä¾›æ›´é«˜è´¨é‡çš„ç›¸å…³æ€§è¯„ä¼°ã€‚</p><h6 id="1-Ranked-Pairingã€Zhai-et-al-2024ã€‘ï¼š-1"><a href="#1-Ranked-Pairingã€Zhai-et-al-2024ã€‘ï¼š-1" class="headerlink" title="1. Ranked Pairingã€Zhai et al., 2024ã€‘ï¼š"></a>1. <strong>Ranked Pairing</strong>ã€Zhai et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ç§åŸºäºåŸºçº¿æ¯”è¾ƒçš„æ’åºæ–¹æ³•ï¼Œé€šè¿‡å¯¹æ‰€æœ‰å€™é€‰é¡¹ä¸åŸºçº¿è¿›è¡Œæ¯”è¾ƒç¡®å®šä¼˜åŠ£ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºé¿å…ä¼ ç»Ÿä¸¤ä¸¤æ¯”è¾ƒçš„é«˜è®¡ç®—å¼€é”€ï¼Œæ˜¾è‘—æé«˜äº†è¯„ä¼°æ•ˆç‡ã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”æ¯”è¾ƒç­–ç•¥ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ’åºæ€§èƒ½ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒRanked Pairingåœ¨å¤§è§„æ¨¡æ’åºä»»åŠ¡ä¸­è¡¨ç°å‡ºæé«˜çš„æ•ˆç‡ã€‚</li><li>æ­¤æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºéœ€è¦å¿«é€Ÿç”Ÿæˆæ’åºç»“æœçš„åœºæ™¯ã€‚</li></ul><h6 id="2-LLM-Evalã€Lin-and-Chen-2023aã€‘ï¼š"><a href="#2-LLM-Evalã€Lin-and-Chen-2023aã€‘ï¼š" class="headerlink" title="2. LLM-Evalã€Lin and Chen, 2023aã€‘ï¼š"></a>2. <strong>LLM-Eval</strong>ã€Lin and Chen, 2023aã€‘ï¼š</h6><ul><li>æå‡ºäº†åœ¨å¯¹è¯ç”Ÿæˆä¸­çš„ç›¸å…³æ€§è¯„ä¼°æ¡†æ¶ï¼Œåˆ©ç”¨LLMæ›¿ä»£äººå·¥æ ‡æ³¨ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†ç»“åˆä¸Šä¸‹æ–‡å’Œç”Ÿæˆå†…å®¹çš„æç¤ºæŠ€æœ¯ï¼Œç¡®ä¿è¯„ä¼°æ›´åŠ ç²¾ç¡®ã€‚</li><li>ä½œè€…é€šè¿‡å¯¹æ¯”å®éªŒéªŒè¯äº†LLMåœ¨ä¼šè¯ç›¸å…³æ€§è¯„ä¼°ä¸­çš„æ½œåŠ›ï¼Œç»“æœä¸äººå·¥æ ‡æ³¨é«˜åº¦ä¸€è‡´ã€‚</li><li>æ­¤æ¡†æ¶æ˜¾è‘—å‡å°‘äº†è¯„ä¼°æˆæœ¬ï¼ŒåŒæ—¶æå‡äº†æ•ˆç‡ã€‚</li><li>LLM-Evalåœ¨å¯¹è¯ç”Ÿæˆä»»åŠ¡ä¸­çš„åº”ç”¨è¡¨æ˜ï¼Œæ¨¡å‹åœ¨ç”Ÿæˆè¯„ä¼°ä¸­çš„è§’è‰²æ—¥ç›Šé‡è¦ã€‚</li></ul><h6 id="3-ToT-Tree-of-Thought-ã€Yao-et-al-2023aã€‘ï¼š"><a href="#3-ToT-Tree-of-Thought-ã€Yao-et-al-2023aã€‘ï¼š" class="headerlink" title="3. **ToT (Tree of Thought)**ã€Yao et al., 2023aã€‘ï¼š"></a>3. **ToT (Tree of Thought)**ã€Yao et al., 2023aã€‘ï¼š</h6><ul><li>æå‡ºäº†é€šè¿‡æ ‘çŠ¶ç»“æ„å¢å¼ºæ¨ç†èƒ½åŠ›çš„æ–¹æ³•ï¼Œå¹¶ç»“åˆLLMè¿›è¡Œè¯„ä¼°ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†çŠ¶æ€è¯„ä¼°æ¨¡å—ï¼Œé€šè¿‡é€æ­¥ç­›é€‰æœ€ä¼˜æ¨ç†è·¯å¾„æå‡æ£€ç´¢å’Œç”Ÿæˆä»»åŠ¡çš„ç²¾åº¦ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒToTæ¡†æ¶æ˜¾è‘—æå‡äº†å¤æ‚ä»»åŠ¡çš„è§£å†³èƒ½åŠ›ï¼Œå°¤å…¶åœ¨å¤šæ­¥æ¨ç†å’Œå†³ç­–ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li><li>ä½œè€…è¿˜æå‡ºäº†è¯„ä¼°è·¯å¾„çš„åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œä½¿LLMèƒ½å¤Ÿæ›´çµæ´»åœ°åº”å¯¹å¤šæ ·åŒ–ä»»åŠ¡ã€‚</li><li>ToTéªŒè¯äº†ç»“æ„åŒ–è¯„ä¼°æ¡†æ¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</li></ul><hr><h4 id="5-4-æ¨ç†ï¼ˆReasoningï¼‰"><a href="#5-4-æ¨ç†ï¼ˆReasoningï¼‰" class="headerlink" title="5.4 æ¨ç†ï¼ˆReasoningï¼‰"></a>5.4 æ¨ç†ï¼ˆReasoningï¼‰</h4><h5 id="æ¦‚è¿°-12"><a href="#æ¦‚è¿°-12" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h5><p>æ¨ç†ä»»åŠ¡çš„æ ¸å¿ƒæ˜¯è¯„ä¼°LLMçš„ä¸­é—´æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§ã€‚LLM-as-a-Judgeåœ¨æ•°å­¦æ¨ç†ã€æ—¶é—´æ¨ç†å’Œå¤æ‚é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­å±•ç¤ºäº†æ˜¾è‘—çš„è¯„ä¼°èƒ½åŠ›ã€‚</p><h6 id="1-HALU-Jã€Wang-et-al-2024aã€‘ï¼š"><a href="#1-HALU-Jã€Wang-et-al-2024aã€‘ï¼š" class="headerlink" title="1. HALU-Jã€Wang et al., 2024aã€‘ï¼š"></a>1. <strong>HALU-J</strong>ã€Wang et al., 2024aã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ç§åŸºäºæ‰¹è¯„çš„åå¥½å­¦ä¹ æ–¹æ³•ï¼Œä¸“æ³¨äºé€‰æ‹©ç›¸å…³è¯æ®å¹¶ç”Ÿæˆè¯¦ç»†æ‰¹è¯„ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†å¤šè¯æ®é€‰æ‹©æœºåˆ¶ï¼Œæé«˜äº†LLMçš„å¯é æ€§è¯„ä¼°èƒ½åŠ›ã€‚</li><li>è¯¥æ–¹æ³•é€šè¿‡Directed Preference Optimizationï¼ˆDPOï¼‰è¿›è¡Œä¼˜åŒ–ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åˆ¤æ–­ä»»åŠ¡é—´çš„ä¼˜åŠ£ã€‚</li><li>HALU-Jè¿˜ç»“åˆäº†ä¸Šä¸‹æ–‡æ¨ç†ï¼Œæ‰©å±•äº†åå¥½å­¦ä¹ çš„åº”ç”¨åœºæ™¯ã€‚</li><li>å®éªŒè¡¨æ˜ï¼ŒHALU-Jæ˜¾è‘—æå‡äº†å¤æ‚ä»»åŠ¡çš„è¯„ä¼°å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨äº‹å®æ€§å’Œé€»è¾‘æ€§åˆ¤æ–­ä¸Šã€‚</li></ul><h6 id="2-KIEvalã€Yu-et-al-2024ã€‘ï¼š"><a href="#2-KIEvalã€Yu-et-al-2024ã€‘ï¼š" class="headerlink" title="2. KIEvalã€Yu et al., 2024ã€‘ï¼š"></a>2. <strong>KIEval</strong>ã€Yu et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†çŸ¥è¯†äº¤äº’å¼è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€é—®ç­”ç”Ÿæˆä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†â€œäº¤äº’è€…â€è§’è‰²ï¼Œæ¨¡æ‹Ÿç”¨æˆ·å’Œæ¨¡å‹ä¹‹é—´çš„åŠ¨æ€äº¤äº’ã€‚</li><li>ä½œè€…è®¾è®¡äº†ä¸€ç§é²æ£’æ€§æ£€æµ‹æœºåˆ¶ï¼Œé¿å…å› ä¸Šä¸‹æ–‡æ±¡æŸ“å¯¼è‡´çš„é”™è¯¯è¯„ä¼°ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒKIEvalåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿé™æ€è¯„ä¼°æ–¹æ³•ã€‚</li><li>æ­¤æ¡†æ¶é€‚ç”¨äºå¤šç»´åº¦è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦åŠ¨æ€è°ƒæ•´ä¸Šä¸‹æ–‡çš„åœºæ™¯ä¸­ã€‚</li></ul><hr><h3 id="6-è¯„ä¼°åŸºå‡†"><a href="#6-è¯„ä¼°åŸºå‡†" class="headerlink" title="6. è¯„ä¼°åŸºå‡†"></a>6. è¯„ä¼°åŸºå‡†</h3><h4 id="æ¦‚è¿°-13"><a href="#æ¦‚è¿°-13" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h4><p>è¯„ä¼°åŸºå‡†æ˜¯éªŒè¯LLM-as-a-Judgeèƒ½åŠ›çš„é‡è¦å·¥å…·ã€‚æœ¬èŠ‚æ•´ç†å¹¶ä»‹ç»å½“å‰ç”¨äºä¸åŒè¯„ä¼°ç»´åº¦çš„åŸºå‡†ï¼ŒåŒ…æ‹¬æœ‰ç”¨æ€§ã€æ— å®³æ€§ã€å¯é æ€§ç­‰æ–¹é¢çš„å…·ä½“æ¡†æ¶å’Œå…¶æ ¸å¿ƒæ€æƒ³ã€‚è¿™äº›åŸºå‡†è¦†ç›–äº†ä»å¯¹è¯ç”Ÿæˆåˆ°å¤æ‚ä»»åŠ¡æ¨ç†çš„å¹¿æ³›åº”ç”¨åœºæ™¯ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†å…³é”®æ•°æ®æ”¯æŒã€‚</p><hr><h5 id="6-1-ç»¼åˆè¯„ä¼°åŸºå‡†"><a href="#6-1-ç»¼åˆè¯„ä¼°åŸºå‡†" class="headerlink" title="6.1 ç»¼åˆè¯„ä¼°åŸºå‡†"></a>6.1 ç»¼åˆè¯„ä¼°åŸºå‡†</h5><h6 id="1-SORRY-Benchã€Xie-et-al-2024aã€‘ï¼š"><a href="#1-SORRY-Benchã€Xie-et-al-2024aã€‘ï¼š" class="headerlink" title="1. SORRY-Benchã€Xie et al., 2024aã€‘ï¼š"></a>1. <strong>SORRY-Bench</strong>ã€Xie et al., 2024aã€‘ï¼š</h6><ul><li>è®¾è®¡äº†ä¸€ä¸ªä¸“æ³¨äºå®‰å…¨æ€§å’Œæ— å®³æ€§è¯„ä¼°çš„ç»¼åˆåŸºå‡†ï¼Œé‡ç‚¹æµ‹è¯•LLMå¯¹æ½œåœ¨æœ‰å®³å†…å®¹çš„æ‹’ç»èƒ½åŠ›ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºæä¾›äº†ä¸€ä¸ªå¤šæ¨¡å‹å¯¹æ¯”æ¡†æ¶ï¼ŒåŒ…æ‹¬å¼€æºå’Œä¸“æœ‰LLMçš„è¡¨ç°åˆ†æã€‚</li><li>åŸºå‡†æ•°æ®é›†æ¶µç›–å¤šç§æ½œåœ¨å±é™©åœºæ™¯ï¼Œå¦‚æ”¿æ²»æ•æ„Ÿå†…å®¹å’Œè™šå‡ä¿¡æ¯ç”Ÿæˆã€‚</li><li>ä½œè€…è¿˜å¼•å…¥äº†åŠ¨æ€æ‹’ç»ç‡ä½œä¸ºè¡¡é‡æŒ‡æ ‡ï¼Œå±•ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨æ‹’ç»ä»»åŠ¡ä¸­çš„ç»†ç²’åº¦è¡¨ç°ã€‚</li><li>å®éªŒè¡¨æ˜ï¼Œå°å‹LLMç»è¿‡å¾®è°ƒåå¯ä»¥åœ¨å®‰å…¨æ€§è¯„ä¼°ä¸­è¾¾åˆ°ä¸å¤§å‹æ¨¡å‹ç›¸å½“çš„æ°´å¹³ã€‚</li></ul><h6 id="2-HalluJudgeã€Luo-et-al-2024ã€‘ï¼š"><a href="#2-HalluJudgeã€Luo-et-al-2024ã€‘ï¼š" class="headerlink" title="2. HalluJudgeã€Luo et al., 2024ã€‘ï¼š"></a>2. <strong>HalluJudge</strong>ã€Luo et al., 2024ã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ä¸ªä¸“é—¨ç”¨äºå¯¹è¯çº§äº‹å®æ€§è¯„ä¼°çš„åŸºå‡†ï¼Œæ¶µç›–å¤§è§„æ¨¡å¯¹è¯æ•°æ®é›†ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°åœ¨äºè®¾è®¡äº†ä¸€ç§ç»†ç²’åº¦çš„äº‹å®æ€§è¯„åˆ†æœºåˆ¶ï¼Œé€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡éªŒè¯ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ã€‚</li><li>æ•°æ®é›†ä¸­åŒ…æ‹¬å¤šç§ç±»å‹çš„äº‹å®æ€§é”™è¯¯ï¼Œå¦‚æ•°æ®é—æ¼ã€æ¨¡ç³Šè¡¨è¿°å’Œç›´æ¥è™šå‡ä¿¡æ¯ã€‚</li><li>HalluJudgeè¿˜æ•´åˆäº†è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°æ–¹æ³•ï¼Œæé«˜äº†åŸºå‡†çš„è¦†ç›–é¢å’Œå¯é æ€§ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼ŒHalluJudgeèƒ½å¤Ÿæ˜¾è‘—æé«˜LLMåœ¨å¯¹è¯åœºæ™¯ä¸­çš„äº‹å®æ€§æ£€æµ‹èƒ½åŠ›ã€‚</li></ul><hr><h5 id="6-2-ä¸“ç”¨é¢†åŸŸè¯„ä¼°åŸºå‡†"><a href="#6-2-ä¸“ç”¨é¢†åŸŸè¯„ä¼°åŸºå‡†" class="headerlink" title="6.2 ä¸“ç”¨é¢†åŸŸè¯„ä¼°åŸºå‡†"></a>6.2 ä¸“ç”¨é¢†åŸŸè¯„ä¼°åŸºå‡†</h5><h6 id="1-FaithScoreã€Jing-et-al-2024ã€‘ï¼š"><a href="#1-FaithScoreã€Jing-et-al-2024ã€‘ï¼š" class="headerlink" title="1. FaithScoreã€Jing et al., 2024ã€‘ï¼š"></a>1. <strong>FaithScore</strong>ã€Jing et al., 2024ã€‘ï¼š</h6><ul><li>FaithScoreæ˜¯ç¬¬ä¸€ä¸ªè·¨æ¨¡æ€çš„å¯é æ€§è¯„ä¼°æ¡†æ¶ï¼Œé€‚ç”¨äºæ–‡æœ¬å’Œå›¾åƒç”Ÿæˆä»»åŠ¡ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºè®¾è®¡äº†å¤šæ¨¡æ€è¯„ä¼°æ–¹æ³•ï¼Œç»“åˆè¯­è¨€å’Œè§†è§‰ä¿¡å·æ¥éªŒè¯ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§ã€‚</li><li>æ•°æ®é›†è¦†ç›–äº†ä»äº‹å®æè¿°åˆ°è·¨æ¨¡æ€æ¨ç†çš„å¤šä¸ªä»»åŠ¡ï¼Œæµ‹è¯•äº†æ¨¡å‹çš„å…¨å±€ä¸€è‡´æ€§å’Œç»†èŠ‚å‡†ç¡®æ€§ã€‚</li><li>FaithScoreè¿˜å¼•å…¥äº†å¤šé˜¶æ®µè¯„åˆ†æœºåˆ¶ï¼Œé€æ­¥åˆ†è§£ä»»åŠ¡ä»¥æé«˜è¯„ä¼°çš„ç²¾ç»†åŒ–ç¨‹åº¦ã€‚</li><li>å®éªŒæ˜¾ç¤ºï¼ŒFaithScoreåœ¨å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ä¸­çš„è¯„ä¼°ç»“æœä¸äººå·¥è¯„åˆ†é«˜åº¦ä¸€è‡´ã€‚</li></ul><h6 id="2-GEMBAã€Kocmi-and-Federmann-2023ã€‘ï¼š"><a href="#2-GEMBAã€Kocmi-and-Federmann-2023ã€‘ï¼š" class="headerlink" title="2. GEMBAã€Kocmi and Federmann, 2023ã€‘ï¼š"></a>2. <strong>GEMBA</strong>ã€Kocmi and Federmann, 2023ã€‘ï¼š</h6><ul><li>GEMBAåŸºå‡†ä¸“æ³¨äºæœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬æ‘˜è¦ä»»åŠ¡çš„æ•´ä½“è´¨é‡è¯„ä¼°ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºç»“åˆBLEUç­‰ä¼ ç»ŸæŒ‡æ ‡å’ŒLLMç”Ÿæˆçš„ç»¼åˆè¯„åˆ†ï¼Œæä¾›æ›´å…¨é¢çš„è¯„ä¼°ç»“æœã€‚</li><li>æ•°æ®é›†ä¸­åŒ…å«å¤šç§è¯­è¨€å’Œé¢†åŸŸçš„çœŸå®æ–‡æœ¬ï¼Œè¦†ç›–å¤šæ ·åŒ–çš„ä»»åŠ¡éœ€æ±‚ã€‚</li><li>ä½œè€…è®¾è®¡äº†ä¸€ç§åŠ¨æ€åé¦ˆæœºåˆ¶ï¼Œå…è®¸LLMåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ã€‚</li><li>GEMBAåŸºå‡†çš„å¼•å…¥æ˜¾è‘—æ¨åŠ¨äº†æœºå™¨ç¿»è¯‘å’Œæ‘˜è¦ä»»åŠ¡ä¸­LLM-as-a-Judgeçš„åº”ç”¨ã€‚</li></ul><h6 id="3-Just-Evalã€Lin-et-al-2023ã€‘ï¼š"><a href="#3-Just-Evalã€Lin-et-al-2023ã€‘ï¼š" class="headerlink" title="3. Just-Evalã€Lin et al., 2023ã€‘ï¼š"></a>3. <strong>Just-Eval</strong>ã€Lin et al., 2023ã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ä¸ªåŸºäºç”Ÿæˆå†…å®¹æœ‰ç”¨æ€§å’Œæ— å®³æ€§çš„ç»¼åˆåŸºå‡†ï¼Œé€‚ç”¨äºå¹¿æ³›çš„å¼€æ”¾å¼ä»»åŠ¡ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºä¸ºä¸åŒä»»åŠ¡è®¾è®¡äº†å®šåˆ¶åŒ–çš„è¯„ä¼°æ ‡å‡†ï¼Œå¹¶ç»“åˆå¤šç»´è¯„åˆ†ç³»ç»Ÿç”Ÿæˆæœ€ç»ˆè¯„ä»·ã€‚</li><li>æ•°æ®é›†ä¸­æ¶µç›–äº†å¯¹è¯ã€é—®ç­”å’Œå¤æ‚æ¨ç†ç­‰ä»»åŠ¡ï¼ŒéªŒè¯äº†åŸºå‡†çš„é€šç”¨æ€§ã€‚</li><li>ä½œè€…è¿˜åˆ†æäº†æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡å’Œé¢†åŸŸä¸Šçš„è¡¨ç°ï¼Œæä¾›äº†è¯¦ç»†çš„å¯¹æ¯”ç»“æœã€‚</li><li>Just-Evalçš„åº”ç”¨è¡¨æ˜ï¼Œè¯„ä¼°æ¡†æ¶éœ€è¦ç»“åˆä»»åŠ¡ç‰¹ç‚¹è¿›è¡Œä¼˜åŒ–ï¼Œæ‰èƒ½æœ€å¤§åŒ–è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚</li></ul><hr><h4 id="6-3-åŠ¨æ€è¯„ä¼°åŸºå‡†"><a href="#6-3-åŠ¨æ€è¯„ä¼°åŸºå‡†" class="headerlink" title="6.3 åŠ¨æ€è¯„ä¼°åŸºå‡†"></a>6.3 åŠ¨æ€è¯„ä¼°åŸºå‡†</h4><h6 id="1-RevisEvalã€Zhang-et-al-2024eã€‘ï¼š"><a href="#1-RevisEvalã€Zhang-et-al-2024eã€‘ï¼š" class="headerlink" title="1. RevisEvalã€Zhang et al., 2024eã€‘ï¼š"></a>1. <strong>RevisEval</strong>ã€Zhang et al., 2024eã€‘ï¼š</h6><ul><li>RevisEvalé€šè¿‡å¼•å…¥åŠ¨æ€è‡ªæˆ‘ä¿®æ­£æœºåˆ¶ï¼Œè®©LLMåœ¨ç”Ÿæˆè¯„ä¼°ä¹‹å‰å¯¹è¾“å‡ºè¿›è¡Œå¤šæ¬¡è°ƒæ•´ã€‚</li><li>æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆLLMçš„è‡ªæˆ‘çº é”™èƒ½åŠ›ï¼Œå°†æœ€ç»ˆè¾“å‡ºç”¨äºå¤šç»´åº¦è¯„ä¼°ã€‚</li><li>æ•°æ®é›†ä¸­è¦†ç›–äº†å¯¹è¯ç”Ÿæˆã€æ‘˜è¦å’Œå¤æ‚æ¨ç†ä»»åŠ¡ï¼ŒéªŒè¯äº†åŸºå‡†çš„åŠ¨æ€é€‚åº”èƒ½åŠ›ã€‚</li><li>RevisEvalå¼•å…¥äº†å¤šè½®åé¦ˆæœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­è¿­ä»£æ”¹è¿›ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠ¨æ€è¯„ä¼°èƒ½å¤Ÿæ˜¾è‘—æå‡å¤æ‚ä»»åŠ¡ä¸­è¯„ä¼°çš„ç²¾ç¡®æ€§å’Œç¨³å®šæ€§ã€‚</li></ul><h6 id="2-Meta-rankingã€Liu-et-al-2024cã€‘ï¼š"><a href="#2-Meta-rankingã€Liu-et-al-2024cã€‘ï¼š" class="headerlink" title="2. Meta-rankingã€Liu et al., 2024cã€‘ï¼š"></a>2. <strong>Meta-ranking</strong>ã€Liu et al., 2024cã€‘ï¼š</h6><ul><li>Meta-rankingæ¡†æ¶é€šè¿‡å¼±æ¨¡å‹ç”Ÿæˆåˆæ­¥æ’åºï¼Œå†ç”±å¼ºæ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨å¤šé˜¶æ®µçš„æ’åæ–¹æ³•ï¼Œæé«˜è¯„ä¼°æ•ˆç‡å¹¶é™ä½è®¡ç®—å¼€é”€ã€‚</li><li>æ•°æ®é›†ä¸­åŒ…å«äº†å¤šç§ä»»åŠ¡ç±»å‹ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†Meta-rankingçš„é€šç”¨æ€§ã€‚</li><li>è¯¥æ¡†æ¶ç‰¹åˆ«é€‚ç”¨äºå¤§è§„æ¨¡æ’åºä»»åŠ¡ï¼Œæ˜¾è‘—å‡å°‘äº†è¯„ä¼°æ—¶é—´ã€‚</li><li>Meta-rankingå±•ç¤ºäº†å¼±æ¨¡å‹å’Œå¼ºæ¨¡å‹åä½œè¯„ä¼°çš„æ½œåŠ›ï¼Œæ˜¯å¤šæ¨¡å‹è¯„ä¼°çš„æ–°æ–¹å‘ã€‚</li></ul><hr><h3 id="7-æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘"><a href="#7-æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘" class="headerlink" title="7. æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘"></a>7. æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘</h3><h4 id="æ¦‚è¿°-14"><a href="#æ¦‚è¿°-14" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h4><p>å°½ç®¡LLM-as-a-Judgeåœ¨è¯„ä¼°ä»»åŠ¡ä¸­å±•ç°äº†å¼ºå¤§èƒ½åŠ›ï¼Œä½†ä¾ç„¶é¢ä¸´ç€å¤šæ–¹é¢çš„æŒ‘æˆ˜ã€‚ä¸»è¦é—®é¢˜åŒ…æ‹¬è¯„ä¼°åå·®ä¸è„†å¼±æ€§ã€åŠ¨æ€ä¸å¤æ‚ä»»åŠ¡ä¸­çš„é€‚åº”æ€§ï¼Œä»¥åŠäººæœºååŒè¯„ä¼°çš„æ½œåŠ›ã€‚æœ¬èŠ‚æ¢è®¨è¿™äº›æŒ‘æˆ˜å¹¶æå‡ºæœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</p><hr><h5 id="7-1-åå·®ä¸è„†å¼±æ€§"><a href="#7-1-åå·®ä¸è„†å¼±æ€§" class="headerlink" title="7.1 åå·®ä¸è„†å¼±æ€§"></a>7.1 åå·®ä¸è„†å¼±æ€§</h5><h6 id="1-OffsetBiasã€Park-et-al-2024ã€‘ï¼š"><a href="#1-OffsetBiasã€Park-et-al-2024ã€‘ï¼š" class="headerlink" title="1. OffsetBiasã€Park et al., 2024ã€‘ï¼š"></a>1. <strong>OffsetBias</strong>ã€Park et al., 2024ã€‘ï¼š</h6><ul><li>OffsetBiasé€šè¿‡è®¾è®¡ä¸€ä¸ªå»åä¼˜åŒ–æ¡†æ¶ï¼Œå‡å°‘LLMåœ¨è¯„ä¼°ä»»åŠ¡ä¸­çš„ä½ç½®åå·®å’Œå†…å®¹åè§ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨åˆæˆæ•°æ®ç”Ÿæˆâ€œåâ€æ ·æœ¬ï¼Œé€šè¿‡è®­ç»ƒæ¨¡å‹è¯†åˆ«å¹¶ä¿®æ­£åå·®ã€‚</li><li>ä½œè€…æå‡ºäº†ä¸€ç§å¤šç»´åº¦çš„å»åå­¦ä¹ æœºåˆ¶ï¼Œç¡®ä¿è¯„ä¼°åœ¨ä¸åŒåœºæ™¯ä¸‹çš„ä¸€è‡´æ€§ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼ŒOffsetBiasèƒ½å¤Ÿæ˜¾è‘—é™ä½æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­çš„ä¸å…¬å¹³è¡¨ç°ã€‚</li><li>æ­¤æ–¹æ³•ä¸ºå‡å°‘LLMè¯„ä¼°ä¸­çš„åå·®é—®é¢˜æä¾›äº†é‡è¦æ–¹å‘ã€‚</li></ul><h6 id="2-SORRY-Benchã€Xie-et-al-2024aã€‘ï¼š"><a href="#2-SORRY-Benchã€Xie-et-al-2024aã€‘ï¼š" class="headerlink" title="2. SORRY-Benchã€Xie et al., 2024aã€‘ï¼š"></a>2. <strong>SORRY-Bench</strong>ã€Xie et al., 2024aã€‘ï¼š</h6><ul><li>è¿›ä¸€æ­¥ç ”ç©¶äº†æ¨¡å‹åœ¨æ‹’ç»æœ‰å®³å†…å®¹æ—¶å¯èƒ½å‡ºç°çš„è¯¯æ‹’ç»é—®é¢˜ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºç»“åˆåŠ¨æ€è¯„åˆ†æœºåˆ¶å’Œæ‹’ç»æ•°æ®é›†ï¼Œåˆ†ææ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸­çš„æ‹’ç»å€¾å‘ã€‚</li><li>ä½œè€…æŒ‡å‡ºï¼Œå°å‹æ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯ä¸­å¯èƒ½æ¯”å¤§å‹æ¨¡å‹æ›´é«˜æ•ˆã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSORRY-Benchèƒ½å¤Ÿå¸®åŠ©è¯†åˆ«å¹¶å‡è½»è¯„ä¼°åå·®ã€‚</li><li>æ­¤åŸºå‡†æˆä¸ºæ¢è®¨è¯„ä¼°è„†å¼±æ€§çš„ä¸€ä¸ªé‡è¦å·¥å…·ã€‚</li></ul><hr><h5 id="7-2-åŠ¨æ€ä¸å¤æ‚è¯„ä¼°"><a href="#7-2-åŠ¨æ€ä¸å¤æ‚è¯„ä¼°" class="headerlink" title="7.2 åŠ¨æ€ä¸å¤æ‚è¯„ä¼°"></a>7.2 åŠ¨æ€ä¸å¤æ‚è¯„ä¼°</h5><h6 id="1-Tree-of-Thought-ToT-ã€Yao-et-al-2023aã€‘ï¼š"><a href="#1-Tree-of-Thought-ToT-ã€Yao-et-al-2023aã€‘ï¼š" class="headerlink" title="1. **Tree of Thought (ToT)**ã€Yao et al., 2023aã€‘ï¼š"></a>1. **Tree of Thought (ToT)**ã€Yao et al., 2023aã€‘ï¼š</h6><ul><li>ToTé€šè¿‡æ ‘çŠ¶ç»“æ„ä¼˜åŒ–å¤æ‚ä»»åŠ¡çš„å¤šæ­¥æ¨ç†å’Œè¯„ä¼°ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºç»“åˆåŠ¨æ€çŠ¶æ€è¯„ä¼°æœºåˆ¶ï¼Œä½¿è¯„ä¼°æ›´åŠ é€‚åº”å¤æ‚å¤šå˜çš„ä»»åŠ¡éœ€æ±‚ã€‚</li><li>æ•°æ®é›†ä¸­è¦†ç›–äº†éœ€è¦å¤šæ­¥æ¨ç†çš„å¤æ‚ä»»åŠ¡ï¼Œå¦‚é—®ç­”å’Œå†³ç­–ä¼˜åŒ–ã€‚</li><li>å®éªŒè¡¨æ˜ï¼ŒToTæ¡†æ¶æ˜¾è‘—æå‡äº†å¤æ‚ä»»åŠ¡çš„è§£å†³èƒ½åŠ›å’Œè¯„ä¼°å‡†ç¡®æ€§ã€‚</li><li>è¯¥ç ”ç©¶ä¸ºåŠ¨æ€è¯„ä¼°æä¾›äº†æ–°çš„ç†è®ºå’Œå®è·µæ”¯æŒã€‚</li></ul><h6 id="2-RAINã€Li-et-al-2024ã€‘ï¼š"><a href="#2-RAINã€Li-et-al-2024ã€‘ï¼š" class="headerlink" title="2. RAINã€Li et al., 2024ã€‘ï¼š"></a>2. <strong>RAIN</strong>ã€Li et al., 2024ã€‘ï¼š</h6><ul><li>RAINæå‡ºäº†å¯å›æº¯çš„è‡ªå›å½’æ¨ç†æœºåˆ¶ï¼Œè®©LLMèƒ½å¤Ÿåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­åŠ¨æ€ä¿®æ­£é”™è¯¯ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºç»“åˆè‡ªæˆ‘è¯„ä¼°å’Œå¤šè½®æ¨ç†æœºåˆ¶ï¼Œç¡®ä¿æœ€ç»ˆè¾“å‡ºçš„é«˜è´¨é‡ã€‚</li><li>ä½œè€…è¿˜è®¾è®¡äº†ä¸€ç§åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä¸åŒä»»åŠ¡çš„å˜åŒ–ã€‚</li><li>å®éªŒæ˜¾ç¤ºï¼ŒRAINåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¯„ä¼°èƒ½åŠ›ä¼˜äºä¼ ç»Ÿé™æ€æ–¹æ³•ã€‚</li><li>æ­¤æ¡†æ¶å±•ç¤ºäº†åŠ¨æ€è¯„ä¼°åœ¨å¤æ‚åœºæ™¯ä¸­çš„æ½œåŠ›ã€‚</li></ul><hr><h5 id="7-3-è‡ªæˆ‘è¯„ä¼°ä¸äººæœºååŒ"><a href="#7-3-è‡ªæˆ‘è¯„ä¼°ä¸äººæœºååŒ" class="headerlink" title="7.3 è‡ªæˆ‘è¯„ä¼°ä¸äººæœºååŒ"></a>7.3 è‡ªæˆ‘è¯„ä¼°ä¸äººæœºååŒ</h5><h6 id="1-Self-Taught-Evaluatorsã€Wang-et-al-2024fã€‘ï¼š"><a href="#1-Self-Taught-Evaluatorsã€Wang-et-al-2024fã€‘ï¼š" class="headerlink" title="1. Self-Taught Evaluatorsã€Wang et al., 2024fã€‘ï¼š"></a>1. <strong>Self-Taught Evaluators</strong>ã€Wang et al., 2024fã€‘ï¼š</h6><ul><li>æå‡ºäº†ä¸€ç§è‡ªæˆ‘å­¦ä¹ æ¡†æ¶ï¼Œæ¨¡å‹é€šè¿‡ç”Ÿæˆä½è´¨é‡æ•°æ®å¯¹è‡ªèº«è¿›è¡ŒåŠ¨æ€ä¼˜åŒ–ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ä¸€ç§åŠ¨æ€è¯„ä¼°æœºåˆ¶ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿé€æ­¥æå‡è‡ªèº«è¯„ä¼°èƒ½åŠ›ã€‚</li><li>æ•°æ®é›†ä¸­åŒ…æ‹¬äº†å¤šç§ç±»å‹çš„ä»»åŠ¡ï¼Œä¸ºè‡ªæˆ‘è¯„ä¼°æä¾›äº†å¹¿æ³›æ”¯æŒã€‚</li><li>Self-Taught Evaluatorså±•ç¤ºäº†æ¨¡å‹åœ¨æ— éœ€äººå·¥å¹²é¢„æƒ…å†µä¸‹çš„è‡ªæˆ‘æå‡èƒ½åŠ›ã€‚</li><li>æ­¤æ¡†æ¶ä¸ºè‡ªåŠ¨åŒ–è¯„ä¼°ä»»åŠ¡æä¾›äº†æ–°æ€è·¯ã€‚</li></ul><h6 id="2-Meta-Rewardingã€Wu-et-al-2024ã€‘ï¼š"><a href="#2-Meta-Rewardingã€Wu-et-al-2024ã€‘ï¼š" class="headerlink" title="2. Meta-Rewardingã€Wu et al., 2024ã€‘ï¼š"></a>2. <strong>Meta-Rewarding</strong>ã€Wu et al., 2024ã€‘ï¼š</h6><ul><li>Meta-Rewardingé€šè¿‡å°†LLMçš„è‡ªè¯„ä¼°ä¿¡å·ä½œä¸ºåå¥½æ•°æ®ï¼Œç”¨äºè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ã€‚</li><li>åˆ›æ–°ç‚¹åœ¨äºç»“åˆç­–ç•¥æ¨¡å‹è‡ªæˆ‘åé¦ˆï¼Œå¢å¼ºæ¨¡å‹çš„è‡ªé€‚åº”èƒ½åŠ›ã€‚</li><li>ä½œè€…è¿˜æ¢è®¨äº†å¦‚ä½•åŠ¨æ€è°ƒæ•´è¯„ä¼°ç­–ç•¥ä»¥æé«˜é²æ£’æ€§ã€‚</li><li>å®éªŒè¡¨æ˜ï¼ŒMeta-Rewardingèƒ½å¤Ÿæ˜¾è‘—æå‡å¤æ‚ä»»åŠ¡ä¸­çš„è¯„ä¼°æ•ˆæœã€‚</li><li>è¯¥ç ”ç©¶å±•ç¤ºäº†äººæœºååŒè¯„ä¼°çš„æ½œåœ¨ä¼˜åŠ¿ã€‚</li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h1 id=&quot;åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜&quot;&gt;&lt;a href=&quot;#åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡ä¸æŒ‘æˆ˜&quot; class=&quot;headerlink&quot; title=&quot;åŸºäºç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°ï¼šä»ç”Ÿæˆåˆ°åˆ¤æ–­çš„æœºé‡</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="Onnx" scheme="https://chenhuiyu.github.io/tags/Onnx/"/>
    
    <category term="Deployment" scheme="https://chenhuiyu.github.io/tags/Deployment/"/>
    
  </entry>
  
  <entry>
    <title>Reflections on Identity and Subjectivity</title>
    <link href="https://chenhuiyu.github.io/2024/12/03/Life%20Reflections/Reflections%20on%20Identity%20and%20Subjectivity/"/>
    <id>https://chenhuiyu.github.io/2024/12/03/Life%20Reflections/Reflections%20on%20Identity%20and%20Subjectivity/</id>
    <published>2024-12-03T06:11:06.000Z</published>
    <updated>2026-02-20T21:56:22.868Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PR-Application-Rejected-Reflections-on-Identity-and-Subjectivity"><a href="#PR-Application-Rejected-Reflections-on-Identity-and-Subjectivity" class="headerlink" title="PR Application Rejected: Reflections on Identity and Subjectivity"></a>PR Application Rejected: Reflections on Identity and Subjectivity</h1><p>When I received the news of my PR application being rejected, after a brief moment of shock, what arose within me was not merely frustration but a peculiar sense of â€œexistential dilemma.â€ On the surface, it seemed like just an administrative outcome, yet it profoundly mirrored the multiple tensions between the structure of contemporary global mobility and the construction of subjectivity.</p><ul><li>Amid the tension between globalization and national sovereignty, is it even possible to affirm an individualâ€™s identity?</li><li>Does the rejection of a PR application symbolically exclude an individual from a collective sense of belonging?</li></ul><hr><h2 id="PR-Application-From-the-Fantasy-of-Rights-to-the-Maze-of-Identity"><a href="#PR-Application-From-the-Fantasy-of-Rights-to-the-Maze-of-Identity" class="headerlink" title="PR Application: From the Fantasy of Rights to the Maze of Identity"></a>PR Application: From the Fantasy of Rights to the Maze of Identity</h2><p>Within the theoretical framework of Anthony Giddensâ€™ <em>Modernity and Self-Identity</em>, applying for PR is not merely a pursuit of residency rights but a symbolic quest for identity stability and future possibilities. However, in the context of globalization, this pursuit often falls into what Derrida describes as the structure of <em>diffÃ©rance</em>: the realization of rights is perpetually deferred, and the confirmation of identity remains suspended.</p><p>In this context, rejection is tantamount to a form of <strong>symbolic violence</strong>. It not only disrupts my plans for the future but also shatters the illusion of subjectivity I held within this domain.</p><hr><h2 id="Subjectivity-vs-Institutional-Discipline"><a href="#Subjectivity-vs-Institutional-Discipline" class="headerlink" title="Subjectivity vs. Institutional Discipline"></a>Subjectivity vs. Institutional Discipline</h2><p>Bourdieuâ€™s field theory reveals the distribution of power in social practices, and the practice of PR applications is a concrete field where power disciplines individuals. Rejection is not merely an administrative outcome but an invisible disciplining of the subject, hinting at the imbalance of power between individuals and institutions in the era of platform capitalism.</p><p>Through Foucaultâ€™s lens of discipline, this process not only constrains individualsâ€™ <strong>physical mobility</strong> but also profoundly affects the <strong>emotional and mental freedom</strong> of individuals.</p><hr><h2 id="From-Loss-to-Reflection"><a href="#From-Loss-to-Reflection" class="headerlink" title="From Loss to Reflection"></a>From Loss to Reflection</h2><p>In a sense, rejection is not an end but an opportunity for <strong>reconstruction</strong>. Baumanâ€™s concept of <em>liquid modernity</em> might help me interpret this failure: in a constantly fluid world, fixed identities and stable senses of belonging are scarce resources. Perhaps I need to redefine my position amid this loss and find my own meaning in the fragments of grand narratives.</p><p>As Å½iÅ¾ek puts it: <strong>â€œTrue freedom is not about getting what you want but about confronting the trauma of reality.â€</strong> The failure of my PR application may not be the end of identity but a challenge to how I reconstruct subjectivity in the face of uncertainty.</p><p>Thus, this is not an ending but a dialectical transformation: in the moment of shattered stability, perhaps lies the beginning of transcending grand narratives and rediscovering the meaning of oneâ€™s existence.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PR-Application-Rejected-Reflections-on-Identity-and-Subjectivity&quot;&gt;&lt;a href=&quot;#PR-Application-Rejected-Reflections-on-Identity-and-Subj</summary>
      
    
    
    
    <category term="Life Reflections" scheme="https://chenhuiyu.github.io/categories/Life-Reflections/"/>
    
    
    <category term="Living in Singapore" scheme="https://chenhuiyu.github.io/tags/Living-in-Singapore/"/>
    
  </entry>
  
  <entry>
    <title>èº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€</title>
    <link href="https://chenhuiyu.github.io/2024/12/03/Life%20Reflections/%E8%BA%AB%E4%BB%BD%E4%B8%8E%E4%B8%BB%E4%BD%93%E6%80%A7%E7%9A%84%E5%8F%8D%E6%80%9D/"/>
    <id>https://chenhuiyu.github.io/2024/12/03/Life%20Reflections/%E8%BA%AB%E4%BB%BD%E4%B8%8E%E4%B8%BB%E4%BD%93%E6%80%A7%E7%9A%84%E5%8F%8D%E6%80%9D/</id>
    <published>2024-12-03T06:11:06.000Z</published>
    <updated>2026-02-20T21:56:22.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€"><a href="#æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€" class="headerlink" title="æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€"></a>æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€</h1><p>å½“æˆ‘æ¥åˆ°æ°¸å±…ç”³è¯·è¢«æ‹’çš„æ¶ˆæ¯æ—¶ï¼ŒçŸ­æš‚çš„æ„£ç¥ä¹‹åï¼Œå†…å¿ƒæ¶ŒåŠ¨çš„å´å¹¶éå•çº¯çš„æŒ«è´¥ï¼Œè€Œæ˜¯ä¸€ç§å¥‡å¼‚çš„â€œç”Ÿå­˜è®ºå›°å¢ƒâ€æ„Ÿã€‚è¡¨é¢ä¸Šï¼Œè¿™ä¼¼ä¹åªæ˜¯ä¸€æ¬¡è¡Œæ”¿ç»“æœçš„ä½“ç°ï¼Œä½†å…¶èƒŒåå´æ·±åˆ»æŠ˜å°„äº†å½“ä»£å…¨çƒæµåŠ¨æ€§ç»“æ„ä¸ä¸»ä½“æ€§å»ºæ„ä¹‹é—´çš„å¤šé‡å¼ åŠ›ã€‚</p><ul><li>åœ¨å…¨çƒåŒ–ä¸å›½å®¶ä¸»æƒçš„å¼ åŠ›ä¸‹ï¼Œä¸ªä½“èº«ä»½çš„ç¡®è®¤ç©¶ç«Ÿæ˜¯å¦å¯èƒ½ï¼Ÿ</li><li>å½“æ°¸å±…ç”³è¯·è¢«æ‹’æ—¶ï¼Œæ˜¯å¦æ„å‘³ç€ä¸ªä½“è¢«è±¡å¾æ€§åœ°æ’é™¤åœ¨æŸç§é›†ä½“æ„ä¹‰ä¹‹å¤–ï¼Ÿ</li></ul><hr><h2 id="æ°¸å±…ç”³è¯·ï¼šä»æƒåˆ©å¹»æƒ³åˆ°èº«ä»½è¿·å®«"><a href="#æ°¸å±…ç”³è¯·ï¼šä»æƒåˆ©å¹»æƒ³åˆ°èº«ä»½è¿·å®«" class="headerlink" title="æ°¸å±…ç”³è¯·ï¼šä»æƒåˆ©å¹»æƒ³åˆ°èº«ä»½è¿·å®«"></a>æ°¸å±…ç”³è¯·ï¼šä»æƒåˆ©å¹»æƒ³åˆ°èº«ä»½è¿·å®«</h2><p>åœ¨å‰ç™»æ–¯çš„â€œç°ä»£æ€§ä¸è‡ªæˆ‘è®¤åŒâ€ç†è®ºæ¡†æ¶ä¸‹ï¼Œæ°¸å±…ç”³è¯·ä¸ä»…æ˜¯ä¸€ç§å±…ç•™æƒçš„äº‰å–ï¼Œæ›´æ˜¯ä¸€ç§å¯¹èº«ä»½ç¨³å®šæ€§ä¸æœªæ¥å¯èƒ½æ€§çš„ç¬¦å·åŒ–è¿½æ±‚ã€‚ç„¶è€Œï¼Œåœ¨å…¨çƒåŒ–è¯­å¢ƒä¸‹ï¼Œè¿™ç§è¿½æ±‚å¾€å¾€é™·å…¥å¾·é‡Œè¾¾æ‰€æè¿°çš„â€œå»¶å¼‚â€ç»“æ„ï¼šæƒåˆ©çš„å®ç°æ€»æ˜¯è¢«æ¨è¿Ÿï¼Œèº«ä»½çš„ç¡®è®¤æ€»æ˜¯æ‚¬ç½®ã€‚</p><p>åœ¨æ­¤æƒ…å¢ƒä¸­ï¼Œç”³è¯·è¢«æ‹’çš„ç»“æœæ— å¼‚äºä¸€ç§<strong>ç¬¦å·æš´åŠ›</strong>ã€‚å®ƒä¸ä»…æ–­è£‚äº†æˆ‘å¯¹æœªæ¥çš„è§„åˆ’ï¼Œä¹Ÿæ’•è£‚äº†æˆ‘åœ¨è¿™ä¸€åœºåŸŸä¸­çš„ä¸»ä½“æ€§å¹»è±¡ã€‚</p><hr><h2 id="ä¸»ä½“æ€§ä¸åˆ¶åº¦è§„è®­çš„å¯¹æŠ—"><a href="#ä¸»ä½“æ€§ä¸åˆ¶åº¦è§„è®­çš„å¯¹æŠ—" class="headerlink" title="ä¸»ä½“æ€§ä¸åˆ¶åº¦è§„è®­çš„å¯¹æŠ—"></a>ä¸»ä½“æ€§ä¸åˆ¶åº¦è§„è®­çš„å¯¹æŠ—</h2><p>å¸ƒå°”è¿ªå„çš„åœºåŸŸç†è®ºæ­ç¤ºäº†æƒåŠ›åœ¨ç¤¾ä¼šå®è·µä¸­çš„åˆ†å¸ƒæ–¹å¼ï¼Œè€Œæ°¸å±…ç”³è¯·è¿™ä¸€åˆ¶åº¦å®è·µæ­£æ˜¯æƒåŠ›è§„è®­ä¸ªä½“çš„å…·ä½“åŒ–åœºåŸŸã€‚æ‹’ç»ä¸ä»…æ˜¯ä¸€ç§è¡Œæ”¿ç»“æœï¼Œæ›´æ˜¯ä¸€ç§å¯¹ä¸»ä½“çš„éšå½¢è§„è®­ï¼Œæš—ç¤ºäº†å¹³å°èµ„æœ¬ä¸»ä¹‰æ—¶ä»£ä¸ªä½“ä¸åˆ¶åº¦ä¹‹é—´çš„æƒåŠ›å¤±è¡¡ã€‚</p><p>ç¦æŸ¯çš„è§„è®­è§†è§’è®©æˆ‘ä»¬çœ‹åˆ°ï¼Œè¿™ä¸€è¿‡ç¨‹ä¸ä»…é™åˆ¶äº†ä¸ªä½“çš„<strong>ç‰©ç†æµåŠ¨æ€§</strong>ï¼Œä¹Ÿæ·±åˆ»å½±å“äº†<strong>æƒ…æ„Ÿä¸ç²¾ç¥çš„è‡ªç”±æµåŠ¨</strong>ã€‚</p><hr><h2 id="ä»å¤±è½åˆ°åæ€"><a href="#ä»å¤±è½åˆ°åæ€" class="headerlink" title="ä»å¤±è½åˆ°åæ€"></a>ä»å¤±è½åˆ°åæ€</h2><p>ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œè¢«æ‹’å¹¶éä¸€ç§ç»ˆç»“ï¼Œè€Œæ˜¯ä¸€ç§<strong>é‡æ„çš„å¥‘æœº</strong>ã€‚é²æ›¼æå‡ºçš„â€œæ¶²æ€ç°ä»£æ€§â€æˆ–è®¸èƒ½å¸®åŠ©æˆ‘ç†è§£è¿™æ¬¡å¤±è´¥ï¼šåœ¨ä¸€ä¸ªä¸æ–­æµåŠ¨çš„ä¸–ç•Œä¸­ï¼Œå›ºå®šçš„èº«ä»½å’Œç¨³å®šçš„å½’å±æ„Ÿæœ¬å°±æ˜¯ç¨€ç¼ºèµ„æºã€‚æˆ–è®¸ï¼Œæˆ‘éœ€è¦åœ¨å¤±è½ä¸­é‡æ–°å®šä¹‰è‡ªå·±çš„ä½ç½®ï¼Œä»å®å¤§å™äº‹çš„ç ´ç¢ä¸­æ‰¾åˆ°å±äºè‡ªå·±çš„æ„ä¹‰ã€‚</p><p>æ­£å¦‚é½æ³½å…‹æ‰€è¨€ï¼š<strong>â€œçœŸæ­£çš„è‡ªç”±ä¸æ˜¯å¾—åˆ°ä½ æƒ³è¦çš„ï¼Œè€Œæ˜¯é¢å¯¹ç°å®çš„åˆ›ä¼¤ã€‚â€</strong> æ°¸å±…ç”³è¯·çš„å¤±è´¥ä¹Ÿè®¸ä¸æ˜¯èº«ä»½çš„ç»ˆç»“ï¼Œè€Œæ˜¯å¯¹æˆ‘å¦‚ä½•åœ¨ä¸ç¡®å®šæ€§ä¸­é‡æ–°æ„å»ºä¸»ä½“æ€§çš„ç»ˆææŒ‘æˆ˜ã€‚</p><p>å› æ­¤ï¼Œè¿™å¹¶éç»ˆç»“ï¼Œè€Œæ˜¯ä¸€æ¬¡è¾©è¯çš„è½¬åŒ–ï¼šåœ¨ç¨³å®šæ€§ç ´ç¢çš„ç¬é—´ï¼Œæˆ–è®¸æ°æ˜¯æˆ‘ä»¬è¶…è¶Šå®å¤§å™äº‹ã€é‡æ–°å‘ç°è‡ªæˆ‘å­˜åœ¨æ„ä¹‰çš„å¼€ç«¯ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€&quot;&gt;&lt;a href=&quot;#æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€&quot; class=&quot;headerlink&quot; title=&quot;æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€&quot;&gt;&lt;/a&gt;æ°¸å±…ç”³è¯·è¢«æ‹’ï¼šèº«ä»½ä¸ä¸»ä½“æ€§çš„åæ€&lt;/h1&gt;&lt;p&gt;å½“æˆ‘æ¥åˆ°æ°¸å±…ç”³è¯·è¢«æ‹’çš„æ¶ˆæ¯æ—¶</summary>
      
    
    
    
    <category term="Life Reflections" scheme="https://chenhuiyu.github.io/categories/Life-Reflections/"/>
    
    
    <category term="å¡å²›ç”Ÿæ´»æŒ‡åŒ—" scheme="https://chenhuiyu.github.io/tags/%E5%9D%A1%E5%B2%9B%E7%94%9F%E6%B4%BB%E6%8C%87%E5%8C%97/"/>
    
  </entry>
  
  <entry>
    <title>ã€Leetcode Pythoné¢˜è§£ã€‘ã€Œ1346. Check If N and Its Double Existã€</title>
    <link href="https://chenhuiyu.github.io/2024/12/02/Code%20Chronicles/Leetcode%20Python%E9%A2%98%E8%A7%A3%E3%80%91%E3%80%8C1346.%20Check%20If%20N%20and%20Its%20Double%20Exist%E3%80%8D/"/>
    <id>https://chenhuiyu.github.io/2024/12/02/Code%20Chronicles/Leetcode%20Python%E9%A2%98%E8%A7%A3%E3%80%91%E3%80%8C1346.%20Check%20If%20N%20and%20Its%20Double%20Exist%E3%80%8D/</id>
    <published>2024-12-01T16:00:00.000Z</published>
    <updated>2026-02-20T21:56:22.865Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ1346-Check-If-N-and-Its-Double-Existã€"><a href="#ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ1346-Check-If-N-and-Its-Double-Existã€" class="headerlink" title="ã€Leetcode Pythoné¢˜è§£ã€‘ã€Œ1346. Check If N and Its Double Existã€"></a>ã€Leetcode Pythoné¢˜è§£ã€‘ã€Œ1346. Check If N and Its Double Existã€</h1><h2 id="é¢˜ç›®ï¼š1346-Check-If-N-and-Its-Double-Exist"><a href="#é¢˜ç›®ï¼š1346-Check-If-N-and-Its-Double-Exist" class="headerlink" title="é¢˜ç›®ï¼š1346. Check If N and Its Double Exist"></a>é¢˜ç›®ï¼š<a href="https://leetcode.com/problems/check-if-n-and-its-double-exist/description/?envType=daily-question&amp;envId=2024-12-01">1346. Check If N and Its Double Exist</a></h2><h2 id="é¢˜ç›®æè¿°"><a href="#é¢˜ç›®æè¿°" class="headerlink" title="é¢˜ç›®æè¿°"></a>é¢˜ç›®æè¿°</h2><p>ç»™å®šä¸€ä¸ªæ•´æ•°æ•°ç»„ <code>arr</code>ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸¤ä¸ªä¸åŒçš„ç´¢å¼• <code>i</code> å’Œ <code>j</code>ï¼Œæ»¡è¶³ï¼š</p><ul><li><code>i != j</code></li><li><code>0 &lt;= i, j &lt; arr.length</code></li><li><code>arr[i] == 2 * arr[j]</code></li></ul><h3 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h3><p><strong>ç¤ºä¾‹ 1:</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">è¾“å…¥ï¼šarr = [10,2,5,3]</span><br><span class="line">è¾“å‡ºï¼štrue</span><br><span class="line">è§£é‡Šï¼šå¯¹äº i = 0 å’Œ j = 2ï¼Œarr[i] = 10 ç­‰äº 2 * 5 = 2 * arr[j]</span><br></pre></td></tr></tbody></table></figure><p><strong>ç¤ºä¾‹ 2:</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">è¾“å…¥ï¼šarr = [3,1,7,11]</span><br><span class="line">è¾“å‡ºï¼šfalse</span><br><span class="line">è§£é‡Šï¼šä¸å­˜åœ¨æ»¡è¶³æ¡ä»¶çš„ i å’Œ jã€‚</span><br></pre></td></tr></tbody></table></figure><h3 id="çº¦æŸæ¡ä»¶"><a href="#çº¦æŸæ¡ä»¶" class="headerlink" title="çº¦æŸæ¡ä»¶"></a>çº¦æŸæ¡ä»¶</h3><ul><li><code>2 &lt;= arr.length &lt;= 500</code></li><li><code>-10Â³ &lt;= arr[i] &lt;= 10Â³</code></li></ul><h2 id="è§£é¢˜æ€è·¯"><a href="#è§£é¢˜æ€è·¯" class="headerlink" title="è§£é¢˜æ€è·¯"></a>è§£é¢˜æ€è·¯</h2><p>è¿™é“é¢˜å¯ä»¥ç”¨å¤šç§æ–¹æ³•è§£å†³ï¼Œæˆ‘ä»¬æ¥åˆ†æä¸¤ç§ä¸»è¦çš„è§£æ³•ï¼šæš´åŠ›è§£æ³•å’Œå“ˆå¸Œè¡¨è§£æ³•ã€‚</p><h3 id="1-æš´åŠ›è§£æ³•"><a href="#1-æš´åŠ›è§£æ³•" class="headerlink" title="1. æš´åŠ›è§£æ³•"></a>1. æš´åŠ›è§£æ³•</h3><p>æœ€ç›´è§‚çš„è§£æ³•æ˜¯ä½¿ç”¨ä¸¤å±‚å¾ªç¯ï¼Œéå†æ‰€æœ‰å¯èƒ½çš„æ•°å¯¹ã€‚</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">checkIfExist</span>(<span class="params">arr</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> i != j <span class="keyword">and</span> arr[i] == <span class="number">2</span> * arr[j]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><p><strong>å¤æ‚åº¦åˆ†æï¼š</strong></p><ul><li>æ—¶é—´å¤æ‚åº¦ï¼šO(nÂ²)ï¼Œå…¶ä¸­ n æ˜¯æ•°ç»„é•¿åº¦</li><li>ç©ºé—´å¤æ‚åº¦ï¼šO(1)ï¼Œåªä½¿ç”¨äº†å¸¸æ•°é¢å¤–ç©ºé—´</li></ul><h3 id="2-å“ˆå¸Œè¡¨è§£æ³•"><a href="#2-å“ˆå¸Œè¡¨è§£æ³•" class="headerlink" title="2. å“ˆå¸Œè¡¨è§£æ³•"></a>2. å“ˆå¸Œè¡¨è§£æ³•</h3><p>ä½¿ç”¨å“ˆå¸Œè¡¨å¯ä»¥æ˜¾è‘—ä¼˜åŒ–æ—¶é—´å¤æ‚åº¦ã€‚æˆ‘ä»¬åªéœ€è¦ä¸€æ¬¡éå†æ•°ç»„ï¼ŒåŒæ—¶ç”¨å“ˆå¸Œè¡¨è®°å½•å·²ç»é‡åˆ°çš„æ•°å­—ã€‚</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">checkIfExist</span>(<span class="params">arr</span>):</span><br><span class="line">    seen = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> arr:</span><br><span class="line">        <span class="keyword">if</span> num * <span class="number">2</span> <span class="keyword">in</span> seen <span class="keyword">or</span> (num % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> num // <span class="number">2</span> <span class="keyword">in</span> seen):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        seen.add(num)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><p><strong>å¤æ‚åº¦åˆ†æï¼š</strong></p><ul><li>æ—¶é—´å¤æ‚åº¦ï¼šO(n)ï¼Œåªéœ€è¦éå†ä¸€æ¬¡æ•°ç»„</li><li>ç©ºé—´å¤æ‚åº¦ï¼šO(n)ï¼Œéœ€è¦é¢å¤–çš„å“ˆå¸Œè¡¨ç©ºé—´</li></ul><h3 id="ä»£ç ä¼˜åŒ–æ¡ˆä¾‹"><a href="#ä»£ç ä¼˜åŒ–æ¡ˆä¾‹" class="headerlink" title="ä»£ç ä¼˜åŒ–æ¡ˆä¾‹"></a>ä»£ç ä¼˜åŒ–æ¡ˆä¾‹</h3><p>è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªåˆå§‹ç‰ˆæœ¬çš„ä»£ç ï¼Œä»¥åŠå¦‚ä½•ä¼˜åŒ–å®ƒï¼š</p><p><strong>åŸå§‹ç‰ˆæœ¬ï¼š</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">checkIfExist</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        hashmap = {}</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(arr):</span><br><span class="line">            hashmap[i] = item</span><br><span class="line">            <span class="keyword">if</span> item * <span class="number">2</span> <span class="keyword">in</span> hashmap.values():</span><br><span class="line">                j = <span class="built_in">next</span>(k <span class="keyword">for</span> k, v <span class="keyword">in</span> hashmap.items() <span class="keyword">if</span> v == item * <span class="number">2</span>)</span><br><span class="line">                <span class="keyword">if</span> i != j:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">if</span> item//<span class="number">2</span> <span class="keyword">in</span> hashmap.values() <span class="keyword">and</span> item%<span class="number">2</span>==<span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">next</span>(k <span class="keyword">for</span> k, v <span class="keyword">in</span> hashmap.items() <span class="keyword">if</span> v == item//<span class="number">2</span>)</span><br><span class="line">                <span class="keyword">if</span> i != j:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><p><strong>ä¼˜åŒ–ç‰ˆæœ¬ï¼š</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">checkIfExist</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        seen = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> arr:</span><br><span class="line">            <span class="keyword">if</span> num * <span class="number">2</span> <span class="keyword">in</span> seen <span class="keyword">or</span> (num % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> num // <span class="number">2</span> <span class="keyword">in</span> seen):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            seen.add(num)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure><h3 id="ä¼˜åŒ–è¦ç‚¹"><a href="#ä¼˜åŒ–è¦ç‚¹" class="headerlink" title="ä¼˜åŒ–è¦ç‚¹"></a>ä¼˜åŒ–è¦ç‚¹</h3><ol><li><p><strong>æ•°æ®ç»“æ„é€‰æ‹©</strong></p><ul><li>ä½¿ç”¨é›†åˆ(set)æ›¿ä»£å­—å…¸(dict)</li><li>ä¸éœ€è¦å­˜å‚¨ç´¢å¼•ä¿¡æ¯ï¼Œåªå…³æ³¨å€¼çš„å­˜åœ¨æ€§</li></ul></li><li><p><strong>ä»£ç ç®€åŒ–</strong></p><ul><li>åˆå¹¶é‡å¤çš„æ£€æŸ¥é€»è¾‘</li><li>ç§»é™¤ä¸å¿…è¦çš„å˜é‡å’Œè®¡ç®—</li><li>ä½¿ç”¨æ›´ç®€æ´çš„æ¡ä»¶åˆ¤æ–­</li></ul></li><li><p><strong>æ€§èƒ½æå‡</strong></p><ul><li>é¿å…ä½¿ç”¨ <code>hashmap.values()</code> éå†</li><li>ä½¿ç”¨é›†åˆçš„ O(1) æŸ¥æ‰¾ç‰¹æ€§</li><li>å‡å°‘é‡å¤è®¡ç®—</li></ul></li></ol><h2 id="å…³é”®æ³¨æ„ç‚¹"><a href="#å…³é”®æ³¨æ„ç‚¹" class="headerlink" title="å…³é”®æ³¨æ„ç‚¹"></a>å…³é”®æ³¨æ„ç‚¹</h2><ol><li><p><strong>è¾¹ç•Œæƒ…å†µå¤„ç†</strong></p><ul><li>è€ƒè™‘æ•°ç»„ä¸­æœ‰ 0 çš„æƒ…å†µï¼ˆ0 çš„ä¸¤å€ä»ç„¶æ˜¯ 0ï¼‰</li><li>æ³¨æ„è´Ÿæ•°çš„å¤„ç†</li><li>ç¡®ä¿ä¸ä½¿ç”¨åŒä¸€ä¸ªç´¢å¼•ï¼ˆi != jï¼‰</li></ul></li><li><p><strong>æ•°å€¼æ£€æŸ¥</strong></p><ul><li>éœ€è¦åŒæ—¶æ£€æŸ¥ä¸€ä¸ªæ•°çš„ä¸¤å€å’Œä¸€åŠ</li><li>æ£€æŸ¥ä¸€åŠæ—¶è¦ç¡®ä¿æ•°å­—æ˜¯å¶æ•°</li></ul></li><li><p><strong>æ€§èƒ½ä¼˜åŒ–</strong></p><ul><li>ä½¿ç”¨æ°å½“çš„æ•°æ®ç»“æ„ï¼ˆé›†åˆï¼‰</li><li>é¿å…ä¸å¿…è¦çš„è®¡ç®—å’Œéå†</li></ul></li></ol><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>è¿™é“é¢˜å±•ç¤ºäº†å¦‚ä½•é€šè¿‡é€‰æ‹©é€‚å½“çš„æ•°æ®ç»“æ„å’Œä¼˜åŒ–ä»£ç é€»è¾‘æ¥æå‡ç®—æ³•çš„æ€§èƒ½ã€‚ä»åˆå§‹çš„æš´åŠ›è§£æ³•åˆ°ä½¿ç”¨å“ˆå¸Œè¡¨ï¼Œå†åˆ°ä»£ç çš„ä¼˜åŒ–ï¼Œæ¯ä¸€æ­¥éƒ½å¸¦æ¥äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚æœ€ç»ˆçš„è§£å†³æ–¹æ¡ˆä¸ä»…è¿è¡Œæ•ˆç‡é«˜ï¼Œè€Œä¸”ä»£ç ç®€æ´æ˜“æ‡‚ã€‚</p><p>å…³é”®æ˜¯è¦ç†è§£ï¼š</p><ol><li>æš´åŠ›è§£æ³•è™½ç„¶ç›´è§‚ï¼Œä½†æ•ˆç‡ä½ä¸‹</li><li>å“ˆå¸Œè¡¨æä¾›äº†æœ€ä¼˜çš„æ—¶ç©ºæƒè¡¡</li><li>ä»£ç ä¼˜åŒ–ä¸ä»…æ˜¯ä¸ºäº†æ•ˆç‡ï¼Œä¹Ÿæ˜¯ä¸ºäº†å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ1346-Check-If-N-and-Its-Double-Existã€&quot;&gt;&lt;a href=&quot;#ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ1346-Check-If-N-and-Its-Double-Existã€&quot; clas</summary>
      
    
    
    
    <category term="Code Chronicles" scheme="https://chenhuiyu.github.io/categories/Code-Chronicles/"/>
    
    
    <category term="Python" scheme="https://chenhuiyu.github.io/tags/Python/"/>
    
    <category term="Leetcode" scheme="https://chenhuiyu.github.io/tags/Leetcode/"/>
    
    <category term="æ¯æ—¥ä¸€é¢˜" scheme="https://chenhuiyu.github.io/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode Python Solution - 2097. Valid Arrangement of Pairs</title>
    <link href="https://chenhuiyu.github.io/2024/12/01/Code%20Chronicles/[Leetcode%20Python%20Solution]%202097.%20Valid%20Arrangement%20of%20Pairs/"/>
    <id>https://chenhuiyu.github.io/2024/12/01/Code%20Chronicles/[Leetcode%20Python%20Solution]%202097.%20Valid%20Arrangement%20of%20Pairs/</id>
    <published>2024-11-30T19:00:00.000Z</published>
    <updated>2026-02-20T21:56:22.866Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Leetcode-Python-Solution-2097-Valid-Arrangement-of-Pairs"><a href="#Leetcode-Python-Solution-2097-Valid-Arrangement-of-Pairs" class="headerlink" title="[Leetcode Python Solution] 2097. Valid Arrangement of Pairs"></a>[Leetcode Python Solution] 2097. Valid Arrangement of Pairs</h1><p>In this technical blog, weâ€™ll dive deep into Leetcode Problem 2097 â€” <em>Valid Arrangement of Pairs</em>. We will break down the solution step by step, from understanding the problem, modeling it as a graph theory problem, to implementing the solution.</p><p>Problem Link: <a href="https://leetcode.com/problems/valid-arrangement-of-pairs/description/">2097. Valid Arrangement of Pairs</a></p><hr><h2 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h2><p>Given a 2D array <code>pairs</code> where <code>pairs[i] = [start, end]</code>, you need to rearrange these pairs so that for adjacent pairs <code>[start1, end1]</code> and <code>[start2, end2]</code>, the condition <code>end1 == start2</code> holds.</p><p>It is guaranteed that at least one valid arrangement exists.</p><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h4><p><strong>Input:</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pairs = [[<span class="number">5</span>,<span class="number">1</span>],[<span class="number">4</span>,<span class="number">5</span>],[<span class="number">11</span>,<span class="number">9</span>],[<span class="number">9</span>,<span class="number">4</span>]]</span><br></pre></td></tr></tbody></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">11</span>,<span class="number">9</span>],[<span class="number">9</span>,<span class="number">4</span>],[<span class="number">4</span>,<span class="number">5</span>],[<span class="number">5</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure><p><strong>Explanation:</strong><br>The arrangement satisfies:</p><ul><li><code>end0 = 9 == 9 = start1</code></li><li><code>end1 = 4 == 4 = start2</code></li><li><code>end2 = 5 == 5 = start3</code></li></ul><h4 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h4><p><strong>Input:</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pairs = [[<span class="number">1</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure><p><strong>Output:</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="Problem-Modeling-Eulerian-Path-Problem"><a href="#Problem-Modeling-Eulerian-Path-Problem" class="headerlink" title="Problem Modeling: Eulerian Path Problem"></a>Problem Modeling: Eulerian Path Problem</h2><p>This problem can be modeled as an <strong>Eulerian Path Problem</strong> in graph theory. Each <code>pair [start, end]</code> is treated as a directed edge from <code>start</code> to <code>end</code>, and we aim to find a path that traverses all edges while satisfying the given condition.</p><h3 id="What-is-an-Eulerian-Path"><a href="#What-is-an-Eulerian-Path" class="headerlink" title="What is an Eulerian Path?"></a>What is an Eulerian Path?</h3><ul><li><strong>Definition</strong>: An Eulerian path is a path in a graph that visits every edge exactly once.</li><li><strong>Conditions</strong>:<ol><li>An Eulerian path exists if and only if there are exactly two nodes in the graph with unbalanced in-degrees and out-degrees:<ul><li>Start node: the node where <code>out-degree - in-degree = 1</code>.</li><li>End node: the node where <code>in-degree - out-degree = 1</code>.</li></ul></li><li>If all nodes have equal in-degrees and out-degrees, the graph contains an Eulerian circuit, and the path can start at any node.</li></ol></li></ul><hr><h2 id="Solution-Approach"><a href="#Solution-Approach" class="headerlink" title="Solution Approach"></a>Solution Approach</h2><h3 id="1-Graph-Construction"><a href="#1-Graph-Construction" class="headerlink" title="1. Graph Construction"></a>1. Graph Construction</h3><p>Model each <code>pair [start, end]</code> as a directed edge:</p><ul><li>Nodes: <code>start</code> and <code>end</code>.</li><li>Edges: Directed edge from <code>start</code> to <code>end</code>.</li></ul><p>Simultaneously, calculate the <strong>in-degrees</strong> and <strong>out-degrees</strong> of each node to identify the starting node.</p><h3 id="2-Finding-the-Start-Node"><a href="#2-Finding-the-Start-Node" class="headerlink" title="2. Finding the Start Node"></a>2. Finding the Start Node</h3><p>Using the in-degree and out-degree counts:</p><ul><li>A node with <code>out-degree - in-degree = 1</code> is the start node.</li><li>If no such node exists, the graph contains an Eulerian circuit, and we can start from any node.</li></ul><h3 id="3-Using-Hierholzerâ€™s-Algorithm-to-Find-the-Path"><a href="#3-Using-Hierholzerâ€™s-Algorithm-to-Find-the-Path" class="headerlink" title="3. Using Hierholzerâ€™s Algorithm to Find the Path"></a>3. Using Hierholzerâ€™s Algorithm to Find the Path</h3><p><strong>Hierholzerâ€™s Algorithm</strong> is used to find an Eulerian path:</p><ol><li>Start at the chosen node and follow any unvisited edge.</li><li>Continue until reaching a dead end (a node with no outgoing edges).</li><li>Backtrack and record the path.</li><li>Reverse the recorded path to get the correct order.</li></ol><hr><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>Hereâ€™s the complete Python solution:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validArrangement</span>(<span class="params">pairs</span>):</span><br><span class="line">    <span class="comment"># Construct the graph</span></span><br><span class="line">    graph = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    in_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    out_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> start, end <span class="keyword">in</span> pairs:</span><br><span class="line">        graph[start].append(end)</span><br><span class="line">        out_degree[start] += <span class="number">1</span></span><br><span class="line">        in_degree[end] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Find the starting node</span></span><br><span class="line">    start_node = pairs[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># Default start node</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> out_degree[node] - in_degree[node] == <span class="number">1</span>:</span><br><span class="line">            start_node = node</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Hierholzer's Algorithm</span></span><br><span class="line">    path = []</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">current_node</span>):</span><br><span class="line">        <span class="keyword">while</span> graph[current_node]:</span><br><span class="line">            next_node = graph[current_node].pop()</span><br><span class="line">            dfs(next_node)</span><br><span class="line">            path.append([current_node, next_node])</span><br><span class="line">    </span><br><span class="line">    dfs(start_node)</span><br><span class="line">    <span class="keyword">return</span> path[::-<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="Code-Explanation"><a href="#Code-Explanation" class="headerlink" title="Code Explanation"></a>Code Explanation</h2><h3 id="Graph-Construction"><a href="#Graph-Construction" class="headerlink" title="Graph Construction"></a>Graph Construction</h3><p>Using <code>defaultdict</code> to store the adjacency list and count the in-degrees and out-degrees:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">in_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">out_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> start, end <span class="keyword">in</span> pairs:</span><br><span class="line">    graph[start].append(end)</span><br><span class="line">    out_degree[start] += <span class="number">1</span></span><br><span class="line">    in_degree[end] += <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><h3 id="Finding-the-Start-Node"><a href="#Finding-the-Start-Node" class="headerlink" title="Finding the Start Node"></a>Finding the Start Node</h3><p>Based on the rules for Eulerian paths:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start_node = pairs[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># Default value</span></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> graph:</span><br><span class="line">    <span class="keyword">if</span> out_degree[node] - in_degree[node] == <span class="number">1</span>:</span><br><span class="line">        start_node = node</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure><h3 id="Hierholzerâ€™s-Algorithm"><a href="#Hierholzerâ€™s-Algorithm" class="headerlink" title="Hierholzerâ€™s Algorithm"></a>Hierholzerâ€™s Algorithm</h3><p>Using a recursive DFS to find the Eulerian path:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">path = []  <span class="comment"># To store the path</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">current_node</span>):</span><br><span class="line">    <span class="keyword">while</span> graph[current_node]:  <span class="comment"># While there are outgoing edges</span></span><br><span class="line">        next_node = graph[current_node].pop()  <span class="comment"># Remove edge</span></span><br><span class="line">        dfs(next_node)</span><br><span class="line">        path.append([current_node, next_node])  <span class="comment"># Record path</span></span><br></pre></td></tr></tbody></table></figure><hr><h2 id="Example-Execution"><a href="#Example-Execution" class="headerlink" title="Example Execution"></a>Example Execution</h2><p>For <code>pairs = [[5,1],[4,5],[11,9],[9,4]]</code>:</p><h3 id="Graph-State"><a href="#Graph-State" class="headerlink" title="Graph State"></a>Graph State</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">11 â†’ 9</span><br><span class="line"> 9 â†’ 4</span><br><span class="line"> 4 â†’ 5</span><br><span class="line"> 5 â†’ 1</span><br></pre></td></tr></tbody></table></figure><h3 id="Execution-Process"><a href="#Execution-Process" class="headerlink" title="Execution Process"></a>Execution Process</h3><ol><li><p>Start DFS from node <code>11</code>:</p><ul><li>Visit <code>11 â†’ 9</code> and remove the edge.</li><li>Visit <code>9 â†’ 4</code> and remove the edge.</li><li>Visit <code>4 â†’ 5</code> and remove the edge.</li><li>Visit <code>5 â†’ 1</code> and remove the edge.</li></ul></li><li><p>Backtrack to record the path:</p><ul><li><code>path = [[5,1], [4,5], [9,4], [11,9]]</code>.</li></ul></li><li><p>Reverse the path for the final result:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">11</span>,<span class="number">9</span>], [<span class="number">9</span>,<span class="number">4</span>], [<span class="number">4</span>,<span class="number">5</span>], [<span class="number">5</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure></li></ol><hr><h2 id="Time-and-Space-Complexity"><a href="#Time-and-Space-Complexity" class="headerlink" title="Time and Space Complexity"></a>Time and Space Complexity</h2><ul><li><strong>Time Complexity</strong>: <code>O(E)</code>, where <code>E</code> is the number of edges.<ul><li>Constructing the graph: <code>O(E)</code>.</li><li>DFS traversal: <code>O(E)</code>.</li></ul></li><li><strong>Space Complexity</strong>: <code>O(E)</code> for storing the adjacency list and result path.</li></ul><hr><h2 id="Python-Tips-and-Tricks"><a href="#Python-Tips-and-Tricks" class="headerlink" title="Python Tips and Tricks"></a>Python Tips and Tricks</h2><h3 id="1-Closures"><a href="#1-Closures" class="headerlink" title="1. Closures"></a>1. Closures</h3><p>A <strong>closure</strong> allows inner functions to access variables from the outer function, even after the outer function has finished executing.</p><h4 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">outer</span>():</span><br><span class="line">    x = <span class="number">10</span>  <span class="comment"># Outer variable</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="keyword">nonlocal</span> x  <span class="comment"># Use the outer variable</span></span><br><span class="line">        x += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line">closure_func = outer()  <span class="comment"># Returns the inner function</span></span><br><span class="line">closure_func()  <span class="comment"># Outputs 11</span></span><br><span class="line">closure_func()  <span class="comment"># Outputs 12</span></span><br></pre></td></tr></tbody></table></figure><p>In the solution, <code>dfs()</code> uses a closure to access and modify the <code>path</code> list without passing it explicitly.</p><hr><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This problem showcases how to model a graph problem as an Eulerian path and use Hierholzerâ€™s algorithm for an efficient solution. Such graph theory techniques provide a robust framework for solving similar problems.</p><p>Feel free to leave questions or share your thoughts!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Leetcode-Python-Solution-2097-Valid-Arrangement-of-Pairs&quot;&gt;&lt;a href=&quot;#Leetcode-Python-Solution-2097-Valid-Arrangement-of-Pairs&quot; class=</summary>
      
    
    
    
    <category term="Code Chronicles" scheme="https://chenhuiyu.github.io/categories/Code-Chronicles/"/>
    
    
    <category term="Python" scheme="https://chenhuiyu.github.io/tags/Python/"/>
    
    <category term="Leetcode" scheme="https://chenhuiyu.github.io/tags/Leetcode/"/>
    
    <category term="Daily Challenge" scheme="https://chenhuiyu.github.io/tags/Daily-Challenge/"/>
    
  </entry>
  
  <entry>
    <title>ã€Leetcode Pythoné¢˜è§£ã€‘ã€Œ2097. Valid Arrangement of Pairsã€</title>
    <link href="https://chenhuiyu.github.io/2024/12/01/Code%20Chronicles/%E3%80%90Leetcode%20Python%E9%A2%98%E8%A7%A3%E3%80%91%E3%80%8C2097.%20Valid%20Arrangement%20of%20Pairs%E3%80%8D/"/>
    <id>https://chenhuiyu.github.io/2024/12/01/Code%20Chronicles/%E3%80%90Leetcode%20Python%E9%A2%98%E8%A7%A3%E3%80%91%E3%80%8C2097.%20Valid%20Arrangement%20of%20Pairs%E3%80%8D/</id>
    <published>2024-11-30T19:00:00.000Z</published>
    <updated>2026-02-20T21:56:22.866Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ2097-Valid-Arrangement-of-Pairsã€"><a href="#ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ2097-Valid-Arrangement-of-Pairsã€" class="headerlink" title="ã€Leetcode Pythoné¢˜è§£ã€‘ã€Œ2097. Valid Arrangement of Pairsã€"></a>ã€Leetcode Pythoné¢˜è§£ã€‘ã€Œ2097. Valid Arrangement of Pairsã€</h1><h2 id="åœ¨è¿™ç¯‡æŠ€æœ¯åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥è§£æ-LeetCode-çš„ç¬¬-2097-é¢˜-â€”â€”-Valid-Arrangement-of-Pairsï¼Œå¹¶å…¨é¢ä»‹ç»å¦‚ä½•ä»é¢˜æ„ç†è§£ã€å›¾è®ºå»ºæ¨¡åˆ°ç®—æ³•å®ç°é€æ­¥è§£å†³é—®é¢˜ã€‚é¢˜ç›®ï¼š2097-Valid-Arrangement-of-Pairs"><a href="#åœ¨è¿™ç¯‡æŠ€æœ¯åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥è§£æ-LeetCode-çš„ç¬¬-2097-é¢˜-â€”â€”-Valid-Arrangement-of-Pairsï¼Œå¹¶å…¨é¢ä»‹ç»å¦‚ä½•ä»é¢˜æ„ç†è§£ã€å›¾è®ºå»ºæ¨¡åˆ°ç®—æ³•å®ç°é€æ­¥è§£å†³é—®é¢˜ã€‚é¢˜ç›®ï¼š2097-Valid-Arrangement-of-Pairs" class="headerlink" title="åœ¨è¿™ç¯‡æŠ€æœ¯åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥è§£æ LeetCode çš„ç¬¬ 2097 é¢˜ â€”â€” Valid Arrangement of Pairsï¼Œå¹¶å…¨é¢ä»‹ç»å¦‚ä½•ä»é¢˜æ„ç†è§£ã€å›¾è®ºå»ºæ¨¡åˆ°ç®—æ³•å®ç°é€æ­¥è§£å†³é—®é¢˜ã€‚é¢˜ç›®ï¼š2097. Valid Arrangement of Pairs"></a>åœ¨è¿™ç¯‡æŠ€æœ¯åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥è§£æ LeetCode çš„ç¬¬ 2097 é¢˜ â€”â€” <em>Valid Arrangement of Pairs</em>ï¼Œå¹¶å…¨é¢ä»‹ç»å¦‚ä½•ä»é¢˜æ„ç†è§£ã€å›¾è®ºå»ºæ¨¡åˆ°ç®—æ³•å®ç°é€æ­¥è§£å†³é—®é¢˜ã€‚<br>é¢˜ç›®ï¼š<a href="https://leetcode.com/problems/valid-arrangement-of-pairs/description/">2097. Valid Arrangement of Pairs</a></h2><h2 id="é—®é¢˜æè¿°"><a href="#é—®é¢˜æè¿°" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h2><p>ç»™å®šä¸€ä¸ªäºŒç»´æ•°ç»„ <code>pairs</code>ï¼Œå…¶ä¸­ <code>pairs[i] = [start, end]</code>ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°æ’åˆ—è¿™äº›æ•°å­—å¯¹ï¼Œä½¿å¾—ç›¸é‚»çš„ä¸¤ä¸ªæ•°å­—å¯¹ <code>[start1, end1]</code> å’Œ <code>[start2, end2]</code> æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š</p><ul><li><code>end1 == start2</code>ã€‚</li></ul><p>è¾“å…¥æ•°æ®ä¿è¯ä¸€å®šå­˜åœ¨è¿™æ ·ä¸€ç§åˆæ³•çš„æ’åˆ—æ–¹å¼ã€‚</p><h3 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h3><h4 id="ç¤ºä¾‹-1"><a href="#ç¤ºä¾‹-1" class="headerlink" title="ç¤ºä¾‹ 1"></a>ç¤ºä¾‹ 1</h4><p><strong>è¾“å…¥ï¼š</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pairs = [[<span class="number">5</span>,<span class="number">1</span>],[<span class="number">4</span>,<span class="number">5</span>],[<span class="number">11</span>,<span class="number">9</span>],[<span class="number">9</span>,<span class="number">4</span>]]</span><br></pre></td></tr></tbody></table></figure><p><strong>è¾“å‡ºï¼š</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">11</span>,<span class="number">9</span>],[<span class="number">9</span>,<span class="number">4</span>],[<span class="number">4</span>,<span class="number">5</span>],[<span class="number">5</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure><p><strong>è§£é‡Šï¼š</strong><br>æ’åˆ—åæ»¡è¶³æ¡ä»¶ï¼š</p><ul><li><code>end0 = 9 == 9 = start1</code></li><li><code>end1 = 4 == 4 = start2</code></li><li><code>end2 = 5 == 5 = start3</code></li></ul><h4 id="ç¤ºä¾‹-2"><a href="#ç¤ºä¾‹-2" class="headerlink" title="ç¤ºä¾‹ 2"></a>ç¤ºä¾‹ 2</h4><p><strong>è¾“å…¥ï¼š</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pairs = [[<span class="number">1</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure><p><strong>è¾“å‡ºï¼š</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="é—®é¢˜å»ºæ¨¡ï¼šæ¬§æ‹‰è·¯å¾„é—®é¢˜"><a href="#é—®é¢˜å»ºæ¨¡ï¼šæ¬§æ‹‰è·¯å¾„é—®é¢˜" class="headerlink" title="é—®é¢˜å»ºæ¨¡ï¼šæ¬§æ‹‰è·¯å¾„é—®é¢˜"></a>é—®é¢˜å»ºæ¨¡ï¼šæ¬§æ‹‰è·¯å¾„é—®é¢˜</h2><p>è¿™é“é¢˜çš„æœ¬è´¨æ˜¯ä¸€ä¸ªå›¾è®ºä¸­çš„æ¬§æ‹‰è·¯å¾„é—®é¢˜ã€‚æˆ‘ä»¬å°†æ¯ä¸ª <code>pair [start, end]</code> çœ‹ä½œä¸€æ¡ä» <code>start</code> åˆ° <code>end</code> çš„æœ‰å‘è¾¹ï¼Œå¹¶è¯•å›¾æ‰¾åˆ°ä¸€æ¡è·¯å¾„èƒ½éå†æ‰€æœ‰è¾¹ä¸”æ»¡è¶³æ¡ä»¶ã€‚</p><h3 id="ä»€ä¹ˆæ˜¯æ¬§æ‹‰è·¯å¾„ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯æ¬§æ‹‰è·¯å¾„ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯æ¬§æ‹‰è·¯å¾„ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯æ¬§æ‹‰è·¯å¾„ï¼Ÿ</h3><ul><li><strong>å®šä¹‰</strong>ï¼šæ¬§æ‹‰è·¯å¾„æ˜¯ä¸€æ¡è·¯å¾„ï¼Œå®ƒèƒ½éå†å›¾ä¸­æ¯æ¡è¾¹æ°å¥½ä¸€æ¬¡ã€‚</li><li><strong>æ¡ä»¶</strong>ï¼š<ol><li>å¦‚æœå›¾ä¸­æœ‰ä¸”ä»…æœ‰ä¸¤ä¸ªèŠ‚ç‚¹çš„å…¥åº¦å’Œå‡ºåº¦ä¸ç›¸ç­‰ï¼Œåˆ™å¯ä»¥å­˜åœ¨æ¬§æ‹‰è·¯å¾„ã€‚<ul><li>èµ·ç‚¹ï¼šå‡ºåº¦æ¯”å…¥åº¦å¤§ 1 çš„èŠ‚ç‚¹ã€‚</li><li>ç»ˆç‚¹ï¼šå…¥åº¦æ¯”å‡ºåº¦å¤§ 1 çš„èŠ‚ç‚¹ã€‚</li></ul></li><li>å¦‚æœæ‰€æœ‰èŠ‚ç‚¹çš„å…¥åº¦ç­‰äºå‡ºåº¦ï¼Œåˆ™å›¾ä¸­å­˜åœ¨æ¬§æ‹‰å›è·¯ã€‚</li></ol></li></ul><hr><h2 id="è§£é¢˜æ€è·¯"><a href="#è§£é¢˜æ€è·¯" class="headerlink" title="è§£é¢˜æ€è·¯"></a>è§£é¢˜æ€è·¯</h2><h3 id="1-å›¾çš„æ„å»º"><a href="#1-å›¾çš„æ„å»º" class="headerlink" title="1. å›¾çš„æ„å»º"></a>1. å›¾çš„æ„å»º</h3><p>å°†æ¯ä¸ª <code>pair [start, end]</code> å»ºæ¨¡ä¸ºæœ‰å‘è¾¹ï¼š</p><ul><li>èŠ‚ç‚¹ä¸º <code>start</code> å’Œ <code>end</code>ã€‚</li><li>è¾¹ä¸ºä» <code>start</code> åˆ° <code>end</code>ã€‚</li></ul><p>åŒæ—¶ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„ <strong>å…¥åº¦</strong> å’Œ <strong>å‡ºåº¦</strong>ï¼Œç”¨äºåç»­åˆ¤æ–­èµ·ç‚¹ã€‚</p><h3 id="2-å¯»æ‰¾èµ·ç‚¹"><a href="#2-å¯»æ‰¾èµ·ç‚¹" class="headerlink" title="2. å¯»æ‰¾èµ·ç‚¹"></a>2. å¯»æ‰¾èµ·ç‚¹</h3><p>é€šè¿‡å…¥åº¦å’Œå‡ºåº¦çš„ç»Ÿè®¡ï¼š</p><ul><li>å‡ºåº¦ - å…¥åº¦ = 1 çš„èŠ‚ç‚¹æ˜¯è·¯å¾„çš„èµ·ç‚¹ã€‚</li><li>å¦‚æœæ²¡æœ‰è¿™æ ·çš„èŠ‚ç‚¹ï¼Œè¯´æ˜å›¾ä¸­å­˜åœ¨æ¬§æ‹‰å›è·¯ï¼Œå¯ä»ä»»æ„èŠ‚ç‚¹å¼€å§‹ã€‚</li></ul><h3 id="3-Hierholzer-ç®—æ³•æ‰¾è·¯å¾„"><a href="#3-Hierholzer-ç®—æ³•æ‰¾è·¯å¾„" class="headerlink" title="3. Hierholzer ç®—æ³•æ‰¾è·¯å¾„"></a>3. Hierholzer ç®—æ³•æ‰¾è·¯å¾„</h3><p><strong>Hierholzer ç®—æ³•</strong> ç”¨äºå¯»æ‰¾æ¬§æ‹‰è·¯å¾„ï¼Œå…¶æ ¸å¿ƒæ­¥éª¤ï¼š</p><ol><li>ä»èµ·ç‚¹å¼€å§‹ï¼Œä»»æ„é€‰æ‹©ä¸€æ¡æœªè®¿é—®çš„è¾¹èµ°ã€‚</li><li>ä¸€ç›´èµ°ç›´åˆ°èµ°åˆ°æ­»èƒ¡åŒï¼ˆå½“å‰èŠ‚ç‚¹æ²¡æœ‰å‡ºè¾¹ï¼‰ã€‚</li><li>å›æº¯è¿‡ç¨‹ä¸­è®°å½•è·¯å¾„ã€‚</li><li>æœ€ç»ˆè®°å½•çš„è·¯å¾„éœ€è¦åè½¬æ‰èƒ½å¾—åˆ°æ­£ç¡®çš„é¡ºåºã€‚</li></ol><hr><h2 id="ç®—æ³•å®ç°"><a href="#ç®—æ³•å®ç°" class="headerlink" title="ç®—æ³•å®ç°"></a>ç®—æ³•å®ç°</h2><p>ä¸‹é¢æ˜¯ Python å®ç°çš„å®Œæ•´ä»£ç ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validArrangement</span>(<span class="params">pairs</span>):</span><br><span class="line">    <span class="comment"># æ„å»ºå›¾</span></span><br><span class="line">    graph = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    in_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    out_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> start, end <span class="keyword">in</span> pairs:</span><br><span class="line">        graph[start].append(end)</span><br><span class="line">        out_degree[start] += <span class="number">1</span></span><br><span class="line">        in_degree[end] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># å¯»æ‰¾èµ·ç‚¹</span></span><br><span class="line">    start_node = pairs[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># é»˜è®¤èµ·ç‚¹</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> out_degree[node] - in_degree[node] == <span class="number">1</span>:</span><br><span class="line">            start_node = node</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Hierholzerç®—æ³•</span></span><br><span class="line">    path = []</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">current_node</span>):</span><br><span class="line">        <span class="keyword">while</span> graph[current_node]:</span><br><span class="line">            next_node = graph[current_node].pop()</span><br><span class="line">            dfs(next_node)</span><br><span class="line">            path.append([current_node, next_node])</span><br><span class="line">    </span><br><span class="line">    dfs(start_node)</span><br><span class="line">    <span class="keyword">return</span> path[::-<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="ä»£ç è§£æ"><a href="#ä»£ç è§£æ" class="headerlink" title="ä»£ç è§£æ"></a>ä»£ç è§£æ</h2><h3 id="å›¾çš„æ„å»º"><a href="#å›¾çš„æ„å»º" class="headerlink" title="å›¾çš„æ„å»º"></a>å›¾çš„æ„å»º</h3><p>ä½¿ç”¨ <code>defaultdict</code> æ¥å­˜å‚¨å›¾çš„é‚»æ¥è¡¨ï¼Œä»¥åŠç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„å…¥åº¦å’Œå‡ºåº¦ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">in_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">out_degree = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> start, end <span class="keyword">in</span> pairs:</span><br><span class="line">    graph[start].append(end)</span><br><span class="line">    out_degree[start] += <span class="number">1</span></span><br><span class="line">    in_degree[end] += <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><h3 id="å¯»æ‰¾èµ·ç‚¹"><a href="#å¯»æ‰¾èµ·ç‚¹" class="headerlink" title="å¯»æ‰¾èµ·ç‚¹"></a>å¯»æ‰¾èµ·ç‚¹</h3><p>æ ¹æ®å…¥åº¦å’Œå‡ºåº¦çš„ç»Ÿè®¡è§„åˆ™ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start_node = pairs[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># é»˜è®¤å€¼</span></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> graph:</span><br><span class="line">    <span class="keyword">if</span> out_degree[node] - in_degree[node] == <span class="number">1</span>:</span><br><span class="line">        start_node = node</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure><h3 id="Hierholzerç®—æ³•"><a href="#Hierholzerç®—æ³•" class="headerlink" title="Hierholzerç®—æ³•"></a>Hierholzerç®—æ³•</h3><p>é€šè¿‡æ·±åº¦ä¼˜å…ˆæœç´¢ï¼ˆDFSï¼‰æ‰¾åˆ°è·¯å¾„ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">path = []  <span class="comment"># å­˜å‚¨è·¯å¾„</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">current_node</span>):</span><br><span class="line">    <span class="keyword">while</span> graph[current_node]:  <span class="comment"># å½“å‰èŠ‚ç‚¹è¿˜æœ‰å‡ºè¾¹</span></span><br><span class="line">        next_node = graph[current_node].pop()  <span class="comment"># è·å–å¹¶åˆ é™¤è¾¹</span></span><br><span class="line">        dfs(next_node)</span><br><span class="line">        path.append([current_node, next_node])  <span class="comment"># è®°å½•è·¯å¾„</span></span><br></pre></td></tr></tbody></table></figure><hr><h2 id="ç¤ºä¾‹è¿è¡Œ"><a href="#ç¤ºä¾‹è¿è¡Œ" class="headerlink" title="ç¤ºä¾‹è¿è¡Œ"></a>ç¤ºä¾‹è¿è¡Œ</h2><p>ä»¥ <code>pairs = [[5,1],[4,5],[11,9],[9,4]]</code> ä¸ºä¾‹ï¼š</p><h3 id="å›¾çš„çŠ¶æ€"><a href="#å›¾çš„çŠ¶æ€" class="headerlink" title="å›¾çš„çŠ¶æ€"></a>å›¾çš„çŠ¶æ€</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">11 â†’ 9</span><br><span class="line"> 9 â†’ 4</span><br><span class="line"> 4 â†’ 5</span><br><span class="line"> 5 â†’ 1</span><br></pre></td></tr></tbody></table></figure><h3 id="æ‰§è¡Œè¿‡ç¨‹"><a href="#æ‰§è¡Œè¿‡ç¨‹" class="headerlink" title="æ‰§è¡Œè¿‡ç¨‹"></a>æ‰§è¡Œè¿‡ç¨‹</h3><ol><li><p>ä»èŠ‚ç‚¹ <code>11</code> å¼€å§‹ï¼ŒDFS éå†ï¼š</p><ul><li>èµ° <code>11 â†’ 9</code>ï¼Œç§»é™¤è¾¹ã€‚</li><li>èµ° <code>9 â†’ 4</code>ï¼Œç§»é™¤è¾¹ã€‚</li><li>èµ° <code>4 â†’ 5</code>ï¼Œç§»é™¤è¾¹ã€‚</li><li>èµ° <code>5 â†’ 1</code>ï¼Œç§»é™¤è¾¹ã€‚</li></ul></li><li><p>å›æº¯è®°å½•è·¯å¾„ï¼š</p><ul><li><code>path = [[5,1], [4,5], [9,4], [11,9]]</code></li></ul></li><li><p>åè½¬è·¯å¾„å¾—åˆ°æœ€ç»ˆç»“æœï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">11</span>,<span class="number">9</span>], [<span class="number">9</span>,<span class="number">4</span>], [<span class="number">4</span>,<span class="number">5</span>], [<span class="number">5</span>,<span class="number">1</span>]]</span><br></pre></td></tr></tbody></table></figure></li></ol><hr><h2 id="ç®—æ³•å¤æ‚åº¦"><a href="#ç®—æ³•å¤æ‚åº¦" class="headerlink" title="ç®—æ³•å¤æ‚åº¦"></a>ç®—æ³•å¤æ‚åº¦</h2><ul><li><strong>æ—¶é—´å¤æ‚åº¦</strong>ï¼š<code>O(E)</code>ï¼Œå…¶ä¸­ <code>E</code> æ˜¯è¾¹çš„æ•°é‡ã€‚<ul><li>æ„å»ºå›¾éœ€è¦ <code>O(E)</code>ã€‚</li><li>DFS éå†æ¯æ¡è¾¹éœ€è¦ <code>O(E)</code>ã€‚</li></ul></li><li><strong>ç©ºé—´å¤æ‚åº¦</strong>ï¼š<code>O(E)</code>ï¼Œç”¨äºå­˜å‚¨å›¾çš„é‚»æ¥è¡¨å’Œç»“æœè·¯å¾„ã€‚</li></ul><hr><h2 id="Python-æŠ€å·§è¡¥å……"><a href="#Python-æŠ€å·§è¡¥å……" class="headerlink" title="Python æŠ€å·§è¡¥å……"></a>Python æŠ€å·§è¡¥å……</h2><p>æœ€åï¼Œæˆ‘ä»¬è¡¥å……ä¸€äº›ä»£ç ä¸­ç”¨åˆ°çš„ä¸€äº› Python æŠ€å·§ã€‚</p><h3 id="1-é—­åŒ…ï¼ˆClosureï¼‰"><a href="#1-é—­åŒ…ï¼ˆClosureï¼‰" class="headerlink" title="1. é—­åŒ…ï¼ˆClosureï¼‰"></a>1. é—­åŒ…ï¼ˆClosureï¼‰</h3><p><strong>é—­åŒ…</strong> æ˜¯æŒ‡åœ¨ä¸€ä¸ªå‡½æ•°å†…éƒ¨å®šä¹‰å¦ä¸€ä¸ªå‡½æ•°æ—¶ï¼Œå†…éƒ¨å‡½æ•°å¯ä»¥è®¿é—®å¤–éƒ¨å‡½æ•°çš„å˜é‡ï¼Œå³ä½¿å¤–éƒ¨å‡½æ•°å·²ç»æ‰§è¡Œå®Œæ¯•ã€‚ </p><p>åœ¨ä»£ç ä¸­ï¼Œé—­åŒ…çš„ä½œç”¨æ˜¯é€šè¿‡å†…éƒ¨å‡½æ•°è®¿é—®å’Œä¿®æ”¹å¤–éƒ¨ä½œç”¨åŸŸçš„å˜é‡ï¼Œè€Œæ— éœ€é€šè¿‡å‡½æ•°å‚æ•°æ˜¾å¼ä¼ é€’ã€‚</p><h4 id="ç¤ºä¾‹ï¼š"><a href="#ç¤ºä¾‹ï¼š" class="headerlink" title="ç¤ºä¾‹ï¼š"></a>ç¤ºä¾‹ï¼š</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">outer</span>():</span><br><span class="line">    x = <span class="number">10</span>  <span class="comment"># å¤–éƒ¨å˜é‡</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="keyword">nonlocal</span> x  <span class="comment"># æŒ‡å®šä½¿ç”¨å¤–éƒ¨å˜é‡</span></span><br><span class="line">        x += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line">closure_func = outer()  <span class="comment"># è¿”å› inner å‡½æ•°</span></span><br><span class="line">closure_func()  <span class="comment"># è¾“å‡º 11</span></span><br><span class="line">closure_func()  <span class="comment"># è¾“å‡º 12</span></span><br></pre></td></tr></tbody></table></figure><p>åœ¨æœ¬æ–‡çš„ç®—æ³•ä¸­ï¼Œ<code>dfs()</code> å‡½æ•°åˆ©ç”¨é—­åŒ…è®¿é—® <code>path</code> åˆ—è¡¨ï¼Œé¿å…äº†é€šè¿‡å‚æ•°æ˜¾å¼ä¼ é€’è·¯å¾„çš„å¤æ‚æ“ä½œã€‚</p><h4 id="ä¸ºä»€ä¹ˆä¸éœ€è¦å°†-path-ä½œä¸ºå‚æ•°ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸éœ€è¦å°†-path-ä½œä¸ºå‚æ•°ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸éœ€è¦å°† path ä½œä¸ºå‚æ•°ï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸éœ€è¦å°† <code>path</code> ä½œä¸ºå‚æ•°ï¼Ÿ</h4><ul><li><strong>æ˜“è¯»æ€§</strong>ï¼šé—­åŒ…è®©ä»£ç æ›´åŠ ç›´è§‚ï¼Œé¿å…ä¼ é€’å¤šä¸ªå‚æ•°ã€‚</li><li><strong>æ•ˆç‡</strong>ï¼šé—­åŒ…ç›´æ¥æ“ä½œå¤–éƒ¨å˜é‡ï¼Œé¿å…åœ¨é€’å½’è¿‡ç¨‹ä¸­ä¼ é€’å’Œåˆå¹¶è·¯å¾„ã€‚</li></ul><h3 id="2-defaultdict-ä¸-Counter"><a href="#2-defaultdict-ä¸-Counter" class="headerlink" title="2. defaultdict ä¸ Counter"></a>2. <code>defaultdict</code> ä¸ <code>Counter</code></h3><p>Python çš„ <code>collections</code> æ¨¡å—æä¾›äº†è®¸å¤šå·¥å…·ç±»ï¼Œå…¶ä¸­ <code>defaultdict</code> å’Œ <code>Counter</code> æ˜¯æœ¬é¢˜çš„æ ¸å¿ƒå·¥å…·ã€‚</p><h4 id="defaultdict"><a href="#defaultdict" class="headerlink" title="defaultdict"></a><code>defaultdict</code></h4><p><code>defaultdict</code> æ˜¯å­—å…¸çš„ä¸€ä¸ªå­ç±»ï¼Œå¯ä»¥ä¸ºä¸å­˜åœ¨çš„é”®æä¾›é»˜è®¤å€¼ï¼Œä»è€Œé¿å…è®¿é—®ä¸å­˜åœ¨é”®æ—¶æŠ›å‡º <code>KeyError</code>ã€‚</p><h5 id="ä½¿ç”¨æ–¹å¼ï¼š"><a href="#ä½¿ç”¨æ–¹å¼ï¼š" class="headerlink" title="ä½¿ç”¨æ–¹å¼ï¼š"></a>ä½¿ç”¨æ–¹å¼ï¼š</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="comment"># é»˜è®¤å€¼æ˜¯åˆ—è¡¨</span></span><br><span class="line">graph = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">graph[<span class="number">1</span>].append(<span class="number">2</span>)</span><br><span class="line">graph[<span class="number">2</span>].append(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(graph)  <span class="comment"># è¾“å‡ºï¼š{1: [2], 2: [3]}</span></span><br><span class="line"><span class="built_in">print</span>(graph[<span class="number">3</span>])  <span class="comment"># è¾“å‡ºï¼š[]ï¼Œä¸ä¼šæŠ¥é”™</span></span><br></pre></td></tr></tbody></table></figure><p>åœ¨æœ¬æ–‡ä¸­ï¼Œ<code>defaultdict</code> è¢«ç”¨ä½œå›¾çš„é‚»æ¥è¡¨ï¼Œç®€åŒ–äº†å›¾çš„æ„å»ºå’Œæ›´æ–°æ“ä½œã€‚</p><h4 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a><code>Counter</code></h4><p><code>Counter</code> æ˜¯å­—å…¸çš„å­ç±»ï¼Œç”¨äºç»Ÿè®¡å…ƒç´ çš„å‡ºç°æ¬¡æ•°ã€‚å®ƒå°†æ¯ä¸ªå…ƒç´ ä½œä¸ºé”®ï¼Œå‡ºç°æ¬¡æ•°ä½œä¸ºå€¼ã€‚</p><h5 id="ä½¿ç”¨æ–¹å¼ï¼š-1"><a href="#ä½¿ç”¨æ–¹å¼ï¼š-1" class="headerlink" title="ä½¿ç”¨æ–¹å¼ï¼š"></a>ä½¿ç”¨æ–¹å¼ï¼š</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">counts = Counter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(counts)  <span class="comment"># è¾“å‡ºï¼šCounter({3: 3, 2: 2, 1: 1})</span></span><br></pre></td></tr></tbody></table></figure><p>åœ¨æœ¬æ–‡ä¸­ï¼Œå¯ä»¥é€šè¿‡ <code>Counter</code> å¿«é€Ÿç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„å…¥åº¦å’Œå‡ºåº¦ã€‚</p><hr><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>è¿™é“é¢˜é€šè¿‡å°†æ•°å­—å¯¹å»ºæ¨¡ä¸ºå›¾çš„æ¬§æ‹‰è·¯å¾„é—®é¢˜ï¼Œä½¿ç”¨ Hierholzer ç®—æ³•é«˜æ•ˆåœ°æ‰¾åˆ°åˆæ³•æ’åˆ—ã€‚è¿™ç§å›¾è®ºé—®é¢˜çš„å»ºæ¨¡æ–¹æ³•ä¸ä»…æå‡äº†é¢˜ç›®ç†è§£ï¼Œè¿˜ä¸ºç±»ä¼¼é—®é¢˜æä¾›äº†é€šç”¨è§£æ³•ã€‚</p><p>å¸Œæœ›è¿™ç¯‡åšå®¢èƒ½å¸®åŠ©ä½ å½»åº•æŒæ¡è¿™é“é¢˜ï¼å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿äº¤æµï¼</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ2097-Valid-Arrangement-of-Pairsã€&quot;&gt;&lt;a href=&quot;#ã€Leetcode-Pythoné¢˜è§£ã€‘ã€Œ2097-Valid-Arrangement-of-Pairsã€&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="Code Chronicles" scheme="https://chenhuiyu.github.io/categories/Code-Chronicles/"/>
    
    
    <category term="Python" scheme="https://chenhuiyu.github.io/tags/Python/"/>
    
    <category term="Leetcode" scheme="https://chenhuiyu.github.io/tags/Leetcode/"/>
    
    <category term="æ¯æ—¥ä¸€é¢˜" scheme="https://chenhuiyu.github.io/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Detailed Explanation of LoRA, DPO, KTO, and SFT Technologies</title>
    <link href="https://chenhuiyu.github.io/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies/"/>
    <id>https://chenhuiyu.github.io/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies/</id>
    <published>2024-10-23T08:26:29.000Z</published>
    <updated>2026-02-20T21:56:22.872Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Introduction-to-LLM-Training-Terminology-LoRA-DPO-KTO-and-SFT-Technologies"><a href="#Introduction-to-LLM-Training-Terminology-LoRA-DPO-KTO-and-SFT-Technologies" class="headerlink" title="Introduction to LLM Training Terminology:LoRA, DPO, KTO, and SFT Technologies"></a><strong>Introduction to LLM Training Terminology:LoRA, DPO, KTO, and SFT Technologies</strong></h3><p>This document provides a detailed introduction to several important techniques used in fine-tuning and optimizing large language models (such as LLAMA3), including <strong>SFT (Supervised Fine-Tuning)</strong>, <strong>LoRA (Low-Rank Adaptation)</strong>, <strong>Alignment</strong> technologies, <strong>KTO (Kahneman-Tversky Optimization)</strong>, and <strong>DPO (Direct Preference Optimization)</strong>. The document also elaborates on the principles of each technique, specific implementation methods, as well as the selection of corresponding loss functions and optimizers.</p><hr><h2 id="1-SFT-Supervised-Fine-Tuning"><a href="#1-SFT-Supervised-Fine-Tuning" class="headerlink" title="1. SFT (Supervised Fine-Tuning)"></a>1. <strong>SFT (Supervised Fine-Tuning)</strong></h2><h3 id="1-1-Principle"><a href="#1-1-Principle" class="headerlink" title="1.1 Principle"></a>1.1 <strong>Principle</strong></h3><p>SFT is a traditional fine-tuning method that adjusts the parameters of a pre-trained model through supervised learning to improve its performance on specific tasks. SFT is typically used to fine-tune models on specific labeled datasets, with the training process resembling standard supervised learning.</p><h3 id="1-2-Implementation-Method"><a href="#1-2-Implementation-Method" class="headerlink" title="1.2 Implementation Method"></a>1.2 <strong>Implementation Method</strong></h3><ul><li><strong>Select a Pre-trained Model</strong>: Such as GPT, BERT, and other language models.</li><li><strong>Prepare a Labeled Dataset</strong>: The dataset includes input-output pairs.</li><li><strong>Train the Model</strong>: Use a standard cross-entropy loss function to train the model, optimizing parameters through gradient descent.</li></ul><h3 id="1-3-Core-Code"><a href="#1-3-Core-Code" class="headerlink" title="1.3 Core Code"></a>1.3 <strong>Core Code</strong></h3><p>Using Hugging Faceâ€™s <code>Trainer</code> interface for SFT:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments, AutoModelForSeq2SeqLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">"gpt2"</span></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">train_dataset = load_dataset(<span class="string">"my_dataset"</span>, split=<span class="string">"train"</span>)</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">"./results"</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">"epoch"</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=train_dataset,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="2-LoRA-Low-Rank-Adaptation"><a href="#2-LoRA-Low-Rank-Adaptation" class="headerlink" title="2. LoRA (Low-Rank Adaptation)"></a>2. <strong>LoRA (Low-Rank Adaptation)</strong></h2><h3 id="2-1-Principle"><a href="#2-1-Principle" class="headerlink" title="2.1 Principle"></a>2.1 <strong>Principle</strong></h3><p>LoRA is a parameter-efficient fine-tuning technique that performs low-rank decomposition of the weight matrices in large models. It decomposes the original weight matrix $W$ into two low-rank matrices $B$ and $A$, and only fine-tunes these low-rank matrices. The design goal of LoRA is to reduce the number of fine-tuning parameters while retaining the pre-trained model weights, optimizing model performance by adjusting the low-rank matrices.</p><h3 id="2-2-Implementation-Method"><a href="#2-2-Implementation-Method" class="headerlink" title="2.2 Implementation Method"></a>2.2 <strong>Implementation Method</strong></h3><ul><li><strong>Weight Decomposition</strong>: For the modelâ€™s linear layers (such as the <code>q_proj</code> and <code>v_proj</code> layers in the attention mechanism), decompose the weight matrix into two low-rank matrices $B$ and $A$.</li><li><strong>Fine-Tune Specific Layers</strong>: Apply LoRA only to these specific linear layers, keeping other layers in the model unchanged.</li></ul><h3 id="2-3-Layers-to-Fine-Tune-vs-Layers-to-Keep-Unchanged"><a href="#2-3-Layers-to-Fine-Tune-vs-Layers-to-Keep-Unchanged" class="headerlink" title="2.3 Layers to Fine-Tune vs. Layers to Keep Unchanged"></a>2.3 <strong>Layers to Fine-Tune vs. Layers to Keep Unchanged</strong></h3><h4 id="Layers-to-Fine-Tune"><a href="#Layers-to-Fine-Tune" class="headerlink" title="Layers to Fine-Tune"></a><strong>Layers to Fine-Tune</strong></h4><p>LoRA is typically applied to the linear projection layers in Transformer models, especially several key layers in the multi-head attention mechanism:</p><ul><li><strong>q_proj</strong> (Query Projection Layer)</li><li><strong>k_proj</strong> (Key Projection Layer)</li><li><strong>v_proj</strong> (Value Projection Layer)</li><li><strong>o_proj</strong> (Output Projection Layer)</li><li><strong>ffn_up_proj</strong> and <strong>ffn_down_proj</strong> (Up and Down Projection Layers of the Feedforward Neural Network)</li></ul><h4 id="Layers-to-Keep-Unchanged"><a href="#Layers-to-Keep-Unchanged" class="headerlink" title="Layers to Keep Unchanged"></a><strong>Layers to Keep Unchanged</strong></h4><ul><li><strong>Embedding Layers</strong>: Responsible for encoding inputs and outputs, usually do not require fine-tuning.</li><li><strong>LayerNorm Layers</strong>: These layers are mainly used for normalization, do not contain many parameters, and are typically kept unchanged.</li><li><strong>Activation Function Layers</strong>: Non-linear activation functions like ReLU or GELU do not involve parameters and do not require fine-tuning.</li></ul><h3 id="2-4-Loss-Function"><a href="#2-4-Loss-Function" class="headerlink" title="2.4 Loss Function"></a>2.4 <strong>Loss Function</strong></h3><p>The loss function for LoRA is usually task-specific. In language generation tasks, LoRA uses <strong>cross-entropy loss</strong> to measure the difference between the generated text and the target text:</p><p>$$<br>\mathcal{L}<em>{\text{LoRA}} = - \sum</em>{i} y_i \log(\hat{y}_i)<br>$$</p><p>where $y_i$ is the true label, and $\hat{y}_i$ is the modelâ€™s output probability.</p><h3 id="2-5-Optimizer"><a href="#2-5-Optimizer" class="headerlink" title="2.5 Optimizer"></a>2.5 <strong>Optimizer</strong></h3><p>LoRA fine-tuning typically uses the <strong>AdamW</strong> optimizer, as shown in the following code:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.AdamW(lora_model.parameters(), lr=<span class="number">5e-5</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="2-6-Core-Code"><a href="#2-6-Core-Code" class="headerlink" title="2.6 Core Code"></a>2.6 <strong>Core Code</strong></h3><p>Implementing LoRA using the <code>peft</code> library:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, get_peft_model</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">"gpt2"</span></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    r=<span class="number">8</span>,                </span><br><span class="line">    lora_alpha=<span class="number">32</span>,      </span><br><span class="line">    target_modules=[<span class="string">"q_proj"</span>, <span class="string">"v_proj"</span>],  </span><br><span class="line">    lora_dropout=<span class="number">0.1</span>,   </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">lora_model = get_peft_model(model, lora_config)</span><br><span class="line">lora_model.train()</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="3-Alignment-Alignment-Techniques"><a href="#3-Alignment-Alignment-Techniques" class="headerlink" title="3. Alignment (Alignment Techniques)"></a>3. <strong>Alignment (Alignment Techniques)</strong></h2><p>Before introducing KL divergence, we first need to clarify how LLM alignment is achieved, along with the underlying principles and mathematical formulas.</p><h3 id="1-What-is-Model-Alignment"><a href="#1-What-is-Model-Alignment" class="headerlink" title="1. What is Model Alignment?"></a><strong>1. What is Model Alignment?</strong></h3><p>The core objective of model alignment is to ensure that the language modelâ€™s outputs meet human expectations or preferences. Typically, the model is initially trained through large-scale supervised learning (SFT, Supervised Fine-Tuning) to generate a model with basic capabilities. Subsequently, through alignment techniques, the model is further adjusted to ensure that its generated content better aligns with human preferences or avoids producing harmful or erroneous information.</p><p><strong>Core Mechanism of Alignment</strong>:</p><ul><li><strong>Positive Samples</strong>: Outputs that meet human expectations (e.g., correct answers).</li><li><strong>Negative Samples</strong>: Outputs that do not meet human expectations (e.g., incorrect answers).</li></ul><p>By using paired preference data or labels (correct/incorrect), the modelâ€™s outputs are further fine-tuned to generate more positive samples while reducing the probability of generating negative samples.</p><hr><h3 id="2-Mathematical-Principles-of-Model-Alignment"><a href="#2-Mathematical-Principles-of-Model-Alignment" class="headerlink" title="2. Mathematical Principles of Model Alignment"></a><strong>2. Mathematical Principles of Model Alignment</strong></h3><p>During the alignment process, the model generates outputs through a <strong>policy model</strong>, which is typically an SFT-trained language model used to generate outputs given an input. To optimize the modelâ€™s outputs to better align with human preferences, the following loss functions and optimization methods are commonly used:</p><h4 id="2-1-Policy-Model"><a href="#2-1-Policy-Model" class="headerlink" title="2.1 Policy Model"></a><strong>2.1 Policy Model</strong></h4><p>Assume the current policy of the model is $\pi_\theta$, which represents the probability of the model generating output $y$ given input $x$:</p><p>$$<br>\pi_\theta(y|x)<br>$$</p><p>The objective of the policy model is to adjust the parameters $\theta$ to increase the probability of generating correct outputs (positive samples) and decrease the probability of generating incorrect outputs (negative samples).</p><h4 id="2-2-Mechanism-for-Increasing-Positive-Sample-Probability-and-Decreasing-Negative-Sample-Probability"><a href="#2-2-Mechanism-for-Increasing-Positive-Sample-Probability-and-Decreasing-Negative-Sample-Probability" class="headerlink" title="2.2 Mechanism for Increasing Positive Sample Probability and Decreasing Negative Sample Probability"></a><strong>2.2 Mechanism for Increasing Positive Sample Probability and Decreasing Negative Sample Probability</strong></h4><p>To achieve this goal, loss functions with preference comparisons or labels are typically used for optimization:</p><ol><li><p><strong>Optimization of Positive Samples</strong>: By increasing the loss weight of positive samples, the model is guided to generate positive samples with higher probability when faced with the same problem.</p><ul><li>The loss function for positive samples guides the model to produce more outputs that meet human expectations.</li></ul></li><li><p><strong>Penalty for Negative Samples</strong>: By applying higher loss weights to negative samples, the model learns to reduce the probability of generating these incorrect outputs.</p><ul><li>The loss function for negative samples aims to penalize the model more when it generates incorrect answers, thereby reducing the likelihood of such outputs.</li></ul></li></ol><p>In some methods, such as DPO and KTO, <strong>KL divergence</strong> between the current policy model and a reference model is calculated to prevent the model from deviating excessively from the original pre-trained model during optimization.</p><hr><h3 id="3-Role-of-Loss-Functions-and-KL-Divergence"><a href="#3-Role-of-Loss-Functions-and-KL-Divergence" class="headerlink" title="3. Role of Loss Functions and KL Divergence"></a><strong>3. Role of Loss Functions and KL Divergence</strong></h3><p>In the model alignment process, the loss function typically consists of two parts:</p><ol><li><strong>Preference Loss</strong> or <strong>Label Loss</strong>, used to optimize the model to generate outputs that meet human expectations.</li><li><strong>KL Divergence</strong>, used to constrain the model from deviating from the reference model.</li></ol><h4 id="3-1-Role-of-KL-Divergence"><a href="#3-1-Role-of-KL-Divergence" class="headerlink" title="3.1 Role of KL Divergence"></a><strong>3.1 Role of KL Divergence</strong></h4><p>KL divergence (Kullback-Leibler Divergence) measures the difference between two probability distributions. In model alignment, KL divergence is used to limit the distribution difference between the current model $\pi_\theta$ and the reference model $\pi_{\text{ref}}$, ensuring that the modelâ€™s outputs do not deviate excessively from the pre-trained model during optimization. The specific formula is:</p><p>$$<br>\text{KL}(\pi_\theta(y|x) | \pi_{\text{ref}}(y|x)) = \sum_y \pi_\theta(y|x) \log \frac{\pi_\theta(y|x)}{\pi_{\text{ref}}(y|x)}<br>$$</p><ul><li>If the KL divergence is large, it indicates that the current modelâ€™s generated distribution significantly differs from the reference model, which may mean the model is producing unreasonable outputs.</li><li>By minimizing KL divergence, the model can be further optimized while ensuring the reasonableness of its outputs.</li></ul><h4 id="3-2-Loss-Function-Formulas"><a href="#3-2-Loss-Function-Formulas" class="headerlink" title="3.2 Loss Function Formulas"></a><strong>3.2 Loss Function Formulas</strong></h4><p>Based on preferences or labels, the modelâ€™s loss function can be expressed in the following forms:</p><h5 id="Loss-Function-in-DPO"><a href="#Loss-Function-in-DPO" class="headerlink" title="Loss Function in DPO:"></a><strong>Loss Function in DPO</strong>:</h5><p>$$<br>L_{DPO} = -\mathbb{E}_{x, y_w, y_l \sim D} [\log \sigma(\beta (\log(\pi_\theta(y_w|x)) - \log(\pi_\theta(y_l|x))))]<br>$$</p><ul><li>$y_w$: Higher-preference answer.</li><li>$y_l$: Lower-preference answer.</li></ul><p>In DPO, KL divergence can be introduced as a regularization term:<br>$$<br>L_{DPO} = -\log \sigma(\log(\pi_\theta(y_w|x)) - \log(\pi_\theta(y_l|x)) + \beta \cdot \text{KL}(\pi_\theta | \pi_{\text{ref}}))<br>$$<br>By controlling KL divergence, the modelâ€™s outputs do not deviate too much from the reference model.</p><h5 id="Loss-Function-in-KTO"><a href="#Loss-Function-in-KTO" class="headerlink" title="Loss Function in KTO:"></a><strong>Loss Function in KTO</strong>:</h5><p>The loss function in KTO is based on prospect theory and incorporates KL divergence as a core component:<br>$$<br>L_{KTO} = \lambda_U \cdot \sigma(\beta \cdot (\text{KL}(\pi_\theta(\text{Answer 2}) | \pi_{\text{ref}}) - r_{\theta}(\text{Answer 2})))<br>$$</p><ul><li>$r_{\theta}(x, y)$: The current policyâ€™s confidence in negative samples (incorrect answers).</li><li>KL divergence is used to measure the difference between the current model and the reference model, ensuring that while reducing the generation of negative samples, the model does not deviate from the original reference model.</li></ul><p>By increasing the loss for negative samples (i.e., increasing the value of $\lambda_U$), the model reduces the confidence in negative samples, thereby decreasing the probability of generating similar incorrect answers in the future.</p><hr><h3 id="4-How-to-Optimize-the-Model"><a href="#4-How-to-Optimize-the-Model" class="headerlink" title="4. How to Optimize the Model"></a><strong>4. How to Optimize the Model</strong></h3><p>Through the loss functions introduced above, model optimization is typically performed using <strong>Gradient Descent</strong>. The gradients of the loss function reflect the differences between the modelâ€™s outputs and the expected outputs, and the optimization goal is to minimize the loss function.</p><p><strong>Gradient Update Formula</strong>:<br>$$<br>\theta_{\text{new}} = \theta_{\text{old}} - \eta \nabla_{\theta} L<br>$$<br>where:</p><ul><li>$\eta$ is the learning rate, determining the step size of each parameter update.</li><li>$\nabla_{\theta} L$ is the gradient of the loss function with respect to the model parameters, indicating the contribution of the current parameters to the loss.</li></ul><p>Through continuous iteration, the model gradually increases the probability of generating positive samples and decreases the probability of generating negative samples, ultimately achieving model alignment.</p><ul><li>The core objective of <strong>Model Alignment</strong> is to optimize the modelâ€™s outputs to meet human expectations through preference or label data.</li><li>The <strong>Policy Model</strong> ($\pi_\theta$) generates outputs, and KL divergence is used to control the degree of deviation from the reference model, preventing unreasonable biases during optimization.</li><li>The <strong>Probability of Positive Samples</strong> is gradually increased through the optimization of the loss function, while the <strong>Probability of Negative Samples</strong> is reduced by increasing loss weights and lowering confidence.</li><li>Gradient descent is used to update model parameters, ultimately achieving model alignment.</li></ul><hr><h2 id="4-DPO-Direct-Preference-Optimization"><a href="#4-DPO-Direct-Preference-Optimization" class="headerlink" title="4. DPO (Direct Preference Optimization)"></a>4. <strong>DPO (Direct Preference Optimization)</strong></h2><h3 id="4-1-Principle"><a href="#4-1-Principle" class="headerlink" title="4.1 Principle"></a>4.1 <strong>Principle</strong></h3><p>DPO directly optimizes the modelâ€™s output preference function to make the modelâ€™s outputs more aligned with human preferences. It compares different outputs generated by the model and uses a preference function to evaluate which of the two outputs is better, thereby guiding the optimization of the model parameters.</p><h3 id="4-2-Loss-Function"><a href="#4-2-Loss-Function" class="headerlink" title="4.2 Loss Function"></a>4.2 <strong>Loss Function</strong></h3><p>DPO uses a preference loss function to compare the quality of two outputs:</p><p>$$<br>\mathcal{L}_{\text{DPO}} = \log(1 + \exp(-\sigma \cdot (\hat{y}_a - \hat{y}_b) \cdot p))<br>$$</p><ul><li>$ \hat{y}_a $ and $ \hat{y}_b $ are the modelâ€™s predictions for two samples.</li><li>$ p $ is the human preference (1 indicates preference for $a$, -1 indicates preference for $b$).</li><li>$ \sigma $ is a smoothing parameter.</li></ul><h3 id="4-3-Optimizer"><a href="#4-3-Optimizer" class="headerlink" title="4.3 Optimizer"></a>4.3 <strong>Optimizer</strong></h3><p>DPO typically uses the <strong>AdamW</strong> optimizer, which is suitable for optimizing large-scale parameter models. The code is as follows:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="number">1e-5</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="4-4-Core-Code"><a href="#4-4-Core-Code" class="headerlink" title="4.4 Core Code"></a>4.4 <strong>Core Code</strong></h3><p>The following are the training steps for DPO:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preference_loss</span>(<span class="params">output_a, output_b, human_preference</span>):</span><br><span class="line">    preference = human_preference(output_a, output_b)</span><br><span class="line">    loss = torch.log(<span class="number">1</span> + torch.exp(-preference * (output_a - output_b)))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dpo_training_step</span>(<span class="params">model, data_a, data_b, human_preference</span>):</span><br><span class="line">    output_a = model(data_a)</span><br><span class="line">    output_b = model(data_b)</span><br><span class="line">    </span><br><span class="line">    loss = preference_loss(output_a, output_b, human_preference)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_a, batch_b <span class="keyword">in</span> training_data:</span><br><span class="line">    dpo_training_step(model, batch_a, batch_b, human_preference_function)</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="5-KTO-Kahneman-Tversky-Optimization"><a href="#5-KTO-Kahneman-Tversky-Optimization" class="headerlink" title="5. KTO (Kahneman-Tversky Optimization)"></a>5. <strong>KTO (Kahneman-Tversky Optimization)</strong></h2><h3 id="5-1-Principle"><a href="#5-1-Principle" class="headerlink" title="5.1 Principle"></a>5.1 <strong>Principle</strong></h3><p>KTO is based on Kahneman and Tverskyâ€™s Prospect Theory, which uses an asymmetric utility function to measure the modelâ€™s gains and losses. It aims to optimize the modelâ€™s performance, especially in scenarios with asymmetric risks and rewards. The utility function is defined as follows:</p><p>$$<br>\mathcal{U}(x) =<br>\begin{cases}<br>x^{\alpha}, &amp; x \geq 0 \<br>-\lambda (-x)^{\alpha}, &amp; x &lt; 0<br>\end{cases}<br>$$</p><ul><li>$x$ is the difference between the modelâ€™s prediction and the true value.</li><li>$\alpha$ is the non-linear coefficient, typically 0.88.</li><li>$\lambda$ is the loss penalty weight, typically 2.25.</li></ul><h3 id="5-2-Loss-Function"><a href="#5-2-Loss-Function" class="headerlink" title="5.2 Loss Function"></a>5.2 <strong>Loss Function</strong></h3><p>The loss function for KTO is based on the utility function from Prospect Theory and is used to penalize the modelâ€™s prediction errors:</p><p>$$<br>\mathcal{L}<em>{\text{KTO}} = -\mathbb{E}[\mathcal{U}(y</em>{\text{pred}} - y_{\text{true}})]<br>$$</p><h3 id="5-3-Optimizer"><a href="#5-3-Optimizer" class="headerlink" title="5.3 Optimizer"></a>5.3 <strong>Optimizer</strong></h3><p>KTO commonly uses the <strong>AdamW</strong> optimizer to ensure stability during the training process:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="number">3e-5</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="5-4-Core-Code"><a href="#5-4-Core-Code" class="headerlink" title="5.4 Core Code"></a>5.4 <strong>Core Code</strong></h3><p>The following is the code for calculating the KTO loss function:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prospect_utility</span>(<span class="params">value, alpha=<span class="number">0.88</span>, lambda_=<span class="number">2.25</span></span>):</span><br><span class="line">    <span class="keyword">if</span> value &gt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">pow</span>(value, alpha)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> -lambda_ * torch.<span class="built_in">pow</span>(-value, alpha)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kto_loss</span>(<span class="params">predictions, targets</span>):</span><br><span class="line">    value = predictions - targets</span><br><span class="line">    utility = prospect_utility(value)</span><br><span class="line">    loss = -torch.mean(utility)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    predictions = model(data)</span><br><span class="line">    loss = kto_loss(predictions, targets)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></tbody></table></figure><hr><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><strong>Summary</strong></h3><table><thead><tr><th>Method</th><th>Loss Function</th><th>Optimizer</th></tr></thead><tbody><tr><td><strong>SFT</strong></td><td>Cross-Entropy Loss</td><td>AdamW, RMSprop, SGD</td></tr><tr><td><strong>LoRA</strong></td><td>Cross-Entropy Loss</td><td>AdamW, RMSprop, SGD</td></tr><tr><td><strong>DPO</strong></td><td>Preference Loss Function: $\log(1 + \exp(-\sigma (\hat{y}_a - \hat{y}_b)p))$</td><td>AdamW</td></tr><tr><td><strong>KTO</strong></td><td>Prospect Theory Utility Function: $-\mathbb{E}[\mathcal{U}(y_{\text{pred}} - y_{\text{true}})]$</td><td>AdamW</td></tr></tbody></table><p>Through the organization of this document, readers can clearly understand the principles, specific implementation steps, loss function designs, and optimizer selections for technologies such as SFT, LoRA, DPO, and KTO, especially in the context of fine-tuning large-scale pre-trained models like LLAMA3.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Introduction-to-LLM-Training-Terminology-LoRA-DPO-KTO-and-SFT-Technologies&quot;&gt;&lt;a href=&quot;#Introduction-to-LLM-Training-Terminology-LoRA-</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="LLM" scheme="https://chenhuiyu.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>LoRA, DPO, KTO ä¸ SFT æŠ€æœ¯è¯¦è§£</title>
    <link href="https://chenhuiyu.github.io/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO/"/>
    <id>https://chenhuiyu.github.io/2024/10/23/NLP%20Insights/LLM%E8%AE%AD%E7%BB%83%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D%EF%BC%9ASFT%E3%80%81LoRA%E3%80%81Alignment%E3%80%81KTO%E5%92%8CDPO/</id>
    <published>2024-10-23T08:26:29.000Z</published>
    <updated>2026-02-20T21:56:22.873Z</updated>
    
    <content type="html"><![CDATA[<h3 id="LoRA-DPO-KTO-ä¸-SFT-æŠ€æœ¯è¯¦è§£"><a href="#LoRA-DPO-KTO-ä¸-SFT-æŠ€æœ¯è¯¦è§£" class="headerlink" title="LoRA, DPO, KTO ä¸ SFT æŠ€æœ¯è¯¦è§£"></a><strong>LoRA, DPO, KTO ä¸ SFT æŠ€æœ¯è¯¦è§£</strong></h3><p>æœ¬ç¯‡æ–‡æ¡£å°†è¯¦ç»†ä»‹ç»å‡ ç§åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ LLAMA3ï¼‰å¾®è°ƒå’Œä¼˜åŒ–ä¸­çš„é‡è¦æŠ€æœ¯ï¼ŒåŒ…æ‹¬ <strong>SFTï¼ˆSupervised Fine-Tuningï¼‰</strong>ã€<strong>LoRAï¼ˆLow-Rank Adaptationï¼‰</strong>ã€<strong>Alignment</strong> æŠ€æœ¯ã€<strong>KTOï¼ˆKahneman-Tversky Optimizationï¼‰</strong> å’Œ <strong>DPOï¼ˆDirect Preference Optimizationï¼‰</strong>ã€‚æ–‡ä¸­è¿˜å°†è¯¦ç»†é˜è¿°æ¯ç§æŠ€æœ¯çš„åŸç†ã€å…·ä½“å®ç°æ–¹æ³•ä»¥åŠç›¸åº”çš„æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨é€‰æ‹©ã€‚</p><hr><h2 id="1-SFTï¼ˆSupervised-Fine-Tuningï¼‰"><a href="#1-SFTï¼ˆSupervised-Fine-Tuningï¼‰" class="headerlink" title="1. SFTï¼ˆSupervised Fine-Tuningï¼‰"></a>1. <strong>SFTï¼ˆSupervised Fine-Tuningï¼‰</strong></h2><h3 id="1-1-åŸç†"><a href="#1-1-åŸç†" class="headerlink" title="1.1 åŸç†"></a>1.1 <strong>åŸç†</strong></h3><p>SFT æ˜¯ä¸€ç§ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡ç›‘ç£å­¦ä¹ å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè°ƒæ•´æ¨¡å‹çš„å‚æ•°ä½¿å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ã€‚SFT é€šå¸¸ç”¨äºé’ˆå¯¹ç‰¹å®šçš„æ ‡æ³¨æ•°æ®è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼Œè®­ç»ƒçš„è¿‡ç¨‹ç±»ä¼¼äºå¸¸è§„çš„ç›‘ç£å­¦ä¹ ã€‚</p><h3 id="1-2-å®ç°æ–¹æ³•"><a href="#1-2-å®ç°æ–¹æ³•" class="headerlink" title="1.2 å®ç°æ–¹æ³•"></a>1.2 <strong>å®ç°æ–¹æ³•</strong></h3><ul><li><strong>é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹</strong>ï¼šå¦‚ GPTã€BERT ç­‰è¯­è¨€æ¨¡å‹ã€‚</li><li><strong>å‡†å¤‡æ ‡æ³¨æ•°æ®é›†</strong>ï¼šæ•°æ®é›†åŒ…å«è¾“å…¥å’Œè¾“å‡ºå¯¹ã€‚</li><li><strong>è®­ç»ƒæ¨¡å‹</strong>ï¼šä½¿ç”¨æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±å‡½æ•°å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å‚æ•°ã€‚</li></ul><h3 id="1-3-æ ¸å¿ƒä»£ç "><a href="#1-3-æ ¸å¿ƒä»£ç " class="headerlink" title="1.3 æ ¸å¿ƒä»£ç "></a>1.3 <strong>æ ¸å¿ƒä»£ç </strong></h3><p>ä½¿ç”¨ Hugging Face çš„ <code>Trainer</code> æ¥å£è¿›è¡Œ SFTï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments, AutoModelForSeq2SeqLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">"gpt2"</span></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">train_dataset = load_dataset(<span class="string">"my_dataset"</span>, split=<span class="string">"train"</span>)</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">"./results"</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">"epoch"</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=train_dataset,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="2-LoRAï¼ˆLow-Rank-Adaptationï¼‰"><a href="#2-LoRAï¼ˆLow-Rank-Adaptationï¼‰" class="headerlink" title="2. LoRAï¼ˆLow-Rank Adaptationï¼‰"></a>2. <strong>LoRAï¼ˆLow-Rank Adaptationï¼‰</strong></h2><h3 id="2-1-åŸç†"><a href="#2-1-åŸç†" class="headerlink" title="2.1 åŸç†"></a>2.1 <strong>åŸç†</strong></h3><p>LoRA æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæŠ€æœ¯ï¼Œé€šè¿‡å¯¹å¤§æ¨¡å‹ä¸­çš„æƒé‡çŸ©é˜µè¿›è¡Œä½ç§©åˆ†è§£ï¼Œå°†åŸå§‹æƒé‡çŸ©é˜µ $W$ åˆ†è§£ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µ $B$ å’Œ $A$ï¼Œå¹¶ä»…å¯¹è¿™äº›ä½ç§©çŸ©é˜µè¿›è¡Œå¾®è°ƒã€‚LoRA çš„è®¾è®¡ç›®æ ‡æ˜¯å‡å°‘å¾®è°ƒå‚æ•°çš„æ•°é‡ï¼Œåœ¨ä¿ç•™é¢„è®­ç»ƒæ¨¡å‹æƒé‡çš„åŒæ—¶ï¼Œé€šè¿‡è°ƒæ•´ä½ç§©çŸ©é˜µæ¥ä¼˜åŒ–æ¨¡å‹è¡¨ç°ã€‚</p><h3 id="2-2-å®ç°æ–¹æ³•"><a href="#2-2-å®ç°æ–¹æ³•" class="headerlink" title="2.2 å®ç°æ–¹æ³•"></a>2.2 <strong>å®ç°æ–¹æ³•</strong></h3><ul><li><strong>æƒé‡åˆ†è§£</strong>ï¼šå¯¹äºæ¨¡å‹çš„çº¿æ€§å±‚ï¼ˆå¦‚æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ <code>q_proj</code> å’Œ <code>v_proj</code> å±‚ï¼‰ï¼Œå°†æƒé‡çŸ©é˜µåˆ†è§£ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µ $B$ å’Œ $A$ã€‚</li><li><strong>å¾®è°ƒç‰¹å®šå±‚</strong>ï¼šä»…å¯¹è¿™äº›ç‰¹å®šçš„çº¿æ€§å±‚åº”ç”¨ LoRAï¼Œè€Œæ¨¡å‹ä¸­çš„å…¶ä»–å±‚ä¿æŒä¸å˜ã€‚</li></ul><h3 id="2-3-å¯å¾®è°ƒçš„å±‚ä¸ä¸å˜çš„å±‚"><a href="#2-3-å¯å¾®è°ƒçš„å±‚ä¸ä¸å˜çš„å±‚" class="headerlink" title="2.3 å¯å¾®è°ƒçš„å±‚ä¸ä¸å˜çš„å±‚"></a>2.3 <strong>å¯å¾®è°ƒçš„å±‚ä¸ä¸å˜çš„å±‚</strong></h3><h4 id="å¯å¾®è°ƒçš„å±‚"><a href="#å¯å¾®è°ƒçš„å±‚" class="headerlink" title="å¯å¾®è°ƒçš„å±‚"></a><strong>å¯å¾®è°ƒçš„å±‚</strong></h4><p>LoRA é€šå¸¸åº”ç”¨äº Transformer æ¨¡å‹ä¸­çš„çº¿æ€§æŠ•å½±å±‚ï¼Œå°¤å…¶æ˜¯å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„å‡ ä¸ªå…³é”®å±‚ï¼š</p><ul><li><strong>q_proj</strong>ï¼ˆQuery æŠ•å½±å±‚ï¼‰</li><li><strong>k_proj</strong>ï¼ˆKey æŠ•å½±å±‚ï¼‰</li><li><strong>v_proj</strong>ï¼ˆValue æŠ•å½±å±‚ï¼‰</li><li><strong>o_proj</strong>ï¼ˆOutput æŠ•å½±å±‚ï¼‰</li><li><strong>ffn_up_proj</strong> å’Œ <strong>ffn_down_proj</strong>ï¼ˆå‰é¦ˆç¥ç»ç½‘ç»œçš„ä¸Šä¸‹æŠ•å½±å±‚ï¼‰</li></ul><h4 id="ä¸å˜çš„å±‚"><a href="#ä¸å˜çš„å±‚" class="headerlink" title="ä¸å˜çš„å±‚"></a><strong>ä¸å˜çš„å±‚</strong></h4><ul><li><strong>Embedding å±‚</strong>ï¼šè´Ÿè´£è¾“å…¥å’Œè¾“å‡ºçš„ç¼–ç ï¼Œé€šå¸¸ä¸éœ€è¦å¾®è°ƒã€‚</li><li><strong>LayerNorm å±‚</strong>ï¼šè¿™äº›å±‚ä¸»è¦ç”¨äºå½’ä¸€åŒ–ï¼Œä¸å«å¤§é‡å‚æ•°ï¼Œé€šå¸¸ä¿æŒä¸å˜ã€‚</li><li><strong>æ¿€æ´»å‡½æ•°å±‚</strong>ï¼šå¦‚ ReLU æˆ– GELU ç­‰éçº¿æ€§æ¿€æ´»å‡½æ•°ä¸æ¶‰åŠå‚æ•°ï¼Œä¸éœ€è¦è¿›è¡Œå¾®è°ƒã€‚</li></ul><h3 id="2-4-æŸå¤±å‡½æ•°"><a href="#2-4-æŸå¤±å‡½æ•°" class="headerlink" title="2.4 æŸå¤±å‡½æ•°"></a>2.4 <strong>æŸå¤±å‡½æ•°</strong></h3><p>LoRA çš„æŸå¤±å‡½æ•°é€šå¸¸ä¸å…·ä½“ä»»åŠ¡ç›¸å…³ã€‚åœ¨è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒLoRA ä½¿ç”¨<strong>äº¤å‰ç†µæŸå¤±</strong>æ¥åº¦é‡ç”Ÿæˆæ–‡æœ¬å’Œç›®æ ‡æ–‡æœ¬ä¹‹é—´çš„å·®å¼‚ï¼š</p><p>$$<br>\mathcal{L}<em>{\text{LoRA}} = - \sum</em>{i} y_i \log(\hat{y}_i)<br>$$</p><p>å…¶ä¸­ $y_i$ æ˜¯çœŸå®æ ‡ç­¾ï¼Œ$\hat{y}_i$ æ˜¯æ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡ã€‚</p><h3 id="2-5-ä¼˜åŒ–å™¨"><a href="#2-5-ä¼˜åŒ–å™¨" class="headerlink" title="2.5 ä¼˜åŒ–å™¨"></a>2.5 <strong>ä¼˜åŒ–å™¨</strong></h3><p>LoRA å¾®è°ƒé€šå¸¸ä½¿ç”¨ <strong>AdamW</strong> ä¼˜åŒ–å™¨ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.AdamW(lora_model.parameters(), lr=<span class="number">5e-5</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="2-6-æ ¸å¿ƒä»£ç "><a href="#2-6-æ ¸å¿ƒä»£ç " class="headerlink" title="2.6 æ ¸å¿ƒä»£ç "></a>2.6 <strong>æ ¸å¿ƒä»£ç </strong></h3><p>ä½¿ç”¨ <code>peft</code> åº“å®ç° LoRAï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, get_peft_model</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">"gpt2"</span></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    r=<span class="number">8</span>,                </span><br><span class="line">    lora_alpha=<span class="number">32</span>,      </span><br><span class="line">    target_modules=[<span class="string">"q_proj"</span>, <span class="string">"v_proj"</span>],  </span><br><span class="line">    lora_dropout=<span class="number">0.1</span>,   </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">lora_model = get_peft_model(model, lora_config)</span><br><span class="line">lora_model.train()</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="3-Alignmentï¼ˆå¯¹é½æŠ€æœ¯ï¼‰"><a href="#3-Alignmentï¼ˆå¯¹é½æŠ€æœ¯ï¼‰" class="headerlink" title="3. Alignmentï¼ˆå¯¹é½æŠ€æœ¯ï¼‰"></a>3. <strong>Alignmentï¼ˆå¯¹é½æŠ€æœ¯ï¼‰</strong></h2><p>åœ¨å¼•å…¥KLæ•£åº¦ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ˜ç¡®LLMå¯¹é½ï¼ˆAlignmentï¼‰æ˜¯å¦‚ä½•å®ç°çš„ï¼Œä»¥åŠèƒŒåçš„åŸç†å’Œæ•°å­¦å…¬å¼ã€‚</p><h3 id="1-ä»€ä¹ˆæ˜¯æ¨¡å‹å¯¹é½ï¼ˆAlignmentï¼‰ï¼Ÿ"><a href="#1-ä»€ä¹ˆæ˜¯æ¨¡å‹å¯¹é½ï¼ˆAlignmentï¼‰ï¼Ÿ" class="headerlink" title="1. ä»€ä¹ˆæ˜¯æ¨¡å‹å¯¹é½ï¼ˆAlignmentï¼‰ï¼Ÿ"></a><strong>1. ä»€ä¹ˆæ˜¯æ¨¡å‹å¯¹é½ï¼ˆAlignmentï¼‰ï¼Ÿ</strong></h3><p>æ¨¡å‹å¯¹é½çš„æ ¸å¿ƒç›®æ ‡æ˜¯è®©è¯­è¨€æ¨¡å‹çš„è¾“å‡ºç¬¦åˆäººç±»çš„æœŸæœ›æˆ–åå¥½ã€‚é€šå¸¸ï¼Œæ¨¡å‹æœ€åˆé€šè¿‡å¤§è§„æ¨¡ç›‘ç£å­¦ä¹ ï¼ˆSFTï¼ŒSupervised Fine-Tuningï¼‰è®­ç»ƒï¼Œç”Ÿæˆå…·æœ‰åŸºç¡€èƒ½åŠ›çš„æ¨¡å‹ã€‚æ¥ä¸‹æ¥ï¼Œé€šè¿‡å¯¹é½æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥è°ƒæ•´æ¨¡å‹ï¼Œä½¿å…¶ç”Ÿæˆçš„å†…å®¹æ›´ç¬¦åˆäººç±»åå¥½æˆ–é¿å…äº§ç”Ÿæœ‰å®³ã€é”™è¯¯çš„ä¿¡æ¯ã€‚</p><p><strong>å¯¹é½çš„æ ¸å¿ƒæœºåˆ¶</strong>ï¼š</p><ul><li><strong>æ­£æ ·æœ¬</strong>ï¼šç¬¦åˆäººç±»é¢„æœŸçš„è¾“å‡ºï¼ˆå¦‚æ­£ç¡®å›ç­”ï¼‰ã€‚</li><li><strong>è´Ÿæ ·æœ¬</strong>ï¼šä¸ç¬¦åˆäººç±»é¢„æœŸçš„è¾“å‡ºï¼ˆå¦‚é”™è¯¯å›ç­”ï¼‰ã€‚</li></ul><p>é€šè¿‡ä½¿ç”¨æˆå¯¹åå¥½æ•°æ®æˆ–æ ‡ç­¾ï¼ˆæ­£ç¡®/é”™è¯¯ï¼‰ï¼Œå¯¹æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œè¿›ä¸€æ­¥å¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´å¤šçš„æ­£æ ·æœ¬ï¼ŒåŒæ—¶å‡å°‘è´Ÿæ ·æœ¬çš„ç”Ÿæˆæ¦‚ç‡ã€‚</p><hr><h3 id="2-æ¨¡å‹å¯¹é½çš„æ•°å­¦åŸç†"><a href="#2-æ¨¡å‹å¯¹é½çš„æ•°å­¦åŸç†" class="headerlink" title="2. æ¨¡å‹å¯¹é½çš„æ•°å­¦åŸç†"></a><strong>2. æ¨¡å‹å¯¹é½çš„æ•°å­¦åŸç†</strong></h3><p>åœ¨å¯¹é½è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šé€šè¿‡<strong>ç­–ç•¥æ¨¡å‹</strong>ï¼ˆPolicy Modelï¼‰æ¥ç”Ÿæˆè¾“å‡ºï¼Œç­–ç•¥æ¨¡å‹é€šå¸¸æ˜¯ç»è¿‡SFTè®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œç”¨æ¥åœ¨ç»™å®šè¾“å…¥ä¸‹ç”Ÿæˆè¾“å‡ºã€‚ä¸ºäº†ä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºï¼Œä½¿å…¶æ›´åŠ ç¬¦åˆäººç±»åå¥½ï¼Œå¸¸å¸¸ä½¿ç”¨ä»¥ä¸‹æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ï¼š</p><h4 id="2-1-ç­–ç•¥æ¨¡å‹"><a href="#2-1-ç­–ç•¥æ¨¡å‹" class="headerlink" title="2.1 ç­–ç•¥æ¨¡å‹"></a><strong>2.1 ç­–ç•¥æ¨¡å‹</strong></h4><p>å‡è®¾å½“å‰æ¨¡å‹çš„ç­–ç•¥ä¸º $\pi_\theta$ï¼Œå®ƒè¡¨ç¤ºåœ¨ç»™å®šè¾“å…¥ $x$ æ—¶ï¼Œæ¨¡å‹ç”Ÿæˆè¾“å‡º $y$ çš„æ¦‚ç‡ï¼š<br>$$<br>\pi_\theta(y|x)<br>$$<br>ç­–ç•¥æ¨¡å‹çš„ç›®æ ‡æ˜¯é€šè¿‡è°ƒæ•´å‚æ•° $\theta$ï¼Œæé«˜ç”Ÿæˆæ­£ç¡®è¾“å‡ºï¼ˆæ­£æ ·æœ¬ï¼‰çš„æ¦‚ç‡ï¼Œé™ä½ç”Ÿæˆé”™è¯¯è¾“å‡ºï¼ˆè´Ÿæ ·æœ¬ï¼‰çš„æ¦‚ç‡ã€‚</p><h4 id="2-2-æé«˜æ­£æ ·æœ¬æ¦‚ç‡ä¸é™ä½è´Ÿæ ·æœ¬æ¦‚ç‡çš„æœºåˆ¶"><a href="#2-2-æé«˜æ­£æ ·æœ¬æ¦‚ç‡ä¸é™ä½è´Ÿæ ·æœ¬æ¦‚ç‡çš„æœºåˆ¶" class="headerlink" title="2.2 æé«˜æ­£æ ·æœ¬æ¦‚ç‡ä¸é™ä½è´Ÿæ ·æœ¬æ¦‚ç‡çš„æœºåˆ¶"></a><strong>2.2 æé«˜æ­£æ ·æœ¬æ¦‚ç‡ä¸é™ä½è´Ÿæ ·æœ¬æ¦‚ç‡çš„æœºåˆ¶</strong></h4><p>ä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œé€šå¸¸ä½¿ç”¨å¸¦æœ‰åå¥½æ¯”è¾ƒæˆ–æ ‡ç­¾çš„æŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ï¼š</p><ol><li><p><strong>æ­£æ ·æœ¬çš„ä¼˜åŒ–</strong>ï¼šé€šè¿‡å¢åŠ æ­£æ ·æœ¬çš„æŸå¤±æƒé‡ï¼Œä½¿å¾—æ¨¡å‹ç”Ÿæˆæ­£æ ·æœ¬çš„æ¦‚ç‡æ›´é«˜ã€‚</p><ul><li>æ­£æ ·æœ¬çš„æŸå¤±å‡½æ•°ä¼šå¼•å¯¼æ¨¡å‹åœ¨é¢å¯¹ç›¸åŒé—®é¢˜æ—¶ï¼Œç”Ÿæˆæ›´å¤šç¬¦åˆäººç±»æœŸæœ›çš„ç­”æ¡ˆã€‚</li></ul></li><li><p><strong>è´Ÿæ ·æœ¬çš„æƒ©ç½š</strong>ï¼šå¯¹è´Ÿæ ·æœ¬æ–½åŠ æ›´é«˜çš„æŸå¤±æƒé‡ï¼Œæ¨¡å‹ä¼šå­¦ä¹ åˆ°å‡å°‘è¿™äº›é”™è¯¯è¾“å‡ºçš„æ¦‚ç‡ã€‚</p><ul><li>è´Ÿæ ·æœ¬çš„æŸå¤±å‡½æ•°æ—¨åœ¨è®©æ¨¡å‹åœ¨ç”Ÿæˆé”™è¯¯ç­”æ¡ˆæ—¶æ„ŸçŸ¥åˆ°æ›´å¤§çš„æƒ©ç½šï¼Œä»è€Œå‡å°‘è¿™äº›è¾“å‡ºçš„ç”Ÿæˆã€‚</li></ul></li></ol><p>åœ¨æŸäº›æ–¹æ³•ä¸­ï¼Œä¾‹å¦‚DPOå’ŒKTOï¼Œè¿˜ä¼šé€šè¿‡è®¡ç®—å½“å‰ç­–ç•¥æ¨¡å‹ä¸å‚è€ƒæ¨¡å‹ä¹‹é—´çš„<strong>KLæ•£åº¦</strong>ï¼Œæ¥é˜²æ­¢æ¨¡å‹åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿‡åº¦åç¦»åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ã€‚</p><hr><h3 id="3-æŸå¤±å‡½æ•°ä¸KLæ•£åº¦çš„ä½œç”¨"><a href="#3-æŸå¤±å‡½æ•°ä¸KLæ•£åº¦çš„ä½œç”¨" class="headerlink" title="3. æŸå¤±å‡½æ•°ä¸KLæ•£åº¦çš„ä½œç”¨"></a><strong>3. æŸå¤±å‡½æ•°ä¸KLæ•£åº¦çš„ä½œç”¨</strong></h3><p>åœ¨æ¨¡å‹å¯¹é½çš„è¿‡ç¨‹ä¸­ï¼ŒæŸå¤±å‡½æ•°é€šå¸¸åŒ…å«ä¸¤éƒ¨åˆ†ï¼š</p><ol><li><strong>åå¥½æŸå¤±</strong>æˆ–<strong>æ ‡ç­¾æŸå¤±</strong>ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹ç”Ÿæˆç¬¦åˆäººç±»æœŸæœ›çš„è¾“å‡ºã€‚</li><li><strong>KLæ•£åº¦</strong>ï¼Œç”¨äºçº¦æŸæ¨¡å‹ä¸è¦åç¦»å‚è€ƒæ¨¡å‹ã€‚</li></ol><h4 id="3-1-KLæ•£åº¦çš„ä½œç”¨"><a href="#3-1-KLæ•£åº¦çš„ä½œç”¨" class="headerlink" title="3.1 KLæ•£åº¦çš„ä½œç”¨"></a><strong>3.1 KLæ•£åº¦çš„ä½œç”¨</strong></h4><p>KLæ•£åº¦ï¼ˆKullback-Leibler Divergenceï¼‰è¡¡é‡çš„æ˜¯ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚åœ¨æ¨¡å‹å¯¹é½ä¸­ï¼ŒKLæ•£åº¦ç”¨äºé™åˆ¶å½“å‰æ¨¡å‹ \(\pi_\theta\) å’Œå‚è€ƒæ¨¡å‹ \(\pi_{\text{ref}}\) çš„åˆ†å¸ƒå·®å¼‚ï¼Œç¡®ä¿åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æ¨¡å‹çš„è¾“å‡ºä¸ä¼šè¿‡åº¦åç¦»é¢„è®­ç»ƒæ¨¡å‹ã€‚å…·ä½“å…¬å¼ä¸ºï¼š<br>$$<br>\text{KL}(\pi_\theta(y|x) | \pi_{\text{ref}}(y|x)) = \sum_y \pi_\theta(y|x) \log \frac{\pi_\theta(y|x)}{\pi_{\text{ref}}(y|x)}<br>$$</p><ul><li>å¦‚æœKLæ•£åº¦è¾ƒå¤§ï¼Œè¡¨ç¤ºå½“å‰æ¨¡å‹ç”Ÿæˆçš„åˆ†å¸ƒä¸å‚è€ƒæ¨¡å‹æœ‰è¾ƒå¤§çš„å·®å¼‚ï¼Œè¿™å¯èƒ½æ„å‘³ç€æ¨¡å‹ç”Ÿæˆäº†ä¸åˆç†çš„è¾“å‡ºã€‚</li><li>é€šè¿‡æœ€å°åŒ–KLæ•£åº¦ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¿è¯è¾“å‡ºåˆç†æ€§çš„åŸºç¡€ä¸Šï¼Œè¿›è¡Œè¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚</li></ul><h4 id="3-2-æŸå¤±å‡½æ•°å…¬å¼"><a href="#3-2-æŸå¤±å‡½æ•°å…¬å¼" class="headerlink" title="3.2 æŸå¤±å‡½æ•°å…¬å¼"></a><strong>3.2 æŸå¤±å‡½æ•°å…¬å¼</strong></h4><p>æ ¹æ®åå¥½æˆ–æ ‡ç­¾ï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°å¯ä»¥è¡¨è¾¾ä¸ºä»¥ä¸‹å½¢å¼ï¼š</p><h5 id="DPOä¸­çš„æŸå¤±å‡½æ•°ï¼š"><a href="#DPOä¸­çš„æŸå¤±å‡½æ•°ï¼š" class="headerlink" title="DPOä¸­çš„æŸå¤±å‡½æ•°ï¼š"></a><strong>DPOä¸­çš„æŸå¤±å‡½æ•°</strong>ï¼š</h5><p>$$<br>L_{DPO} = -\mathbb{E}_{x, y_w, y_l \sim D} [\log \sigma(\beta (\log(\pi_\theta(y_w|x)) - \log(\pi_\theta(y_l|x))))]<br>$$</p><ul><li>$y_w$ï¼šåå¥½è¾ƒé«˜çš„ç­”æ¡ˆã€‚</li><li>$y_l$ï¼šåå¥½è¾ƒä½çš„ç­”æ¡ˆã€‚</li></ul><p>DPOä¸­å¯ä»¥å¼•å…¥KLæ•£åº¦ä½œä¸ºæ­£åˆ™åŒ–é¡¹ï¼š<br>$$<br>L_{DPO} = -\log \sigma(\log(\pi_\theta(y_w|x)) - \log(\pi_\theta(y_l|x)) + \beta \cdot \text{KL}(\pi_\theta | \pi_{\text{ref}}))<br>$$<br>é€šè¿‡æ§åˆ¶KLæ•£åº¦ï¼Œæ¨¡å‹çš„è¾“å‡ºä¸ä¼šåç¦»å‚è€ƒæ¨¡å‹å¤ªå¤šã€‚</p><h5 id="KTOä¸­çš„æŸå¤±å‡½æ•°ï¼š"><a href="#KTOä¸­çš„æŸå¤±å‡½æ•°ï¼š" class="headerlink" title="KTOä¸­çš„æŸå¤±å‡½æ•°ï¼š"></a><strong>KTOä¸­çš„æŸå¤±å‡½æ•°</strong>ï¼š</h5><p>KTOçš„æŸå¤±å‡½æ•°åŸºäºå‰æ™¯ç†è®ºï¼Œå¹¶å°†KLæ•£åº¦ä½œä¸ºæ ¸å¿ƒéƒ¨åˆ†ï¼Œè¡¨è¾¾ä¸ºï¼š<br>$$<br>L_{KTO} = \lambda_U \cdot \sigma(\beta \cdot (\text{KL}(\pi_\theta(\text{Answer 2}) | \pi_{\text{ref}}) - r_{\theta}(\text{Answer 2})))<br>$$</p><ul><li>$r_{\theta}(x, y)$ï¼šå½“å‰ç­–ç•¥å¯¹è´Ÿæ ·æœ¬ï¼ˆé”™è¯¯ç­”æ¡ˆï¼‰çš„ç½®ä¿¡åº¦ã€‚</li><li>KLæ•£åº¦ç”¨äºè¡¡é‡å½“å‰æ¨¡å‹ä¸å‚è€ƒæ¨¡å‹çš„å·®å¼‚ï¼Œç¡®ä¿æ¨¡å‹åœ¨å‡å°‘è´Ÿæ ·æœ¬ç”Ÿæˆçš„åŒæ—¶ï¼Œä¸åç¦»åŸå§‹å‚è€ƒæ¨¡å‹ã€‚</li></ul><p>é€šè¿‡å¢åŠ è´Ÿæ ·æœ¬çš„æŸå¤±ï¼ˆå³å¢åŠ  $\lambda_U$ çš„å€¼ï¼‰ï¼Œæ¨¡å‹ä¼šé™ä½è´Ÿæ ·æœ¬çš„ç½®ä¿¡åº¦ï¼Œä½¿æœªæ¥ç”Ÿæˆç±»ä¼¼é”™è¯¯ç­”æ¡ˆçš„æ¦‚ç‡å˜å°ã€‚</p><hr><h3 id="4-å¦‚ä½•ä¼˜åŒ–æ¨¡å‹"><a href="#4-å¦‚ä½•ä¼˜åŒ–æ¨¡å‹" class="headerlink" title="4. å¦‚ä½•ä¼˜åŒ–æ¨¡å‹"></a><strong>4. å¦‚ä½•ä¼˜åŒ–æ¨¡å‹</strong></h3><p>é€šè¿‡ä¸Šé¢ä»‹ç»çš„æŸå¤±å‡½æ•°ï¼Œæ¨¡å‹çš„ä¼˜åŒ–é€šå¸¸æ˜¯é€šè¿‡<strong>æ¢¯åº¦ä¸‹é™</strong>ï¼ˆGradient Descentï¼‰æ¥å®Œæˆçš„ã€‚æŸå¤±å‡½æ•°çš„æ¢¯åº¦åæ˜ äº†æ¨¡å‹è¾“å‡ºä¸æœŸæœ›è¾“å‡ºä¹‹é—´çš„å·®å¼‚ï¼Œä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚</p><p><strong>æ¢¯åº¦æ›´æ–°å…¬å¼</strong>ï¼š<br>$$<br>\theta_{\text{new}} = \theta_{\text{old}} - \eta \nabla_{\theta} L<br>$$<br>å…¶ä¸­ï¼š</p><ul><li>$\eta$ æ˜¯å­¦ä¹ ç‡ï¼Œå†³å®šæ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿ã€‚</li><li>$\nabla_{\theta} L$ æ˜¯æŸå¤±å‡½æ•°å¯¹æ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼Œè¡¨ç¤ºå½“å‰å‚æ•°å¯¹æŸå¤±çš„è´¡çŒ®ã€‚</li></ul><p>é€šè¿‡ä¸æ–­è¿­ä»£ï¼Œæ¨¡å‹ä¼šé€æ¸æé«˜ç”Ÿæˆæ­£æ ·æœ¬çš„æ¦‚ç‡ï¼Œå‡å°‘è´Ÿæ ·æœ¬çš„ç”Ÿæˆæ¦‚ç‡ï¼Œæœ€ç»ˆå®ç°æ¨¡å‹å¯¹é½ã€‚</p><ul><li>æ¨¡å‹å¯¹é½ï¼ˆAlignmentï¼‰çš„æ ¸å¿ƒç›®æ ‡æ˜¯é€šè¿‡åå¥½æˆ–æ ‡ç­¾æ•°æ®ï¼Œä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºï¼Œä½¿å…¶ç¬¦åˆäººç±»æœŸæœ›ã€‚</li><li><strong>ç­–ç•¥æ¨¡å‹</strong>ï¼ˆ$\pi_\theta$ï¼‰ç”Ÿæˆè¾“å‡ºï¼ŒKLæ•£åº¦ç”¨äºæ§åˆ¶æ¨¡å‹ä¸å‚è€ƒæ¨¡å‹çš„åç¦»ç¨‹åº¦ï¼Œé¿å…æ¨¡å‹åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­äº§ç”Ÿä¸åˆç†çš„åå·®ã€‚</li><li><strong>æ­£æ ·æœ¬çš„æ¦‚ç‡</strong>é€šè¿‡æŸå¤±å‡½æ•°çš„ä¼˜åŒ–é€æ­¥æå‡ï¼Œ<strong>è´Ÿæ ·æœ¬çš„æ¦‚ç‡</strong>é€šè¿‡å¢åŠ æŸå¤±æƒé‡å’Œé™ä½ç½®ä¿¡åº¦æ¥å‡å°‘ã€‚</li><li>æ¢¯åº¦ä¸‹é™ç”¨äºæ›´æ–°æ¨¡å‹å‚æ•°ï¼Œæœ€ç»ˆå®ç°æ¨¡å‹å¯¹é½</li></ul><hr><h2 id="4-DPOï¼ˆDirect-Preference-Optimizationï¼‰"><a href="#4-DPOï¼ˆDirect-Preference-Optimizationï¼‰" class="headerlink" title="4. DPOï¼ˆDirect Preference Optimizationï¼‰"></a>4. <strong>DPOï¼ˆDirect Preference Optimizationï¼‰</strong></h2><h3 id="4-1-åŸç†"><a href="#4-1-åŸç†" class="headerlink" title="4.1 åŸç†"></a>4.1 <strong>åŸç†</strong></h3><p>DPO é€šè¿‡ç›´æ¥ä¼˜åŒ–æ¨¡å‹è¾“å‡ºçš„åå¥½å‡½æ•°ï¼Œä½¿æ¨¡å‹çš„è¾“å‡ºæ›´åŠ ç¬¦åˆäººç±»åå¥½ã€‚å®ƒæ¯”è¾ƒæ¨¡å‹çš„ä¸åŒè¾“å‡ºï¼Œå¹¶é€šè¿‡åå¥½å‡½æ•°è¯„ä¼°è¿™ä¸¤ä¸ªè¾“å‡ºå“ªä¸ªæ›´å¥½ï¼Œä»è€ŒæŒ‡å¯¼æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–ã€‚</p><h3 id="4-2-æŸå¤±å‡½æ•°"><a href="#4-2-æŸå¤±å‡½æ•°" class="headerlink" title="4.2 æŸå¤±å‡½æ•°"></a>4.2 <strong>æŸå¤±å‡½æ•°</strong></h3><p>DPO ä½¿ç”¨åå¥½æŸå¤±å‡½æ•°ï¼ˆPreference Lossï¼‰ï¼Œç”¨äºæ¯”è¾ƒä¸¤ä¸ªè¾“å‡ºçš„ä¼˜åŠ£ï¼š</p><p>$$<br>\mathcal{L}_{\text{DPO}} = \log(1 + \exp(-\sigma \cdot (\hat{y}_a - \hat{y}_b) \cdot p))<br>$$</p><ul><li>$ \hat{y}_a $ å’Œ $ \hat{y}_b $ æ˜¯æ¨¡å‹å¯¹ä¸¤ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼ã€‚</li><li>$ p $ æ˜¯äººç±»åå¥½ï¼ˆ1 è¡¨ç¤ºåå¥½ $a$ï¼Œ-1 è¡¨ç¤ºåå¥½ $b$ï¼‰ã€‚</li><li>$ \sigma $ æ˜¯å¹³æ»‘å‚æ•°ã€‚</li></ul><h3 id="4-3-ä¼˜åŒ–å™¨"><a href="#4-3-ä¼˜åŒ–å™¨" class="headerlink" title="4.3 ä¼˜åŒ–å™¨"></a>4.3 <strong>ä¼˜åŒ–å™¨</strong></h3><p>DPO é€šå¸¸ä½¿ç”¨ <strong>AdamW</strong> ä¼˜åŒ–å™¨ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡å‚æ•°æ¨¡å‹çš„ä¼˜åŒ–ï¼Œä»£ç å¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="number">1e-5</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="4-4-æ ¸å¿ƒä»£ç "><a href="#4-4-æ ¸å¿ƒä»£ç " class="headerlink" title="4.4 æ ¸å¿ƒä»£ç "></a>4.4 <strong>æ ¸å¿ƒä»£ç </strong></h3><p>ä»¥ä¸‹æ˜¯ DPO çš„è®­ç»ƒæ­¥éª¤ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preference_loss</span>(<span class="params">output_a, output_b, human_preference</span>):</span><br><span class="line">    preference = human_preference(output_a, output_b)</span><br><span class="line">    loss = torch.log(<span class="number">1</span> + torch.exp(-preference * (output_a - output_b)))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dpo_training_step</span>(<span class="params">model, data_a, data_b, human_preference</span>):</span><br><span class="line">    output_a = model(data_a)</span><br><span class="line">    output_b = model(data_b)</span><br><span class="line">    </span><br><span class="line">    loss = preference_loss(output_a, output_b, human_preference)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_a, batch_b <span class="keyword">in</span> training_data:</span><br><span class="line">    dpo_training_step(model, batch_a, batch_b, human_preference_function)</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="5-KTOï¼ˆKahneman-Tversky-Optimizationï¼‰"><a href="#5-KTOï¼ˆKahneman-Tversky-Optimizationï¼‰" class="headerlink" title="5. KTOï¼ˆKahneman-Tversky Optimizationï¼‰"></a>5. <strong>KTOï¼ˆKahneman-Tversky Optimizationï¼‰</strong></h2><h3 id="5-1-åŸç†"><a href="#5-1-åŸç†" class="headerlink" title="5.1 åŸç†"></a>5.1 <strong>åŸç†</strong></h3><p>KTO åŸºäº Kahneman å’Œ Tversky çš„å‰æ™¯ç†è®ºï¼ˆProspect Theoryï¼‰ï¼Œé€šè¿‡éå¯¹ç§°æ•ˆç”¨å‡½æ•°è¡¡é‡æ¨¡å‹çš„å¢ç›Šå’ŒæŸå¤±ï¼Œæ—¨åœ¨ä¼˜åŒ–æ¨¡å‹çš„è¡¨ç°ï¼Œå°¤å…¶åœ¨é£é™©å’Œæ”¶ç›Šä¸å¯¹ç§°çš„åœºæ™¯ä¸‹ã€‚æ•ˆç”¨å‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š</p><p>$$<br>\mathcal{U}(x) =<br>\begin{cases}<br>x^{\alpha}, &amp; x \geq 0 \<br>-\lambda (-x)^{\alpha}, &amp; x &lt; 0<br>\end{cases}<br>$$</p><ul><li>$x$ æ˜¯æ¨¡å‹é¢„æµ‹ä¸çœŸå®å€¼çš„å·®å¼‚ã€‚</li><li>$\alpha$ æ˜¯éçº¿æ€§ç³»æ•°ï¼Œé€šå¸¸ä¸º 0</li></ul><p>.88ã€‚</p><ul><li>$\lambda$ æ˜¯æŸå¤±çš„æƒ©ç½šæƒé‡ï¼Œé€šå¸¸ä¸º 2.25ã€‚</li></ul><h3 id="5-2-æŸå¤±å‡½æ•°"><a href="#5-2-æŸå¤±å‡½æ•°" class="headerlink" title="5.2 æŸå¤±å‡½æ•°"></a>5.2 <strong>æŸå¤±å‡½æ•°</strong></h3><p>KTO çš„æŸå¤±å‡½æ•°åŸºäºå‰æ™¯ç†è®ºçš„æ•ˆç”¨å‡½æ•°ï¼Œç”¨äºæƒ©ç½šæ¨¡å‹çš„é¢„æµ‹è¯¯å·®ï¼š</p><p>$$<br>\mathcal{L}<em>{\text{KTO}} = -\mathbb{E}[\mathcal{U}(y</em>{\text{pred}} - y_{\text{true}})]<br>$$</p><h3 id="5-3-ä¼˜åŒ–å™¨"><a href="#5-3-ä¼˜åŒ–å™¨" class="headerlink" title="5.3 ä¼˜åŒ–å™¨"></a>5.3 <strong>ä¼˜åŒ–å™¨</strong></h3><p>KTO å¸¸ä½¿ç”¨ <strong>AdamW</strong> ä¼˜åŒ–å™¨ï¼Œä»¥ç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="number">3e-5</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="5-4-æ ¸å¿ƒä»£ç "><a href="#5-4-æ ¸å¿ƒä»£ç " class="headerlink" title="5.4 æ ¸å¿ƒä»£ç "></a>5.4 <strong>æ ¸å¿ƒä»£ç </strong></h3><p>ä»¥ä¸‹æ˜¯ KTO æŸå¤±å‡½æ•°çš„è®¡ç®—ä»£ç ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prospect_utility</span>(<span class="params">value, alpha=<span class="number">0.88</span>, lambda_=<span class="number">2.25</span></span>):</span><br><span class="line">    <span class="keyword">if</span> value &gt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">pow</span>(value, alpha)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> -lambda_ * torch.<span class="built_in">pow</span>(-value, alpha)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kto_loss</span>(<span class="params">predictions, targets</span>):</span><br><span class="line">    value = predictions - targets</span><br><span class="line">    utility = prospect_utility(value)</span><br><span class="line">    loss = -torch.mean(utility)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    predictions = model(data)</span><br><span class="line">    loss = kto_loss(predictions, targets)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></tbody></table></figure><hr><h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a><strong>æ€»ç»“</strong></h3><table><thead><tr><th>æ–¹æ³•</th><th>æŸå¤±å‡½æ•°</th><th>ä¼˜åŒ–å™¨</th></tr></thead><tbody><tr><td><strong>SFT</strong></td><td>äº¤å‰ç†µæŸå¤±</td><td>AdamWï¼ŒRMSpropï¼ŒSGD</td></tr><tr><td><strong>LoRA</strong></td><td>äº¤å‰ç†µæŸå¤±</td><td>AdamWï¼ŒRMSpropï¼ŒSGD</td></tr><tr><td><strong>DPO</strong></td><td>åå¥½æŸå¤±å‡½æ•°ï¼š $\log(1 + \exp(-\sigma (\hat{y}_a - \hat{y}_b)p))$</td><td>AdamW</td></tr><tr><td><strong>KTO</strong></td><td>å‰æ™¯ç†è®ºæ•ˆç”¨å‡½æ•°ï¼š $-\mathbb{E}[\mathcal{U}(y_{\text{pred}} - y_{\text{true}})]$</td><td>AdamW</td></tr></tbody></table><p>é€šè¿‡æœ¬æ–‡æ¡£çš„æ•´ç†ï¼Œè¯»è€…èƒ½å¤Ÿæ¸…æ™°ç†è§£ SFTã€LoRAã€DPO å’Œ KTO ç­‰æŠ€æœ¯çš„åŸç†ã€å…·ä½“å®ç°æ­¥éª¤ã€æŸå¤±å‡½æ•°è®¾è®¡å’Œä¼˜åŒ–å™¨é€‰æ‹©ï¼Œç‰¹åˆ«æ˜¯åœ¨ LLAMA3 è¿™ç§å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒåœºæ™¯ä¸‹çš„å®é™…åº”ç”¨ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;LoRA-DPO-KTO-ä¸-SFT-æŠ€æœ¯è¯¦è§£&quot;&gt;&lt;a href=&quot;#LoRA-DPO-KTO-ä¸-SFT-æŠ€æœ¯è¯¦è§£&quot; class=&quot;headerlink&quot; title=&quot;LoRA, DPO, KTO ä¸ SFT æŠ€æœ¯è¯¦è§£&quot;&gt;&lt;/a&gt;&lt;strong&gt;LoRA, D</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="LLM" scheme="https://chenhuiyu.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ° LLM çš„å¿«é€Ÿ JSON è§£ç </title>
    <link href="https://chenhuiyu.github.io/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/"/>
    <id>https://chenhuiyu.github.io/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/</id>
    <published>2024-08-13T08:12:10.000Z</published>
    <updated>2026-02-20T21:56:22.875Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ°-LLM-çš„å¿«é€Ÿ-JSON-è§£ç "><a href="#ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ°-LLM-çš„å¿«é€Ÿ-JSON-è§£ç " class="headerlink" title="ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ° LLM çš„å¿«é€Ÿ JSON è§£ç "></a>ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ° LLM çš„å¿«é€Ÿ JSON è§£ç </h2><p><strong>ä½œè€…</strong>: Liangsheng Yin, Ying Sheng, Lianmin Zheng<br><strong>æ—¥æœŸ</strong>: 2024 å¹´ 2 æœˆ 5 æ—¥</p><hr><p>æœ¬æ–‡å†…å®¹åŸºäº LMSYS Org å‘å¸ƒçš„ä¸€ç¯‡åšå®¢æ–‡ç« ï¼ŒåŸæ–‡é“¾æ¥ï¼š<a href="https://lmsys.org/blog/2024-02-05-compressed-fsm/">LMSYS Org åšå®¢</a>ã€‚ç›¸å…³çš„ä»£ç åº“å¯ä»¥åœ¨ä»¥ä¸‹é“¾æ¥æ‰¾åˆ°ï¼š<a href="https://github.com/sgl-project/sglang/tree/main?tab=readme-ov-file#json-decoding">SGLang ä»£ç åº“</a>ã€‚</p><p>è®©ä¸€ä¸ª LLM å§‹ç»ˆç”Ÿæˆç¬¦åˆç‰¹å®šæ¨¡å¼çš„æœ‰æ•ˆ JSON æˆ– YAMLï¼Œå¯¹äºè®¸å¤šåº”ç”¨æ¥è¯´æ˜¯ä¸€ä¸ªå…³é”®ç‰¹æ€§ã€‚åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ˜¾è‘—åŠ é€Ÿè¿™ç§çº¦æŸè§£ç çš„ä¼˜åŒ–æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨äº†å‹ç¼©çš„æœ‰é™çŠ¶æ€æœºï¼Œå¹¶ä¸”å…¼å®¹ä»»ä½•æ­£åˆ™è¡¨è¾¾å¼ï¼Œå› æ­¤å¯ä»¥é€‚ç”¨äºä»»ä½• JSON æˆ– YAML æ¨¡å¼ã€‚ä¸ç°æœ‰ç³»ç»Ÿé€æ­¥è§£ç ä¸€ä¸ªæ ‡è®°çš„æ–¹å¼ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ†æäº†æ­£åˆ™è¡¨è¾¾å¼çš„æœ‰é™çŠ¶æ€æœºï¼Œå‹ç¼©äº†å•ä¸€çš„è½¬æ¢è·¯å¾„ï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ä¸€æ¬¡æ€§è§£ç å¤šä¸ªæ ‡è®°ã€‚ä¸æœ€å…ˆè¿›çš„ç³»ç»Ÿï¼ˆguidance + llama.cppï¼Œoutlines + vLLMï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å°†å»¶è¿Ÿå‡å°‘æœ€å¤š 2 å€ï¼Œå¹¶æé«˜ååé‡æœ€å¤š 2.5 å€ã€‚è¿™ä¸€ä¼˜åŒ–è¿˜ä½¿å¾—çº¦æŸè§£ç æ¯”æ™®é€šè§£ç æ›´å¿«ã€‚ä½ å¯ä»¥åœ¨ SGLang ä¸Šè¯•ç”¨å®ƒã€‚</p><p><img src="https://lmsys.org/images/blog/compressed_fsm/demo.gif" alt="å›¾1ï¼šSGLangå’ŒOutlines + vLLMåœ¨JSONè§£ç ä¸­çš„æ¯”è¾ƒ"></p><p>å›¾ä¸€å±•ç¤ºäº† SGLang å’Œ Outlines + vLLM åœ¨ JSON è§£ç ä»»åŠ¡ä¸­çš„æ€§èƒ½æ¯”è¾ƒã€‚è¿™æ˜¯ä¸€ä¸ªåŠ¨æ€å¯¹æ¯”ï¼Œç›®çš„æ˜¯å±•ç¤ºä¸¤è€…åœ¨ç›¸åŒä»»åŠ¡ä¸‹çš„é€Ÿåº¦å·®å¼‚ã€‚SGLang é‡‡ç”¨äº†ä¸€ç§æ–°çš„è·³è·ƒå‰è¿›è§£ç ç®—æ³•ï¼Œé€šè¿‡å‹ç¼©æœ‰é™çŠ¶æ€æœºæ¥åŠ é€Ÿè§£ç è¿‡ç¨‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒOutlines + vLLM ä½¿ç”¨äº†ä¼ ç»Ÿçš„é€æ­¥è§£ç æ–¹æ³•ã€‚å›¾ä¸­çš„åŠ¨ç”»æ¼”ç¤ºäº† SGLang åœ¨å¤„ç†å¤šå­—ç¬¦ï¼ˆæˆ–æ ‡è®°ï¼‰è§£ç æ—¶çš„ä¼˜åŠ¿ï¼Œæ˜¾è‘—å‡å°‘äº†è§£ç æ—¶é—´ã€‚</p><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>JSON æ˜¯æ•°æ®äº¤æ¢ä¸­æœ€é‡è¦çš„æ ¼å¼ä¹‹ä¸€ã€‚è¦æ±‚ LLM å§‹ç»ˆç”Ÿæˆæœ‰æ•ˆçš„ JSON å¯ä»¥ä½¿ LLM çš„è¾“å‡ºä»¥ç»“æ„åŒ–æ–¹å¼è½»æ¾è§£æã€‚è®¤è¯†åˆ°å…¶é‡è¦æ€§ï¼ŒOpenAI å¼•å…¥äº† JSON æ¨¡å¼ï¼Œå®ƒçº¦æŸæ¨¡å‹å§‹ç»ˆè¿”å›æœ‰æ•ˆçš„ JSON å¯¹è±¡ã€‚ç„¶è€Œï¼Œé€šå¸¸éœ€è¦æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„ JSON å¯¹è±¡ç¬¦åˆç‰¹å®šçš„æ¨¡å¼ï¼Œä¾‹å¦‚ï¼š</p><img src="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/image-1.png" class="" title="å›¾2ï¼šéµå¾ªJSONæ¨¡å¼çš„çº¦æŸç”Ÿæˆç¤ºä¾‹"><p>å›¾äºŒå±•ç¤ºäº†ä¸€ä¸ªå—é™ç”Ÿæˆçš„ä¾‹å­ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥ç”Ÿæˆç¬¦åˆç‰¹å®š JSON æ¨¡å¼çš„å¯¹è±¡ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå·¦ä¾§çš„ JSON æ¨¡å¼å®šä¹‰äº†ä¸€ä¸ªå¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«äº† nameã€age å’Œ house ä¸‰ä¸ªå±æ€§ï¼Œåˆ†åˆ«æ˜¯å­—ç¬¦ä¸²å’Œæ•´æ•°ç±»å‹ã€‚å³ä¾§åˆ™æ˜¾ç¤ºäº†å—é™ç”Ÿæˆçš„è¾“å‡ºå¯¹è±¡ï¼Œæ¨¡å‹é€šè¿‡çº¦æŸç”ŸæˆæŠ€æœ¯ï¼Œç”Ÿæˆäº†ç¬¦åˆè¿™äº›å±æ€§çš„å…·ä½“å®ä¾‹ï¼Œå¦‚â€œHarryâ€çš„åå­—ã€15 å²çš„å¹´é¾„ä»¥åŠå±äºâ€œGryffindorâ€çš„æˆ¿å­ã€‚è¿™å±•ç¤ºäº† LLMs åœ¨ç”Ÿæˆç»“æ„åŒ–æ•°æ®æ—¶çš„èƒ½åŠ›ï¼ŒåŒæ—¶ç¡®ä¿äº†ç”Ÿæˆå†…å®¹ç¬¦åˆé¢„å®šçš„æ ¼å¼ã€‚</p><p>å¯¹äºæœ¬åœ° LLMï¼Œæœ‰ä¸¤ç§ä¸»è¦æ–¹æ³•æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆç¬¦åˆç‰¹å®šæ¨¡å¼çš„ JSON å¯¹è±¡ã€‚</p><h3 id="æ–¹æ³•-1ï¼šåŸºäºæœ‰é™çŠ¶æ€æœº"><a href="#æ–¹æ³•-1ï¼šåŸºäºæœ‰é™çŠ¶æ€æœº" class="headerlink" title="æ–¹æ³• 1ï¼šåŸºäºæœ‰é™çŠ¶æ€æœº"></a>æ–¹æ³• 1ï¼šåŸºäºæœ‰é™çŠ¶æ€æœº</h3><p>è¿™ç§æ–¹æ³•æ¶‰åŠå°† JSON æ¨¡å¼è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥åŸºäºæ­£åˆ™è¡¨è¾¾å¼æ„å»ºä¸€ä¸ªæœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰ã€‚FSM ç”¨äºå¼•å¯¼ LLM çš„ç”Ÿæˆã€‚åœ¨ FSM çš„æ¯ä¸ªçŠ¶æ€ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å…è®¸çš„è½¬æ¢å¹¶è¯†åˆ«å¯æ¥å—çš„ä¸‹ä¸€ä¸ªæ ‡è®°ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨è§£ç è¿‡ç¨‹ä¸­è·Ÿè¸ªå½“å‰çŠ¶æ€ï¼Œå¹¶é€šè¿‡å¯¹è¾“å‡ºåº”ç”¨ logit åå·®æ¥è¿‡æ»¤æ‰æ— æ•ˆçš„æ ‡è®°ã€‚ä½ å¯ä»¥åœ¨ outlines è®ºæ–‡ä¸­äº†è§£æ›´å¤šå…³äºè¿™ç§æ–¹æ³•çš„ä¿¡æ¯ã€‚</p><img src="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/image-2.png" class="" title="å›¾3ï¼šåŸºäºFSMå’ŒLogitså±è”½çš„çº¦æŸè§£ç ã€‚åœ¨ç¬¬ä¸€æ¬¡çº¦æŸè§£ç è¿‡ç¨‹ä¸­ï¼Œä»…å…è®¸ageã€‚åœ¨ç¬¬äºŒæ¬¡è¿‡ç¨‹ä¸­ï¼Œç”±äºæ­£åˆ™è¡¨è¾¾å¼éœ€è¦æ•°å­—ï¼Œå› æ­¤å…è®¸0å’Œ1ï¼Œä½†LLMæ›´æœ‰å¯èƒ½é‡‡æ ·1"><p>å›¾ä¸‰å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰æ¥å®ç°å—é™è§£ç ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆå°† JSON æ¨¡å¼è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œç„¶ååˆ©ç”¨ FSM æ¥å¼•å¯¼ LLM çš„ç”Ÿæˆã€‚åœ¨å›¾ä¸­ï¼ŒFSM çŠ¶æ€å›¾å±•ç¤ºäº† age å­—æ®µçš„å—é™ç”Ÿæˆè¿‡ç¨‹ï¼Œå…¶ä¸­åªæœ‰åˆæ³•çš„æ•°å­—ï¼ˆå¦‚ 0-9ï¼‰ä¼šè¢«å…è®¸ã€‚æ¯ä¸ªçŠ¶æ€çš„è½¬æ¢ç”±æ­£åˆ™è¡¨è¾¾å¼çš„è§„åˆ™å®šä¹‰ï¼Œç¡®ä¿ç”Ÿæˆçš„ JSON æ•°æ®å§‹ç»ˆæœ‰æ•ˆã€‚è¿™ç§æ–¹æ³•é€šè¿‡åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æ–½åŠ é™åˆ¶ï¼Œæ¥æ§åˆ¶ LLM ç”Ÿæˆç‰¹å®šçš„è¾“å‡ºã€‚</p><p>FSM æ–¹æ³•åˆ©ç”¨å¹¿ä¹‰çš„æ­£åˆ™è¡¨è¾¾å¼æ¥å®šä¹‰ä½å±‚æ¬¡è§„åˆ™ï¼Œå¯ä»¥åº”ç”¨äºå¹¿æ³›çš„è¯­æ³•ï¼Œä¾‹å¦‚ JSON æ¨¡å¼ã€IP åœ°å€å’Œç”µå­é‚®ä»¶ã€‚</p><h4 id="é™åˆ¶ï¼š"><a href="#é™åˆ¶ï¼š" class="headerlink" title="é™åˆ¶ï¼š"></a>é™åˆ¶ï¼š</h4><p>ç”±äº FSM æ˜¯åœ¨æ ‡è®°çº§åˆ«æ„å»ºçš„ï¼Œå› æ­¤å®ƒåªèƒ½åœ¨æ¯ä¸€æ­¥é€šè¿‡ä¸€ä¸ªæ ‡è®°æ¥è½¬æ¢çŠ¶æ€ã€‚å› æ­¤ï¼Œå®ƒä¸€æ¬¡åªèƒ½è§£ç ä¸€ä¸ªæ ‡è®°ï¼Œå¯¼è‡´è§£ç é€Ÿåº¦è¾ƒæ…¢ã€‚</p><h3 id="æ–¹æ³•-2ï¼šåŸºäºäº¤ç»‡"><a href="#æ–¹æ³•-2ï¼šåŸºäºäº¤ç»‡" class="headerlink" title="æ–¹æ³• 2ï¼šåŸºäºäº¤ç»‡"></a>æ–¹æ³• 2ï¼šåŸºäºäº¤ç»‡</h3><p>é™¤äº†å°†æ•´ä¸ª JSON æ¨¡å¼è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼ä¹‹å¤–ï¼Œå¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨åŸºäºäº¤ç»‡çš„è§£ç ã€‚åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œç»™å®šçš„ JSON æ¨¡å¼å¯ä»¥åˆ†è§£ä¸ºå‡ ä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†åŒ…å«ä¸€ä¸ªåˆ†å—é¢„å¡«å……éƒ¨åˆ†æˆ–ä¸€ä¸ªçº¦æŸè§£ç éƒ¨åˆ†ã€‚è¿™äº›ä¸åŒçš„éƒ¨åˆ†ç”±æ¨ç†ç³»ç»Ÿäº¤ç»‡æ‰§è¡Œã€‚ç”±äºåˆ†å—é¢„å¡«å……å¯ä»¥åœ¨ä¸€ä¸ªå‰å‘ä¼ é€’ä¸­å¤„ç†å¤šä¸ªæ ‡è®°ï¼Œå®ƒæ¯”é€æ ‡è®°è§£ç æ›´å¿«ã€‚</p><p>Guidance æä¾›äº†ä¸€å¥—åŸºäºäº¤ç»‡è§£ç çš„è¯­æ³•è§„åˆ™ï¼Œä½¿ç”¨ llama.cpp ä½œä¸ºåç«¯ã€‚</p><img src="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/image-3.png" class="" title="å›¾4ï¼šGuidanceä¸­çš„äº¤ç»‡JSONè§£ç "><p>å›¾å››å±•ç¤ºäº† Guidance æ¡†æ¶ä¸­çš„äº¤ç»‡è¯­æ³•ï¼Œå¦‚ä½•åˆ©ç”¨äº¤ç»‡è¯­æ³•æ¥è¿›è¡Œ JSON çš„è§£ç ã€‚å›¾ä¸­çš„ä»£ç ç‰‡æ®µå®šä¹‰äº†ä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨ Guidance è¯­æ³•ç”Ÿæˆä¸€ä¸ªåŒ…å« nameã€age å’Œ house çš„ JSON å¯¹è±¡ã€‚äº¤ç»‡è¯­æ³•é€šè¿‡å°†ä¸åŒéƒ¨åˆ†çš„è§£ç ä¸é¢„å¡«å……éƒ¨åˆ†äº¤æ›¿è¿›è¡Œï¼Œèƒ½å¤Ÿæé«˜è§£ç é€Ÿåº¦ã€‚å›¾ä¸‹æ–¹å±•ç¤ºäº†è¿™ä¸€è¿‡ç¨‹çš„å·¥ä½œåŸç†ï¼Œç»¿è‰²å’Œè“è‰²çš„æ¡å½¢ä»£è¡¨ä¸åŒéƒ¨åˆ†çš„å¤„ç†è¿‡ç¨‹ï¼Œå±•ç¤ºäº†äº¤ç»‡è§£ç åœ¨ä¸åŒé˜¶æ®µçš„æ‰§è¡Œæƒ…å†µã€‚</p><h4 id="é™åˆ¶ï¼š-1"><a href="#é™åˆ¶ï¼š-1" class="headerlink" title="é™åˆ¶ï¼š"></a>é™åˆ¶ï¼š</h4><ul><li>åŸºäºäº¤ç»‡çš„æ–¹æ³•éœ€è¦è‡ªå®šä¹‰è¯­æ³•ï¼Œä½¿å…¶ä¸å¦‚å•ä¸ªæ­£åˆ™è¡¨è¾¾å¼çµæ´»å’Œè¡¨è¾¾åŠ›å¼ºã€‚</li><li>ç”±äºè§£ç å’Œåˆ†å—é¢„å¡«å……æ®µä¹‹é—´å¯èƒ½å­˜åœ¨å†²çªï¼Œå¤„ç†æ ‡è®°è¾¹ç•Œæ—¶å­˜åœ¨å›°éš¾ã€‚</li><li>è§£é‡Šå™¨ä¸åç«¯ä¹‹é—´çš„é¢‘ç¹é€šä¿¡å¸¦æ¥äº†é¢å¤–çš„å¼€é”€ã€‚</li></ul><h3 id="æˆ‘ä»¬çš„æ–¹æ³•ï¼šä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºçš„è·³è·ƒå‰è¿›è§£ç "><a href="#æˆ‘ä»¬çš„æ–¹æ³•ï¼šä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºçš„è·³è·ƒå‰è¿›è§£ç " class="headerlink" title="æˆ‘ä»¬çš„æ–¹æ³•ï¼šä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºçš„è·³è·ƒå‰è¿›è§£ç "></a>æˆ‘ä»¬çš„æ–¹æ³•ï¼šä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºçš„è·³è·ƒå‰è¿›è§£ç </h3><p>é€šè¿‡å¼•å…¥åŸºäºå‹ç¼©æœ‰é™çŠ¶æ€æœºçš„æ–°è§£ç ç®—æ³•â€”â€”è·³è·ƒå‰è¿›è§£ç ï¼Œæˆ‘ä»¬å¯ä»¥ç»“åˆ FSM å’Œäº¤ç»‡æ–¹æ³•çš„ä¼˜ç‚¹ã€‚</p><p>åœ¨ç”± JSON æ¨¡å¼è½¬æ¢çš„æ­£åˆ™è¡¨è¾¾å¼å¼•å¯¼çš„è§£ç è¿‡ç¨‹ä¸­ï¼Œå½“æˆ‘ä»¬è¾¾åˆ°ç‰¹å®šèŠ‚ç‚¹æ—¶ï¼Œå¯ä»¥é¢„æµ‹å³å°†åˆ°æ¥çš„å­—ç¬¦ä¸²ï¼š</p><p>åœ¨å›¾ 3 ä¸­ï¼Œè§£ç å¼€å§‹æ—¶ï¼Œæ ¹æ®æ­£åˆ™è¡¨è¾¾å¼ï¼Œæˆ‘ä»¬å¯ä»¥é¢„è§åˆ°æ¥ä¸‹æ¥çš„å­—ç¬¦ä¸²æ˜¯ï¼š</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"name"</span><span class="punctuation">:</span></span><br></pre></td></tr></tbody></table></figure><p>ç„¶åè¿›å…¥å®é™…çš„è§£ç éƒ¨åˆ†ã€‚<br>åŒæ ·ï¼Œå½“ LLM åœ¨ä¸ºè§’è‰²å¡«å†™æˆ¿å­å±æ€§æ—¶è¾“å‡ºäº† Gï¼Œæˆ‘ä»¬å¯ä»¥è‡ªä¿¡åœ°é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ä¸²å°†æ˜¯ ryffindorï¼Œä»è€Œå®Œæˆæ•´ä¸ªå­—ç¬¦ä¸²ä¸º Gryffindorã€‚</p><p>è¿™æ­£æ˜¯è·³è·ƒå‰è¿›è§£ç ç®—æ³•åŠ é€Ÿè§£ç çš„æ–¹å¼ã€‚åœ¨è·³è·ƒå‰è¿›ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬æ£€æŸ¥ç»™å®šæ­£åˆ™è¡¨è¾¾å¼çš„æœ‰é™çŠ¶æ€æœºï¼Œè¯†åˆ«æ‰€æœ‰å•ä¸€çš„è½¬æ¢è¾¹ï¼Œå¹¶å°†è¿ç»­çš„è½¬æ¢è·¯å¾„å‹ç¼©ä¸ºå•ä¸€è·¯å¾„ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥é¢„å¡«å……ï¼ˆæ‰©å±•ï¼‰è¿™äº›å•ä¸€è·¯å¾„ï¼Œè·³è¿‡é€æ ‡è®°è§£ç ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªåˆ†æ”¯ç‚¹ã€‚</p><img src="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/image-4.png" class="" title="å›¾5ï¼šè·³è·ƒå‰è¿›è§£ç ä¸å‹ç¼©FSMå’Œæ™®é€šè§£ç çš„æ¯”è¾ƒ"><p>å›¾äº”å±•ç¤ºäº†è·³è·ƒå‰è¿›è§£ç ä¸æ™®é€šè§£ç çš„å¯¹æ¯”ã€‚è·³è·ƒå‰è¿›è§£ç åˆ©ç”¨å‹ç¼©çš„æœ‰é™çŠ¶æ€æœºï¼Œé€šè¿‡æå‰é¢„æµ‹å¹¶é¢„å¡«å……å¯èƒ½çš„å­—ç¬¦ä¸²ï¼Œå‡å°‘äº†é€æ ‡è®°è§£ç çš„æ¬¡æ•°ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸º house å­—æ®µç”Ÿæˆå€¼æ—¶ï¼Œæ¨¡å‹åœ¨è§£ç è¿‡ç¨‹ä¸­ç›´æ¥è·³è·ƒå¹¶é¢„å¡«å……äº†â€œGryffindorâ€è¿™ä¸ªå­—ç¬¦ä¸²ï¼Œè€Œæ— éœ€é€å­—ç¬¦ç”Ÿæˆã€‚å›¾ä¸­çš„æµç¨‹å±•ç¤ºäº†å¦‚ä½•é€šè¿‡è¿™ç§æ–¹æ³•æé«˜è§£ç æ•ˆç‡ï¼ŒåŒæ—¶é¿å…äº†ä¸å¿…è¦çš„é‡å¤è®¡ç®—ã€‚<br>å›¾äº”å±•ç¤ºäº†<strong>å‹ç¼©æœ‰é™çŠ¶æ€æœºçš„è·³è·ƒå‰è¿›è§£ç </strong>ä¸<strong>æ™®é€šè§£ç </strong>çš„å¯¹æ¯”ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆ JSON æ•°æ®æ—¶çš„æ€§èƒ½å·®å¼‚ã€‚ä¸ºäº†æ›´è¯¦ç»†åœ°ç†è§£è¿™å¼ å›¾ï¼Œæˆ‘ä»¬éœ€è¦åˆ†æ­¥éª¤åˆ†æå›¾ä¸­çš„å„ä¸ªéƒ¨åˆ†ã€‚</p><ol><li><p><strong>è¾“å…¥æç¤º</strong>ï¼ˆå·¦ä¾§çš„ç»¿è‰²éƒ¨åˆ†ï¼‰ï¼šæç¤ºæ¨¡å‹ç”Ÿæˆä¸€ä¸ªç¬¦åˆ JSON æ¨¡å¼çš„å¯¹è±¡ã€‚è¿™é‡Œçš„ JSON å¯¹è±¡åŒ…æ‹¬â€œnameâ€ã€â€œageâ€å’Œâ€œhouseâ€ä¸‰ä¸ªå±æ€§ï¼Œåˆ†åˆ«ä»£è¡¨åå­—ã€å¹´é¾„å’Œå­¦é™¢ã€‚</p></li><li><p><strong>è·³è·ƒå‰è¿›è§£ç è¿‡ç¨‹</strong>ï¼ˆä¸­é—´éƒ¨åˆ†çš„è“è‰²å’Œæ©™è‰²æ–¹å—ï¼‰ï¼š</p><ul><li><strong>æ©™è‰²æ–¹å—</strong>ä»£è¡¨éœ€è¦çº¦æŸè§£ç çš„éƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼Œç”Ÿæˆâ€œnameâ€å±æ€§æ—¶ï¼Œæ¨¡å‹é€šè¿‡è·³è·ƒå‰è¿›è§£ç ç®—æ³•å¯ä»¥ç›´æ¥ç”Ÿæˆå®Œæ•´çš„å­—ç¬¦ä¸²â€œHarryâ€ã€‚</li><li><strong>è“è‰²æ–¹å—</strong>ä»£è¡¨æ¨¡å‹åœ¨è·³è·ƒå‰è¿›è¿‡ç¨‹ä¸­é€å­—ç¬¦ï¼ˆæˆ–é€æ ‡è®°ï¼‰è§£ç çš„éƒ¨åˆ†ã€‚è¿™ç§è§£ç æ–¹å¼åœ¨é‡åˆ°éç¡®å®šæ€§æ—¶ï¼ˆä¾‹å¦‚å¤šä¸ªå¯èƒ½çš„å€¼ï¼‰æ‰ä¼šå‡ºç°ã€‚</li></ul></li><li><p><strong>æ™®é€šè§£ç è¿‡ç¨‹</strong>ï¼ˆä¸­é—´éƒ¨åˆ†çš„è“è‰²æ–¹å—ï¼‰ï¼šæ™®é€šè§£ç éœ€è¦é€å­—ç¬¦æˆ–é€æ ‡è®°åœ°ç”Ÿæˆæ•´ä¸ª JSON å¯¹è±¡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ™®é€šè§£ç æ–¹å¼åœ¨å¤„ç†æ¯ä¸€ä¸ªå­—ç¬¦æˆ–æ ‡è®°æ—¶éƒ½éœ€è¦è¿›è¡Œé¢„æµ‹å’Œé€‰æ‹©ï¼Œæ˜¾è‘—é™ä½äº†è§£ç é€Ÿåº¦ã€‚</p></li><li><p><strong>å¯¹æ¯”ç»“æœ</strong>ï¼ˆå³ä¾§éƒ¨åˆ†ï¼‰ï¼š</p><ul><li><strong>è·³è·ƒå‰è¿›è§£ç </strong>ç”Ÿæˆçš„ JSON å¯¹è±¡å±•ç¤ºåœ¨æœ€ä¸Šæ–¹ï¼Œè¿™ç§æ–¹æ³•é€šè¿‡é¢„æµ‹å¹¶é¢„å¡«å……å¯èƒ½çš„å­—ç¬¦ä¸²ï¼Œå¤§å¤§åŠ é€Ÿäº†è§£ç è¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼Œåœ¨ç”Ÿæˆâ€œGryffindorâ€è¿™ä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œæ¨¡å‹ç›´æ¥è·³è¿‡äº†é€å­—ç¬¦ç”Ÿæˆçš„æ­¥éª¤ã€‚</li><li><strong>æ™®é€šè§£ç </strong>ç”Ÿæˆçš„ JSON å¯¹è±¡å±•ç¤ºåœ¨æœ€ä¸‹æ–¹ï¼Œè¿™ç§æ–¹æ³•é€å­—ç¬¦è§£ç ï¼Œè™½ç„¶èƒ½å¤Ÿä¿è¯ç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œä½†æ•ˆç‡è¾ƒä½ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†é•¿å­—ç¬¦ä¸²æˆ–å¤æ‚ç»“æ„æ—¶ã€‚</li></ul></li></ol><h3 id="è¯¦ç»†è§£è¯»ï¼š"><a href="#è¯¦ç»†è§£è¯»ï¼š" class="headerlink" title="è¯¦ç»†è§£è¯»ï¼š"></a>è¯¦ç»†è§£è¯»ï¼š</h3><ol><li><p><strong>è·³è·ƒå‰è¿›è§£ç çš„å·¥ä½œåŸç†</strong>ï¼š</p><ul><li>åœ¨è§£ç çš„è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä½¿ç”¨å‹ç¼©åçš„æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰æ¥é¢„æµ‹å’Œè¯†åˆ«å³å°†ç”Ÿæˆçš„å­—ç¬¦ä¸²ã€‚å¦‚æœæ¨¡å‹èƒ½åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­å‡†ç¡®é¢„æµ‹å‡ºæ¥ä¸‹æ¥è¦ç”Ÿæˆçš„å­—ç¬¦ä¸²ï¼Œé‚£ä¹ˆå®ƒå¯ä»¥è·³è¿‡è¿™äº›å­—ç¬¦ä¸²çš„é€æ ‡è®°è§£ç ï¼Œç›´æ¥ç”Ÿæˆæ•´ä¸ªå­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚â€œGryffindorâ€ï¼‰ã€‚</li><li>è¿™ç§æ–¹æ³•åˆ©ç”¨äº†æ­£åˆ™è¡¨è¾¾å¼çš„ç»“æ„ç‰¹ç‚¹ï¼Œå°†è¿ç»­çš„è½¬æ¢è·¯å¾„å‹ç¼©æˆä¸€ä¸ªå•ä¸€è·¯å¾„ï¼Œä»è€Œé¿å…äº†ä¸å¿…è¦çš„é€æ ‡è®°è§£ç æ­¥éª¤ã€‚</li></ul></li><li><p><strong>æ™®é€šè§£ç çš„é™åˆ¶</strong>ï¼š</p><ul><li>æ™®é€šè§£ç æ–¹æ³•éœ€è¦é€æ­¥è§£ç æ¯ä¸€ä¸ªå­—ç¬¦æˆ–æ ‡è®°ï¼Œå› æ­¤åœ¨å¤„ç†å¤æ‚çš„ JSON å¯¹è±¡æ—¶æ•ˆç‡è¾ƒä½ã€‚æ¯ä¸€æ­¥éƒ½éœ€è¦æ¨¡å‹é‡æ–°è®¡ç®—å¯èƒ½çš„è¾“å‡ºï¼Œå¹¶ä»ä¸­é€‰æ‹©æœ€ä¼˜è§£ï¼Œè¿™ä¼šå¤§å¹…å¢åŠ è§£ç æ—¶é—´ã€‚</li></ul></li><li><p><strong>æ€§èƒ½å·®å¼‚</strong>ï¼š</p><ul><li>ç”±äºè·³è·ƒå‰è¿›è§£ç å‡å°‘äº†é€å­—ç¬¦è§£ç çš„æ¬¡æ•°ï¼Œå¹¶ä¸”åˆ©ç”¨äº† FSM çš„å‹ç¼©ç‰¹æ€§ï¼Œå®ƒåœ¨æ—¶é—´å’Œè®¡ç®—èµ„æºä¸Šçš„å¼€é”€éƒ½æ˜¾è‘—ä½äºæ™®é€šè§£ç ã€‚å°¤å…¶åœ¨éœ€è¦ç”Ÿæˆå¤§é‡æ•°æ®æˆ–å¤„ç†å¤æ‚ç»“æ„æ—¶ï¼Œè·³è·ƒå‰è¿›è§£ç çš„ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ã€‚</li></ul></li></ol><p>SGLang çš„ RadixAttention æœºåˆ¶æå¤§åœ°ç®€åŒ–äº†è·³è·ƒå‰è¿›è§£ç ç®—æ³•çš„å®ç°ã€‚å½“æ‰§è¡Œè·³è·ƒå‰è¿›æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ç»ˆæ­¢å½“å‰è¯·æ±‚å¹¶æ’å…¥æ–°è¯·æ±‚ã€‚SGLang è¿è¡Œæ—¶çš„ RadixAttention å’Œé«˜æ•ˆçš„æ‰©å±•åŸè¯­å°†è‡ªåŠ¨é‡ç”¨å‰ä¸€ç»„æ ‡è®°çš„ KV ç¼“å­˜ï¼Œä»è€Œé¿å…å†—ä½™è®¡ç®—ã€‚</p><h2 id="æ ‡è®°è¾¹ç•Œå¤„ç†"><a href="#æ ‡è®°è¾¹ç•Œå¤„ç†" class="headerlink" title="æ ‡è®°è¾¹ç•Œå¤„ç†"></a>æ ‡è®°è¾¹ç•Œå¤„ç†</h2><p>åœ¨å®ç°çº¦æŸè§£ç æ—¶ï¼Œç”±äºå­—ç¬¦ä¸æ ‡è®°ä¹‹é—´å¤æ‚çš„å¯èƒ½æ˜ å°„å…³ç³»ï¼Œå¤„ç†æ ‡è®°è¾¹ç•Œæ€»æ˜¯å¾ˆæ£˜æ‰‹ã€‚</p><p>åœ¨ LLM è§£ç è¿‡ç¨‹ä¸­ï¼Œå®ƒå¯èƒ½æ›´å€¾å‘ï¼ˆæ„å‘³ç€æ¦‚ç‡æ›´é«˜ï¼‰äºå°†å¤šä¸ªå­—ç¬¦ç»„åˆæˆä¸€ä¸ªæ ‡è®°ã€‚ä¾‹å¦‚ï¼Œåœ¨ JSON è§£ç çš„ä¸Šä¸‹æ–‡ä¸­è§£ç â€Helloâ€æ—¶ï¼ŒLLM å¯èƒ½ä¼šè¾“å‡ºå¦‚ä¸‹æ ‡è®°ï¼š<br>â€œ He llo â€œï¼Œ</p><p>è€Œä¸æ˜¯è§£ç æœ€åçš„â€ ï¼Œå®ƒæ€»æ˜¯å€¾å‘äºå°†å…¶ä¸åç»­å­—ç¬¦ç»„åˆæˆæ›´å¸¸è§çš„æ ‡è®°â€ï¼Œ è¿™ç§æ•ˆæœå¯èƒ½å¯¼è‡´ä¸€äº›å¥‡æ€ªçš„è¡Œä¸ºã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸Šè¿°æƒ…å†µä¸‹ï¼Œå¦‚æœæ­£åˆ™è¡¨è¾¾å¼è®¾ç½®ä¸ºâ€[\w\d\s]*â€œï¼ˆä¸åŒ…å«æœ€åçš„â€ï¼Œ ï¼‰ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æ— é™è§£ç ï¼Œå› ä¸º LLM æƒ³è¦åœæ­¢äºâ€ï¼Œä½†è¯¥æ ‡è®°æ˜¯ä¸å…è®¸çš„ã€‚</p><p>æ­¤å¤–ï¼Œåœ¨è·³è·ƒå‰è¿›è§£ç è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°å¯¹è·³è·ƒå‰è¿›éƒ¨åˆ†ä½¿ç”¨ä¸åŒçš„æ ‡è®°ç­–ç•¥å¯èƒ½ä¼šå¯¼è‡´åç»­æ ‡è®°çš„ logit åˆ†å¸ƒä¸åŒã€‚ç®€å•åœ°å°†æ ‡è®°åŒ–çš„è·³è·ƒå‰è¿›éƒ¨åˆ†é™„åŠ åˆ°å½“å‰çš„æ ‡è®°åºåˆ—ä¸­å¯èƒ½ä¼šäº§ç”Ÿæ„å¤–çš„ç»“æœã€‚</p><p>ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š</p><ul><li>æˆ‘ä»¬åœ¨è·³è·ƒå‰è¿›é˜¶æ®µå®æ–½äº†é‡æ–°æ ‡è®°åŒ–æœºåˆ¶ã€‚è¿™åŒ…æ‹¬é™„åŠ å­—ç¬¦ä¸²è€Œä¸æ˜¯æ ‡è®°ï¼Œç„¶åé‡æ–°æ ‡è®°æ•´ä¸ªæ–‡æœ¬ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°è§£å†³äº†å¤§å¤šæ•°æ ‡è®°åŒ–é—®é¢˜ï¼Œå¹¶ä¸”ä»…å¯¼è‡´è®¡ç®—å¼€é”€å¢åŠ çº¦ 4%ã€‚</li><li><strong>å»ºè®®</strong>ä½¿ç”¨ç»¼åˆæ­£åˆ™è¡¨è¾¾å¼å¼•å¯¼æ•´ä¸ªè§£ç è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å¤šä¸ªè¿æ¥çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚è¿™ç§æ–¹æ³•ç¡®ä¿ FSM å’Œ LLM éƒ½äº†è§£æ•´ä¸ªè§£ç è¿‡ç¨‹ï¼Œä»è€Œå°½é‡å‡å°‘ä¸è¾¹ç•Œç›¸å…³çš„é—®é¢˜ã€‚<br>ä½ è¿˜å¯ä»¥åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­é˜…è¯»ä¸€äº›é¢å¤–çš„è®¨è®ºã€‚</li></ul><h2 id="åŸºå‡†æµ‹è¯•ç»“æœ"><a href="#åŸºå‡†æµ‹è¯•ç»“æœ" class="headerlink" title="åŸºå‡†æµ‹è¯•ç»“æœ"></a>åŸºå‡†æµ‹è¯•ç»“æœ</h2><p>æˆ‘ä»¬åœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šå¯¹æˆ‘ä»¬çš„è·³è·ƒå‰è¿›è§£ç è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼š</p><ol><li>ä½¿ç”¨ç®€çŸ­çš„æç¤ºç”Ÿæˆ JSON æ ¼å¼çš„è§’è‰²æ•°æ®ã€‚</li><li>ä»é•¿æ–‡æ¡£ä¸­æå–åŸå¸‚ä¿¡æ¯å¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚</li></ol><p>æˆ‘ä»¬åœ¨ NVIDIA A10 GPUï¼ˆ24GBï¼‰ä¸Šæµ‹è¯•äº† llama-7Bï¼Œä½¿ç”¨äº† vllm v0.2.7ï¼Œguidance v0.1.0ï¼Œoutlines v0.2.5 å’Œ llama.cpp v0.2.38ï¼ˆPython ç»‘å®šï¼‰ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†è¿™äº›æ–¹æ³•çš„ååé‡ï¼ˆä½¿ç”¨æ¯ä¸ªç³»ç»Ÿæ”¯æŒçš„æœ€å¤§æ‰¹æ¬¡å¤§å°ï¼‰å’Œå»¶è¿Ÿï¼ˆæ‰¹æ¬¡å¤§å°ä¸º 1ï¼‰ï¼š</p><img src="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/image-5.png" class="" title="å›¾6ï¼šåŸºå‡†æµ‹è¯•ç»“æœ"><p>ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„è§£ç ç®—æ³•çš„ SGLang æ˜¾è‘—ä¼˜äºæ‰€æœ‰å…¶ä»–ç³»ç»Ÿã€‚å®ƒå¯ä»¥å°†å»¶è¿Ÿå‡å°‘æœ€å¤š 2 å€ï¼Œå¹¶å°†ååé‡æé«˜æœ€å¤š 2.5 å€ã€‚åœ¨è§’è‰²ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå³ä½¿ä¸ä½¿ç”¨è·³è·ƒå‰è¿›çš„ SGLang ä¹Ÿæ¯” Outlines+vLLM å®ç°äº†æ›´é«˜çš„ååé‡ï¼›æˆ‘ä»¬æ€€ç–‘è¿™æ˜¯ç”±äº Outlines ä¸­çš„æŸäº›å¼€é”€æ‰€è‡´ã€‚</p><h2 id="ç”¨ä¾‹"><a href="#ç”¨ä¾‹" class="headerlink" title="ç”¨ä¾‹"></a>ç”¨ä¾‹</h2><p>æˆ‘ä»¬å·²ç»ä¸ Boson.ai æµ‹è¯•äº†è¿™ä¸ªåŠŸèƒ½ä¸¤å‘¨ï¼Œä»–ä»¬æ­£åœ¨å°†è¿™ä¸ªåŠŸèƒ½å¼•å…¥ä»–ä»¬çš„ç”Ÿäº§ç”¨ä¾‹ä¸­ï¼Œå› ä¸ºå®ƒä¿è¯äº†æ›´é«˜çš„è§£ç ååé‡å’Œå¯é çš„å“åº”ã€‚</p><p>æ­¤å¤–ï¼Œå¦ä¸€ä½ç”¨æˆ·ä½¿ç”¨æ­¤åŠŸèƒ½é€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹ LLaVA ä»å›¾åƒä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚</p><img src="/2024/08/13/NLP%20Insights/%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%20LLM%20%E7%9A%84%E5%BF%AB%E9%80%9F%20JSON%20%E8%A7%A3%E7%A0%81/image-6.png" class="" title="å›¾7ï¼šä½¿ç”¨SGLangå’ŒLLaVAä»å›¾åƒä¸­æå–ç»“æ„åŒ–ä¿¡æ¯">]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ°-LLM-çš„å¿«é€Ÿ-JSON-è§£ç &quot;&gt;&lt;a href=&quot;#ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ°-LLM-çš„å¿«é€Ÿ-JSON-è§£ç &quot; class=&quot;headerlink&quot; title=&quot;ä½¿ç”¨å‹ç¼©æœ‰é™çŠ¶æ€æœºè¿›è¡Œæœ¬åœ° LLM çš„å¿«é€Ÿ JSON è§£ç &quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="SGLang" scheme="https://chenhuiyu.github.io/tags/SGLang/"/>
    
    <category term="Structured LLM" scheme="https://chenhuiyu.github.io/tags/Structured-LLM/"/>
    
  </entry>
  
  <entry>
    <title>Detailed Steps for Running Fine-tuned Gemma-2-2b-it with vLLM</title>
    <link href="https://chenhuiyu.github.io/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM/"/>
    <id>https://chenhuiyu.github.io/2024/08/07/NLP%20Insights/Running%20Fine-tuned%20Gemma-2-2b-it%20with%20vLLM/</id>
    <published>2024-08-07T02:30:00.000Z</published>
    <updated>2026-02-20T21:56:22.874Z</updated>
    
    <content type="html"><![CDATA[<p>In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process, environment configuration, and common troubleshooting tips.</p><h2 id="Installation-and-Verification-of-vLLM"><a href="#Installation-and-Verification-of-vLLM" class="headerlink" title="Installation and Verification of vLLM"></a>Installation and Verification of vLLM</h2><p>First, ensure that you have installed and verified vLLM version 0.5.3.</p><ol><li><p>Install vLLM:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install vllm==0.5.3</span><br></pre></td></tr></tbody></table></figure></li><li><p>Verify the installation:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> vllm</span><br><span class="line"><span class="built_in">print</span>(vllm.__version__)</span><br><span class="line"><span class="comment"># Output: 0.5.3</span></span><br></pre></td></tr></tbody></table></figure></li></ol><h2 id="Installing-Flashinfer"><a href="#Installing-Flashinfer" class="headerlink" title="Installing Flashinfer"></a>Installing Flashinfer</h2><p>Follow these steps to install Flashinfer, ensuring compatibility with your torch version and CUDA.</p><ol><li><p>Check the torch version and CUDA compatibility:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)  <span class="comment"># Should output: 2.3.1+cu121</span></span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda) <span class="comment"># Should output: 12.1</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>Install Flashinfer:<br>According to the documentation, Gemma runs on version 0.0.8. vLLM requires FlashInfer v0.0.8 (refer to <a href="https://github.com/vllm-project/vllm/issues/7060">vLLM Version and Flashinfer Documentation</a> for details on Gemma 2).</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install flashinfer==0.0.8 -i https://flashinfer.ai/whl/cu121/torch2.3/</span><br></pre></td></tr></tbody></table></figure></li></ol><h2 id="Updating-Environment-Variables-for-vLLM-Backend"><a href="#Updating-Environment-Variables-for-vLLM-Backend" class="headerlink" title="Updating Environment Variables for vLLM Backend"></a>Updating Environment Variables for vLLM Backend</h2><p>Ensure that Flashinfer is set as the attention mechanism backend for vLLM:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"VLLM_ATTENTION_BACKEND"</span>] = <span class="string">"FLASHINFER"</span></span><br></pre></td></tr></tbody></table></figure><h2 id="Testing-vLLM"><a href="#Testing-vLLM" class="headerlink" title="Testing vLLM"></a>Testing vLLM</h2><p>Here is the test code to generate text using vLLM:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">llm = LLM(model=<span class="string">"gemma-2-2b-model"</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=<span class="number">0.8</span>,</span><br><span class="line">    max_tokens=<span class="number">512</span>,</span><br><span class="line">    top_p=<span class="number">0.95</span>,</span><br><span class="line">    top_k=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example test data</span></span><br><span class="line">test_data = [{<span class="string">"text"</span>: <span class="string">"Input test text 1"</span>}, {<span class="string">"text"</span>: <span class="string">"Input test text 2"</span>}]</span><br><span class="line"></span><br><span class="line">prompts = [</span><br><span class="line">    test_data[random.randint(<span class="number">0</span>, <span class="built_in">len</span>(test_data) - <span class="number">1</span>)][<span class="string">"text"</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">outputs = llm.generate(</span><br><span class="line">    prompts,</span><br><span class="line">    sampling_params</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>By following these steps, you should be able to successfully run the fine-tuned Gemma-2-2b-it model.</p><h2 id="Common-Errors-and-Solutions"><a href="#Common-Errors-and-Solutions" class="headerlink" title="Common Errors and Solutions"></a>Common Errors and Solutions</h2><p>Here are some common errors you might encounter and their solutions:</p><ol><li><p><strong>RuntimeError: <code>CHECK_EQ(paged_kv_indptr.size(0), batch_size + 1) failed. 1 vs 257</code></strong></p><ul><li><strong>Cause</strong>: Incorrect Flashinfer version.</li><li><strong>Solution</strong>: Ensure you have installed the correct version of Flashinfer.</li></ul></li><li><p><strong>TypeError: <code>'NoneType' object is not callable</code></strong></p><ul><li><strong>Cause</strong>: Flashinfer is not installed.</li><li><strong>Solution</strong>: Install Flashinfer following the steps above.</li></ul></li><li><p><strong>ValueError: <code>Please use Flashinfer backend for models with logits_soft_cap (i.e., Gemma-2). Otherwise, the output might be wrong. Set Flashinfer backend by export VLLM_ATTENTION_BACKEND=FLASHINFER.</code></strong></p><ul><li><strong>Cause</strong>: Flashinfer backend is not set.</li><li><strong>Solution</strong>: Set the environment variable <code>VLLM_ATTENTION_BACKEND</code> to <code>FLASHINFER</code>.</li></ul></li></ol><p>By following these detailed steps and solutions, you should be able to successfully run and debug the fine-tuned Gemma-2-2b-it model. If you encounter any issues, refer to the relevant documentation or seek help from the community.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In this post, I will share the steps to run the fine-tuned Gemma-2-2b-it model using vLLM. This guide will cover the installation process</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="vLLM" scheme="https://chenhuiyu.github.io/tags/vLLM/"/>
    
    <category term="Gemma-2-2b-it" scheme="https://chenhuiyu.github.io/tags/Gemma-2-2b-it/"/>
    
  </entry>
  
  <entry>
    <title>ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2</title>
    <link href="https://chenhuiyu.github.io/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2/"/>
    <id>https://chenhuiyu.github.io/2024/08/07/NLP%20Insights/%E4%BD%BF%E7%94%A8vLLM%E8%BF%90%E8%A1%8C%E5%BE%AE%E8%B0%83%E5%90%8E%E7%9A%84Gemma-2/</id>
    <published>2024-08-07T02:30:00.000Z</published>
    <updated>2026-02-20T21:56:22.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤"><a href="#ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤" class="headerlink" title="ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤"></a>ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤</h1><p>åœ¨è¿™é‡Œåˆ†äº«ä¸€ä¸‹æˆ‘è¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itæ¨¡å‹å¹¶ä½¿ç”¨vLLMçš„æ­¥éª¤ï¼Œå¸Œæœ›å¯¹å…¶ä»–äººæœ‰æ‰€å¸®åŠ©ã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»å®‰è£…è¿‡ç¨‹ã€ç¯å¢ƒé…ç½®ä»¥åŠå¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ³•ã€‚</p><h2 id="å®‰è£…å’ŒéªŒè¯vLLM"><a href="#å®‰è£…å’ŒéªŒè¯vLLM" class="headerlink" title="å®‰è£…å’ŒéªŒè¯vLLM"></a>å®‰è£…å’ŒéªŒè¯vLLM</h2><p>é¦–å…ˆï¼Œç¡®ä¿å®‰è£…å¹¶éªŒè¯vLLMçš„ç‰ˆæœ¬æ˜¯0.5.3ã€‚</p><ol><li><p>å®‰è£…vLLMï¼š</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install vllm==0.5.3</span><br></pre></td></tr></tbody></table></figure></li><li><p>éªŒè¯å®‰è£…ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> vllm</span><br><span class="line"><span class="built_in">print</span>(vllm.__version__)</span><br><span class="line"><span class="comment"># è¾“å‡º: 0.5.3</span></span><br></pre></td></tr></tbody></table></figure></li></ol><h2 id="å®‰è£…Flashinfer"><a href="#å®‰è£…Flashinfer" class="headerlink" title="å®‰è£…Flashinfer"></a>å®‰è£…Flashinfer</h2><p>æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®‰è£…Flashinferï¼Œå¹¶ç¡®ä¿æ‚¨çš„torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ã€‚</p><ol><li><p>æ£€æŸ¥torchç‰ˆæœ¬å’ŒCUDAå…¼å®¹æ€§ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)  <span class="comment"># åº”è¾“å‡º: 2.3.1+cu121</span></span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda) <span class="comment"># åº”è¾“å‡º: 12.1</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>å®‰è£…Flashinferï¼š<br>æ ¹æ®æ–‡æ¡£ï¼ŒGemmaè¿è¡Œåœ¨ç‰ˆæœ¬0.08ã€‚vLLMéœ€è¦FlashInfer v0.0.8ï¼ˆè¯·å‚é˜…<a href="https://github.com/vllm-project/vllm/issues/7060">vLLMç‰ˆæœ¬å’ŒFlashinferæ–‡æ¡£</a>ä¸­å…³äºGemma 2çš„éƒ¨åˆ†ï¼‰ã€‚</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install flashinfer==0.0.8 -i https://flashinfer.ai/whl/cu121/torch2.3/</span><br></pre></td></tr></tbody></table></figure></li></ol><h2 id="æ›´æ–°ç¯å¢ƒä¸­çš„VLLMåç«¯å˜é‡"><a href="#æ›´æ–°ç¯å¢ƒä¸­çš„VLLMåç«¯å˜é‡" class="headerlink" title="æ›´æ–°ç¯å¢ƒä¸­çš„VLLMåç«¯å˜é‡"></a>æ›´æ–°ç¯å¢ƒä¸­çš„VLLMåç«¯å˜é‡</h2><p>ç¡®ä¿è®¾ç½®Flashinferä¸ºvLLMçš„æ³¨æ„åŠ›æœºåˆ¶åç«¯ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"VLLM_ATTENTION_BACKEND"</span>] = <span class="string">"FLASHINFER"</span></span><br></pre></td></tr></tbody></table></figure><h2 id="æµ‹è¯•vLLM"><a href="#æµ‹è¯•vLLM" class="headerlink" title="æµ‹è¯•vLLM"></a>æµ‹è¯•vLLM</h2><p>ä»¥ä¸‹æ˜¯ä½¿ç”¨vLLMç”Ÿæˆæ–‡æœ¬çš„æµ‹è¯•ä»£ç ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">llm = LLM(model=<span class="string">"gemma-2-2b-model"</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=<span class="number">0.8</span>,</span><br><span class="line">    max_tokens=<span class="number">512</span>,</span><br><span class="line">    top_p=<span class="number">0.95</span>,</span><br><span class="line">    top_k=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¤ºä¾‹æµ‹è¯•æ•°æ®</span></span><br><span class="line">test_data = [{<span class="string">"text"</span>: <span class="string">"è¾“å…¥æµ‹è¯•æ–‡æœ¬1"</span>}, {<span class="string">"text"</span>: <span class="string">"è¾“å…¥æµ‹è¯•æ–‡æœ¬2"</span>}]</span><br><span class="line"></span><br><span class="line">prompts = [</span><br><span class="line">    test_data[random.randint(<span class="number">0</span>, <span class="built_in">len</span>(test_data) - <span class="number">1</span>)][<span class="string">"text"</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">outputs = llm.generate(</span><br><span class="line">    prompts,</span><br><span class="line">    sampling_params</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¢„æœŸè¾“å‡º:</span></span><br><span class="line"><span class="comment"># Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01&lt;00:00,  1.24s/it, est. speed input: 991.44 toks/s, output: 87.79 toks/s]</span></span><br></pre></td></tr></tbody></table></figure><p>é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæ‚¨åº”è¯¥èƒ½å¤ŸæˆåŠŸè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itæ¨¡å‹ã€‚</p><h2 id="å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ³•"><a href="#å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ³•" class="headerlink" title="å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ³•"></a>å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ³•</h2><p>åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œå¯èƒ½ä¼šé‡åˆ°ä»¥ä¸‹å¸¸è§é”™è¯¯ï¼š</p><ol><li><p><strong>RuntimeError: <code>CHECK_EQ(paged_kv_indptr.size(0), batch_size + 1) failed. 1 vs 257</code></strong></p><ul><li><strong>åŸå› </strong>ï¼šFlashinferç‰ˆæœ¬é”™è¯¯ã€‚</li><li><strong>è§£å†³æ–¹æ³•</strong>ï¼šè¯·ç¡®ä¿å®‰è£…äº†æ­£ç¡®ç‰ˆæœ¬çš„Flashinferã€‚</li></ul></li><li><p><strong>TypeError: <code>'NoneType' object is not callable</code></strong></p><ul><li><strong>åŸå› </strong>ï¼šæ²¡æœ‰å®‰è£…Flashinferã€‚</li><li><strong>è§£å†³æ–¹æ³•</strong>ï¼šæŒ‰ç…§ä¸Šè¿°æ­¥éª¤å®‰è£…Flashinferã€‚</li></ul></li><li><p><strong>ValueError: <code>Please use Flashinfer backend for models with logits_soft_cap (i.e., Gemma-2). Otherwise, the output might be wrong. Set Flashinfer backend by export VLLM_ATTENTION_BACKEND=FLASHINFER.</code></strong></p><ul><li><strong>åŸå› </strong>ï¼šæœªè®¾ç½®Flashinferåç«¯ã€‚</li><li><strong>è§£å†³æ–¹æ³•</strong>ï¼šè®¾ç½®ç¯å¢ƒå˜é‡<code>VLLM_ATTENTION_BACKEND</code>ä¸º<code>FLASHINFER</code>ã€‚</li></ul></li></ol><p>é€šè¿‡ä¸Šè¿°è¯¦ç»†æ­¥éª¤å’Œè§£å†³æ–¹æ³•ï¼Œæ‚¨åº”è¯¥èƒ½å¤ŸæˆåŠŸè¿è¡Œå¹¶è°ƒè¯•å¾®è°ƒåçš„Gemma-2-2b-itæ¨¡å‹ã€‚å¦‚æœæ‚¨åœ¨ä»»ä½•ä¸€æ­¥é‡åˆ°é—®é¢˜ï¼Œè¯·å‚è€ƒç›¸åº”çš„æ–‡æ¡£æˆ–åœ¨ç¤¾åŒºä¸­å¯»æ±‚å¸®åŠ©ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤&quot;&gt;&lt;a href=&quot;#ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤&quot; class=&quot;headerlink&quot; title=&quot;ä½¿ç”¨vLLMè¿è¡Œå¾®è°ƒåçš„Gemma-2-2b-itçš„è¯¦ç»†æ­¥éª¤&quot;&gt;</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="vLLM" scheme="https://chenhuiyu.github.io/tags/vLLM/"/>
    
    <category term="Gemma-2" scheme="https://chenhuiyu.github.io/tags/Gemma-2/"/>
    
  </entry>
  
  <entry>
    <title>å¦‚ä½•å‡†ç¡®è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰</title>
    <link href="https://chenhuiyu.github.io/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL)/"/>
    <id>https://chenhuiyu.github.io/2024/04/17/NLP%20Insights/%20%E5%9B%B0%E6%83%91%E5%BA%A6(PPL)/</id>
    <published>2024-04-17T04:00:00.000Z</published>
    <updated>2026-02-20T21:56:22.870Z</updated>
    
    <content type="html"><![CDATA[<h1 id="å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰"><a href="#å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰" class="headerlink" title="å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰"></a>å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰</h1><p>å›°æƒ‘åº¦ï¼ˆPPLï¼‰æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹æœ€å¸¸ç”¨çš„æŒ‡æ ‡ä¹‹ä¸€ã€‚åœ¨æ·±å…¥æ¢è®¨ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥æ³¨æ„è¿™ä¸ªæŒ‡æ ‡ç‰¹åˆ«é€‚ç”¨äºä¼ ç»Ÿè¯­è¨€æ¨¡å‹ï¼ˆæœ‰æ—¶è¢«ç§°ä¸ºè‡ªå›å½’æˆ–å› æœè¯­è¨€æ¨¡å‹ï¼‰ï¼Œè€Œå¯¹äºåƒ BERT è¿™æ ·çš„ masked language models åˆ™æ²¡æœ‰æ˜ç¡®å®šä¹‰ï¼ˆè§<a href="https://huggingface.co/docs/transformers/main/en/model_summary">æ¨¡å‹æ€»ç»“</a>ï¼‰ã€‚</p><p>å›°æƒ‘åº¦è¢«å®šä¹‰ä¸ºåºåˆ—çš„æŒ‡æ•°åŒ–å¹³å‡è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ ‡è®°åŒ–åºåˆ— $X = (x_0, x_1, \dots, x_t)$ï¼Œé‚£ä¹ˆ $X$ çš„å›°æƒ‘åº¦ä¸ºï¼Œ</p><p>$$<br>\text{PPL}(X) = \exp \left{ -\frac{1}{t}\sum*{i=1}^t \log p<em>\theta (x</em>i|x*{&lt;i}) \right}<br>$$</p><p>å…¶ä¸­ $\log p<em>\theta (x_i|x</em>{&lt;i})$ æ˜¯ç¬¬ i ä¸ªæ ‡è®°çš„å¯¹æ•°ä¼¼ç„¶ï¼Œæ¡ä»¶æ˜¯æ ¹æ®æˆ‘ä»¬çš„æ¨¡å‹å‰é¢çš„æ ‡è®° $x_{&lt;i}$ã€‚ç›´è§‚ä¸Šï¼Œå®ƒå¯ä»¥è¢«è®¤ä¸ºæ˜¯è¯„ä¼°æ¨¡å‹åœ¨è¯­æ–™åº“ä¸­æŒ‡å®šæ ‡è®°é›†åˆä¸Šé¢„æµ‹å‡åŒ€æ€§çš„èƒ½åŠ›ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™æ„å‘³ç€æ ‡è®°åŒ–ç¨‹åºç›´æ¥å½±å“æ¨¡å‹çš„å›°æƒ‘åº¦ï¼Œè¿™åœ¨æ¯”è¾ƒä¸åŒæ¨¡å‹æ—¶åº”å§‹ç»ˆè€ƒè™‘ã€‚</p><p>è¿™ä¹Ÿç›¸å½“äºæ•°æ®å’Œæ¨¡å‹é¢„æµ‹ä¹‹é—´çš„äº¤å‰ç†µçš„æŒ‡æ•°åŒ–ã€‚æƒ³è¦äº†è§£æ›´å¤šå…³äºå›°æƒ‘åº¦åŠå…¶ä¸æ¯å­—ç¬¦ä½æ•°ï¼ˆBPCï¼‰å’Œæ•°æ®å‹ç¼©çš„å…³ç³»çš„ç›´è§‰ï¼Œå¯ä»¥æŸ¥çœ‹è¿™ç¯‡åœ¨ The Gradient ä¸Šçš„<a href="https://thegradient.pub/understanding-evaluation-metrics-for-language-models/">ç²¾å½©åšå®¢æ–‡ç« </a>ã€‚</p><h2 id="Calculating-PPL-with-fixed-length-models"><a href="#Calculating-PPL-with-fixed-length-models" class="headerlink" title="Calculating PPL with fixed-length models"></a>Calculating PPL with fixed-length models</h2><p>å¦‚æœæˆ‘ä»¬ä¸å—æ¨¡å‹ä¸Šä¸‹æ–‡å¤§å°çš„é™åˆ¶ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡è‡ªå›å½’åœ°åˆ†è§£åºåˆ—å¹¶åœ¨æ¯ä¸€æ­¥éƒ½åŸºäºæ•´ä¸ªå‰åºå­åºåˆ—æ¥æ¡ä»¶åŒ–ï¼Œä»è€Œè¯„ä¼°æ¨¡å‹çš„å›°æƒ‘åº¦ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><img width="600" alt="Full decomposition of a sequence with unlimited context length" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif"><p>ç„¶è€Œï¼Œåœ¨å¤„ç†è¿‘ä¼¼æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å—åˆ°æ¨¡å‹å¯ä»¥å¤„ç†çš„æ ‡è®°æ•°é‡çš„é™åˆ¶ã€‚ä¾‹å¦‚ï¼Œ<a href="https://huggingface.co/docs/transformers/main/en/model_doc/gpt2">GPT-2</a>çš„æœ€å¤§ç‰ˆæœ¬æœ‰å›ºå®šçš„ 1024 ä¸ªæ ‡è®°é•¿åº¦ï¼Œæ‰€ä»¥å½“ $t$ å¤§äº 1024 æ—¶ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®— $p<em>\theta(x_t|x</em>{&lt;t})$ã€‚</p><p>ç›¸åï¼Œåºåˆ—é€šå¸¸è¢«åˆ†è§£æˆç­‰äºæ¨¡å‹æœ€å¤§è¾“å…¥å¤§å°çš„å­åºåˆ—ã€‚å¦‚æœæ¨¡å‹çš„æœ€å¤§è¾“å…¥å¤§å°æ˜¯ $k$ï¼Œé‚£ä¹ˆæˆ‘ä»¬é€šè¿‡åªæ¡ä»¶åŒ–å‰ $k-1$ ä¸ªæ ‡è®°ï¼ˆè€Œä¸æ˜¯æ•´ä¸ªä¸Šä¸‹æ–‡ï¼‰æ¥è¿‘ä¼¼è®¡ç®—ä¸€ä¸ªæ ‡è®° $x_t$ çš„ä¼¼ç„¶ã€‚åœ¨è¯„ä¼°æ¨¡å‹åºåˆ—çš„å›°æƒ‘åº¦æ—¶ï¼Œä¸€ç§è¯±äººä½†æ¬¡ä¼˜çš„æ–¹æ³•æ˜¯å°†åºåˆ—åˆ†è§£æˆä¸ç›¸äº¤çš„å—ï¼Œå¹¶ç‹¬ç«‹åœ°ç´¯åŠ æ¯ä¸ªæ®µçš„åˆ†è§£å¯¹æ•°ä¼¼ç„¶ã€‚</p><img width="600" alt="Suboptimal PPL not taking advantage of full available context" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif"><p>è¿™ç§è®¡ç®—å¾ˆå¿«ï¼Œå› ä¸ºæ¯ä¸ªæ®µçš„å›°æƒ‘åº¦å¯ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­è®¡ç®—å‡ºæ¥ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªè¾ƒå·®çš„å®Œå…¨åˆ†è§£å›°æƒ‘åº¦çš„è¿‘ä¼¼ï¼Œå¹¶ä¸”é€šå¸¸ä¼šäº§ç”Ÿæ›´é«˜ï¼ˆæ›´å·®ï¼‰çš„ PPLï¼Œå› ä¸ºæ¨¡å‹åœ¨å¤§å¤šæ•°é¢„æµ‹æ­¥éª¤ä¸­çš„ä¸Šä¸‹æ–‡è¾ƒå°‘ã€‚</p><p>ç›¸åï¼Œåº”è¯¥ä½¿ç”¨æ»‘åŠ¨çª—å£ç­–ç•¥æ¥è¯„ä¼°å›ºå®šé•¿åº¦æ¨¡å‹çš„ PPLã€‚è¿™æ¶‰åŠåˆ°é‡å¤æ»‘åŠ¨ä¸Šä¸‹æ–‡çª—å£ï¼Œä½¿æ¨¡å‹åœ¨åšå‡ºæ¯ä¸ªé¢„æµ‹æ—¶æ‹¥æœ‰æ›´å¤šçš„ä¸Šä¸‹æ–‡ã€‚</p><img width="600" alt="Sliding window PPL taking advantage of all available context" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_sliding.gif"><ol><li><p><strong>æ— é™ä¸Šä¸‹æ–‡åˆ†è§£ï¼š</strong> å¦‚æœæ²¡æœ‰å¯¹æ¨¡å‹è¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¯ä¸€æ­¥éƒ½ä½¿ç”¨æ•´ä¸ªå‰åºå­åºåˆ—æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªæ ‡è®°ã€‚è¿™æ ·å¯ä»¥æœ€å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå› ä¸ºæ¯æ¬¡é¢„æµ‹éƒ½è€ƒè™‘äº†æ‰€æœ‰å…ˆå‰çš„ä¿¡æ¯ã€‚</p></li><li><p><strong>å›ºå®šé•¿åº¦é™åˆ¶ï¼š</strong> å®é™…ä¸­ï¼Œå¤§å¤šæ•°æ¨¡å‹å¦‚ GPT-2 æœ‰å›ºå®šçš„è¾“å…¥é•¿åº¦é™åˆ¶ï¼ˆä¾‹å¦‚ 1024 ä¸ªæ ‡è®°ï¼‰ã€‚å½“åºåˆ—é•¿åº¦è¶…è¿‡è¿™ä¸ªé™åˆ¶æ—¶ï¼Œä¸èƒ½ç›´æ¥è®¡ç®—æ¯ä¸ªæ ‡è®°çš„æ¡ä»¶æ¦‚ç‡ï¼Œå› ä¸ºä¸èƒ½å°†æ•´ä¸ªåºåˆ—ä½œä¸ºæ¡ä»¶ã€‚</p></li><li><p><strong>åˆ†å—è¿‘ä¼¼ï¼š</strong> ä¸€ç§å¤„ç†é•¿åºåˆ—çš„æ–¹æ³•æ˜¯å°†åºåˆ—åˆ†è§£æˆå¤šä¸ªä¸æ¨¡å‹æœ€å¤§è¾“å…¥é•¿åº¦ç›¸ç­‰çš„å­åºåˆ—ã€‚æ¯ä¸ªå­åºåˆ—å•ç‹¬è¯„ä¼°ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½ä¼šå› ä¸ºæ²¡æœ‰ä½¿ç”¨å®Œæ•´çš„ä¸Šä¸‹æ–‡è€Œå¯¼è‡´æ›´é«˜çš„å›°æƒ‘åº¦ã€‚</p></li><li><p><strong>æ»‘åŠ¨çª—å£ç­–ç•¥ï¼š</strong> ä¸ºäº†æ›´å¥½åœ°åˆ©ç”¨å¯ç”¨çš„ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ä½¿ç”¨æ»‘åŠ¨çª—å£ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•é€šè¿‡ä¸æ–­ç§»åŠ¨ä¸Šä¸‹æ–‡çª—å£æ¥å°è¯•åœ¨æ¯æ¬¡é¢„æµ‹æ—¶ä¸ºæ¨¡å‹æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæ›´æ¥è¿‘äºä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡çš„ç†æƒ³æƒ…å†µã€‚</p></li><li><p><strong>è·¨æ­¥æ»‘åŠ¨çª—å£ï¼š</strong> ä¸€ä¸ªå®é™…çš„æŠ˜ä¸­æ–¹æ³•æ˜¯ä½¿ç”¨è·¨æ­¥æ»‘åŠ¨çª—å£ï¼Œè¿™æ ·å¯ä»¥åœ¨ä¿è¯ä¸€å®šæ•ˆç‡çš„åŒæ—¶ï¼Œä¸ºæ¯æ¬¡æ¨¡å‹é¢„æµ‹æä¾›è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ï¼Œä»è€Œæ”¹å–„å›°æƒ‘åº¦çš„è®¡ç®—å’Œæ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</p></li></ol><p>è¿™äº›æ–¹æ³•éƒ½æ˜¯ä¸ºäº†è§£å†³å› æ¨¡å‹è¾“å…¥é•¿åº¦é™åˆ¶è€Œä¸èƒ½ç›´æ¥è¯„ä¼°æ•´ä¸ªåºåˆ—çš„é—®é¢˜ï¼Œè¯•å›¾é€šè¿‡ä¸åŒçš„æŠ€æœ¯ä½¿è¯„ä¼°æ›´åŠ å‡†ç¡®ï¼ŒåŒæ—¶è€ƒè™‘åˆ°è®¡ç®—èµ„æºçš„æœ‰æ•ˆä½¿ç”¨ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰&quot;&gt;&lt;a href=&quot;#å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰&quot; class=&quot;headerlink&quot; title=&quot;å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰&quot;&gt;&lt;/a&gt;å¦‚ä½•è®¡ç®—å›ºå®šé•¿åº¦æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰&lt;/h1&gt;&lt;p&gt;å›°æƒ‘</summary>
      
    
    
    
    <category term="NLP Insights" scheme="https://chenhuiyu.github.io/categories/NLP-Insights/"/>
    
    
    <category term="Language Modeling" scheme="https://chenhuiyu.github.io/tags/Language-Modeling/"/>
    
    <category term="Perplexity" scheme="https://chenhuiyu.github.io/tags/Perplexity/"/>
    
  </entry>
  
</feed>
