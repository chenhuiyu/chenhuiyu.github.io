<!DOCTYPE html><html lang="[&quot;zh-CN&quot;,&quot;en&quot;]" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰² | é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…</title><meta name="author" content="Huiyu Chen"><meta name="copyright" content="Huiyu Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²åŸæ–‡åœ°å€ï¼šA Visual Guide to Mixture of Experts (MoE) ğŸ“… ä½œè€…ï¼šMaarten Grootendorst ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥  æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—ç›®å½• MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰² æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶">
<meta property="og:type" content="article">
<meta property="og:title" content="MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²">
<meta property="og:url" content="https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/index.html">
<meta property="og:site_name" content="é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…">
<meta property="og:description" content="MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²åŸæ–‡åœ°å€ï¼šA Visual Guide to Mixture of Experts (MoE) ğŸ“… ä½œè€…ï¼šMaarten Grootendorst ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥  æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—ç›®å½• MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰² æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://chenhuiyu.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-02-11T03:50:29.000Z">
<meta property="article:modified_time" content="2026-02-20T21:46:38.693Z">
<meta property="article:author" content="Huiyu Chen">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chenhuiyu.github.io/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²",
  "url": "https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/",
  "image": "https://chenhuiyu.github.io/img/butterfly-icon.png",
  "datePublished": "2025-02-11T03:50:29.000Z",
  "dateModified": "2026-02-20T21:46:38.693Z",
  "author": [
    {
      "@type": "Person",
      "name": "Huiyu Chen",
      "url": "https://chenhuiyu.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶å¤±è´¥',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: 'åŠ è½½æ›´å¤š'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div class="bg-animation" id="web_bg" style="background-image: url(/img/site-bg.jpg);"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…</span></a><a class="nav-page-title" href="/"><span class="site-name">MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  è¿”å›é¦–é¡µ</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2025-02-11T03:50:29.000Z" title="å‘è¡¨äº 2025-02-11 11:50:29">2025-02-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2026-02-20T21:46:38.693Z" title="æ›´æ–°äº 2026-02-21 05:46:38">2026-02-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NLP-Insights/">NLP Insights</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">æµè§ˆé‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="MoE-æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜-MoE-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²"><a href="#MoE-æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜-MoE-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²" class="headerlink" title="MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²"></a>MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</h1><p><strong>åŸæ–‡åœ°å€</strong>ï¼š<a target="_blank" rel="noopener" href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts">A Visual Guide to Mixture of Experts (MoE)</a></p>
<p>ğŸ“… ä½œè€…ï¼šMaarten Grootendorst</p>
<p>ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥</p>
<hr>
<h1 id="æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—"><a href="#æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—" class="headerlink" title="æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—"></a>æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—</h1><h2 id="ç›®å½•"><a href="#ç›®å½•" class="headerlink" title="ç›®å½•"></a>ç›®å½•</h2><ul>
<li><a href="#moe-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%E6%8F%AD%E7%A7%98-moe-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</a></li>
<li><a href="#%E6%8E%A2%E7%B4%A2%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8Bmoe%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97">æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—</a><ul>
<li><a href="#%E7%9B%AE%E5%BD%95">ç›®å½•</a></li>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6moe%E6%A8%A1%E5%9E%8B">ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ</a></li>
<li><a href="#experts">Experts</a><ul>
<li><a href="#dense-layers">Dense Layers</a></li>
<li><a href="#sparse-layers">Sparse Layers</a></li>
<li><a href="#what-does-an-expert-learn">What does an Expert Learn?</a></li>
<li><a href="#%E4%B8%93%E5%AE%B6%E7%9A%84%E6%9E%B6%E6%9E%84architecture-of-experts">ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>å½“æˆ‘ä»¬æŸ¥çœ‹æœ€æ–°å‘å¸ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆ<strong>LLMs</strong>ï¼ŒLarge Language Modelsï¼‰æ—¶ï¼Œå¸¸å¸¸ä¼šåœ¨æ ‡é¢˜ä¸­çœ‹åˆ° â€œ<strong>MoE</strong>â€ã€‚è¿™ä¸ª â€œMoEâ€ ä»£è¡¨ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¿™ä¹ˆå¤š LLM éƒ½åœ¨ä½¿ç”¨å®ƒï¼Ÿ</p>
<p>åœ¨è¿™ä»½å¯è§†åŒ–æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ 50 å¤šä¸ªå¯è§†åŒ–å›¾ç¤ºï¼Œé€æ­¥æ¢ç´¢è¿™ä¸€å…³é”®ç»„ä»¶ï¼š**Mixture of Experts (MoE)**ã€‚</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_145859.png" class="">

<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šåœ¨è¿™å¼ å›¾ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¸€ä¸ªå…¸å‹ <strong>MoE</strong> ç»“æ„çš„ä¸¤ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š<strong>Experts</strong>ï¼ˆä¸“å®¶ï¼‰å’Œ <strong>Router</strong>ï¼ˆè·¯ç”±å™¨æˆ–é—¨æ§ç½‘ç»œï¼‰ã€‚å›¾ä¸­æ˜¾ç¤ºäº†ä¸€ä¸ª <strong>Router</strong>ï¼Œä»¥åŠä¸‹æ–¹å¹¶åˆ—çš„å¤šä¸ª <strong>Experts</strong>ï¼Œè¡¨æ˜åœ¨ <strong>LLM</strong> æ¶æ„ä¸­ï¼ŒMoE ä¼šå°†è¾“å…¥æ ¹æ®éœ€è¦è·¯ç”±åˆ°åˆé€‚çš„ä¸“å®¶ã€‚<br><strong>å›¾ 1 è¯¦ç»†è¯´æ˜</strong>ï¼š</p>
<ol>
<li><strong>Router</strong>ï¼šå†³å®šå°†è¾“å…¥ï¼ˆä¾‹å¦‚ tokenï¼‰å‘é€ç»™å“ªä¸€ä¸ªæˆ–å“ªå‡ ä¸ªä¸“å®¶ã€‚</li>
<li><strong>Experts</strong>ï¼šè‹¥å¹²ä¸ªä¸åŒçš„å­æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ <strong>FFNN</strong> ç»“æ„ï¼‰ï¼Œæ¯ä¸ªä¸“å®¶å¯èƒ½åœ¨ä¸åŒæ–¹é¢å…·æœ‰ä¸“é•¿ã€‚</li>
<li><strong>å·¥ä½œæµç¨‹</strong>ï¼šè¾“å…¥å…ˆé€šè¿‡ <strong>Router</strong>ï¼Œå†è¢«åˆ†é…åˆ°ä¸åŒçš„ä¸“å®¶è¿›è¡Œå¤„ç†ï¼Œæœ€åæ±‡æ€»ç»“æœã€‚</li>
</ol>
<h2 id="ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ</h2><p><strong>Mixture of Experts (MoE)</strong> æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨è®¸å¤šä¸åŒçš„å­æ¨¡å‹ï¼ˆæˆ–â€œ<strong>experts</strong>â€ï¼‰æ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è´¨é‡ã€‚</p>
<p>åœ¨ MoE ä¸­ï¼Œæœ‰ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š</p>
<ol>
<li><strong>Experts</strong><ul>
<li>æ¯ä¸ª <strong>FFNN</strong> å±‚éƒ½ä¸å†æ˜¯ä¸€ä¸ªå•ç‹¬çš„ç½‘ç»œï¼Œè€Œæ˜¯æœ‰ä¸€ç»„â€œä¸“å®¶â€å¯ä¾›é€‰æ‹©ã€‚</li>
<li>è¿™äº›â€œä¸“å®¶â€é€šå¸¸ä¹Ÿæ˜¯ <strong>FFNN</strong>ï¼ˆFeedforward Neural Networkï¼‰ç»“æ„ã€‚</li>
</ul>
</li>
<li><strong>Router</strong> æˆ– <strong>gate network</strong><ul>
<li>è´Ÿè´£å†³å®šå“ªäº› <strong>tokens</strong> è¢«å‘é€åˆ°å“ªäº›ä¸“å®¶ã€‚</li>
</ul>
</li>
</ol>
<p>åœ¨ä¸€ä¸ªå¸¦æœ‰ MoE çš„ <strong>LLM</strong> çš„æ¯ä¸€å±‚ï¼Œæˆ‘ä»¬éƒ½èƒ½çœ‹åˆ°ï¼ˆåœ¨æŸç§ç¨‹åº¦ä¸Šï¼‰æœ‰æ‰€ä¸“é—¨åŒ–çš„ä¸“å®¶ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_150409.png" class="">

<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†åœ¨ <strong>LLM</strong> çš„æ¯ä¸€å±‚éƒ½å¯ä»¥æ‹¥æœ‰å¤šä¸ª <strong>Experts</strong>ã€‚å®ƒå¼ºè°ƒäº†è¿™äº›ä¸“å®¶åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­èƒ½å¤Ÿå¤„ç†ä¸åŒçš„è¾“å…¥ tokenã€‚<br><strong>å›¾2è¯¦ç»†è¯´æ˜</strong>ï¼š  </p>
<ol>
<li><strong>å±‚ç»“æ„</strong>ï¼šå›¾ä¸­ç”¨ä¸åŒçš„å±‚çº§ï¼ˆLayer 1ã€Layer 2ã€Layer 3â€¦â€¦ï¼‰è¡¨ç¤ºå¤šå±‚æ¨¡å‹ã€‚  </li>
<li><strong>Experts</strong>ï¼šåœ¨æ¯ä¸€å±‚ï¼Œéƒ½æœ‰è‹¥å¹²ä¸ªä¸“å®¶ï¼ˆExpert 1ã€Expert 2ã€Expert 3ã€Expert 4ï¼‰ï¼Œè¿™äº›ä¸“å®¶å¹¶è¡Œå­˜åœ¨ã€‚  </li>
<li><strong>ç›®æ ‡</strong>ï¼šå¼ºè°ƒä¸“å®¶åœ¨ç‰¹å®šä¸Šä¸‹æ–‡æˆ–ç‰¹å®šè¾“å…¥æ—¶æ›´å…·å¤‡â€œä¸“ä¸šæ€§â€ï¼Œä»è€Œè¢«é€‰ä¸­æ¥å¤„ç†è¯¥è¾“å…¥ã€‚</li>
</ol>
<p>å°½ç®¡ MoE å¹¶ä¸ä¼šåœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚å¿ƒç†å­¦æˆ–ç”Ÿç‰©å­¦ï¼‰ä¸Šä¸“é—¨è®­ç»ƒä¸“å®¶ï¼Œä½†å®ƒä»¬ä»å¯èƒ½åœ¨è¯æ³•æˆ–å¥æ³•çº§åˆ«ä¸Šå½¢æˆä¸€å®šçš„åå‘ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_153715.png" class="">

<ul>
<li><strong>MoE ä¸“å®¶å¯èƒ½å­¦ä¹ åˆ°ä¸åŒçš„è¯­è¨€ç‰¹å¾</strong><ul>
<li><strong>Expert 1</strong> å¤„ç†<strong>æ ‡ç‚¹ç¬¦å·</strong>ï¼ˆPunctuationï¼‰ï¼šå¦‚ <code>, . : &amp; - ?</code> ç­‰ã€‚</li>
<li><strong>Expert 2</strong> å¤„ç†<strong>åŠ¨è¯</strong>ï¼ˆVerbsï¼‰ï¼šå¦‚ <code>said, read, miss</code> ç­‰ã€‚</li>
<li><strong>Expert 3</strong> å¤„ç†<strong>è¿æ¥è¯</strong>ï¼ˆConjunctionsï¼‰ï¼šå¦‚ <code>the, and, if, not</code> ç­‰ã€‚</li>
<li><strong>Expert 4</strong> å¤„ç†<strong>è§†è§‰æè¿°è¯</strong>ï¼ˆVisual Descriptionsï¼‰ï¼šå¦‚ <code>dark, outer, yellow</code> ç­‰ã€‚</li>
</ul>
</li>
</ul>
<p>æ›´å…·ä½“åœ°è¯´ï¼Œä»–ä»¬çš„ä¸“é•¿æ˜¯åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­å¤„ç†ç‰¹å®šçš„æ ‡è®°ï¼ˆtokensï¼‰ã€‚</p>
<hr>
<p><strong>Router (gate network)</strong> é€‰æ‹©æœ€é€‚åˆç»™å®šè¾“å…¥çš„ä¸“å®¶æˆ–ä¸“å®¶ç»„åˆï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_153924.png" class="">

<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº† <strong>Router</strong> å¦‚ä½•åœ¨æ¯ä¸€å±‚æ ¹æ®è¾“å…¥é€‰æ‹©åˆé€‚çš„ä¸“å®¶ã€‚å›¾ä¸­é«˜äº®äº†è¢«é€‰ä¸­çš„ä¸“å®¶ï¼Œä»¥åŠè¾“å…¥ token çš„æµåŠ¨è¿‡ç¨‹ã€‚<br><strong>å›¾3è¯¦ç»†è¯´æ˜</strong>ï¼š  </p>
<ol>
<li><strong>è¾“å…¥</strong>ï¼šå›¾é¡¶éƒ¨çš„ Input ä»£è¡¨æ¨¡å‹æ¥æ”¶åˆ°çš„ token æˆ–å‘é‡è¡¨ç¤ºã€‚  </li>
<li><strong>Router</strong>ï¼šä½äºç½‘ç»œç»“æ„ä¸­ï¼Œèµ·åˆ°å†³ç­–ä½œç”¨ã€‚  </li>
<li><strong>ä¸“å®¶é€‰æ‹©</strong>ï¼šè¢«é€‰ä¸­çš„ä¸“å®¶ä¼šæ¥æ”¶è¾“å…¥ï¼Œå…¶ä½™ä¸“å®¶åˆ™ä¸è¢«æ¿€æ´»ã€‚  </li>
<li><strong>è¾“å‡º</strong>ï¼šæ¥è‡ªè¢«æ¿€æ´»ä¸“å®¶çš„ç»“æœè¢«æ±‡æ€»æˆ–ç»§ç»­æµå‘ä¸‹æ¸¸å±‚ã€‚</li>
</ol>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ¯ä¸ªä¸“å®¶å¹¶ä¸æ˜¯æ•´ä¸ª LLMï¼Œè€Œæ˜¯ <strong>LLM</strong> æ¶æ„ä¸­çš„ä¸€ä¸ªå­æ¨¡å‹éƒ¨åˆ†ã€‚</p>
<hr>
<h2 id="Experts"><a href="#Experts" class="headerlink" title="Experts"></a>Experts</h2><p>ä¸ºäº†ç†è§£ä¸“å®¶ï¼ˆ<strong>Experts</strong>ï¼‰æ˜¯ä»€ä¹ˆä»¥åŠå®ƒä»¬å¦‚ä½•å·¥ä½œï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ MoE å¸Œæœ›æ›¿ä»£çš„ä¸œè¥¿ï¼š<strong>dense layers</strong>ã€‚</p>
<h3 id="Dense-Layers"><a href="#Dense-Layers" class="headerlink" title="Dense Layers"></a>Dense Layers</h3><p>æ‰€æœ‰çš„ <strong>Mixture of Experts (MoE)</strong> éƒ½åŸºäº LLM ä¸­ä¸€ä¸ªç›¸å¯¹åŸºç¡€çš„åŠŸèƒ½ï¼š**Feedforward Neural Network (FFNN)**ã€‚</p>
<p>å›å¿†ä¸€ä¸‹ï¼Œä¸€ä¸ªæ ‡å‡†çš„ <strong>decoder-only Transformer</strong> æ¶æ„ä¸­ï¼Œ<strong>FFNN</strong> é€šå¸¸æ˜¯åœ¨ <strong>layer normalization</strong> ä¹‹ååº”ç”¨çš„ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_154729.png" class="">
<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªå…¸å‹çš„ <strong>decoder</strong> ç»“æ„ï¼Œæ¯ä¸ª <strong>decoder block</strong> åŒ…å« <strong>Masked Self-Attention</strong> å’Œ <strong>FFNN</strong>ï¼ˆä¸­é—´ä¼šæœ‰ <strong>Layer Norm</strong>ï¼‰ã€‚  </p>
<ol>
<li><strong>Position Embedding</strong>ï¼šåœ¨è¾“å…¥ token ä¹‹å‰æˆ–åŒæ—¶åŠ å…¥ä½ç½®ç¼–ç ä¿¡æ¯ã€‚  </li>
<li><strong>Decoder Block</strong>ï¼šåŒ…å« <strong>Masked Self-Attention</strong>ã€<strong>Layer Norm</strong> å’Œ <strong>FFNN</strong>ã€‚  </li>
<li><strong>FFNN</strong>ï¼šåœ¨å›¾ä¸­ç”¨ç´«è‰²æ–¹å—è¡¨ç¤ºï¼Œæ˜¯è¯¥å±‚å¯¹è¾“å…¥è¿›ä¸€æ­¥å˜æ¢ä»¥æ•æ‰æ›´å¤æ‚å…³ç³»çš„å…³é”®ç»„ä»¶ã€‚</li>
</ol>
<p><strong>FFNN</strong> å¯ä»¥åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶äº§ç”Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¹å…¶è¿›è¡Œè¿›ä¸€æ­¥çš„è½¬æ¢ï¼Œä»¥æ•æ‰æ•°æ®ä¸­æ›´å¤æ‚çš„å…³ç³»ã€‚</p>
<p>ä¸è¿‡ï¼Œä¸ºäº†å­¦ä¹ è¿™äº›å¤æ‚å…³ç³»ï¼Œ<strong>FFNN</strong> çš„è§„æ¨¡ä¼šéšä¹‹å¢é•¿ï¼Œé€šå¸¸ä¼šåœ¨è¾“å…¥ä¸Šè¿›è¡Œæ‰©å¼ ï¼ˆä¾‹å¦‚ï¼Œä¸­é—´å±‚ç»´åº¦ä¼šå˜å¤§ï¼‰ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_154923.png" class="">
<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ª <strong>FFNN</strong> çš„ç»“æ„ï¼Œè¾“å…¥å…ˆè¢«æ˜ å°„åˆ°æ›´é«˜ç»´åº¦ï¼Œç„¶åå†è¢«æ˜ å°„å›è¾“å‡ºç»´åº¦ã€‚  </p>
<ol>
<li><strong>è¾“å…¥ç»´åº¦</strong>ï¼šå›¾ä¸­æ˜¾ç¤ºæœ‰ 512 ä¸ªè¾“å…¥å•å…ƒã€‚  </li>
<li><strong>éšè—å±‚</strong>ï¼šé€šå¸¸ä¼šæœ‰ 4 å€æˆ–æ›´å¤šçš„æ‰©å¼ ï¼ˆå›¾ä¸­ç¤ºä¾‹ä¸º 4 å€æ‰©å¼ åˆ° 2048 ç»´ï¼‰ã€‚  </li>
<li><strong>è¾“å‡ºç»´åº¦</strong>ï¼šå†æ˜ å°„å› 512 ç»´çš„è¾“å‡ºã€‚</li>
</ol>
<h3 id="Sparse-Layers"><a href="#Sparse-Layers" class="headerlink" title="Sparse Layers"></a>Sparse Layers</h3><p>åœ¨ä¼ ç»Ÿçš„ Transformer ä¸­ï¼Œ<strong>FFNN</strong> ç§°ä¸º <strong>dense model</strong>ï¼Œå› ä¸ºå®ƒçš„æ‰€æœ‰å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰éƒ½ä¼šè¢«æ¿€æ´»ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹çš„å…¨éƒ¨å‚æ•°éƒ½å‚ä¸è®¡ç®—è¾“å‡ºã€‚</p>
<p>å¦‚æœæˆ‘ä»¬ä»”ç»†è§‚å¯Ÿ <strong>dense model</strong>ï¼Œå¯ä»¥çœ‹åˆ°è¾“å…¥ä¼šæ¿€æ´»æ‰€æœ‰çš„å‚æ•°ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_163850.png" class="">
<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªâ€œå¯†é›†â€æ¨¡å‹ï¼Œè¾“å…¥å±‚çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä¸éšè—å±‚æ‰€æœ‰ç¥ç»å…ƒç›¸è¿ï¼Œéšè—å±‚æ‰€æœ‰ç¥ç»å…ƒåˆä¸è¾“å‡ºå±‚ç¥ç»å…ƒç›¸è¿ã€‚<br><strong>å›¾6è¯¦ç»†è¯´æ˜</strong>ï¼š  </p>
<ol>
<li><strong>å…¨è¿æ¥</strong>ï¼šå›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹éƒ½è¿æ¥åˆ°ä¸‹ä¸€å±‚çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œè¡¨ç¤ºæ— ç¨€ç–æ€§ã€‚  </li>
<li><strong>æ‰€æœ‰å‚æ•°è¢«æ¿€æ´»</strong>ï¼šæ²¡æœ‰ä»»ä½•â€œé—²ç½®â€æˆ–â€œæœªæ¿€æ´»â€çš„å‚æ•°ã€‚</li>
</ol>
<p>ä¸ä¹‹å¯¹æ¯”ï¼Œ<strong>sparse models</strong>ï¼ˆç¨€ç–æ¨¡å‹ï¼‰åªæ¿€æ´»ä¸€éƒ¨åˆ†æ€»å‚æ•°ï¼Œè¿™ä¸ <strong>Mixture of Experts</strong> å¯†åˆ‡ç›¸å…³ã€‚</p>
<p>ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ <strong>dense model</strong> åˆ‡åˆ†æˆå¤šä¸ªéƒ¨åˆ†ï¼ˆå³ä¸“å®¶ï¼Œ<strong>experts</strong>ï¼‰ï¼Œé‡æ–°è®­ç»ƒå®ƒï¼Œå¹¶ä¸”åœ¨æ¨ç†ï¼ˆinferenceï¼‰æ—¶åªæ¿€æ´»å…¶ä¸­ä¸€éƒ¨åˆ†ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_164042.png" class="">

<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå°†åŸæœ¬çš„å¯†é›†æ¨¡å‹åˆ†å‰²æˆå¤šä¸ªä¸“å®¶ï¼ˆExpert 1ã€Expert 2ã€Expert 3ã€Expert 4ï¼‰ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œåªé€‰æ‹©ä¸€éƒ¨åˆ†ä¸“å®¶è¿›è¡Œæ¿€æ´»ã€‚  </p>
<ol>
<li><strong>æ¨¡å‹åˆ‡åˆ†</strong>ï¼šåŸæœ‰çš„å¤§ç½‘ç»œè¢«æ‹†åˆ†æˆå¤šä¸ªè¾ƒå°çš„â€œä¸“å®¶â€ã€‚  </li>
<li><strong>ç¨€ç–æ¿€æ´»</strong>ï¼šå¹¶ä¸æ˜¯æ‰€æœ‰ä¸“å®¶éƒ½è¢«æ¿€æ´»ï¼Œåªæœ‰éƒ¨åˆ†ä¸“å®¶åœ¨æŸäº›è¾“å…¥ä¸‹è¢«æ¿€æ´»ã€‚  </li>
<li><strong>å¥½å¤„</strong>ï¼šé€šè¿‡ç¨€ç–æ¿€æ´»ï¼Œå¯ä»¥åœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œæ‹¥æœ‰æ›´å¤šçš„æ½œåœ¨å‚æ•°å®¹é‡ã€‚</li>
</ol>
<p>å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨è®­ç»ƒæœŸé—´ï¼Œæ¯ä¸ªä¸“å®¶å­¦ä¹ ä¸åŒçš„ä¿¡æ¯ï¼›åœ¨æ¨ç†æ—¶ï¼Œåªç”¨åˆ°ä¸å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„é‚£äº›ä¸“å®¶ã€‚</p>
<p>å½“æˆ‘ä»¬æå‡ºä¸€ä¸ªé—®é¢˜æ—¶ï¼Œå°±ä¼šé€‰æ‹©æœ€é€‚åˆè¯¥ä»»åŠ¡çš„ä¸“å®¶ï¼š</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_170127.png" class="">

<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼šå½“è¾“å…¥æ˜¯ â€œWhat is 1 + 1?â€ è¿™æ ·çš„æ•°å­—ç›¸å…³é—®é¢˜æ—¶ï¼Œè·¯ç”±å™¨åªæ¿€æ´»ä¸æ•°å­—ç›¸å…³çš„ä¸“å®¶ã€‚  </p>
<ol>
<li><strong>è¾“å…¥</strong>ï¼šä¸€ä¸ªè¡¨ç¤ºç®—æœ¯é—®é¢˜çš„å¥å­æˆ– tokenã€‚  </li>
<li><strong>ä¸“å®¶é€‰æ‹©</strong>ï¼šåªæ¿€æ´» â€œNumbersâ€ é¢†åŸŸçš„ä¸“å®¶ã€‚  </li>
<li><strong>è¾“å‡º</strong>ï¼šä¸“å®¶ç»™å‡ºç»“æœ â€œ2â€ã€‚</li>
</ol>
<h3 id="What-does-an-Expert-Learn"><a href="#What-does-an-Expert-Learn" class="headerlink" title="What does an Expert Learn?"></a>What does an Expert Learn?</h3><p>æ­£å¦‚å‰é¢æ‰€æåˆ°çš„ï¼Œä¸“å®¶ï¼ˆ<strong>Experts</strong>ï¼‰å¾€å¾€å­¦ä¹ åˆ°æ¯”æ•´ä¸ªé¢†åŸŸæ›´ç»†è‡´çš„çŸ¥è¯†ã€‚æœ‰äººä¼šè§‰å¾—ç§°å®ƒä»¬ä¸ºâ€œä¸“å®¶â€å¯èƒ½ä¼šå¸¦æ¥è¯¯è§£ï¼Œä½†è¿™æ˜¯å› ä¸ºæ¯ä¸ªä¸“å®¶å¾€å¾€åªä¸“æ³¨äºæŸäº›ç‰¹å®šç±»å‹çš„è¾“å…¥ç‰¹å¾æˆ–ä¸Šä¸‹æ–‡ã€‚</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_170229.png" class="">

<p><strong>å›¾ç¤ºå†…å®¹</strong>ï¼šå±•ç¤ºäº†ä¸€ä¸ªè¡¨æ ¼æˆ–å¯¹ç…§ï¼Œè¯´æ˜åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¸åŒçš„ä¸“å®¶å¯èƒ½å­¦ä¹ åˆ°ä¸åŒçš„ç‰¹å¾ï¼ˆæ¯”å¦‚æ ‡ç‚¹ç¬¦å·ã€åŠ¨è¯ã€æ•°å­—ç­‰ï¼‰ã€‚  </p>
<ol>
<li><strong>ç¤ºä¾‹åŒ–ä¸“å®¶</strong>ï¼šPunctuationã€Conjunctionsã€Verbsã€Numbers ç­‰ã€‚  </li>
<li><strong>åˆ†å±‚ä½ç½®</strong>ï¼šä¸åŒä¸“å®¶å¯èƒ½å‡ºç°åœ¨æ¨¡å‹çš„ä¸åŒå±‚ã€‚  </li>
<li><strong>åˆ†é…</strong>ï¼šæŸäº› token ä¼šè·¯ç”±åˆ°æŸäº›ä¸“å®¶ï¼Œä»¥è·å¾—æ›´æœ‰æ•ˆçš„å¤„ç†ã€‚</li>
</ol>
<p>åœ¨ <strong>decoder</strong> æ¨¡å‹ä¸­ï¼Œä¸“å®¶ä¹‹é—´å¯èƒ½æ²¡æœ‰é‚£ä¹ˆæ˜æ˜¾çš„é¢†åŸŸåˆ†å·¥ã€‚ç„¶è€Œï¼Œè¿™å¹¶ä¸æ„å‘³ç€æ‰€æœ‰ä¸“å®¶éƒ½å®Œå…¨ç›¸åŒã€‚<br>åœ¨ <strong>Mixtral 8x7B</strong> è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæœ‰ä¸€ä¸ªå¾ˆå¥½çš„ç¤ºä¾‹ï¼šæ¯ä¸ª token ä¼šè¢«æ ‡è®°ä¸ºå…¶é¦–é€‰ä¸“å®¶ï¼Œè¿™äº›ä¸“å®¶å¹¶ä¸ä¸€å®šå¯¹åº”ç›´è§‚çš„è¯­ä¹‰é¢†åŸŸï¼Œä½†åœ¨ç»Ÿè®¡ä¸Šè¡¨ç°å‡ºæŸäº›å€¾å‘ã€‚</p>
<img src="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/20250224_182219.png" class="">
<p>è¿™å¼ å¯è§†åŒ–ç¤ºä¾‹è¿˜å±•ç¤ºäº†ï¼Œexpertsï¼ˆä¸“å®¶ï¼‰æ›´å€¾å‘äºå…³æ³¨å¥æ³•ï¼ˆsyntaxï¼‰ï¼Œè€Œä¸æ˜¯ç‰¹å®šçš„é¢†åŸŸï¼ˆdomainï¼‰ã€‚å› æ­¤ï¼Œè™½ç„¶ decoder expertsï¼ˆè§£ç å™¨ä¸“å®¶ï¼‰ä¼¼ä¹å¹¶æ²¡æœ‰æ˜ç¡®çš„â€œä¸“ä¸šé¢†åŸŸï¼ˆspecialismï¼‰â€ï¼Œä½†å®ƒä»¬ä¼¼ä¹ä¼šåœ¨æŸäº›ç‰¹å®šç±»å‹çš„ tokensï¼ˆæ ‡è®°ï¼‰ä¸Šè¢«æŒç»­åœ°ä½¿ç”¨ã€‚</p>
<p>åœ¨[å›¾1]ä¸­ï¼Œå±•ç¤ºäº†ä¸€æ®µå…³äº MoELayer çš„ç¤ºä¾‹ä»£ç æˆ–å¯è§†åŒ–ç»“æœï¼Œè‰²å—åŒºåˆ†äº†ä¸åŒéƒ¨åˆ†ï¼Œå¼ºè°ƒäº†<strong>ä¸“å®¶ï¼ˆexpertsï¼‰ä¸è·¯ç”±å™¨ï¼ˆrouterï¼‰</strong>ä¹‹é—´çš„å…³ç³»ã€‚é€šè¿‡è‰²å—å¯ä»¥çœ‹å‡ºï¼š</p>
<ul>
<li>experts åˆ—è¡¨ï¼ˆåœ¨ä»£ç ä¸­ç”¨ nn.ModuleList è¡¨ç¤ºï¼‰åŒ…å«äº†å¤šä¸ªå­ç½‘ç»œï¼ˆå³å¤šä¸ª FFNNï¼ŒFeed-Forward Neural Networkï¼Œå‰é¦ˆç¥ç»ç½‘ç»œï¼‰ã€‚</li>
<li>gateï¼ˆé—¨æ§ç½‘ç»œï¼Œä¹Ÿç§° routerï¼‰è´Ÿè´£é€‰æ‹©å“ªäº›ä¸“å®¶ä¼šè¢«æ¿€æ´»ã€‚</li>
<li>æ•´ä½“ä¸Šå¯ä»¥çœ‹åˆ°ï¼Œè¿™äº›ä¸“å®¶é€šå¸¸å…³æ³¨åˆ°è¾“å…¥å¥å­çš„å¥æ³•å±‚é¢ï¼Œè€Œéç‰¹å®šä¸»é¢˜æˆ–é¢†åŸŸã€‚</li>
</ul>
<h3 id="ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture-of-Expertsï¼‰"><a href="#ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture-of-Expertsï¼‰" class="headerlink" title="ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰"></a>ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰</h3></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="https://chenhuiyu.github.io">Huiyu Chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/">https://chenhuiyu.github.io/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº <a href="https://chenhuiyu.github.io" target="_blank">é»‘å¤´å‘†é±¼è¿›åŒ–ä¹‹æ—…</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2.zh-CN/" title="MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">ä¸Šä¸€ç¯‡</div><div class="info-item-2">MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</div></div><div class="info-2"><div class="info-item-1">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²åŸæ–‡åœ°å€ï¼šA Visual Guide to Mixture of Experts (MoE) ğŸ“… ä½œè€…ï¼šMaarten Grootendorst ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥  æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—ç›®å½• MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰² æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å— ç›®å½• ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ Experts Dense Layers Sparse Layers What does an Expert Learn? ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰      å½“æˆ‘ä»¬æŸ¥çœ‹æœ€æ–°å‘å¸ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼ŒLarge Language Modelsï¼‰æ—¶ï¼Œå¸¸å¸¸ä¼šåœ¨æ ‡é¢˜ä¸­çœ‹åˆ° â€œMoEâ€ã€‚è¿™ä¸ª â€œMoEâ€ ä»£è¡¨ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¿™ä¹ˆå¤š LLM éƒ½åœ¨ä½¿ç”¨å®ƒï¼Ÿ åœ¨è¿™ä»½å¯è§†åŒ–æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ 50 å¤šä¸ªå¯è§†åŒ–å›¾ç¤ºï¼Œé€æ­¥æ¢ç´¢è¿™ä¸€å…³é”®ç»„ä»¶ï¼š**Mixture of Experts (MoE)**ã€‚   å›¾ç¤ºå†…...</div></div></div></a><a class="pagination-related" href="/2025/02/11/NLP%20Insights/MoE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98%20MoE%20%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2.en/" title="MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">ä¸‹ä¸€ç¯‡</div><div class="info-item-2">MoEæ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</div></div><div class="info-2"><div class="info-item-1">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²åŸæ–‡åœ°å€ï¼šA Visual Guide to Mixture of Experts (MoE) ğŸ“… ä½œè€…ï¼šMaarten Grootendorst ğŸ“† æ—¥æœŸï¼š2024 å¹´ 10 æœˆ 7 æ—¥  æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—ç›®å½• MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰² æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å— ç›®å½• ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ Experts Dense Layers Sparse Layers What does an Expert Learn? ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰      å½“æˆ‘ä»¬æŸ¥çœ‹æœ€æ–°å‘å¸ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼ŒLarge Language Modelsï¼‰æ—¶ï¼Œå¸¸å¸¸ä¼šåœ¨æ ‡é¢˜ä¸­çœ‹åˆ° â€œMoEâ€ã€‚è¿™ä¸ª â€œMoEâ€ ä»£è¡¨ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¿™ä¹ˆå¤š LLM éƒ½åœ¨ä½¿ç”¨å®ƒï¼Ÿ åœ¨è¿™ä»½å¯è§†åŒ–æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ 50 å¤šä¸ªå¯è§†åŒ–å›¾ç¤ºï¼Œé€æ­¥æ¢ç´¢è¿™ä¸€å…³é”®ç»„ä»¶ï¼š**Mixture of Experts (MoE)**ã€‚   å›¾ç¤ºå†…...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/02/27/NLP%20Insights/FastChat%20Training%20Script%20Code%20Analysis%20-%20Train.py%20%E3%80%90FastChat%20Series%20Part%201%E3%80%91.en/" title="FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-27</div><div class="info-item-2">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘</div></div><div class="info-2"><div class="info-item-1">FastChat Training Script Code Analysis - Train.py ã€FastChat Series Part 1ã€‘In this article, we delve into the train.py script of FastChat (https://github.com/lm-sys/FastChat) (https://github.com/lm-sys/FastChat/blob/main/fastchat/train/train.py), a key component for training and optimizing large language models (LLMs). FastChat is an advanced open-source platform focused on developing, deploying, and evaluating chatbots based on LLMs. The platform not only supports top-tier models like Vicuna ...</div></div></div></a><a class="pagination-related" href="/2025/03/06/NLP%20Insights/Differences%20in%20Padding%20Strategies%20Between%20Decoder-only%20and%20Encoder-only%20Models/" title="Differences in Padding Strategies Between Decoder-only and Encoder-only Models"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-06</div><div class="info-item-2">Differences in Padding Strategies Between Decoder-only and Encoder-only Models</div></div><div class="info-2"><div class="info-item-1">ğŸ“Œ What is Padding?In Large Language Models (LLMs), padding is a method used to standardize sequence lengths for batch processing. For example: 12Sentence 1: "I love NLP"Sentence 2: "Padding is useful in LLM training"  Using the &lt;pad&gt; token for alignment: 12"I love NLP &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;""Padding is useful in LLM training"   ğŸ“Œ Padding Positioning: Left vs RightThere are two common padding strategies:  Right padding: 1"I love NLP &lt;pad&gt; &lt;pad&gt;"  Left padding: ...</div></div></div></a><a class="pagination-related" href="/2024/02/19/NLP%20Insights/Understanding%20the%20Differences%20Between%20Fine-tuning%20and%20Further%20Pretraining%20in%20Large%20Language%20Models/" title="Understanding the Differences Between Fine-tuning and Further Pretraining in Large Language Models"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-19</div><div class="info-item-2">Understanding the Differences Between Fine-tuning and Further Pretraining in Large Language Models</div></div><div class="info-2"><div class="info-item-1">Understanding the Differences Between Fine-tuning and Further Pretraining in Large Language ModelsIn the world of Natural Language Processing (NLP), the advent of large language models like GPT and BERT has revolutionized how we approach tasks such as text classification, sentiment analysis, and question-answering. Two pivotal techniques in leveraging these models are Fine-tuning and Further Pretraining. While they may seem similar at a glance, they cater to different needs and scenarios in t...</div></div></div></a><a class="pagination-related" href="/2024/02/19/NLP%20Insights/%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%ADFine-tuning%E5%92%8CFurther%20Pretraining%E7%9A%84%E5%8C%BA%E5%88%AB.zh-CN/" title="ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ä¸­Fine-tuningå’ŒFurther Pretrainingçš„åŒºåˆ«"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-19</div><div class="info-item-2">ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ä¸­Fine-tuningå’ŒFurther Pretrainingçš„åŒºåˆ«</div></div><div class="info-2"><div class="info-item-1">ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ Fine-tuning å’Œ Further Pretraining çš„åŒºåˆ«åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¦‚ GPT å’Œ BERT çš„å‡ºç°ï¼Œå½»åº•æ”¹å˜äº†æˆ‘ä»¬å¤„ç†æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æå’Œé—®ç­”ç­‰ä»»åŠ¡çš„æ–¹å¼ã€‚åœ¨è¿™äº›æ¨¡å‹çš„åº”ç”¨ä¸­ï¼ŒFine-tuningï¼ˆå¾®è°ƒï¼‰å’Œ Further Pretrainingï¼ˆè¿›ä¸€æ­¥é¢„è®­ç»ƒï¼‰æ˜¯ä¸¤ç§å…³é”®æŠ€æœ¯ã€‚è™½ç„¶å®ƒä»¬çœ‹èµ·æ¥ç›¸ä¼¼ï¼Œä½†å®é™…ä¸ŠæœåŠ¡äº NLP æµç¨‹ä¸­çš„ä¸åŒéœ€æ±‚å’Œåœºæ™¯ã€‚ ä»€ä¹ˆæ˜¯ Fine-tuningï¼ŸFine-tuning æ˜¯æŒ‡åœ¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒï¼ˆæˆ–â€œå¾®è°ƒâ€ï¼‰ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ¨¡å‹çš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•åœ¨æ•°æ®é›†ç›¸å¯¹è¾ƒå°ä½†æ ‡æ³¨è‰¯å¥½çš„æƒ…å†µä¸‹ç‰¹åˆ«æœ‰æ•ˆã€‚ ç¤ºä¾‹åœºæ™¯ï¼šæƒ…æ„Ÿåˆ†æå‡è®¾ä½ æœ‰ä¸€ç»„ç”µå½±è¯„è®ºæ•°æ®ï¼Œæ¯æ¡è¯„è®ºéƒ½æ ‡è®°äº†æ­£é¢æˆ–è´Ÿé¢æƒ…æ„Ÿã€‚ä½ æƒ³åˆ›å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹è¯„è®ºçš„æƒ…æ„Ÿã€‚ Python ä»£ç ç¤ºä¾‹ï¼ˆä½¿ç”¨ PyTorch å’Œ HuggingFace çš„ Transformersï¼‰This notebook demonstrates the fine-tuning of a BERT model on the IMDB dataset for sen...</div></div></div></a><a class="pagination-related" href="/2024/10/23/NLP%20Insights/Introduction%20to%20LLM%20Training%20Terminology:%20LoRA,%20DPO,%20KTO,%20and%20SFT%20Technologies.zh-CN/" title="Detailed Explanation of LoRA, DPO, KTO, and SFT Technologies"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-23</div><div class="info-item-2">Detailed Explanation of LoRA, DPO, KTO, and SFT Technologies</div></div><div class="info-2"><div class="info-item-1">Introduction to LLM Training Terminology:LoRA, DPO, KTO, and SFT TechnologiesThis document provides a detailed introduction to several important techniques used in fine-tuning and optimizing large language models (such as LLAMA3), including SFT (Supervised Fine-Tuning), LoRA (Low-Rank Adaptation), Alignment technologies, KTO (Kahneman-Tversky Optimization), and DPO (Direct Preference Optimization). The document also elaborates on the principles of each technique, specific implementation metho...</div></div></div></a><a class="pagination-related" href="/2024/02/28/NLP%20Insights/Gorilla:%20Large%20Language%20Model%20Connected%20with%20Massive%20APIs.zh-CN/" title="Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-28</div><div class="info-item-2">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹</div></div><div class="info-2"><div class="info-item-1">Gorilla LLM å¤§è¯­è¨€æ¨¡å‹ç®€ä»‹ğŸ¦ Gorilla: Large Language Model Connected with Massive APIsLink: https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html  Berkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œBerkeley åŠŸèƒ½è°ƒç”¨æ’è¡Œæ¦œ åœ¨çº¿ä½“éªŒæ¨¡å‹ï¼šGorilla OpenFunctions-v2 ç½‘ç»œæ¼”ç¤º é¡¹ç›®è¯¦æƒ…ï¼šGitHub æ¨¡å‹ï¼ˆ7B å‚æ•°ï¼‰åœ¨ HuggingFace ä¸Šçš„é¡µé¢ï¼šgorilla-llm/gorilla-openfunctions-v2  1. ä¼¯å…‹åˆ©å‡½æ•°è°ƒç”¨æ’è¡Œæ¦œè‡ª 2022 å¹´åº•ä»¥æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‡­å€Ÿå…¶æ‰§è¡Œé€šç”¨ä»»åŠ¡çš„å¼ºå¤§èƒ½åŠ›ï¼Œæˆä¸ºä¼—äººå…³æ³¨çš„ç„¦ç‚¹ã€‚ä¸ä»…é™äºèŠå¤©åº”ç”¨ï¼Œå°†è¿™äº›æ¨¡å‹åº”ç”¨äºå¼€å‘å„ç±» AI åº”ç”¨å’Œè½¯ä»¶ï¼ˆå¦‚ Langchain, Llama Index, AutoGPT, Voyagerï¼‰å·²æˆä¸ºä¸€ç§è¶‹åŠ¿ã€‚GPT, Gemini, Llama, Mistral ç­‰æ¨¡å‹é€šè¿‡ä¸å¤–éƒ¨ä¸–ç•Œçš„äº¤äº’ï¼Œå¦‚å‡½æ•°è°ƒç”¨å’Œæ‰§è¡Œï¼Œå±•ç°äº†å…¶å·¨å¤§...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Huiyu Chen</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">186</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MoE-%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97%EF%BC%9A%E6%8F%AD%E7%A7%98-MoE-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2"><span class="toc-number">1.</span> <span class="toc-text">MoE æ¨¡å‹çš„çš„å¯è§†åŒ–æŒ‡å—ï¼šæ­ç§˜ MoE åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§’è‰²</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%A2%E7%B4%A2%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B%EF%BC%88MoE%EF%BC%89%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97"><span class="toc-number">2.</span> <span class="toc-text">æ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šæ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰å¯è§†åŒ–æŒ‡å—</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E5%BD%95"><span class="toc-number">2.1.</span> <span class="toc-text">ç›®å½•</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88MoE%EF%BC%89%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Ÿ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Experts"><span class="toc-number">2.3.</span> <span class="toc-text">Experts</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Dense-Layers"><span class="toc-number">2.3.1.</span> <span class="toc-text">Dense Layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sparse-Layers"><span class="toc-number">2.3.2.</span> <span class="toc-text">Sparse Layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What-does-an-Expert-Learn"><span class="toc-number">2.3.3.</span> <span class="toc-text">What does an Expert Learn?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%93%E5%AE%B6%E7%9A%84%E6%9E%B6%E6%9E%84%EF%BC%88Architecture-of-Experts%EF%BC%89"><span class="toc-number">2.3.4.</span> <span class="toc-text">ä¸“å®¶çš„æ¶æ„ï¼ˆArchitecture of Expertsï¼‰</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment.en/" title="æ— æ ‡é¢˜">æ— æ ‡é¢˜</a><time datetime="2026-02-20T21:47:32.623Z" title="å‘è¡¨äº 2026-02-21 05:47:32">2026-02-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment.zh-CN/" title="æ— æ ‡é¢˜">æ— æ ‡é¢˜</a><time datetime="2026-02-20T21:47:32.623Z" title="å‘è¡¨äº 2026-02-21 05:47:32">2026-02-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/21/NLP%20Insights/Evaluation%20of%20Generation-Based%20Large%20Language%20Models%20(LLMs):%20Opportunities%20and%20Challenges%20from%20Generation%20to%20Judgment/" title="æ— æ ‡é¢˜">æ— æ ‡é¢˜</a><time datetime="2026-02-20T21:46:38.687Z" title="å‘è¡¨äº 2026-02-21 05:46:38">2026-02-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI.en/" title="SeCom: Redefining Memory Management in Conversational AI">SeCom: Redefining Memory Management in Conversational AI</a><time datetime="2025-06-24T08:00:00.000Z" title="å‘è¡¨äº 2025-06-24 16:00:00">2025-06-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/24/NLP%20Insights/SeCom%20Redefining%20Memory%20Management%20in%20Conversational%20AI/" title="SeCom: Redefining Memory Management in Conversational AI">SeCom: Redefining Memory Management in Conversational AI</a><time datetime="2025-06-24T08:00:00.000Z" title="å‘è¡¨äº 2025-06-24 16:00:00">2025-06-24</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Huiyu Chen</span><span class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 6.3.0</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.4</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="æ—¥é—´å’Œå¤œé—´æ¨¡å¼åˆ‡æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><div class="js-pjax"></div><script src="/js/lang-switch.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>